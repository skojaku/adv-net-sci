[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Preface\nWelcome to Advanced Topics in Network Science! This book provides a comprehensive introduction to the mathematical foundations and computational methods for analyzing complex networks.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "Advanced Topics in Network Science",
    "section": "About This Book",
    "text": "About This Book\nThis interactive textbook covers advanced topics in network science, including:\n\nNetwork structure and topology\nRandom walks and diffusion processes\n\nCommunity detection and clustering\nNetwork centrality measures\nGraph embeddings and neural networks\nRobustness and percolation\n\nEach module combines theoretical foundations with hands-on computational exercises using Python and popular network analysis libraries.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Advanced Topics in Network Science",
    "section": "Getting Started",
    "text": "Getting Started\nTo get the most out of this book, you should have:\n\nBasic knowledge of Python programming\nFamiliarity with linear algebra and probability\nUnderstanding of graph theory fundamentals",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#interactive-features",
    "href": "index.html#interactive-features",
    "title": "Advanced Topics in Network Science",
    "section": "Interactive Features",
    "text": "Interactive Features\nThis Quarto book includes:\n\nCode folding: Click to show/hide code blocks\nCopy code: Hover over code blocks to copy\nLive computation: All examples use real data and can be executed\nSearch: Use the search box to find specific topics",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Advanced Topics in Network Science",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis material was developed for the Advanced Topics in Network Science course. Special thanks to all contributors and students who helped improve this content.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro/why-networks.html",
    "href": "intro/why-networks.html",
    "title": "1¬† Networks",
    "section": "",
    "text": "1.1 Networks are everywhere and they matter\nIn 2009, the H1N1 influenza pandemic started in Mexico and spread around the world. Dirk Brockmann and Dirk Helbing tracked how the disease reached different countries and made a surprising discovery that would revolutionize how we understand spreading processes.\nThe most natural way to think about disease spread is through geographic distance. If you looked at a traditional world map, you might expect the disease to spread in expanding circles - first to nearby countries like Guatemala and the United States, then gradually to more distant places. But look at what the data actually shows:\nDistance does explain the arrival time to some extent - there‚Äôs a rough trend where farther places tend to be infected later (C, D, E). But it doesn‚Äôt tell the whole story. At the same distances, some cities experienced early arrival while others experienced much later arrival. What explains this variation?\nThis mystery was solved by Dirk Brockmann and his colleagues, who realized that disease spread follows the hidden geometry of mobility networks - not geographic maps. Air travel connections, not physical distance, determined how quickly the pandemic reached different parts of the world.\nThe H1N1 example above reveals a fundamental truth: network structure determines how things spread. Geographic distance became irrelevant once we understood the underlying mobility network. This principle extends far beyond disease outbreaks.\nNetworks are everywhere. Look around you: plants depend on pollinators in ecological networks, predators and prey form intricate food webs, your brain operates through neural networks, and modern medicine maps drug interactions. At the molecular level, proteins interact in complex networks that sustain life. Socially, we‚Äôre connected through friendship networks, while globally, financial institutions form interconnected webs that can trigger worldwide crises. Every flight you take follows airport networks, every light switch connects to power grids, and every river flows through branching networks to the sea. Even the internet connecting you to this text and the knowledge graphs organizing human understanding - all are networks.",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Networks</span>"
    ]
  },
  {
    "objectID": "intro/why-networks.html#networks-are-everywhere-and-they-matter",
    "href": "intro/why-networks.html#networks-are-everywhere-and-they-matter",
    "title": "1¬† Networks",
    "section": "",
    "text": "Figure¬†1.1: Geographic distance shows only weak correlation with disease arrival times for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†1.2: Effective distance (based on mobility networks) shows strong correlation with disease arrival times (R¬≤ = 0.973) for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\n\n\nSee (brockmann2013hidden?) for more details.\n\n\n\n\n\n\n\n\nPlant pollinator network\n\n\n\n\n\n\n\nFood web\n\n\n\n\n\n\n\nBrain network\n\n\n\n\n\n\n\n\n\nMedicine network\n\n\n\n\n\n\n\nProtein-protein interaction\n\n\n\n\n\n\n\nSocial network\n\n\n\n\n\n\n\n\n\nInternational financial network\n\n\n\n\n\n\n\nUS airport network\n\n\n\n\n\n\n\nPower grid network\n\n\n\n\n\n\n\n\n\nRiver network\n\n\n\n\n\n\n\nInternet network\n\n\n\n\n\n\n\nKnowledge graph",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Networks</span>"
    ]
  },
  {
    "objectID": "intro/why-networks.html#how-to-represent-a-network",
    "href": "intro/why-networks.html#how-to-represent-a-network",
    "title": "1¬† Networks",
    "section": "1.2 How to represent a network",
    "text": "1.2 How to represent a network\nAlthough networks come from vastly different fields, we can represent them all using the same universal language üòâ. Whether we‚Äôre studying brain connections, protein interactions, or social relationships, the mathematical representation remains identical. This abstraction is what makes network science so interdisciplinary.\nA network is simply a collection of nodes connected by edges. Despite this simplicity, it‚Äôs one of the most powerful abstractions we have for understanding complex systems.\nWe can represent any network in two equivalent ways. Schematically, we draw them as dots and lines - nodes connected by edges, as shown in this network diagram:\n\n\n\n\n\n\nSchematic network\n\n\n\n\n\n\n\nA network of penguins in the Kyoto Aquarium.\n\n\n\n\n\nWhile the schematic representation is useful, things can get complicated as soon as the network becomes large. Also, we want to represent data quantitatively to obtain a quantitative understanding of network properties and behaviors.\nTables are a natural way to represent networks. The idea is to list the pairs of nodes that are connected by an edge. For example:\n\n\n\nSource\nTarget\n\n\n\n\nNode1\nNode2\n\n\nNode1\nNode3\n\n\nNode2\nNode3\n\n\nNode2\nNode4\n\n\nNode3\nNode5\n\n\n\nThis is called an edge table. Each row represents a connection between two nodes. Once we write down networks in this tabular format, we can apply the same analytical tools regardless of the domain - whether it‚Äôs routers, people, neurons, or molecules.",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Networks</span>"
    ]
  },
  {
    "objectID": "intro/why-networks.html#why-networks-are-hard-to-understand",
    "href": "intro/why-networks.html#why-networks-are-hard-to-understand",
    "title": "1¬† Networks",
    "section": "1.3 Why networks are hard to understand",
    "text": "1.3 Why networks are hard to understand\nIf we can represent a network in a table‚Äîa familiar data format that can be analyzed by statistical methods, machine learning, and other tools‚Äîaren‚Äôt we done?\nIn a nutshell, the answer is no. A network is not just a collection of nodes and edges. They work in tandem to create a complex system. And this view‚Äîthat a system is not just a collection of parts‚Äîrepresents a critical shift in science. For centuries, scientists believed in a reductionist approach. If you could create modules that function like duck organs and assemble them together, the machine would eventually behave like a duck. Vaucanson‚Äôs 18th century Digesting Duck seemed to prove this approach worked remarkably well: break down complex systems into fundamental components, understand each part, then reassemble them to understand the whole.\n\n\n\n\n\nVaucanson‚Äôs Digesting Duck\n\n\nFind more details in Wikipedia\nHowever, scientists began to realize that not all systems can be decomposed into units that provide sufficient understanding of the system as a whole. Networks represent a fundamental challenge to reductionist thinking because their most important properties emerge from the interactions between components, not from the components themselves. You can understand every individual neuron in the brain, but this won‚Äôt tell you how consciousness emerges. You can analyze every person in a social movement, but this won‚Äôt predict how ideas spread through the population. You can study every computer on the internet, but this won‚Äôt explain how global information patterns form.\nThe difficulty lies not in the individual nodes or edges, but in how they combine to create system-level behaviors that are genuinely novel. Scale overwhelms intuition; while you can mentally track relationships between three people, the same intuition fails completely with three million. Small changes can have massive consequences; removing one connection might fragment an entire network, while removing another has no effect at all. This is why network science exists as a distinct field: the traditional reductionist toolkit simply isn‚Äôt sufficient for understanding interconnected systems where the connections themselves are the source of complexity!",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Networks</span>"
    ]
  },
  {
    "objectID": "intro/zoo-of-networks.html",
    "href": "intro/zoo-of-networks.html",
    "title": "2¬† Zoo of networks",
    "section": "",
    "text": "Plant pollinator network\n\n\n\n\n\nFood web\n\n\n\n\n\nBrain network\n\n\n\n\n\nNetwork of medicine\n\n\n\n\n\nProtein-protein interaction\n\n\n\n\n\nSocial network\n\n\n\n\n\nInternational financial network\n\n\n\n\n\nUS airport network\n\n\n\n\n\nPower grid network\n\n\n\n\n\nNetwork of rivers\n\n\n\n\n\nInternet\n\n\n\n\n\nKnowledge graph\n\n\n\n\n\nFlavor Network\n\n\n\n\n\nFlavor Network\n\n\n\n\n\nCitation Cartels\n\n\n\n\n\nCitation Cartels\n\n\n\n\n\nVirus spreading network",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Zoo of networks</span>"
    ]
  },
  {
    "objectID": "intro/setup.html",
    "href": "intro/setup.html",
    "title": "3¬† Setup",
    "section": "",
    "text": "3.1 Python\nWe‚Äôll use Python to work with data throughout this course. Python is an excellent choice for network science for several reasons:\nRich ecosystem of libraries: Python has an extensive collection of libraries that we can use immediately without building everything from scratch. For network analysis, we have NetworkX for general network manipulation, igraph for high-performance computations, and graph-tool for large-scale analysis. For data work, we have pandas for data manipulation, numpy for numerical computing, and matplotlib/seaborn for visualization.\nReadable and intuitive: Python code reads almost like English, making it easy to understand what the code does. For example, G.add_node(\"Alice\") clearly adds a node named ‚ÄúAlice‚Äù to a graph G. This readability comes from Python‚Äôs strict rules on indentation - the language enforces consistent formatting by requiring proper indentation to define code blocks, which eliminates the visual clutter of brackets and forces code to be well-structured and easy to follow.\nWell-documented: Python is one of the most well-documented programming languages, with comprehensive official documentation, extensive community resources, and clear examples for every library we‚Äôll use.\nEasy to learn: The combination of readable syntax and extensive documentation makes Python accessible to both beginners and experts. You can focus on understanding network concepts rather than wrestling with complex programming syntax.\nYou‚Äôll need Python 3.8 or higher. We recommend using the latest stable version of Python.\nIf you don‚Äôt have Python installed: - Windows/Mac: Download from python.org - Linux: Use your package manager (e.g., sudo apt install python3)\nInstall the required packages using pip:",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "intro/setup.html#python",
    "href": "intro/setup.html#python",
    "title": "3¬† Setup",
    "section": "",
    "text": "pip install numpy pandas matplotlib seaborn networkx igraph-python graph-tool scikit-learn marimo\n\n3.1.1 Trouble shooting with Google Colab\nGoogle Colab has many packages pre-installed. However, they do not include some packages for network analysis like igraph and graph-tool.\nInstalling igraph Create a cell on top of the notebook and run the following code to install the igraph:\n!sudo apt install libcairo2-dev pkg-config python3-dev\n!pip install pycairo cairocffi\n!pip install igraph\nInstalling graph-tool Create a cell on top of the notebook and run the following code to install the graph-tool:\n!wget https://downloads.skewed.de/skewed-keyring/skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n!dpkg -i skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n!echo \"deb [signed-by=/usr/share/keyrings/skewed-keyring.gpg] https://downloads.skewed.de/apt $(lsb_release -s -c) main\" &gt; /etc/apt/sources.list.d/skewed.list\n!apt-get update\n!apt-get install python3-graph-tool python3-matplotlib python3-cairo\n\n# Colab uses a Python install that deviates from the system's! Bad colab! We need some workarounds.\n!apt purge python3-cairo\n!apt install libcairo2-dev pkg-config python3-dev\n!pip install --force-reinstall pycairo\n!pip install zstandar",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "intro/setup.html#marimo-notebook",
    "href": "intro/setup.html#marimo-notebook",
    "title": "3¬† Setup",
    "section": "3.2 Marimo Notebook",
    "text": "3.2 Marimo Notebook\nWe‚Äôll use Marimo notebooks for assignments and interactive exercises throughout the course. Marimo is a reactive Python notebook that automatically updates when you change code, making it perfect for exploring network data and seeing results in real-time.\n\n3.2.1 Installation\nInstall marimo using pip:\npip install marimo\n\n\n3.2.2 Running Marimo\nTo start a new marimo notebook:\nmarimo edit\nTo open an existing marimo notebook:\nmarimo edit notebook.py\n\n\n3.2.3 Key Features\n\nReactive: Cells automatically re-run when their dependencies change\nVersion control friendly: Notebooks are stored as Python files\nInteractive widgets: Built-in support for sliders, dropdowns, and other UI elements",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "intro/setup.html#vs-code",
    "href": "intro/setup.html#vs-code",
    "title": "3¬† Setup",
    "section": "3.3 VS Code",
    "text": "3.3 VS Code\nVisual Studio Code is our recommended code editor for this course. It provides excellent Python support, integrated debugging, and extensions that make working with network data and Marimo notebooks more efficient.\n\n3.3.1 Installation\nDownload and install VS Code from code.visualstudio.com\n\n\n3.3.2 Recommended Extensions\nInstall these extensions for the best Python development experience:\n\nPython (Microsoft): Python language support\nJupyter (Microsoft): Jupyter notebook support\nPython Docstring Generator: Auto-generate docstrings\nGitLens: Enhanced Git capabilities\nMarimo (marimo-team): Marimo notebook support\n\n\n\n3.3.3 Configuration\nCreate a .vscode/settings.json file in your project root with:\n{\n    \"python.defaultInterpreterPath\": \"python3\",\n    \"python.linting.enabled\": true,\n    \"python.linting.pylintEnabled\": true,\n    \"python.formatting.provider\": \"black\"\n}",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "intro/setup.html#github",
    "href": "intro/setup.html#github",
    "title": "3¬† Setup",
    "section": "3.4 Github",
    "text": "3.4 Github\nWe‚Äôll use GitHub for assignments in this course. GitHub provides version control for your code and a platform for submitting and reviewing your work. You‚Äôll create repositories, commit your solutions, and share them for evaluation.\n\n3.4.1 Creating a Github Account\n\nGo to github.com\nClick ‚ÄúSign up‚Äù\nFollow the registration process\n\n\n\n3.4.2 Setting up Git\nConfigure your Git identity:\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n\n\n3.4.3 SSH Key Setup (Recommended)\n\nGenerate an SSH key:\n\nssh-keygen -t ed25519 -C \"your.email@example.com\"\n\nAdd the key to your SSH agent:\n\nssh-add ~/.ssh/id_ed25519\n\nCopy the public key:\n\ncat ~/.ssh/id_ed25519.pub\n\nAdd the key to your Github account under Settings &gt; SSH and GPG keys\n\n\n\n3.4.4 Basic Git Workflow\n# Clone a repository\ngit clone git@github.com:username/repository.git\n\n# Check status\ngit status\n\n# Add changes\ngit add .\n\n# Commit changes\ngit commit -m \"Your commit message\"\n\n# Push changes\ngit push origin main",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/00-preparation.html",
    "href": "m01-euler_tour/00-preparation.html",
    "title": "4¬† Preparation: Python and Graph Basics",
    "section": "",
    "text": "4.1 Python Essentials\nBefore diving into the Euler Tour problem, let‚Äôs establish the foundational knowledge you‚Äôll need.",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Preparation: Python and Graph Basics</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/00-preparation.html#python-essentials",
    "href": "m01-euler_tour/00-preparation.html#python-essentials",
    "title": "4¬† Preparation: Python and Graph Basics",
    "section": "",
    "text": "4.1.1 Data Structures\nFor graph algorithms, you‚Äôll frequently use: - Lists: For storing sequences of nodes or edges - Dictionaries: For adjacency lists and node mappings - Sets: For tracking visited nodes and unique elements\n# Basic data structures for graphs\nnodes = [1, 2, 3, 4]\nedges = [(1, 2), (2, 3), (3, 4), (4, 1)]\nadjacency_dict = {1: [2, 4], 2: [1, 3], 3: [2, 4], 4: [3, 1]}\nvisited = set()\n\n\n4.1.2 Essential Libraries\n\nNetworkX: Python library for graph creation and analysis\nNumPy: For numerical operations and matrix representations\nMatplotlib: For graph visualization\n\nimport networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Preparation: Python and Graph Basics</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/00-preparation.html#graph-theory-fundamentals",
    "href": "m01-euler_tour/00-preparation.html#graph-theory-fundamentals",
    "title": "4¬† Preparation: Python and Graph Basics",
    "section": "4.2 Graph Theory Fundamentals",
    "text": "4.2 Graph Theory Fundamentals\n\n4.2.1 Basic Definitions\n\nGraph: A collection of nodes (vertices) connected by edges\nDirected vs Undirected: Edges have direction or are bidirectional\nDegree: Number of edges connected to a node\nPath: Sequence of connected edges\nCycle: Path that starts and ends at the same node\n\n\n\n4.2.2 Graph Representations\n\n\n4.2.3 Adjacency List\n# Undirected graph representation\ngraph = {\n    'A': ['B', 'D'],\n    'B': ['A', 'C'],\n    'C': ['B', 'D'],\n    'D': ['A', 'C']\n}\n\n\n4.2.4 Adjacency Matrix\n# For a 4-node graph\nadj_matrix = np.array([\n    [0, 1, 0, 1],  # Node A connections\n    [1, 0, 1, 0],  # Node B connections\n    [0, 1, 0, 1],  # Node C connections\n    [1, 0, 1, 0]   # Node D connections\n])\n\n\n4.2.5 NetworkX Basics\n# Creating a graph\nG = nx.Graph()\n\n# Adding nodes and edges\nG.add_nodes_from([1, 2, 3, 4])\nG.add_edges_from([(1, 2), (2, 3), (3, 4), (4, 1)])\n\n# Basic graph properties\nprint(f\"Number of nodes: {G.number_of_nodes()}\")\nprint(f\"Number of edges: {G.number_of_edges()}\")\nprint(f\"Degree of node 1: {G.degree(1)}\")",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Preparation: Python and Graph Basics</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/00-preparation.html#key-concepts-for-euler-tours",
    "href": "m01-euler_tour/00-preparation.html#key-concepts-for-euler-tours",
    "title": "4¬† Preparation: Python and Graph Basics",
    "section": "4.3 Key Concepts for Euler Tours",
    "text": "4.3 Key Concepts for Euler Tours\n\n4.3.1 Euler Path and Euler Circuit\n\nEuler Path: Visits every edge exactly once\nEuler Circuit: Euler path that returns to starting node\nEulerian Graph: Graph that contains an Euler circuit\n\n\n\n4.3.2 Prerequisites\nUnderstanding these concepts will be essential: 1. Node Degree: Foundation for Euler‚Äôs theorem 2. Connected Components: Euler paths exist only in connected graphs 3. Graph Traversal: Basic algorithms like DFS and BFS\nThis preparation will help you understand the mathematical foundations and implement solutions for the famous Seven Bridges of K√∂nigsberg problem that we‚Äôll explore next.",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Preparation: Python and Graph Basics</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html",
    "href": "m01-euler_tour/01-concepts.html",
    "title": "5¬† Euler Tour Concepts",
    "section": "",
    "text": "5.1 What to learn in this module\nIn this module, we will learn a historical example that leads to the genesis of graph theory in mathematics and modern network science. Through this example, we will learn: - How to describe a network using mathematical language - How to code a network in Python - Keywords: network, degree, Euler walk",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Euler Tour Concepts</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#a-puzzle",
    "href": "m01-euler_tour/01-concepts.html#a-puzzle",
    "title": "5¬† Euler Tour Concepts",
    "section": "5.2 A puzzle",
    "text": "5.2 A puzzle\nBack in 18th century, there was a city called K√∂nigsberg situated on the Pregel River in a historical region of Germany. The city had two large islands connected to each other and the mainland by seven bridges. The citizens of K√∂nigsberg pondered a puzzle during their Sunday walks:\n\n\n\n\n\n\nProblem\n\n\n\nHow could one walk through the city and cross each bridge exactly once?\n\n\n\n\n\nThe seven bridges of K√∂nigsberg {#fig-seven-bridges}\n\n\nLeonard Euler worked out the solution to this puzzle in 1736. He first simplified the city into a network of landmasses connected by bridges, by noting that the landareas, the positions of the islands and the bridges are nothing to do with the puzzle, and that the only thing that matters is the connections between the landmasses.\n\n\n\nEuler‚Äôs graph of the bridges of Knigsberg {#fig-euler-graph}\n\n\nTo better understand this problem, you can work through it step by step using this worksheet (Moro 2017) that guides you through the solution process.",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Euler Tour Concepts</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#eulers-solution",
    "href": "m01-euler_tour/01-concepts.html#eulers-solution",
    "title": "5¬† Euler Tour Concepts",
    "section": "5.3 Euler‚Äôs solution",
    "text": "5.3 Euler‚Äôs solution\nEuler consider two cases: - a node has an even number of edges, or - a node has an odd number of edges.\nWhen a node has an even number 2k of edges, one can enter and leave the node k times by crossing different edges.\nWhen a node has an odd number 2k+1 of edges, one can enter and leave the node k times by crossing different edges but leave one last edge to cross. The only way to cross this last edge is that one starts or ends at the node.\nBased up on the above reasoning, Euler leads to the following necessary (and later shown as sufficient) conditions:\n\n\n\n\n\n\nEuler‚Äôs path\n\n\n\nThere exists a walk that crosses all edges exactly once if and only if all nodes have even number of edges, or exactly two nodes have an odd number of edges.\n\n\n\n\n\nalt text\n\n\nBack to the Konigsberg bridge problem, every node has an odd number of edges, meaning that there is no way to cross all edges exactly once. What a sad story for the citizens of Konigsberg. But the problem was solved during World War II, where Koingberg was bombarded by Soviet Union, losing two of the seven bridges ü´†.\n\n\n\nTwo bridges were bombed by Soviet Union, which allows the Euler path to exist. {#fig-markdown-fig}",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Euler Tour Concepts</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#references",
    "href": "m01-euler_tour/01-concepts.html#references",
    "title": "5¬† Euler Tour Concepts",
    "section": "5.4 References",
    "text": "5.4 References\n\n\nMoro, Esteban. 2017. ‚ÄúNetwork Science for Kids!‚Äù http://estebanmoro.org/2017/03/network-science-for-kids.",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Euler Tour Concepts</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html",
    "href": "m01-euler_tour/02-coding.html",
    "title": "6¬† Compute with networks",
    "section": "",
    "text": "6.1 Network representation\nSo far we worked out the network of bridges of Konigsberg by illustrating the network with points and lines. From now, we will work with a representation of the network that can be easily computed with code.\nAn atomic element of a network is a node, i.e., a network is a collection of edges which are pairs of nodes. We label a unique integer as an identifier for each node. For instance, the bridges of Konigsberg has 4 nodes, and we assign the number 0 to 3 to the nodes. An edge can be represented by a pair of nodes. For instance, the edge between node 0 and node 1 can be represented by the pair (0, 1).\n```idzsepktiui numbered-koningsberg-graph\nLabeled Knigsberg graph\n:::\nAnother, more convenient format is the adjacency matrix. In this form, one regard the node index as a coordinate in the matrix. For instance, edge (1,3) is represented by the entry in the second row and fourth column. The entry of the matrix represents the number of edges between two nodes. Thus, the zeros in the matrix represent the absence of edges.\nCode\nA = [[0, 2, 0, 1],\n     [2, 0, 2, 1],\n     [0, 2, 0, 1],\n     [1, 1, 1, 0]]\nor equivalently, using for loops:\nCode\nimport numpy as np\n\nA = np.zeros((4, 4))\nfor i, j in edges:\n    A[i][j] += 1\n    A[j][i] += 1",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Compute with networks</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#network-representation",
    "href": "m01-euler_tour/02-coding.html#network-representation",
    "title": "6¬† Compute with networks",
    "section": "",
    "text": "file\n\n\n\n\n::: {.callout-note}\nWe label nodes starting from 0 with consecutive numbers, which is convenient for Python. However, this is *not the only way* to label nodes.\n:::\n\nThe Konigsberg graph can be represented by a list of edges.\n\n::: {#f42a88ac .cell}\n``` {.python .cell-code}\nedges = [(0,1), (0, 1), (0, 3), (1, 2), (1, 2), (1, 3), (2, 3)]\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the Konigsberg graph, the edges are undirected, meaning edge (i,j) is the same as edge (j,i), which is why we increment both entries (i,j) and (j,i) in the for loop. If the edges are directed, we treat (i,j) and (j,i) as two different edges, and increment only (i,j).",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Compute with networks</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#edge-counting",
    "href": "m01-euler_tour/02-coding.html#edge-counting",
    "title": "6¬† Compute with networks",
    "section": "6.2 Edge counting",
    "text": "6.2 Edge counting\nLet us showcase the convenience of the adjacency matrix by counting the number of edges in the network.\nThe total number of edges in the network is the sum of the entities in the\n\n\nCode\nnp.sum(A) / 2\n\n\nWe divide by 2 because an edge corresponds to two entries in the matrix. Now, let us consider\nIt is also easy to compute the number of edges pertained to individual nodes by taking the row or column sum of the matrix.\n\n\nCode\nnp.sum(A, axis = 1)\n\n\nThe result is an array of length 4, where the i-th entry is the number of edges connected to node i.\n\n\n\n\n\n\nImportant\n\n\n\nThe number of edges connected to a node is called the degree of the node.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe np.sum(A, axis = 1) is the column sum of A. Alternatively, np.sum(A, axis = 0) is the row sum of A. Check out the numpy documentation for more details.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf the adjacency matrix is scipy CSR format (or CSC format), you can instead use A_csr.sum(axis=1), A_csr.sum(axis=0), and A_csr.sum(). Check out the scipy documentation for more details.\n\n\nWe can check the number of nodes with odd degree by taking the modulus of the degree by 2.\n\n\nCode\ndeg = np.sum(A, axis = 1)\nis_odd = deg % 2 == 1\nis_odd\n\n\n\n\nCode\nif np.sum(is_odd) == 2 or np.sum(is_odd) == 0:\n    print(\"The graph has a Euler path.\")\nelse:\n    print(\"The graph does not have a Euler path.\")",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Compute with networks</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/03-exercises.html",
    "href": "m01-euler_tour/03-exercises.html",
    "title": "7¬† Exercise",
    "section": "",
    "text": "7.1 Exercise 01\nCode\n# If you are using colab, uncomment the following line\n# !sudo apt install libcairo2-dev pkg-config python3-dev\n# !pip install pycairo cairocffi\n# !pip install igraph\nDefine the edges\nCode\n# This is a placeholder for your code for the exercise\nedges = ...\nDefine the adjacnecy matrix (without for loops!)\nCode\nA = ...\nVisualize the graph\nCode\nimport igraph\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef visualize_graph(A, **params):\n  A = np.array(A)\n  src, trg = np.where(A)\n  g = igraph.Graph(directed=False)\n  g.add_vertices(A.shape[0])\n  for s, t in zip(src, trg):\n    for _ in range(A[s, t]):\n      g.add_edge(s, t)\n  return igraph.plot(g, **params)\n\nvisualize_graph(A)\nCheck if the graph has an Euler path",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/03-exercises.html#exercise-01",
    "href": "m01-euler_tour/03-exercises.html#exercise-01",
    "title": "7¬† Exercise",
    "section": "",
    "text": "Create a network of landmasses and bridges of Binghamton, NY.\nFind an Euler path that crosses all the bridges of Binghamton, NY exactly once.\n\n\n\n\nBinghamton Map",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "m01-euler_tour/03-exercises.html#exercise-02",
    "href": "m01-euler_tour/03-exercises.html#exercise-02",
    "title": "7¬† Exercise",
    "section": "7.2 Exercise 02",
    "text": "7.2 Exercise 02\nLet‚Äôs create a network from pre-existing data and check if it has an Euler path.\n\nSelect a network of your choice from Netzschleuder. For convenience, choose a network of nodes less than 5000.\nDownload the csv version of the data by clicking something like ‚Äú3KiB‚Äù under csv column.\nUnzip the file and find ‚Äúedges.csv‚Äù, open it with a text editor to familiarize yourself with the format.\nLoad the data using pandas.\nGet the source and target nodes from the data to create an edge list.\nConstruct the adjacency matrix from the edge list.\nDraw the graph using igraph.\nCheck if the graph has an Euler path.\n\nLoad the data by\n\n\nCode\nimport pandas as pd\ndf = pd.read_csv('edges.csv') # load the data\ndisplay(df)\n\n\nThen, get the srce and target nodes to compose an edge list\n\n\nCode\nsrc = ...\ntrg = ...\nedges = ...\n\n\nCreate the adjacency matrix from the edge list\nGet the degree of each node xhmbapbzurl ipython3 deg = ...\nVisualize the graph\n\n\nCode\nvisualize_graph(A)\n\n\nCheck if the graph has an Euler path xhmbapbzurl ipython3",
    "crumbs": [
      "M01: Euler Tour",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "m02-small-world/00-preparation.html",
    "href": "m02-small-world/00-preparation.html",
    "title": "8¬† Preparation: Distance and Path Analysis Prerequisites",
    "section": "",
    "text": "8.1 Required Knowledge from Module 1\nBefore studying small-world networks, you should understand these concepts from the Euler Tour module: - Basic graph representations (adjacency matrix, edge lists) - Node degree calculations - Graph connectivity fundamentals",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Preparation: Distance and Path Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m02-small-world/00-preparation.html#distance-measures-in-networks",
    "href": "m02-small-world/00-preparation.html#distance-measures-in-networks",
    "title": "8¬† Preparation: Distance and Path Analysis Prerequisites",
    "section": "8.2 Distance Measures in Networks",
    "text": "8.2 Distance Measures in Networks\nSmall-world networks are fundamentally about distances between nodes. You‚Äôll need to understand:\n\n8.2.1 Shortest Path Distance\nThe shortest path distance between two nodes is the minimum number of edges in any path connecting them.\nimport networkx as nx\n\n# Calculate shortest path distances\nG = nx.Graph()\nG.add_edges_from([(1, 2), (2, 3), (3, 4), (1, 4)])\ndistance = nx.shortest_path_length(G, 1, 3)  # Returns 2\n\n\n8.2.2 Average Path Length\nFor network analysis, we often compute the average shortest path length across all pairs of nodes:\n\\langle d \\rangle = \\frac{1}{N(N-1)} \\sum_{i \\neq j} d_{ij}\nwhere d_{ij} is the shortest path distance between nodes i and j.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Preparation: Distance and Path Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m02-small-world/00-preparation.html#clustering-concepts",
    "href": "m02-small-world/00-preparation.html#clustering-concepts",
    "title": "8¬† Preparation: Distance and Path Analysis Prerequisites",
    "section": "8.3 Clustering Concepts",
    "text": "8.3 Clustering Concepts\n\n8.3.1 Local Clustering Coefficient\nThe clustering coefficient measures how densely connected a node‚Äôs neighbors are:\nC_i = \\frac{2E_i}{k_i(k_i-1)}\nwhere E_i is the number of edges between neighbors of node i, and k_i is the degree of node i.\n\n\n8.3.2 Global Clustering\nThe average clustering coefficient across all nodes provides a measure of local connectivity.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Preparation: Distance and Path Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m02-small-world/00-preparation.html#statistical-analysis-prerequisites",
    "href": "m02-small-world/00-preparation.html#statistical-analysis-prerequisites",
    "title": "8¬† Preparation: Distance and Path Analysis Prerequisites",
    "section": "8.4 Statistical Analysis Prerequisites",
    "text": "8.4 Statistical Analysis Prerequisites\n\n8.4.1 Probability Distributions\nYou‚Äôll need basic understanding of: - Random variables and their distributions - Expected values and variance - Comparing observed vs.¬†expected values\n\n\n8.4.2 Network Models\nUnderstanding of random graphs where edges are placed randomly with some probability will help contextualize small-world properties.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Preparation: Distance and Path Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m02-small-world/00-preparation.html#computational-prerequisites",
    "href": "m02-small-world/00-preparation.html#computational-prerequisites",
    "title": "8¬† Preparation: Distance and Path Analysis Prerequisites",
    "section": "8.5 Computational Prerequisites",
    "text": "8.5 Computational Prerequisites\n\n8.5.1 Algorithm Complexity\nBasic understanding of computational complexity (O(n), O(n¬≤)) for evaluating network analysis algorithms.\n\n\n8.5.2 Data Structures\nFamiliarity with: - Lists and dictionaries for graph representations - Efficient storage and retrieval of network data\nThese foundations will help you understand how small-world networks achieve the remarkable property of short average distances despite high local clustering.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Preparation: Distance and Path Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html",
    "href": "m02-small-world/01-concepts.html",
    "title": "9¬† Small-World Networks: Core Concepts",
    "section": "",
    "text": "9.1 What to learn in this module\nIn this module, we will learn small-world experiments and conduct a small small-world experiment . We will learn: - Small-world experiment by Milgram - Different concepts of distance: path, walks, circuits, cycles, connectedness - How to load a large sparse network efficiently into memory - How to measure a distance between two nodes using igraph - Keywords: small-world experiment, six degrees of separation, path, walks, circuits, cycles, connectedness, connected component, weakly connected component, strongly connected component, compressed sparse row format.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Small-World Networks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#small-world-experiment",
    "href": "m02-small-world/01-concepts.html#small-world-experiment",
    "title": "9¬† Small-World Networks: Core Concepts",
    "section": "9.2 Small-world experiment",
    "text": "9.2 Small-world experiment\nHow far are two people in a social network? Milgram and his colleagues conducted a series of expriment to find out in the 1960s.\n\n\n\n\n\n\nFigure¬†9.1: Milgram‚Äôs small world experiment.\n\n\n\nThe experiment went as follows: 1. Milgram first sent out packets to randomly selected people in Omaha, Nebraska, and Wichita, Kansas. 2. The recipient was asked to send the packet to the target person in Boston if they knew them. If not, they were to forward it to someone they knew on a first-name basis who might know the target. 3. The recipient continued to forward the packet to their acquaintances until it reached the target.\nThe results were surprising: out of the 160 letters sent, 64 successfully reached the target person by the chain of nearly six people, which was later called six degrees of separation. The results imply that, despite the fact that there were hundreds of millions of people in the United States, their social network was significantly compact, with two random people being connected to each other in only a few steps.\n\n\n\n\n\n\nTip\n\n\n\nThe term ‚ÄúSix degrees of separation‚Äù is commonly associated with Milgram‚Äôs experiment, but Milgram never used it. John Guare coined the term for his 1991 play and movie ‚ÄúSix Degrees of Separation.‚Äù\n\n\nThe results were later confirmed independently.\n\nYahoo research replicate the Milgram‚Äôs experiment by using emails. Started from more than 24,000 people, only 384 people reached the one of the 18 target person in 13 countries. Among the successful ones, the average length of the chain was about 4. When taken into account the broken chain, the average length was estimated between 5 and 7.{footcite}goel2009social\nResearchers in Facebook and University of Milan analyzed the social network n Facebook, which consisted of 721 million active users and 69 billion friendships. The average length of the shortest chain was found to be 4.74. {footcite}backstrom2012four",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Small-World Networks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#wikirace-experiencing-small-world-networks",
    "href": "m02-small-world/01-concepts.html#wikirace-experiencing-small-world-networks",
    "title": "9¬† Small-World Networks: Core Concepts",
    "section": "9.3 Wikirace: Experiencing Small-World Networks",
    "text": "9.3 Wikirace: Experiencing Small-World Networks\nLet us feel how small a large network can be by playing the Wikirace game.\n\n\n\nAt the end of the module, we will measure the average path length in a social network. Before jumping on, let us arm with some coding techniques to handle the network in the next two sections.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Small-World Networks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#paths-walks-and-network-connectivity",
    "href": "m02-small-world/01-concepts.html#paths-walks-and-network-connectivity",
    "title": "9¬† Small-World Networks: Core Concepts",
    "section": "9.4 Paths, Walks, and Network Connectivity",
    "text": "9.4 Paths, Walks, and Network Connectivity\nWhile we have already used the term path, let us make clear its definition, together with other related terms and concepts of network connectivity.\nBasic Definitions:\n\nA walk is a sequence of nodes that are connected to form a continous route in a network. For instance, walk (0, 1, 2, 3) is a walk in the graph of the bridges of Konigsberg. But the sequence (0,2,3,1) is not a walk, because the node 0 is not directly connected to node 2.\nA trail is a walk with no repeated edge. For instance, walk (0, 1, 2, 3) is also a trail as it does not cross the same edge twice. But walk (0,2,3,1,3) is not a trail due to the repeated edge (1,3).\nA path is a walk without repeated node. For instance, walk (0,1,2,3) is a path. But walk (0, 1, 2, 1, 2, 3) is not a path due to the repeated node 1 and 2.\nWhen a walk starts and ends at the same node, it is called a **loop*. If the loop is a trail, it is called a circuit. If the loop is a path, it is called a cycle.\n\nQuestion: Is a path always a trail, and is a trail always a path?\n\n\n\n\n\n\nFigure¬†9.2: Labeled Knigsberg graph\n\n\n\nShortest Paths:\n\nShortest Path is the path with the smallest number of edges (or nodes) between two nodes. A shortest path from node 0 to 2 is (0, 1, 2). Two nodes can have multiple shortest paths e.g., (0, 3, 2).\nThe shortest path length is the number of edges in the shortest path, not the number of nodes! üëàüëà\n\n\n\n\n\n\n\nAre there shortest trails and shortest walks?\n\n\n\nShortest trails and shortest walks are fundamentally equivalent to shortest paths. A shortest trail must visit each node only once (otherwise it would not be the shortest), and similarly, a shortest walk does not repeat nodes (otherwise it would not be the shortest), both forming a shortest path.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Small-World Networks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#network-connectivity",
    "href": "m02-small-world/01-concepts.html#network-connectivity",
    "title": "9¬† Small-World Networks: Core Concepts",
    "section": "9.5 Network Connectivity",
    "text": "9.5 Network Connectivity\nBasic Connectivity Concepts:\n\nA network is connected if there is a path between every pair of nodes.\nA network is disconnected if there is no path between some pairs of nodes.\nA connected component of a network is a set of nodes that are connected to each other.\nThe giant component of a network is the largest connected component that contains a significant fraction of nodes in the network (in order of the number of nodes).\n\n\n\n\n\n\n\nFigure¬†9.3: connected components of a network. the nodes with the same color form a connected component.\n\n\n\nConnectivity in Directed Networks:\nWe call a network is directed if the edges have a direction. Example directed networks include the network of Web pages, the network of friendships on X, the network of citations on academic papers.\nIn a directed network, a walk must follow the edge directions. Paths, trails, and loops extend similarly to directed networks. But one thing to keep in mind: a walk may not be reversible, meaning there can be a walk from one node to another but not vice versa.\nThis leads to two different types of connectedness as follows:\n\nStrong connectedness: A directed network is said to be strongly connected if there is a path from every node to every other node.\nWeak connectedness: A directed network is said to be weakly connected if there is a path from every node to every other node on its undirected counterpart.\n\n\n\n\n\n\n\nFigure¬†9.4: connected components of a network. the nodes with the same color form a connected component.\n\n\n\nQuestion: Is a strongly-connected component always a weakly-connected component?\nIn the next section, we will learn how to compute the shortest paths and connected components of a network using a library igraph.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Small-World Networks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#references",
    "href": "m02-small-world/01-concepts.html#references",
    "title": "9¬† Small-World Networks: Core Concepts",
    "section": "9.6 References",
    "text": "9.6 References",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Small-World Networks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html",
    "href": "m02-small-world/02-coding.html",
    "title": "10¬† Efficient Network Representation and Computing Paths",
    "section": "",
    "text": "10.1 Efficient representation for large sparse networks\nAn adjacency matrix is a convenient way to represent a network. A challenge of handling large networks is that the adjacency matrix can be too large to fit in memrory. For example, a network with 10^5 nodes requires a 10^5 \\times 10^5 matrix, totaling 10 billion entries! A good news is that we do not need to hold all these entries in memory, if we know the network is sparse.\nMany networks in real-world are sparse, meaning most nodes connect to only a few others. The result is that the adjacency matrix often contains many zeros. This is where we can save significant memory by storing only the non-zero entries.\nCompressed Sparse Row (CSR) is an efficient way to store sparse networks by treating the adjacency matrix like a scatter plot. Instead of storing all entries, CSR only keeps track of the ‚Äúcoordinates‚Äù (row and column indices) of non-zero entries, along with their values.\nThe CSR format is implemented in the scipy library. It is straightforward to convert the CSR matrix from the dense adjacency matrix.\nCode\nfrom scipy.sparse import csr_matrix\n\nA = [[0, 2, 0, 1],\n     [2, 0, 2, 1],\n     [0, 2, 0, 1],\n     [1, 1, 1, 0]]\n\nA_csr = csr_matrix(A)\nA_csr\nIf you have an edge list, you can directly generate the CSR matrix without creating the dense matrix first.\nCode\nfrom scipy.sparse import csr_matrix\n\nedges = [(0,1), (0, 1), (0, 3), (1, 2), (1, 2), (1, 3), (2, 3)]\n\nsrc = [edge[0] for edge in edges]\ntrg = [edge[1] for edge in edges]\nvalues = [1 for _ in edges]\nA_csr = csr_matrix((values, (src, trg)), shape=(4, 4))\nA_csr\nwhere src, trg, and values are lists of the source nodes, target nodes, and edge weights, respectively.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Efficient Network Representation and Computing Paths</span>"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#efficient-representation-for-large-sparse-networks",
    "href": "m02-small-world/02-coding.html#efficient-representation-for-large-sparse-networks",
    "title": "10¬† Efficient Network Representation and Computing Paths",
    "section": "",
    "text": "Optional Exercise\n\n\n\n:class: tip For those who are interested in the details of CSR format, please do the following: - üìù Pen and paper exercise here - üíª (Advanced) Coding exercise in the Appendix.\n\n\n\n\n\n\n\n\nFigure¬†10.1: Compressed Sparse Row (CSR) matrix. Source: Medium: Sparse GEMM and Tensor Core‚Äôs Structured Sparsity",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Efficient Network Representation and Computing Paths</span>"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#computing-shortest-paths-and-connected-components",
    "href": "m02-small-world/02-coding.html#computing-shortest-paths-and-connected-components",
    "title": "10¬† Efficient Network Representation and Computing Paths",
    "section": "10.2 Computing Shortest Paths and Connected Components",
    "text": "10.2 Computing Shortest Paths and Connected Components\nLet‚Äôs use igraph to compute the shortest paths and connected components. We will then use scipy to compute them.\n\n\nCode\n# If you are using Google Colab, uncomment the following line to install igraph\n# !sudo apt install libcairo2-dev pkg-config python3-dev\n# !pip install pycairo cairocffi\n# !pip install igraph\n\n\n\n10.2.1 igraph\n\n\n10.2.2 Create a graph\nLet us create a graph of 4 nodes and 4 edges. Our edge list is given by\n\n\nCode\nedge_list = [(0, 1), (1, 2), (0, 2), (0, 3)]\n\n\nigraph has an object Graph that stores a graph and provides methods to manipulate and analyze the graph. To create a graph from an edge list, we can use the add_edges method.\n\n\nCode\nimport igraph\n\ng = igraph.Graph() # Create an empty graph\ng.add_vertices(4) # Add 4 vertices\ng.add_edges(edge_list) # Add edges to the graph\n\n# Plot the graph\nigraph.plot(g, bbox=(150, 150), vertex_label=list(range(4)))\n\n\n\n\n10.2.3 Shortest Paths\nLet‚Äôs compute the paths between nodes 2 and 3.\n\n\nCode\ng.get_all_simple_paths(2, to=3)\n\n\nThis method enumerates all possible simple paths between two nodes. This is OK for small networks but quickly becomes impractical for larger networks, as the number of paths increases exponentially with the size of the network.\nOften, we are interested in the shortest path, which is the path with the smallest number of edges. The shortest path can be computed by using the get_shortest_paths method.\n\n\nCode\ng.get_shortest_paths(2, to=3)\n\n\nNote that there can be multiple shortest paths between two nodes. If we are interested in the ‚Äúlength‚Äù instead of the path itself, there is a more efficient function distances.\n\n\nCode\ng.distances(2, 3)\n\n\n\n\n10.2.4 Connected Components\nIn the simple network above, we can see that for every pair of nodes, we can find a path connecting them. This is the definition of a connected graph. We can check this property for a given graph:\n\n\nCode\ncomponents = g.connected_components()\n\n\nThe components is a special object called VertexClustering in igraph. It has the following useful functions and attributes:\n\n\nCode\nprint(\"membership: \", components.membership)  # the IDs of the component each node belongs to.\nprint(\"sizes: \", list(components.sizes()))  # the number of nodes in each component.\nprint(\"giant: \", components.giant())  # a subgraph of the largest connected component.\n\n\n\n10.2.4.0.1 Exercise 01 üèãÔ∏è‚Äç‚ôÄÔ∏èüí™üß†\n\nNow, let us add two nodes that are not connected to the existing graph, and call connected_components again. üîó‚ûï\nCall get_shortest_paths between the two new nodes in different connected components. üõ£Ô∏èüîç\nGet the largest connected component. üåêüèÜ\n\n\n\n\n10.2.5 Directed networks\nLet‚Äôs extend these ideas about paths and connected components to directed graphs.\n\n\nCode\nedge_list =[(0, 1), (1, 2), (2, 1), (2, 3), (2, 5), (3, 1), (3, 4), (3, 5), (4, 5), (5, 3)]\ng = igraph.Graph(directed=True)\ng.add_vertices(6)\ng.add_edges(edge_list)\nigraph.plot(g, bbox=(250, 250), vertex_label=list(range(6)))\n\n\nIn directed graphs, edges and paths can be one-way. For instance, in our graph, you can go from node 0 to node 3, but not from 3 to 0.\n\n\nCode\nprint(\"From 0 to 3\", g.get_all_simple_paths(0, to=3))\nprint(\"From 3 to 0\", g.get_all_simple_paths(3, to=0))\n\n\nThe shortest path from 4 to 1 must take a longer route due to edge directions.\n\n\nCode\ng.get_shortest_paths(4, 1)\n\n\nDirected networks have two kinds of connected components.\n\nStrongly connected components: Strongly connected means that there exists a direct path between every pair of nodes, i.e., that from any node to any other nodes while respecting the edge directionality.\nWeakly connected components: Weakly connected means that there exists a path between every pair of nodes when ignoring the edge directionality.\n\n\n\nCode\nprint(list(g.connected_components(mode=\"strong\")))\nprint(list(g.connected_components(mode=\"weak\")))\n\n\n\n\n10.2.6 Scipy\nWe can create a graph, compute the shortest paths, and connected components using scipy.\n\n\n10.2.7 Create a graph\nWith scipy, we represent a network by an adjacency matrix using something called a Compressed Sparse Row (CSR) matrix. CSR matrices are efficient format for storing and manipulating sparse matrices. Why sparse is highlighed here? Because in many networks, the adjacency matrix is sparse, i.e., most of the entries are zero. For example, here is the adjacency matrix of a real-world network:\n\nMost of the entries in this adjacency matrix are white, and white means that the value of the entry is zero. And the adjacency matrix looks very white! This is pretty common in real-world networks. We call these matrices ‚Äúsparse‚Äù because they are mostly empty. And CSR matrices are a way to store these sparse matrices efficiently. Don‚Äôt worry too much about the technical details for now. If you‚Äôre curious to learn more, you can check out the Appendix.\nThe great thing is, scipy (especially the scipy.sparse module) provides efficient tools for working with these sparse matrices. This comes in really handy when we‚Äôre working with large networks.\nLet create a graph using scipy.\n\n\nCode\nfrom scipy import sparse # We will use sparse module in scipy\n\nedge_list = [(0, 1), (1, 2), (0, 2), (0, 3)]\n\nsrc = [src for src, dst in edge_list]\ntrg = [dst for src, dst in edge_list]\nweight = [1 for src, dst in edge_list]\n\nA = sparse.csr_matrix((weight, (src, trg)), shape=(4, 4))\nA = A + A.T # Make the adjacency matrix symmetric\nA\n\n\nLet‚Äôs break down the code. - src and trg are the source and target nodes of the edges. - weight is the weight of the edges. - sparse.csr_matrix((weight, (src, trg))) creates a sparse matrix, filling weight into the positions specified by (src, trg). - A.T is the transpose of A and A + A.T makes the adjacency matrix symmetric.\nThe CSR matrix does not print nicely. But you can see it by converting to a numpy array and printing it.\n\n\nCode\nA.toarray()\n\n\n\n\n10.2.8 Shortest Paths\nThe sparse module has a submodule csgraph that provides APIs for network analysis.\nFor example, csgraph.shortest_path computes the shortest path length from a specific node to all other nodes.\n\n\nCode\nfrom scipy.sparse import csgraph\n\n# `indices` is the node to compute the shortest path from.\nD = csgraph.shortest_path(A, indices=2, directed=False)\nD\n\n\nAdvanced: If you want to get the actual paths (i.e., list of nodes in the path), you can pass return_predecessors=True to csgraph.shortest_path.\n\n\nCode\nD, predecessors = csgraph.shortest_path(A, indices=2, directed=False, return_predecessors=True)\n\n\n\n\n10.2.9 Connected Components\nConnected components can be computed by csgraph.connected_components.\n\n\nCode\nn_components, labels = csgraph.connected_components(A, directed=False, return_labels=True)\n\nprint(\"Number of connected components:\", n_components)\nprint(\"Labels:\", labels)\n\n\n\nn_components is the number of connected components.\nlabels is an array of length n_nodes where each element is the ID of the connected component the node belongs to.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Efficient Network Representation and Computing Paths</span>"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#exercise-02",
    "href": "m02-small-world/02-coding.html#exercise-02",
    "title": "10¬† Efficient Network Representation and Computing Paths",
    "section": "10.3 Exercise 02 üèãÔ∏è‚Äç‚ôÄÔ∏èüí™üß†",
    "text": "10.3 Exercise 02 üèãÔ∏è‚Äç‚ôÄÔ∏èüí™üß†\nLet‚Äôs compute the average path length of a network from pre-existing data and check if how long on average it takes to go from any node to any other node.\n\nSelect a network of your choice from Netzschleuder. For convenience, choose a network of nodes less than 5000.\nDownload the csv version of the data by clicking something like ‚Äú3KiB‚Äù under csv column.\nUnzip the file and find ‚Äúedges.csv‚Äù, open it with a text editor to familiarize yourself with the format.\nLoad the data using pandas.\nGet the source and target nodes from the data to create an edge list.\nConstruct a graph from the edge list, either using igraph or scipy.\nCompute the average path length\n\nHint: Finding all shortest paths is a qubic time operation with respect to the number of nodes, or simply put, it takes a long time to compute. So compute the ‚Äúestimate‚Äù by sampling many pairs of nodes uniformly at random and computing the average path length.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Efficient Network Representation and Computing Paths</span>"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html",
    "href": "m02-small-world/03-exercises.html",
    "title": "11¬† Exercises and Assignments",
    "section": "",
    "text": "11.1 Pen-and-Paper Exercise: Why is our social network small world?",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Exercises and Assignments</span>"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html#pen-and-paper-exercise-why-is-our-social-network-small-world",
    "href": "m02-small-world/03-exercises.html#pen-and-paper-exercise-why-is-our-social-network-small-world",
    "title": "11¬† Exercises and Assignments",
    "section": "",
    "text": "‚úçÔ∏è It‚Äôs a small world!! 6 degrees of separation {footcite}esteban-moro-worksheet",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Exercises and Assignments</span>"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html#assignment",
    "href": "m02-small-world/03-exercises.html#assignment",
    "title": "11¬† Exercises and Assignments",
    "section": "11.2 Assignment",
    "text": "11.2 Assignment\nWe will compute the average path length of a network of scientists. The network is constructed from {footcite:p}sinatra2016quantifying, where each node represents a scientist and two scientists are connected if they have co-authored a paper in Physical Review Journals from American Physical Society.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Exercises and Assignments</span>"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html",
    "href": "m02-small-world/04-appendix.html",
    "title": "12¬† Appendix: Tools and Advanced Topics",
    "section": "",
    "text": "12.1 Toolbox for network analysis\nHere are some useful tools for network analysis in Python:\nWhile networkx is a popular and beginner-friendly library for network analysis in Python, we‚Äôll be using igraph in this course. igraph is a mature library with a wide range of algorithms, originally developed for R. Why igraph instead of networkx? Because networkx has some persistent bugs in the implementations of some algorithms (e.g., LFR benchmark and weighted degree assortativity), which can skew the analysis. igraph offers more reliable implementations.\nWe‚Äôll also use scipy for scientific computing. scipy is one of the most popular Python libraries and also a powerful network analysis tool, especially for large networks. While it requires a bit more effort to learn, once you get the hang of it, you‚Äôll find it‚Äôs a powerful tool for your network analysis projects.",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Appendix: Tools and Advanced Topics</span>"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html#toolbox-for-network-analysis",
    "href": "m02-small-world/04-appendix.html#toolbox-for-network-analysis",
    "title": "12¬† Appendix: Tools and Advanced Topics",
    "section": "",
    "text": "Python built-in data structures (list, tuple, dict)\nnetworkx - a beginner-friendly library for network analysis\nigraph - a mature library with a wide range of algorithms\ngraph-tool - for stochastic block models\nscipy - for analyzing large networks\npytorch-geometric - for graph neural networks",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Appendix: Tools and Advanced Topics</span>"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html#compressed-sparse-row-csr-format",
    "href": "m02-small-world/04-appendix.html#compressed-sparse-row-csr-format",
    "title": "12¬† Appendix: Tools and Advanced Topics",
    "section": "12.2 Compressed Sparse Row (CSR) format",
    "text": "12.2 Compressed Sparse Row (CSR) format\nCSR format is implemented in scipy. This consists of three arrays called indptr, indices, and data. For example,\n\n\nCode\nimport networkx as nx\nfrom scipy import sparse\n\nG = nx.karate_club_graph()\nA = sparse.csr_matrix(nx.adjacency_matrix(G))\n\nprint(\"A.indices:\", A.indices[:5])\nprint(\"A.indptr:\", A.indptr[:5])\nprint(\"A.data:\", A.data[:5])\n\n\nWe will walk you through what these arrays mean, how they are generated, and how we can leverage them for efficient computations.\n\n12.2.1 How to generate CSR format from an adjacency matrix\nLet‚Äôs walk you through how to store an example adjacency matrix in Compressed Sparse Row (CSR) format. Our example adjacency matrix is as follows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n1\n\n\n2\n\n1\n\n1\n\n\n\n\n\n\n1\n\n\n3\n\n\n1\n\n1\n1\n1\n\n\n\n\n\n\n4\n\n\n\n1\n\n\n\n1\n\n\n\n\n\n5\n\n\n\n1\n\n\n\n\n\n\n\n\n\n6\n\n\n\n1\n\n\n\n\n1\n1\n\n\n\n7\n\n\n\n\n1\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n9\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n10\n1\n1\n1\n\n\n\n\n\n1\n1\n\n\n\n\n\nWe will first create adjacency list, which is a dictionary consisting of the row IDs and column IDs for the non-zero entries in the adjacency matrix.\n\n\n\\{\\text{Row ID}: (\\text{Column ID}, \\text{Value})\\}\n\n\nConcretely, in Python,\n\n\nCode\nadj_list = {\n  0:[(10,1)],\n  1:[(2,1), (10, 1)],\n  2:[(1,1), (3,1), (10, 1)],\n  3:[(2,1), (4,1), (5,1), (6,1)],\n  #...\n}\n\n\nCSR format is a concatenation of the keys and values of the adjacency list, respectively. The CSR format has a concatenated array of the values, one for column IDs and one for the values, called indices and data, respectively.\n\n\nCode\nimport numpy as np\n\nindices = np.array([vv[0] for k, v in adj_list.items() for vv in v])\nindices\n\n\n\n\nCode\ndata = np.array([vv[1] for k, v in adj_list.items() for vv in v])\ndata\n\n\nAdditionally, the CSR format has another array called indptr, which stores the Row IDs of the non-zero entries in the adjacency matrix. This indptr array has a value such that indptr[i] is the first index of indices that corresponds to the i-th row of the adjacency matrix. This can be generated by\n\n\nCode\nindptr = np.cumsum([0] + [len(adj_list[i]) for i in range(len(adj_list))])\nindptr\n\n\nwhere we added 0 at the beginning of the array to represent the first non-zero entry in the first row. The first row ends at index len(adj_list[0])-1, and the second row starts at index len(adj_list[0]) and ends at index len(adj_list[0])+len(adj_list[1])-1, and so on.\nNow we have three compressed vectors indptr, indices, and data, that together form the CSR format for the adjacency matrix.\n\n\n12.2.2 How to use CSR format for efficient computations\nThe key advantage of the CSR representation is the memory efficiency. But you can leverage the CSR format for more efficient computations, if you know the semantics of indptr, indices, and data arrays.\nFor instance, one can compute the degree of a node by using\n\n\nCode\nnode = 1\ndegree = indptr[node+1] - indptr[node]\ndegree\n\n\nLet us break down the above code. - indptr[node] is the first index of the indices array that corresponds to the node-th row of the adjacency matrix. - indptr[node+1] is the first index of the indices array that corresponds to the (node+1)-th row of the adjacency matrix. - Thus, indptr[node+1] - indptr[node] is the number of non-zero entries in the node-th row of the adjacency matrix, which is the degree of the node-th node.\nUsing indices, it is easy to identify the neighbors of a given node by using\n\n\nCode\nneighbors = indices[indptr[node]:indptr[node+1]]\nneighbors\n\n\nwhere indices[indptr[node]:indptr[node+1]] is the corresponding column IDs of the non-zero entries in the node-th row of the adjacency matrix, which corresponds to the node IDs connected to the node-th node.\nThe edge weights to the neighbors can be obtained by using\n\n\nCode\nedge_weights = data[indptr[node]:indptr[node+1]]\nedge_weights",
    "crumbs": [
      "M02: Small World",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Appendix: Tools and Advanced Topics</span>"
    ]
  },
  {
    "objectID": "m03-robustness/00-preparation.html",
    "href": "m03-robustness/00-preparation.html",
    "title": "13¬† Preparation: Network Failure Analysis Prerequisites",
    "section": "",
    "text": "13.1 Required Knowledge from Previous Modules\nBefore studying network robustness, ensure you understand: - From M01: Basic graph representations and connectivity concepts - From M02: Shortest path calculations and average path length measurement",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Preparation: Network Failure Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m03-robustness/00-preparation.html#graph-theory-prerequisites-for-robustness-analysis",
    "href": "m03-robustness/00-preparation.html#graph-theory-prerequisites-for-robustness-analysis",
    "title": "13¬† Preparation: Network Failure Analysis Prerequisites",
    "section": "13.2 Graph Theory Prerequisites for Robustness Analysis",
    "text": "13.2 Graph Theory Prerequisites for Robustness Analysis\n\n13.2.1 Tree Structures\nUnderstanding tree structures is essential for robustness analysis: - Tree: A connected graph with no cycles - Spanning Tree: A tree that connects all nodes in a graph - Minimum Spanning Tree (MST): The spanning tree with minimum total edge weight\nTrees are important because they represent the minimal connectivity structure - removing any edge disconnects the network.\n\n\n13.2.2 Network Connectivity Measures\n\n13.2.2.1 Connectivity Robustness\n\nNode connectivity: Minimum number of nodes that must be removed to disconnect the network\nEdge connectivity: Minimum number of edges that must be removed to disconnect the network\nCut sets: Sets of edges or nodes whose removal increases the number of components\n\n\n\n13.2.2.2 Centrality and Vulnerability\nUnderstanding which nodes are most important for network connectivity: - High-degree nodes often play crucial roles in network connectivity - Removing central nodes may have disproportionate impact on network function",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Preparation: Network Failure Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m03-robustness/00-preparation.html#statistical-prerequisites",
    "href": "m03-robustness/00-preparation.html#statistical-prerequisites",
    "title": "13¬† Preparation: Network Failure Analysis Prerequisites",
    "section": "13.3 Statistical Prerequisites",
    "text": "13.3 Statistical Prerequisites\n\n13.3.1 Probability and Random Processes\nFor understanding different types of network attacks: - Random sampling: Understanding uniform random selection of nodes/edges - Probability distributions: How failure events are distributed - Expected values: Average behavior under random failures\n\n\n13.3.2 Network Models for Comparison\n\nRandom graphs: As baseline models to compare robustness\nScale-free networks: Understanding degree heterogeneity effects\nSmall-world networks: Balancing local and global connectivity",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Preparation: Network Failure Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m03-robustness/00-preparation.html#computational-prerequisites",
    "href": "m03-robustness/00-preparation.html#computational-prerequisites",
    "title": "13¬† Preparation: Network Failure Analysis Prerequisites",
    "section": "13.4 Computational Prerequisites",
    "text": "13.4 Computational Prerequisites\n\n13.4.1 Algorithm Analysis\n\nEfficiency considerations: How to efficiently test connectivity after node/edge removal\nSimulation methods: Running multiple trials of failure scenarios\nMeasurement techniques: Quantifying network performance degradation\n\n\n\n13.4.2 Data Structures for Dynamic Networks\n\nEfficient representations for networks that change over time\nMethods for tracking connected components as network is modified",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Preparation: Network Failure Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m03-robustness/00-preparation.html#application-context",
    "href": "m03-robustness/00-preparation.html#application-context",
    "title": "13¬† Preparation: Network Failure Analysis Prerequisites",
    "section": "13.5 Application Context",
    "text": "13.5 Application Context\n\n13.5.1 Infrastructure Networks\nBasic understanding of real-world networks that must remain functional: - Power grids: Electrical distribution networks - Transportation networks: Road, rail, and air traffic systems - Communication networks: Internet and telecommunication systems\nThese prerequisites will help you understand how different network structures respond to various types of failures and attacks.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Preparation: Network Failure Analysis Prerequisites</span>"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html",
    "href": "m03-robustness/01-concepts.html",
    "title": "14¬† Module 3: Robustness - Concepts",
    "section": "",
    "text": "14.1 Learning Objectives\nIn this module, we will explore network robustness and its applications. By the end of this module, you will understand: - Minimum spanning tree algorithms and their role in network design - Network robustness against random failures and targeted attacks - Quantitative measures of network robustness including the R-index - Real-world applications in power grid design and infrastructure planning\nKeywords: minimum spanning tree, Kruskal‚Äôs algorithm, Prim‚Äôs algorithm, random attacks, targeted attacks, network robustness, robustness index",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Module 3: Robustness - Concepts</span>"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#network-robustness-fundamentals",
    "href": "m03-robustness/01-concepts.html#network-robustness-fundamentals",
    "title": "14¬† Module 3: Robustness - Concepts",
    "section": "14.2 Network Robustness Fundamentals",
    "text": "14.2 Network Robustness Fundamentals\nNetworks in the real world face constant threats - nodes and edges can fail or be attacked, disrupting connectivity. A robust network maintains most of its connectivity even after failures or attacks. Understanding and quantifying this robustness is crucial for designing resilient infrastructure, from power grids to communication networks.\nThe key insight is that different types of failures require different defensive strategies. Random failures (like equipment malfunction) affect networks differently than targeted attacks (like deliberate sabotage of critical nodes). Let‚Äôs explore these scenarios and learn how to measure and improve network resilience.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Module 3: Robustness - Concepts</span>"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#random-node-failures",
    "href": "m03-robustness/01-concepts.html#random-node-failures",
    "title": "14¬† Module 3: Robustness - Concepts",
    "section": "14.3 Random Node Failures",
    "text": "14.3 Random Node Failures\nRandom failures occur when nodes disconnect unexpectedly, such as power station closures in electrical grids or server failures in computer networks. In this scenario, nodes are removed randomly from the network along with all their connections.\nThe impact of random failures varies significantly depending on which nodes fail. We measure this damage through connectivity loss - the fraction of nodes remaining in the largest connected component after failure. This metric captures how well the network maintains its overall structure.\n\n\n\n\n\n\nFigure¬†14.1\n\n\n\nWhen multiple nodes fail simultaneously (as in natural disasters), we need systematic ways to assess network vulnerability. The robustness profile provides this by plotting connectivity loss against the number of nodes removed. This visualization reveals how quickly a network fragments under progressive random failures.\n\n\n\n\n\n\nFigure¬†14.2\n\n\n\nTo quantify robustness with a single metric, we use the R-index, defined as the area under the robustness profile curve:\n\nR = \\frac{1}{N} \\sum_{k=1}^{N-1} y_k\n\nwhere y_k is the connectivity at fraction k/N of nodes removed, and N is the total number of nodes. Higher R-index values indicate greater robustness, with a maximum possible value of 0.5.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Module 3: Robustness - Concepts</span>"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#targeted-attacks",
    "href": "m03-robustness/01-concepts.html#targeted-attacks",
    "title": "14¬† Module 3: Robustness - Concepts",
    "section": "14.4 Targeted Attacks",
    "text": "14.4 Targeted Attacks\nWhile a network may survive random failures well, it can still be vulnerable to targeted attacks where adversaries strategically remove specific nodes. The most common strategy targets high-degree nodes (hubs) first, since they have many connections and their removal severely disrupts network connectivity.\nBeyond degree-based attacks, adversaries might target nodes based on centrality measures (closeness, betweenness) or strategic positioning. Each attack strategy exploits different network vulnerabilities, making comprehensive robustness analysis essential for critical infrastructure.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Module 3: Robustness - Concepts</span>"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#power-grid-design-exercise",
    "href": "m03-robustness/01-concepts.html#power-grid-design-exercise",
    "title": "14¬† Module 3: Robustness - Concepts",
    "section": "14.5 Power Grid Design Exercise",
    "text": "14.5 Power Grid Design Exercise\nUnderstanding robustness concepts is crucial for real-world applications like power grid design. Consider the challenge of building a cost-effective electrical grid that maintains service even when components fail.\n\n‚úçÔ∏è Pen and Paper Exercise: Design a cost-effective power grid network using minimum spanning tree concepts, balancing cost minimization with robustness requirements.\n\nThis exercise bridges theoretical concepts with practical engineering decisions, demonstrating how robustness analysis guides infrastructure planning.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Module 3: Robustness - Concepts</span>"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html",
    "href": "m03-robustness/02-coding.html",
    "title": "15¬† Coding: Minimum Spanning Trees and Network Robustness",
    "section": "",
    "text": "15.1 Minimum spanning tree\nMany networks are surprisingly sparse, with most nodes having only a few connections, in part because connections are costly. Like cables in power grids and human-to-human communications, networks are often built with cost constraints, and it is often of a great interest to find the most cost-effective structure.\nMinimum spanning tree is a tree that connects all the nodes in a network with the minimum total weight of edges. The term involves the following two concepts:\nThe minimum spanning tree may not be unique, meaning there can be multiple spanning trees with the same minimum total weight of edges for a network.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Coding: Minimum Spanning Trees and Network Robustness</span>"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#minimum-spanning-tree",
    "href": "m03-robustness/02-coding.html#minimum-spanning-tree",
    "title": "15¬† Coding: Minimum Spanning Trees and Network Robustness",
    "section": "",
    "text": "Tree: A network is a tree if it is connected and has no cycles.\nSpanning tree: A spanning tree is a tree that spans all the nodes in a network.\n\n\n\n\n\nMinimum spanning tree of a network. {#fig-minimum-spanning-tree}\n\n\n\n15.1.1 How to find the minimum spanning tree\nKruskal‚Äôs algorithm and Prim‚Äôs algorithms are two common methods to find a minimum spanning tree. Both start with an empty edge set and add the smallest weight edge iteratively, while ensuring that the edges form a tree, until all nodes are included. The difference between the two algorithms lies in the order of edge addition.\nKruskal‚Äôs algorithm operates as follows: 1. Sort the edges by the increasing order of the edge weights. 2. Select the edge with the smallest weight that does not form a cycle with the edges already in the tree. 3. Repeat step 2 until all the nodes are connected.\nPrim‚Äôs algorithm: 1. Start with a singleton network G consisting of a randomly chosen node. 2. Add the smallest weight edge connecting G to a node not in G. 3. Repeat step 2 until all nodes are connected.\n{{ ‚ÄòüöÄ Check out the Demo for Kruskal's and Prim's algorithm üåê‚Äô.replace(‚ÄòBASE_URL‚Äô, base_url) }}\nKruskal‚Äôs algorithm sorts the edges globally at the beginning, while Prim‚Äôs algorithm sorts the edges locally at each step. Both algorithms find the same minimum spanning tree, provided that all edge weights are distinct. Otherwise, they may yield different trees.\n\n\n15.1.2 Code\nigraph provides a function igraph.Graph.spanning_tree to find a minimum spanning tree in a given network.\nLet‚Äôs first create a network with random edge weights.\n\n\nCode\nimport igraph\nimport random\n\ng = igraph.Graph.Famous('Zachary')\ng.es[\"weight\"] = [random.randint(1, 10) for _ in g.es]\nigraph.plot(g, edge_width = g.es[\"weight\"])\n\n\n\n\n\n\n\n\nNote\n\n\n\nZachary‚Äôs karate club is a famous network of 34 members of a karate club and documents of their links between friends. The network is undirected and unweighted.\n\n\nThe minimum spanning tree of the network can be found by the following code.\n\n\nCode\ngmst = g.spanning_tree(weights=g.es[\"weight\"]) # If not `weights` are not specified, the edges are assumed to be unweighted\nigraph.plot(gmst, edge_width = gmst.es[\"weight\"])",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Coding: Minimum Spanning Trees and Network Robustness</span>"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#hands-on-robustness-random-attack",
    "href": "m03-robustness/02-coding.html#hands-on-robustness-random-attack",
    "title": "15¬† Coding: Minimum Spanning Trees and Network Robustness",
    "section": "15.2 Hands-on: Robustness (Random attack)",
    "text": "15.2 Hands-on: Robustness (Random attack)\n  \n\n\nCode\n# If you are using Google Colab, uncomment the following line to install igraph\n# !sudo apt install libcairo2-dev pkg-config python3-dev\n# !pip install pycairo cairocffi\n# !pip install igraph\n\n\nWe consider a small social network of 34 members in a university karate club, called Zachary‚Äôs karate club network.\n\n\nCode\nimport igraph\ng = igraph.Graph.Famous(\"Zachary\")\nigraph.plot(g, vertex_size=20)\n\n\nLet‚Äôs break the network üòà! We will remove nodes one by one and see how the connectivity of the network changes at each step. It is useful to create a copy of the network to keep the original network unchanged.\n\n\nCode\ng_original = g.copy()\n\n\n\n15.2.1 Robustness against random failures\nLet us remove a single node from the network. To this end, we need to first identify which nodes are in the network. With igraph, the IDs of the nodes in a graph are accessible through Graph.vs.indices as follows:\n\n\nCode\nprint(g.vs.indices)\n\n\nWe randomly choose a node and remove it from the network by using Graph.delete_vertices.\n\n\nCode\nimport numpy as np\nnode_idx = np.random.choice(g.vs.indices)\ng.delete_vertices(node_idx)\nprint(\"Node removed:\", node_idx)\nprint(\"Nodes remaining:\", g.vs.indices)\n\n\n\n\n\n\n\n\nNote\n\n\n\nnp.random.choice(array) takes an array array and returns a single element from the array. For example, np.random.choice(np.array([1, 2, 3])) returns either 1, 2, or 3 with equal probability. See the documentation for more details.\n\n\nThe connectivity of the network is the fraction of nodes in the largest connected component of the network after node removal. We can get the connected components of the network by using Graph.connected_components.\n\n\nCode\ncomponents = g.connected_components()\n\n\nThe sizes of the connected components are accessible via Graph.connected_components.sizes.\n\n\nCode\ncomponents.sizes()\n\n\nThus, the connectivity of the network can be computed by\n\n\nCode\ncomponents = g.connected_components()\nconnectivity = np.max(components.sizes()) / g_original.vcount()\nconnectivity\n\n\nPutting together the above code, let us compute the robustness profile of the network.\n\n\nCode\nimport pandas as pd\n\ng = g_original.copy() # restore the network\nn_nodes = g.vcount()  # Number of nodes\n\nresults = []\nfor i in range(n_nodes -1):  # Loop if the network has at least one node\n\n    # Remove a randomly selected node\n    node_idx = np.random.choice(g.vs.indices)\n    g.delete_vertices(node_idx)\n\n    # Evaluate the connectivity\n    components = g.connected_components()\n    connectivity = np.max(components.sizes()) / g_original.vcount()\n\n    # Save the results\n    results.append(\n        {\n            \"connectivity\": connectivity,\n            \"frac_nodes_removed\": (i + 1) / n_nodes,\n        }\n    )\n\ndf_robustness_profile = pd.DataFrame(results)\n\n\nLet us plot the robustness profile.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style='white', font_scale=1.2)\nsns.set_style('ticks')\n\nax = df_robustness_profile.plot(\n    x=\"frac_nodes_removed\",\n    y=\"connectivity\",\n    kind=\"line\",\n    figsize=(5, 5),\n    label=\"Random attack\",\n)\nplt.xlabel(\"Proportion of nodes removed\")\nplt.ylabel(\"Connectivity\")\nplt.legend().remove()\nplt.show()\n\n\n\n\n15.2.2 Targeted attack\nIn a targeted attack, nodes are removed based on specific criteria rather than randomly. One common strategy is to remove nodes from the largest node degree to the smallest, based on the idea that removing nodes with many edges is more likely to disrupt the network connectivity.\nThe degree of the nodes is accessible via Graph.degree.\n\n\nCode\nprint(g_original.degree())\n\n\nWe compute the robustness profile by removing nodes with the largest degree and measuring the connectivity of the network after each removal.\n\n\nCode\ng = g_original.copy() # restore the network\nn_nodes = g.vcount()  # Number of nodes\n\nresults = []\nfor i in range(n_nodes -1):  # Loop if the network has at least one node\n\n    # Remove the nodes with thelargest degree\n    node_idx = g.vs.indices[np.argmax(g.degree())]\n    g.delete_vertices(node_idx)\n\n    # Evaluate the connectivity\n    components = g.connected_components()\n    connectivity = np.max(components.sizes()) / g_original.vcount()\n\n    # Save the results\n    results.append(\n        {\n            \"connectivity\": connectivity,\n            \"frac_nodes_removed\": (i + 1) / n_nodes,\n        }\n    )\n\ndf_robustness_profile_targeted = pd.DataFrame(results)\n\n\n\n\nCode\nsns.set(style='white', font_scale=1.2)\nsns.set_style('ticks')\n\nsns.set(style=\"white\", font_scale=1.2)\nsns.set_style(\"ticks\")\n\nax = df_robustness_profile.plot(\n    x=\"frac_nodes_removed\",\n    y=\"connectivity\",\n    kind=\"line\",\n    figsize=(5, 5),\n    label=\"Random attack\",\n)\nax = df_robustness_profile_targeted.plot(\n    x=\"frac_nodes_removed\",\n    y=\"connectivity\",\n    kind=\"line\",\n    label=\"Targeted attack\",\n    ax=ax,\n)\nax.set_xlabel(\"Proportion of nodes removed\")\nax.set_ylabel(\"Connectivity\")\nax.legend(frameon=False)\nplt.show()\n\n\nWhile the network is robust against the random attacks, it is vulnerable to the degree-based targeted attack.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Coding: Minimum Spanning Trees and Network Robustness</span>"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#percolation",
    "href": "m03-robustness/02-coding.html#percolation",
    "title": "15¬† Coding: Minimum Spanning Trees and Network Robustness",
    "section": "15.3 Percolation",
    "text": "15.3 Percolation\nNetwork robustness can be viewed as a inverse process of percolation on a network. What is percolation? Imagine a grid where each square has a chance to become a little puddle. Two puddles are connected if they are next to each other. As more puddles appear, they start connecting with their neighbors to form bigger puddles. This is basically what percolation is all about! Random failure can be viewed as an inverse process of percolation, where a puddle is dried up (i.e., removed from the network),\n```cosctllcbou percolation\n\nImage taken from https://jamesmccaffrey.wordpress.com/2021/07/12/whatever-happened-to-percolation-theory/\n\nNow, the big question is: When the probability of a node being puddle is $p$, how big can our largest puddle get? üåä\nAs we increase the chance of puddles appearing (that's our $p$), the biggest puddle does not grow slowly but explodes in size when $p$ reaches a critical value $p_c$. This sudden change is what we call a *phase transition*! From the percolation perspective, we approach to the critical point from disconnected phase, whereas from the network robustness perspective, we approach to the critical point from connected phase.\n\n::: {#75de8d4f .cell}\n``` {.python .cell-code}\n:tags: [\"hide-input\"]\n\nimport igraph as ig\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef percolate(g, p):\n    return g.subgraph(np.where(np.random.rand(g.vcount()) &lt; p)[0])\n\n\ndef largest_cluster_size(g):\n    return g.connected_components().giant().vcount()\n\n\nn, nei = 500, 1\ng = ig.Graph.Lattice([n, n], nei=nei, directed=False, mutual=False, circular=False)\n\np_values = np.linspace(0, 1, 20)\nlargest_sizes = [largest_cluster_size(percolate(g, p)) / n**2 for p in p_values]\n\nsns.set(style=\"ticks\", font_scale=1.2)\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.lineplot(x=p_values, y=largest_sizes, ax=ax, marker=\"o\")\nax.set(\n    xlabel=\"Probability (p)\",\n    ylabel=\"Fractional Largest Cluster Size\",\n    title=\"Percolation on a 500x500 Lattice\",\n)\nsns.despine()\n\ncritical_p = 0.592746  # Critical probability for 2D square lattice\ncolors = sns.color_palette(\"colorblind\", 3)\nax.axvline(x=critical_p, color=\"k\", linestyle=\"--\", alpha=0.7)\nax.fill_betweenx(\n    y=[0, 1], x1=0, x2=critical_p, alpha=0.2, color=colors[0], label=\"Disconnected\"\n)\nax.fill_betweenx(\n    y=[0, 1], x1=critical_p, x2=1, alpha=0.2, color=colors[1], label=\"Connected\"\n)\nax.legend().remove()\n\nax.annotate(\n    \"Disconnected\",\n    xy=(0.3, 0.5),\n    xytext=(0.4, 0.1),\n    textcoords=\"data\",\n    horizontalalignment=\"right\",\n    verticalalignment=\"center\",\n    fontsize=14,\n    fontweight=\"bold\",\n)\nax.annotate(\n    \"Connected\",\n    xy=(0.9, 0.5),\n    xytext=(0.7, 0.1),\n    textcoords=\"data\",\n    horizontalalignment=\"left\",\n    verticalalignment=\"center\",\n    fontsize=14,\n    fontweight=\"bold\",\n)\nax.set_xlim(0, 1)\n\n:::\n\nWant to see this in action? üåü Check out this interactive simulation.\nPlay around with it and watch how the puddles grow and connect. üåä\n\n[Bernoulli Percolation Simulation üåê](https://visualize-it.github.io/bernoulli_percolation/simulation.html) üîó\n\n\nThe transition at $p_c$ is discontinuous in the limit of large $N$, called *first-order phase transition*.\nIn practice, it is often a continuous transition because of the finite size of the network.\n\n\n15.3.1 A criterion for the giant component\nPercolation theory focuses on lattice, a regular structure that is rare in real-world networks. What happens if the network has a complex structure? The Molloy-Reed criterion {footcite}molloy1995critical provides a simple condition for the existence of a giant component in a rewired network. It states that a giant component is likely to exist if:\n\n\\kappa_0 := \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} &gt; 2\n\nwhere k is the degree of a node, and \\langle k \\rangle and \\langle k^2 \\rangle are the average degree and the average of the square of the degree, respectively. The variable \\kappa_0 is a shorthand for the ratio. See the Appendix for the derivation of this criterion.\nWhat does \\kappa_0 represent? It represents the heterogeneity of the degree distribution. For example, a high \\kappa_0 indicates that there are a few nodes with very high degrees and many nodes with low degrees. When \\kappa_0 is small, the nodes have similar degree. And Molloy-Reed criterion tells us an important fact about the role of degree distributions on the robustness of networks: the more heterogeneous the degree distribution is, the more likely the network is to have a giant component.\n\n\nCode\n:tags: [\"remove-input\"]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import uniform, poisson, lognorm\n# Set Seaborn style\nsns.set_style('white')\nsns.set(font_scale=1.5)\nsns.set_style('ticks')\n\n# Set up the plot\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\nfig.suptitle('Degree distributions with different $\\\\kappa_0$ values with the same mean $\\\\langle k \\\\rangle=5$')\n\n# Set the average degree\navg_k = 5\nsamples = 3000\n\n# Uniform distribution\nk_uniform = np.array([avg_k] * samples)\n\n# Poisson distribution\nk_poisson = np.random.poisson(avg_k, size=samples)\n\n# Log-normal distribution\nk_lognorm = np.random.lognormal(mean=0, sigma=1, size=samples)\nk_lognorm = k_lognorm * avg_k / np.mean(k_lognorm)\n\n\n# Plot histograms\nsns.histplot(k_uniform, ax=axs[0], kde=True, stat=\"density\", discrete=True)\naxs[0].set_title(f'Uniform\\n$\\\\kappa_0 = {np.mean(k_uniform**2) / np.mean(k_uniform):.2f}$')\naxs[0].set_xlim(0, 10)\n\nsns.histplot(k_poisson, ax=axs[1], kde=True, stat=\"density\", discrete=True)\naxs[1].set_title(f'Poisson\\n$\\\\kappa_0 = {np.mean(k_poisson**2) / np.mean(k_poisson):.2f}$')\n\nsns.histplot(k_lognorm, ax=axs[2], kde=True, stat=\"density\", bins=20)\naxs[2].set_title(f'Log-normal\\n$\\\\kappa_0 = {np.mean(k_lognorm**2) / np.mean(k_lognorm):.2f}$')\n\n# Set labels and adjust layout\nfor ax in axs:\n    ax.set_xlabel('Degree (k)')\n    ax.set_ylabel('Density')\n\nplt.tight_layout()\nsns.despine()\n\n\nThe rewired network considered here is **the configuration model**, where the edges are rewired randomly while keeping the degree distribution fixed. We will discuss more about the configuration model later.\n\n\n\n15.3.2 How many nodes are needed to break a network?\nWhen does a network become disconnected? Based on the Molloy-Reed criterion, we can identify the critical fraction of nodes f_c that need to be removed for the giant component to disappear in a network with an arbitrary degree distribution. This critical point is given by {footcite}cohen2000resilience:\n\nf_c = 1 - \\frac{1}{\\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} - 1}\n\nSee the Appendix for the derivation of this criterion.\nLet us illustrate this by considering two kinds of networks:\nDegree homogeneous network:\nIn case of a degree homogeneous network like a random network considered in the exercise above,\n\nf_c = 1 - \\frac{1}{\\langle k \\rangle}\n\nThis suggests that the threshold is determined by the average degree \\langle k \\rangle. A large \\langle k \\rangle results in a larger f_c, meaning that the network is more robust against random failures.\nDegree heterogeneous network:\nMost real-world networks are degree heterogeneous, i.e., the degree distribution P(k) \\sim k^{-\\gamma} follows a power law (called scale-free network). In this case, f_c is given by\n\nf_c =\n\\begin{cases}\n1 - \\dfrac{1}{\\frac{\\gamma-2}{3-\\gamma} k_{\\text{min}} ^{\\gamma-2} k_{\\text{max}}^{3-\\gamma} -1} & \\text{if } 2 &lt; \\gamma &lt; 3 \\\\\n1 - \\dfrac{1}{\\frac{\\gamma-2}{3-\\gamma} k_{\\text{min}} - 1} & \\text{if } \\gamma &gt; 3 \\\\\n\\end{cases}\n\nwhere k_{\\text{min}} and k_{\\text{max}} are the minimum and maximum degree, respectively. The variable \\gamma is the exponent of the power law degree distribution, controlling the degree heterogeneity, where a lower \\gamma results in a more degree heterogeneous network.\n\nFor regime 2 &lt; \\gamma &lt; 3, the critical threshold f_c is determined by the extreme values of the degree distribution, k_{\\text{min}} and k_{\\text{max}}. And f_c \\rightarrow 1 when the maximum degree k_{\\text{max}} \\in [k_{\\text{min}}, N-1] increases. Notably, in this regime, the maximum degree k_{\\text{max}} increases as the network size N increases, and this makes f_c \\rightarrow 1.\nFor regime \\gamma &gt; 3, the critical threshold f_c is influenced by the minimum degree k_{\\text{min}}. In contrast to k_{\\text{max}}, k_{\\text{min}} remains constant as the network size N grows. Consequently, the network disintegrates when a finite fraction of its nodes are removed.\n\n\n\n15.3.3 Case study: Airport network\nLet‚Äôs consider an empirical network of international airports, where nodes are airports and edges denote a regular commercial flight between two airports.\nData loading:\n\n\nCode\n:tags: [\"hide-input\", \"hide-output\"]\n\n# Import necessary libraries\nimport igraph as ig\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Load the airport network data from a CSV file\ndf = pd.read_csv(\"https://raw.githubusercontent.com/skojaku/core-periphery-detection/master/data/edge-table-airport.csv\")\n\n# Process the edge data\nedges = df[[\"source\", \"target\"]].to_numpy()\nedges = np.unique(edges.reshape(-1), return_inverse=True)[1]\nedges = edges.reshape(-1, 2)\n\n# Create the original graph\ng = ig.Graph()\ng.add_vertices(np.unique(edges) + 1)\ng.add_edges([tuple(edge) for edge in edges])\n\n\nBased on the argument above, we can predict the critical point f_c for the airport network as follows:\n\n\nCode\nimport numpy as np\n\ng # igraph object of the airport network\n\n# Compute the degree distribution\ndeg = np.array(g.degree())\n\nk_ave = np.mean(deg)\nk_2 = np.mean(deg **2)\n\n# Compute the critical fraction of nodes that need to be removed (prediction)\nf_c = 1 - 1 / (k_2 / k_ave - 1)\nprint(f\"The critical fraction of nodes that need to be removed is predicted to be {f_c:.3f}\")\n\n\nThe f_c is very close to 1, meaning that the network is highly robust to random failures that it keeps the giant component until when almost all nodes are removed. Let us confirm this by simulating the random failures.\n\n\nCode\n:tags: [\"hide-input\"]\n\n# Create a copy of the original graph for manipulation\ng_damaged = g.copy()\nn_nodes = g.vcount()  # Number of nodes in the graph\n\n# Initialize list to store results\nresults = []\n\n# Simulate random node removal and measure network connectivity\nfor i in range(n_nodes - 1):  # Loop until only one node remains\n\n    # Randomly select and remove a node\n    node_idx = np.random.choice(g_damaged.vs.indices)\n    g_damaged.delete_vertices(node_idx)\n\n    # Evaluate the connectivity of the remaining network\n    components = g_damaged.connected_components()\n    connectivity = np.max(components.sizes()) / g.vcount()\n\n    # Save the results\n    results.append(\n        {\n            \"connectivity\": connectivity,\n            \"frac_nodes_removed\": (i + 1) / n_nodes,\n        }\n    )\n\n# Convert results to a DataFrame\ndf_robustness_profile = pd.DataFrame(results)\n\n# Set up the plot style\nsns.set(style='white', font_scale=1.2)\nsns.set_style('ticks')\n\n# Create the plot\nax = df_robustness_profile.plot(\n    x=\"frac_nodes_removed\",\n    y=\"connectivity\",\n    kind=\"line\",\n    figsize=(5, 5),\n    label=\"Random attack\",\n    linewidth=2,\n    color = sns.color_palette()[0]\n)\n\n# Set labels for x and y axes\nplt.xlabel(\"Proportion of nodes removed\")\nplt.ylabel(\"Fractional size of largest component\")\n\n# Remove the legend\nplt.legend().remove()\n\n# Add a diagonal line from top left to bottom right\nax.plot([0, 1], [1, 0], color='gray', linestyle='--')\n\n# Adjust the plot limits to ensure the diagonal line is visible\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\n\n# Add a vertical line at the critical fraction\nax.axvline(x=f_c, color='red', linestyle='--', alpha=0.7, label=\"Critical fraction\")\n\n# Remove top and right spines of the plot\nsns.despine()\n\n\nThe robustness profile of the airport network shows a very robust nature of the network, i.e., the airport network keeps the giant component until almost all nodes are removed.\n\n\n15.3.4 Targeted attacks\nA key implication of the random failures is that a hub plays a critical role in holding the network together. This also implies a vulnerability of the network to targeted attacks. Namely, if we remove the hub preferentially, the network can be quickly disconnected into small components.\nOne can consider a targeted attack as a process of reducing the degree of nodes in a network. The degree-based attack, for example, reduces the maximum degree of the network, together with the degrees of neighboring nodes. An effective attack is one that quickly breaks the Molloy-Reed criterion, and from this perspective, the degree-based attack is not effective because it reduces the maximum degree of the network, a major contributor to the degree heterogeneity, \\kappa_0.\n\n\n15.3.5 How to design a robust network?\nBased on the percolation theory, how we do we design a network that is robust against random failures and targeted attacks? Two key ingredients are:\n\nDegree heterogeneity: As we have seen in the percolation theory, the more heterogeneous the degree distribution is, the more likely the network is to have a giant component.\nResilience to hub removal: A network is vulnerable to targeted attacks if the removal of a single node significantly decreases the heterogeneity of the degree distribution. The most susceptible structure is a star graph, where a central node connects to all other nodes, as removing this central node will disconnect the network.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Coding: Minimum Spanning Trees and Network Robustness</span>"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html",
    "href": "m03-robustness/03-exercises.html",
    "title": "16¬† Robustness Analysis - Exercises",
    "section": "",
    "text": "16.1 Percolation Theory and Network Connectivity\nConsider a random network of N nodes, where every pair of nodes are connected by an edge with a certain probability. The degree k of a node follows a binomial distribution, which we approximate by a Poisson random variable with mean \\langle k \\rangle and variance \\langle k \\rangle.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Robustness Analysis - Exercises</span>"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#percolation-theory-and-network-connectivity",
    "href": "m03-robustness/03-exercises.html#percolation-theory-and-network-connectivity",
    "title": "16¬† Robustness Analysis - Exercises",
    "section": "",
    "text": "Derive \\langle k^2 \\rangle using \\langle k \\rangle.\n\nHint: Variance is defined as \\text{Var}(k) = \\langle (k-\\langle k \\rangle)^2 \\rangle.\n\nCompute the ratio \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}.\nCheck when the network satisfies the Molloy-Reed criterion.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSolution for Q1: To derive \\langle k^2 \\rangle, we start with the definition of variance\n\\text{Var}(k) = \\langle (k - \\langle k \\rangle)^2 \\rangle\nExpanding the square, we get\n\\text{Var}(k) = \\langle k^2 \\rangle - 2\\langle k \\rangle \\langle k \\rangle + \\langle k \\rangle^2\nSince \\text{Var}(k) = \\langle k \\rangle for a Poisson distribution, we can substitute and rearrange\n\\langle k \\rangle = \\langle k^2 \\rangle - \\langle k \\rangle^2\nSolving for \\langle k^2 \\rangle, we obtain\n\\langle k^2 \\rangle = \\langle k \\rangle + \\langle k \\rangle^2\nSolution for Q2: \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} = 1 + \\langle k \\rangle\nSolution for Q3: \\langle k \\rangle &gt;1. In other words, if a node has on average more than one neighbor, the random network is likely to have a giant component.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Robustness Analysis - Exercises</span>"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#robust-network-design",
    "href": "m03-robustness/03-exercises.html#robust-network-design",
    "title": "16¬† Robustness Analysis - Exercises",
    "section": "16.2 Robust Network Design",
    "text": "16.2 Robust Network Design\nDesign strategies for networks that must withstand both random failures and targeted attacks present unique challenges. Consider the trade-offs between different network topologies and their resilience properties.\nChallenge: What design strategy makes a network robust against targeted attacks? Design a network that is robust against both random failures and targeted attacks.\n{{ ‚ÄòüöÄ Interactive Demo‚Äô.replace(‚ÄòBASE_URL‚Äô, base_url) }}\n\n\n\n\n\n\nDesign Strategy\n\n\n\n\n\nA bimodal degree distribution can enhance network robustness against both random failures and targeted attacks. In this setup, (1-r) portion of nodes have a degree of 1, while r portion of nodes have a high degree, k_{\\text{max}}.\nThis structure ensures that the network remains connected even if a hub is removed, as other hubs maintain the connectivity. It also withstands random failures due to its heterogeneous degree distribution.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Robustness Analysis - Exercises</span>"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#power-grid-network-design",
    "href": "m03-robustness/03-exercises.html#power-grid-network-design",
    "title": "16¬† Robustness Analysis - Exercises",
    "section": "16.3 Power Grid Network Design",
    "text": "16.3 Power Grid Network Design\nReal-world infrastructure design requires balancing multiple objectives: cost efficiency, reliability, and robustness. Power grids exemplify this challenge perfectly.\nChallenge: Design a cost-effective power grid network using minimum spanning tree concepts. Consider the trade-offs between cost minimization and network robustness.\n\n‚úçÔ∏è Pen and Paper Exercise\n\nThis exercise bridges theoretical network concepts with practical engineering constraints, demonstrating how robustness analysis guides infrastructure investment decisions.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Robustness Analysis - Exercises</span>"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html",
    "href": "m03-robustness/04-appendix.html",
    "title": "17¬† Appendix",
    "section": "",
    "text": "17.1 Derivation of the Molloy-Reed criterion\nMolloy and Reed derived the following criterion for an existence of a giant component in a network with an arbitrary degree distribution {footcite}molloy1995critical. It is based on a simple heuristic argument: the network has a giant component when a random node i with neighbor j has, on average, is connected to at least one other node. We write the condition as\n\\langle k_i \\vert i \\leftrightarrow j \\rangle = \\sum_{k} k P(k \\vert i \\leftrightarrow j) &gt; 2\nwhere \\langle k_i \\vert i \\leftrightarrow j \\rangle is the conditional average degree of node i given that it is connected to node j. From Bayes‚Äô theorem, we have\nP(k_i \\vert i \\leftrightarrow j) = \\frac{P(i \\leftrightarrow j \\vert k_i) P(k_i)}{P(i \\leftrightarrow j)}\nAssuming that the network is uncorrelated and sparse (meaning, we neglect loops), then P(i \\leftrightarrow j \\vert k_i) = k_i / (N-1) and P(i \\leftrightarrow j) = \\langle k \\rangle / (N-1). Substituting these into the above equation, we get\nP(k_i \\vert i \\leftrightarrow j) = \\frac{k_i P(k_i)}{\\langle k \\rangle}\nThus, the condition for the existence of a giant component is\n\\frac{1}{\\langle k \\rangle} \\sum_{k_i} k_i^2 P(k_i) = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} &gt; 2",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html#derivation-of-the-percolation-threshold-for-a-random-attack.",
    "href": "m03-robustness/04-appendix.html#derivation-of-the-percolation-threshold-for-a-random-attack.",
    "title": "17¬† Appendix",
    "section": "17.2 Derivation of the percolation threshold for a random attack.",
    "text": "17.2 Derivation of the percolation threshold for a random attack.\nAssume a fraction p of nodes are removed independently from the network. The removal of nodes reduces the connectivity of the network and the degree of the remaining nodes. The probability that a node with initial degree k_0 reduces its degree to k follows a binomial distribution,\n\nP(k \\vert k_0, p) = \\binom{k_0}{k} (1-p)^k p^{k_0-k}\n\nConsidering all nodes, the new degree distribution is given by\n\nP'(k) = \\sum_{k_0 = k}^{\\infty} P(k_0) \\binom{k_0}{k} (1-p)^k p^{k_0-k}\n\nTo connect with the Molloy-Reed criterion, we need to compute the first and second moments, denoted by \\langle k \\rangle' and \\langle k^2 \\rangle', of the new degree distribution.\n\n\\begin{align}\n\\langle k \\rangle' &= \\sum_{k} k P'(k_0) \\\\\n&= \\sum_{k} \\sum_{k_0=k}^{\\infty} k \\binom{k_0}{k} (1-p)^k p^{k_0-k} P(k_0) \\\\\n&= \\sum_{k_0=0}^\\infty P(k_0) \\underbrace{\\sum_{k} k \\binom{k_0}{k} (1-p)^k p^{k_0-k}}_{\\text{Expected value of $k$ for a binomial distribution}} \\\\\n&= \\sum_{k_0=0}^\\infty P(k_0) k_0 (1-p) \\\\\n&= \\langle k_0 \\rangle (1-p)\n\\end{align}\n\nSimilarly, we can compute the second moment, which is given by\n\n\\langle k^2 \\rangle' = \\langle k_0^2 \\rangle (1-p)^2 + \\langle k_0 \\rangle p (1-p)\n\nBy substituting these into the Molloy-Reed criterion, we get\n\n\\frac{\\langle k^2 \\rangle'}{\\langle k \\rangle'}  = \\frac{\\langle k_0^2 \\rangle (1-p)^2 + \\langle k_0 \\rangle p (1-p)}{\\langle k_0 \\rangle (1-p)} = \\frac{\\langle k_0^2 \\rangle (1-p) + \\langle k_0 \\rangle p}{\\langle k_0 \\rangle} &gt; 2\n\nBy solving the inequality for p, we get the percolation threshold for a random attack,\n\n1-p &lt; \\frac{1}{\\langle k_0 ^2 \\rangle / \\langle k_0 \\rangle - 1}\n\nwhich is the condition for the existence of a giant component.",
    "crumbs": [
      "M03: Robustness",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html",
    "href": "m04-friendship-paradox/00-preparation.html",
    "title": "18¬† Preparation: Statistical Sampling and Probability Prerequisites",
    "section": "",
    "text": "18.1 Required Knowledge from Previous Modules\nBefore studying the friendship paradox, ensure you understand: - From M01-M03: Basic network concepts (degree, adjacency matrix, connectivity) - General math: Basic calculus and linear algebra",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Preparation: Statistical Sampling and Probability Prerequisites</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#probability-theory-fundamentals",
    "href": "m04-friendship-paradox/00-preparation.html#probability-theory-fundamentals",
    "title": "18¬† Preparation: Statistical Sampling and Probability Prerequisites",
    "section": "18.2 Probability Theory Fundamentals",
    "text": "18.2 Probability Theory Fundamentals\n\n18.2.1 Random Variables and Distributions\nUnderstanding of discrete probability distributions: - Probability mass function: P(X = k) for discrete random variable X - Expected value: E[X] = \\sum_{k} k \\cdot P(X = k)\n- Variance: \\text{Var}(X) = E[X^2] - (E[X])^2\n\n\n18.2.2 Conditional Probability\nEssential for understanding biased sampling: - Conditional probability: P(A|B) = \\frac{P(A \\cap B)}{P(B)} - Law of total expectation: E[X] = E[E[X|Y]]",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Preparation: Statistical Sampling and Probability Prerequisites</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#sampling-theory",
    "href": "m04-friendship-paradox/00-preparation.html#sampling-theory",
    "title": "18¬† Preparation: Statistical Sampling and Probability Prerequisites",
    "section": "18.3 Sampling Theory",
    "text": "18.3 Sampling Theory\n\n18.3.1 Population vs.¬†Sample\n\nPopulation parameters: True values in the complete dataset\nSample statistics: Measured values from a subset\nSampling bias: When sample doesn‚Äôt represent population\n\n\n\n18.3.2 Types of Sampling\n\nSimple random sampling: Each individual has equal probability of selection\nWeighted sampling: Selection probability proportional to some attribute\nSize-biased sampling: Larger items more likely to be selected\n\n\n\n18.3.3 Jensen‚Äôs Inequality\nFor convex functions and random variables: E[f(X)] \\geq f(E[X])\nThis inequality is fundamental to understanding why averages of friends differ from friends of averages.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Preparation: Statistical Sampling and Probability Prerequisites</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#mathematical-prerequisites",
    "href": "m04-friendship-paradox/00-preparation.html#mathematical-prerequisites",
    "title": "18¬† Preparation: Statistical Sampling and Probability Prerequisites",
    "section": "18.4 Mathematical Prerequisites",
    "text": "18.4 Mathematical Prerequisites\n\n18.4.1 Basic Statistical Moments\n\nFirst moment: Mean \\mu = E[X]\nSecond moment: E[X^2]\n\nRelationship: E[X^2] \\geq (E[X])^2 with equality only when X is constant\n\n\n\n18.4.2 Linear Algebra Basics\n\nMatrix operations: For adjacency matrix manipulations\nVector operations: For degree calculations",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Preparation: Statistical Sampling and Probability Prerequisites</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#applications-context",
    "href": "m04-friendship-paradox/00-preparation.html#applications-context",
    "title": "18¬† Preparation: Statistical Sampling and Probability Prerequisites",
    "section": "18.5 Applications Context",
    "text": "18.5 Applications Context\n\n18.5.1 Survey Methodology\nUnderstanding how data collection methods can introduce bias: - Response bias: Who is more likely to participate in surveys - Selection effects: How sampling frames affect results\n\n\n18.5.2 Network Effects in Epidemiology\nBasic concepts about disease spread: - Contact networks: How diseases spread through social connections - Vaccination strategies: Targeting high-contact individuals\nThese mathematical foundations will help you understand the counterintuitive but mathematically precise friendship paradox phenomenon.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Preparation: Statistical Sampling and Probability Prerequisites</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html",
    "href": "m04-friendship-paradox/01-concepts.html",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "",
    "text": "19.1 What We Learn in This Module\nIn this module, we will learn about the friendship paradox. Specifically: - Friendship paradox: what is it, why it‚Äôs important, and what are the consequences? - Keywords: friendship paradox, degree bias",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#in-class-experiment",
    "href": "m04-friendship-paradox/01-concepts.html#in-class-experiment",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.2 In-Class Experiment",
    "text": "19.2 In-Class Experiment\n‚ÄúYour friends have more friends than you‚Äù is a well-known phenomenon in social networks. It appears everywhere from physical social networks to online social networks, and even random networks! OK. Let‚Äôs do not ‚Äúthink‚Äù but ‚Äúfeeeeel‚Äù this paradox through the following in-class experiment.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#experiment-materials-and-procedure",
    "href": "m04-friendship-paradox/01-concepts.html#experiment-materials-and-procedure",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.3 Experiment Materials and Procedure",
    "text": "19.3 Experiment Materials and Procedure\nMaterials: - üìá Friendship card - üñäÔ∏è Pen\nFriendship Network Experiment:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n\n   1. [üìá] Receive Your Card\n      Get a card with a unique letter\n\n   2. [ü§ù] Meet and Greet (5 mins)\n      Move around, exchange cards with at least one friend\n\n   3. [üßÆ] Count Connections (2 mins)\n      Count received cards, write number, return cards\n\n   4. [üìà] Calculate Average (2 mins)\n      Calculate average 'friend count' of your friends\n\n   5. [üìù] Fill Form\n      Write your average and your own friend count\n      in a separate sheet\n\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n‚ùó Important Notes:\n  ‚Ä¢ This is a fun experiment, not a popularity contest\n  ‚Ä¢ Be respectful and inclusive during the meet and greet\n  ‚Ä¢ If you finish early, wait patiently for further instructions",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#the-friendship-paradox-explained",
    "href": "m04-friendship-paradox/01-concepts.html#the-friendship-paradox-explained",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.4 The Friendship Paradox Explained",
    "text": "19.4 The Friendship Paradox Explained",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#the-origin-of-the-friendship-paradox",
    "href": "m04-friendship-paradox/01-concepts.html#the-origin-of-the-friendship-paradox",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.5 The Origin of the Friendship Paradox",
    "text": "19.5 The Origin of the Friendship Paradox\nThe paradox arises not because of the way we form friendships. It‚Äôs about measurement! For example a person with 100 friends generates 100 cards, while a person with 1 friend generates only 1 card. If we average friend counts over the cards, popular people are counted more. This is where the friendship paradox comes from.\nIn network terms, cards represent edges and people represent nodes. The friendship paradox arises because we measure at different levels: nodes or edges. The average friend count at the node level is lower than at the edge level because popular people are counted more often at the edge level.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#key-questions-to-consider",
    "href": "m04-friendship-paradox/01-concepts.html#key-questions-to-consider",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.6 Key Questions to Consider",
    "text": "19.6 Key Questions to Consider\n\nüéâ Fun Challenge: Can you create a network where your friends have the most friends? ü§îüí° Give it a try in this Friendship Paradox Game! üéÆ‚ú®\nQuestion: Can you create a network where the friendship paradox is absent? In other words, can you create a graph, where your friends have the same number of friends as you?",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#practical-applications-vaccination-game",
    "href": "m04-friendship-paradox/01-concepts.html#practical-applications-vaccination-game",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.7 Practical Applications: Vaccination Game",
    "text": "19.7 Practical Applications: Vaccination Game\nBeyond an interesting trivia, the friendship paradox has many practical utilities.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#strategic-vaccination",
    "href": "m04-friendship-paradox/01-concepts.html#strategic-vaccination",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.8 Strategic Vaccination",
    "text": "19.8 Strategic Vaccination\nThe friendship paradox has important implications for public health strategies. By understanding that highly connected individuals are more likely to be selected through their connections, we can develop more effective vaccination strategies.\n\nüéâ Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? ü§îüí° Give it a try in this Vaccination Game! üéÆ‚ú®",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#why-vaccination-strategy-works",
    "href": "m04-friendship-paradox/01-concepts.html#why-vaccination-strategy-works",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.9 Why Vaccination Strategy Works",
    "text": "19.9 Why Vaccination Strategy Works\nWhen we vaccinate people chosen through the friendship paradox principle: 1. We‚Äôre more likely to vaccinate highly connected individuals 2. Highly connected people are more likely to spread diseases 3. Vaccinating them creates a disproportionate impact on disease spread 4. This strategy is more effective than random vaccination",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#mathematical-foundation",
    "href": "m04-friendship-paradox/01-concepts.html#mathematical-foundation",
    "title": "19¬† M04 Concepts: The Friendship Paradox",
    "section": "19.10 Mathematical Foundation",
    "text": "19.10 Mathematical Foundation\nThe friendship paradox can be understood through the concept of degree bias:\n\nNode sampling: Selecting people randomly gives equal weight to everyone\nEdge sampling: Selecting people through their connections gives higher weight to popular people\nResult: Edge sampling systematically overrepresents high-degree nodes\n\nThis mathematical insight has applications beyond friendships, including: - Social network analysis - Epidemiology and disease control - Marketing and influence strategies - Network robustness and vulnerability assessment",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>M04 Concepts: The Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/02-coding.html",
    "href": "m04-friendship-paradox/02-coding.html",
    "title": "20¬† Degree distribution",
    "section": "",
    "text": "20.1 Visualization basics\nUnderstanding degree distribution is the first key step to understand networks! And often, we want to see how the degree distribution looks like by plotting it like using histogram. But, it is not as easy as it may seem‚Ä¶\nTo learn the basics of data visualization, please take a pen and paper exercise.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Degree distribution</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/02-coding.html#coding-exercise",
    "href": "m04-friendship-paradox/02-coding.html#coding-exercise",
    "title": "20¬† Degree distribution",
    "section": "20.2 Coding exercise",
    "text": "20.2 Coding exercise\nExercise: Plotting degree distribution\n\n20.2.1 Plotting degree distribution\n(The following content includes the answer to the exercise. So please do the exercise first before reading the following content.)\nWe will first introduce a formal definition of the degree distribution. Then, we will learn how to plot the degree distribution of a network.\nThe degree of a node i, denoted by d_i, is the number of edges connected to it. With the adjacency matrix A, the degree of node i is given by:\n\nk_i = \\sum_{j=1}^N A_{ij}.\n\nLet us compute the degree distribution of a network. We will create a Barab√°si-Albert network with N=10,000 nodes and m=1 edge per node.\n\n\nCode\nimport igraph\ng = igraph.Graph.Barabasi(n = 10000, m = 1) # Create a Barab√°si-Albert network\nA = g.get_adjacency() # Get the adjacency matrix\n\n\nCompute the degree of each node by summing the elements of the adjacency matrix along the rows.\n\n\nCode\nimport numpy as np\ndeg = np.sum(A, axis=1)\ndeg = deg.flatten()\n\n\nThe degree distribution p(k) can be computed by counting the number of nodes with each degree and dividing by the total number of nodes.\n\n\nCode\np_deg = np.bincount(deg) / len(deg)\n\n\nLet us plot the degree distribution. This is not as trivial as you might think‚Ä¶ ü§î\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\n\n\nWhile it clearly shows that most nodes have small degree, it does not show the tail of the distribution clearly, and often it is this tail that is of great interest (e.g., hub nodes). To show the tail of the distribution more clearly, we can use a log-log plot.\n\n\nCode\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_ylim(np.min(p_deg[p_deg&gt;0])*0.01, None)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\n\n\nWe see fluctuations for large degree nodes because of the small number of nodes with large degree. One can use ‚Äúbinning‚Äù to smooth the plot. Binning involves grouping the data into bins and calculating the fraction of data within each bin. However, selecting an appropriate bin size can be challenging, and even with a well-chosen bin size, some information may be lost.\nA more convenient way is to use the complementary cumulative distribution function (CCDF). The CCDF at degree k is the probability that a randomly chosen node has degree k' greater than k (k' &gt; k). For a visual comparison of CCDF and PDF, see Figure 3 in {footcite}newman2005power or the arxiv version\n\n\\text{CCDF}(k) = P(k' &gt; k) = \\sum_{k'=k+1}^\\infty p(k')\n\n\nCCDF is a monotonically decreasing function of k.\nCCDF encompasses the full information of p(k), i.e., taking the derivative of CCDF gives p(k).\nCCDF can be plotted as a smooth curve on a log-log scale without binning.\n\n\n\nCode\nccdf_deg = 1 - np.cumsum(p_deg)[:-1] # 1 - CDF (cumulative distribution function).\n# The last element is excluded because it is always 1, resulting in CCDF=0, which cannot be plotted on a log-log scale.\n\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\n\n\n\n\nCode\n:tags: [remove-cell]\nfrom myst_nb import glue\n\ncdf_deg = np.cumsum(p_deg)\nfig, ax = plt.subplots(figsize=(3,3))\nax = sns.lineplot(x=np.arange(len(cdf_deg)), y=cdf_deg, ax = ax)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CDF')\nglue(\"cdf_fig\", fig, display=False)\n\n\n\n\n\n\n\n\nNote\n\n\n\nCCDF (complementary cumulative distribution function) is used instead of CDF (cumulative distribution function) because it highlights the tail of the distribution better in a log-log plot. A log scale expands small values and compresses large values. In a CDF, large degree nodes have values close to 1, compressing the tail. In a CCDF, large degree nodes have small values, making the tail more visible. npxnxb cdf_fig :align: center\n\n\nThe slope of the CCDF tells us the heterogeneity of the degree distribution. - Steep slope: more homogeneous degree distribution (similar degrees) - Flat slope: more heterogeneous degree distribution (wide range of degrees)\nThe slope of the CCDF is related to the power-law exponent of the degree distribution. A power-law degree distribution is described by a continuous distribution with the density function (not the probability mass) p(d) given by {footcite}clauset2009power:\n\np(k) = \\frac{\\gamma-1}{k_{\\min}} \\left( \\frac{k}{k_{\\min}} \\right)^{-\\gamma}\n\nwhere: - p(k) is the probability density of a node having degree k - \\gamma is the power-law exponent - k_{\\min} is the minimum degree\n\n\n\n\n\n\nNote\n\n\n\nThe degree distribution is discrete but often approximated by a continuous distribution for mathematical convenience. While generally accurate, caution is needed as the reliability varies depending on the range of the degrees. See {footcite}clauset2009power for more details.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe power-law distribution is ill-defined for d=0, which is why there must be a minimum degree d_{\\min} to avoid this issue.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere has been a long-standing debate in network science as to whether the power-law well represents the real-world networks. Power-law is just one of many possible distributions with a heavy tail (i.e., a long tail on the right side of the distribution), and other distributions may also fit the data well such as log-normal distribution. This discussion is critical as many theories in network science are built on the assumption of the form of the degree distribution. See {footcite}artico2020rare,holme2019rare,voitalov2019scale,barabasi2003scale for the debate.\n\n\nThe CCDF for the power-law distribution is given by:\n\n\\begin{aligned}\n\\text{CCDF}(k) &= 1 - \\int_{k_{\\min}}^k p(x) {\\rm d}x \\\\\n  &= 1 - \\frac{\\gamma -1}{k_{\\min}}\\cdot \\frac{1}{1 - \\gamma} \\left[\n\\left(\\frac{k^{-\\gamma + 1}}{k_{\\min}^{-\\gamma}}\\right) - \\left(\\frac{k_{\\min} ^{-\\gamma + 1}}{k_{\\min} ^{-\n\\gamma}}\\right)\\right] \\\\\n&= \\left( \\frac{k}{k_{\\min}}\\right)^{-\\gamma + 1}\n\\end{aligned}\n\nTaking the logarithm:\n\n\\log \\left[ \\text{CCDF}(k) \\right] = (-\\gamma + 1) \\cdot \\log k + \\text{const.}\n\nThus, the slope of the CCDF in a log-log plot is related to the power-law exponent \\gamma. Specifically, a steeper negative slope (i.e., a more negative value of -\\gamma + 1) corresponds to a larger \\gamma. A larger \\gamma indicates a more homogeneous degree distribution, where the probability of finding nodes with very high degrees decreases more rapidly. Conversely, a flatter slope (i.e., a value of -\\gamma + 1 being closer to zero) corresponds to a smaller \\gamma. A smaller \\gamma indicates a more heterogeneous degree distribution, where there‚Äôs a high probability of finding nodes with high degrees compared to that with a large \\gamma value.\nFor students interested in real-world examples of the CCDF plot, refer to Figure 4 in {footcite}newman2005power, or the arxiv version\nIn sum, the CCDF in a log-log plot provides a convenient visual summary of the degree distribution, with the slope of the CCDF providing a measure of the heterogeneity of the degree distribution.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Degree distribution</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/02-coding.html#degree-distribution-of-a-friend",
    "href": "m04-friendship-paradox/02-coding.html#degree-distribution-of-a-friend",
    "title": "20¬† Degree distribution",
    "section": "20.3 Degree distribution of a friend",
    "text": "20.3 Degree distribution of a friend\nContinuing from the previous page, we will now consider the degree distribution of a friend of a node.\nThere are two ways to sample a friend of a node. 1. Sample a node uniformly at random and then sample a friend of the node. 2. Sample a friendship (i.e., edge) uniformly at random and then sample an end node of the edge.\nLet us focus on the second case and leave the first case for interested students as an exercise. In the second case, we sample an edge from the network. This sampling is biased towards nodes with many edges, i.e., a person with d edges is d times more likely to be sampled than someone with 1 edge. Thus, the degree distribution p'(k) of a friend is given by\n\np' (k) = C \\cdot k \\cdot p(k)\n The additional term k reflects the fact that a person with k friends is k times more likely to be sampled than someone with 1 friend. Term C is the normalization constant that ensures the sum of probabilities p'(k) over all k is 1, which can be easily computed as follows:\n\nC = \\frac{1}{\\sum_{k} k \\cdot p(k)} = \\frac{1}{\\langle k \\rangle}\n\nwhere \\langle k \\rangle is the average degree of the network. Substituting C into p'(k), we get:\n\np' (k) = \\frac{k}{\\langle k \\rangle} p(k)\n\nThis is the degree distribution of a friend, and it is easy to verify that the average degree of a friend is given by\n\n\\langle k' \\rangle = \\sum_{k} k \\cdot p'(k) = \\sum_{k} k \\cdot \\frac{k}{\\langle k \\rangle} p(k) = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}\n\nwhich is always larger than \\langle k \\rangle:\n\n\\langle k' \\rangle = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} \\geq \\langle k \\rangle\n\nwith equality only if every node has the same degree. This is a proof of the friendship paradox üòâ!\n\n\n\n\n\n\nNote\n\n\n\nThe distribution p'(k) is related to the excess degree distribution given by\n\nq(k) = \\frac{k + 1}{\\langle k \\rangle} p(k+1)\n\nThe term excess comes from the fact that the distribution represents the number of additional connections a randomly chosen friend has, beyond the connection that led to their selection. It excludes the link to the focal node and focuses on the remaining connections of the selected friend.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe friend‚Äôs degree, \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}, concides with a term in Molloy-Reed condition:\n$$\n &gt;2\n$$\nwhich is a condition for the existence of a giant component in a network. The Molloy-Reed condition states that the average degree of a node‚Äôs friends must be at least 2 (the inequality is strict because the transition from a small component to a giant component is discontinuous). If a friend has only one edge, you and your friend form an isolated component. If a friend has two edges on average, your friend is a friend of someone else, and that someone else is also friend of another someone else and so on, forming a giant component.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Degree distribution</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/02-coding.html#plotting-degree-distribution-of-a-friend",
    "href": "m04-friendship-paradox/02-coding.html#plotting-degree-distribution-of-a-friend",
    "title": "20¬† Degree distribution",
    "section": "20.4 Plotting degree distribution of a friend",
    "text": "20.4 Plotting degree distribution of a friend\nLet us compare the degree distribution of a node and its friend. We first get the edges in the network, from which we sample a friend.\n\n\nCode\nfrom scipy import sparse\nsrc, trg, _ = sparse.find(A)\n\n\n\nsparse.find(A) returns the source node, target node, and edge weight of the edge.\nsrc is the source node of the edge\ntrg is the target node of the edge\n_ is used to ignore the edge weight values, as we only need the source and target nodes for this analysis.\n\nNow, let us get the degree of each friend\n\n\nCode\ndeg_friend = deg[src]\np_deg_friend = np.bincount(deg_friend) / len(deg_friend)\n\n\nThe CCDF of the degree distributions of a node and a friend can be computed by:\n\n\nCode\nccdf_deg = 1 - np.cumsum(p_deg)[:-1]\nccdf_deg_friend = 1 - np.cumsum(p_deg_friend)[:-1]\n\n\nand plotted by:\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg, label='Node')\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg_friend, label='Friend', ax = ax)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\nax.legend(frameon = False)\n\n\nThe slope of the CCDF of a friend is flatter than that of a node, indicating that the degree distribution of a friend is biased towards higher degrees.",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Degree distribution</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html",
    "href": "m04-friendship-paradox/03-exercises.html",
    "title": "21¬† M04 Exercises: Friendship Paradox",
    "section": "",
    "text": "21.1 Interactive Exercises",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>M04 Exercises: Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html#interactive-exercises",
    "href": "m04-friendship-paradox/03-exercises.html#interactive-exercises",
    "title": "21¬† M04 Exercises: Friendship Paradox",
    "section": "",
    "text": "21.1.1 1. Friendship Paradox Game\nObjective: Experience the friendship paradox interactively\n\nüéâ Fun Challenge: Can you create a network where your friends have the most friends? ü§îüí° Give it a try in this Friendship Paradox Game! üéÆ‚ú®\n\nQuestions to consider: - Can you create a network where the friendship paradox is absent? - In other words, can you create a graph where your friends have the same number of friends as you? - What network structures minimize or maximize the friendship paradox effect?\n\n\n21.1.2 2. Vaccination Game\nObjective: Apply the friendship paradox to disease control strategies\n\nüéâ Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? ü§îüí° Give it a try in this Vaccination Game! üéÆ‚ú®\n\nQuestions to explore: - How does random vaccination compare to targeted vaccination? - Why is vaccinating highly connected individuals more effective? - What happens when vaccination resources are limited?",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>M04 Exercises: Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html#pen-and-paper-exercises",
    "href": "m04-friendship-paradox/03-exercises.html#pen-and-paper-exercises",
    "title": "21¬† M04 Exercises: Friendship Paradox",
    "section": "21.2 Pen and Paper Exercises",
    "text": "21.2 Pen and Paper Exercises\n\n21.2.1 3. Visualization Basics\nObjective: Understand the fundamentals of network data visualization\nüìù Exercise: Data Visualization Basics\nThis exercise covers: - Principles of effective data visualization - Common pitfalls in network visualization - Best practices for degree distribution plots",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>M04 Exercises: Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html#coding-exercises",
    "href": "m04-friendship-paradox/03-exercises.html#coding-exercises",
    "title": "21¬† M04 Exercises: Friendship Paradox",
    "section": "21.3 Coding Exercises",
    "text": "21.3 Coding Exercises\n\n21.3.1 4. Degree Distribution Analysis\n  \nObjective: Master the techniques for analyzing and visualizing degree distributions\nüìù Exercise: Plotting Degree Distribution\nThis coding exercise covers: - Computing degree distributions - Plotting degree distributions effectively - Understanding complementary cumulative distribution functions (CCDF) - Comparing degree distributions of nodes vs.¬†friends - Mathematical proofs of the friendship paradox\nKey concepts to implement: 1. Basic degree distribution computation 2. Log-log plotting for heavy-tailed distributions 3. CCDF calculation and visualization 4. Friend sampling and degree bias analysis 5. Mathematical verification of the friendship paradox\n\n\n21.3.2 5. Extended Analysis (Optional)\nAdvanced Challenge: Implement the first sampling method mentioned in the coding section: - Sample a node uniformly at random and then sample a friend of the node - Compare this with edge-based sampling - Analyze the differences in resulting degree distributions\nResearch Questions: - How do different sampling methods affect the friendship paradox? - Can you derive the mathematical relationship for node-first sampling? - What are the practical implications of each sampling method?",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>M04 Exercises: Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html#assessment-questions",
    "href": "m04-friendship-paradox/03-exercises.html#assessment-questions",
    "title": "21¬† M04 Exercises: Friendship Paradox",
    "section": "21.4 Assessment Questions",
    "text": "21.4 Assessment Questions\n\n21.4.1 Conceptual Understanding\n\nExplain why the friendship paradox occurs in mathematical terms\nDescribe the relationship between CCDF slope and network heterogeneity\nConnect the friendship paradox to the Molloy-Reed condition for giant components\n\n\n\n21.4.2 Practical Applications\n\nDesign a vaccination strategy for a social network\nIdentify potential biases in social network surveys\nPropose methods to mitigate sampling bias in network studies\n\n\n\n21.4.3 Mathematical Analysis\n\nProve that \\langle k' \\rangle = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} \\geq \\langle k \\rangle\nDerive the relationship between power-law exponent and CCDF slope\nCalculate the exact friendship paradox magnitude for specific network types",
    "crumbs": [
      "M04: Friendship Paradox",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>M04 Exercises: Friendship Paradox</span>"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html",
    "href": "m05-clustering/00-preparation.html",
    "title": "22¬† Preparation: Linear Algebra and Optimization Prerequisites",
    "section": "",
    "text": "22.1 Required Knowledge from Previous Modules\nBefore studying clustering methods, ensure you understand: - From M01-M04: Basic network representations, degree distributions, and sampling bias concepts - Mathematical foundations: Sampling theory and statistical bias from M04",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Preparation: Linear Algebra and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#linear-algebra-fundamentals",
    "href": "m05-clustering/00-preparation.html#linear-algebra-fundamentals",
    "title": "22¬† Preparation: Linear Algebra and Optimization Prerequisites",
    "section": "22.2 Linear Algebra Fundamentals",
    "text": "22.2 Linear Algebra Fundamentals\n\n22.2.1 Matrix Operations\nEssential matrix operations for clustering algorithms:\n\n22.2.1.1 Basic Operations\n\nMatrix multiplication: C = AB where C_{ij} = \\sum_k A_{ik}B_{kj}\nMatrix transpose: (A^T)_{ij} = A_{ji}\nIdentity matrix: I where I_{ii} = 1 and I_{ij} = 0 for i \\neq j\n\n\n\n22.2.1.2 Symmetric Matrices\n\nSymmetric: A = A^T (important for undirected graphs)\nPositive semidefinite: All eigenvalues are non-negative\nSpectral theorem: Symmetric matrices can be diagonalized with real eigenvalues\n\n\n\n\n22.2.2 Eigenvalue Decomposition\n\n22.2.2.1 Eigenvalue Problem\nFor matrix M and vector v: Mv = \\lambda v where \\lambda is an eigenvalue and v is the corresponding eigenvector.\n\n\n22.2.2.2 Key Properties\n\nOrthogonality: Eigenvectors of symmetric matrices are orthogonal\nReal eigenvalues: Symmetric matrices have real eigenvalues\nEigenvector basis: Eigenvectors form a basis for the vector space\n\n\n\n\n22.2.3 Quadratic Forms\nExpression x^T M x for vector x and matrix M: - Interpretation: Measures how vector x interacts with matrix M - Optimization: Many clustering problems minimize quadratic forms - Geometric meaning: Related to distances and similarities",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Preparation: Linear Algebra and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#optimization-prerequisites",
    "href": "m05-clustering/00-preparation.html#optimization-prerequisites",
    "title": "22¬† Preparation: Linear Algebra and Optimization Prerequisites",
    "section": "22.3 Optimization Prerequisites",
    "text": "22.3 Optimization Prerequisites\n\n22.3.1 Constrained Optimization\nBasic understanding of optimization with constraints: - Objective function: What we want to minimize or maximize - Constraints: Restrictions on feasible solutions - Lagrange multipliers: Method for handling equality constraints\n\n\n22.3.2 Relaxation Techniques\n\nDiscrete vs.¬†continuous: Converting integer problems to real-valued problems\nApproximation quality: Understanding when relaxations provide good solutions",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Preparation: Linear Algebra and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#graph-theory-prerequisites",
    "href": "m05-clustering/00-preparation.html#graph-theory-prerequisites",
    "title": "22¬† Preparation: Linear Algebra and Optimization Prerequisites",
    "section": "22.4 Graph Theory Prerequisites",
    "text": "22.4 Graph Theory Prerequisites\n\n22.4.1 Cut Problems\nUnderstanding graph partitioning: - Cut: Set of edges between two groups of nodes - Minimum cut: Finding the smallest cut between node groups - Balanced cuts: Ensuring groups are roughly equal in size\n\n\n22.4.2 Spectral Graph Theory Basics\n\nGraph spectrum: Set of eigenvalues of graph matrices\nConnectivity and eigenvalues: How eigenvalues relate to graph structure\nFiedler vector: Second smallest eigenvector and its clustering properties",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Preparation: Linear Algebra and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#computational-prerequisites",
    "href": "m05-clustering/00-preparation.html#computational-prerequisites",
    "title": "22¬† Preparation: Linear Algebra and Optimization Prerequisites",
    "section": "22.5 Computational Prerequisites",
    "text": "22.5 Computational Prerequisites\n\n22.5.1 Algorithm Analysis\n\nTime complexity: Understanding O(n¬≤), O(n¬≥) for matrix operations\nSpace complexity: Memory requirements for large matrices\nNumerical stability: Issues with floating-point computations\n\n\n\n22.5.2 Data Structures\n\nSparse matrices: Efficient storage for large, sparse adjacency matrices\nPriority queues: For optimization algorithms\n\nThese mathematical foundations are essential for understanding how clustering algorithms transform network structure problems into linear algebra problems that can be solved efficiently.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Preparation: Linear Algebra and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html",
    "href": "m05-clustering/01-concepts.html",
    "title": "23¬† Module 5: Clustering Concepts",
    "section": "",
    "text": "23.1 What to learn in this module\nIn this module, we will learn community detection, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is community structure in networks? - How to operationalize community structure? - How to find communities in networks? - Limitations of community detection - Keywords: community detection, assortativity, modularity, resolution limit, rugged landscape, random graph, label switching algorithm, Louvain algorithm, stochastic block model, the configuration model.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Module 5: Clustering Concepts</span>"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#understanding-communities-in-networks",
    "href": "m05-clustering/01-concepts.html#understanding-communities-in-networks",
    "title": "23¬† Module 5: Clustering Concepts",
    "section": "23.2 Understanding communities in networks",
    "text": "23.2 Understanding communities in networks\nBirds of a feather flock together, and so do many other things. For instance, we have a group of friends with similar interests who hang out together frequently but may not interact as much with other groups.\n\n\n\nBirds of a feather\n\n\nIn networks, communities are groups of nodes that share similar connection patterns. These communities do not always mean densely-connected nodes. Sometimes, a community can be nodes that are not connected to each other, but connect similarly to other groups. For instance, in a user-movie rating network, a community might be users with similar movie tastes, even if they don‚Äôt directly connect to each other.\n\n\n\nCommunity structure in a social network\n\n\nCommunities reflect underlying mechanisms of network formation and underpin the dynamics of information propagation. Examples include:\n\nHomophily: The tendency of similar nodes to form connections.\nFunctional groups: Nodes that collaborate for specific purposes.\nHierarchical structure: Smaller communities existing within larger ones.\nInformation flow: The patterns of information, influence, or disease propagation through the network.\n\nThis is why network scientists are sooo obsessed with community structure in networks. See {footcite}fortunato2010community,fortunato2016community,peixoto2019bayesian for comprehensive reviews on network communities.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Module 5: Clustering Concepts</span>"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#pattern-matching-approach",
    "href": "m05-clustering/01-concepts.html#pattern-matching-approach",
    "title": "23¬† Module 5: Clustering Concepts",
    "section": "23.3 Pattern matching approach",
    "text": "23.3 Pattern matching approach\nCommunity detection is an abstract unsupervised problem. It is abstract because there is no clear-cut definition or ground truth to compare against. The concept of a community in a network is subjective and highly context-dependent.\nA classical approach to community detection is based on pattern matching. Namely, we first explicitly define a community by a specific connectivity pattern of its members. Then, we search for these communities in the network.\n\n\n\n\n\n\nFigure¬†23.1: Cliques of different sizes. Taken from https://pythonhosted.org/trustedanalytics/python_api/graphs/graph-/kclique_percolation.html\n\n\n\nPerhaps, the strictest definition of a community is a clique: a group of nodes all connected to each other. Examples include triangles (3-node cliques) and fully-connected squares (4-node cliques). However, cliques are often too rigid for real-world networks. In social networks, for instance, large groups of friends rarely have every member connected to every other, yet we want to accept such ‚Äúin-perfect‚Äù social circles as communities. This leads to the idea of relaxed versions of cliques, called pseudo-cliques.\nPseudo-cliques are defined by relaxing at least one of the following three dimensions of strictness:\n\nDegree: Not all nodes need to connect to every other node.\n\nk-plex: each node connects to all but k others in the group {footcite}seidman1978graph.\nk-core: each node connects to k others in the group {footcite}seidman1983network.\n\nDensity: The overall connection density can be lower.\n\n\\rho-dense subgraphs, with a minimum edge density of \\rho {footcite}goldberg1984finding.\n\nDistance: Nodes can be further apart.\n\nn-clique, where all nodes are within n steps of each other {footcite}luce1950connectivity.\n\nCombination of the above:\n\nn-clan and n-club {footcite}mokken1979cliques\nk-truss, a maximal subgraph where all edges participate in at least k-2 triangles {footcite}saito2008extracting,cohen2009graph,wang2010triangulation.\n\\rho-dense core, a subgraph with minimum conductance \\rho {footcite}koujaku2016dense.\n\n\n\n\n\n\n\n\nFigure¬†23.2: Illustation of different pseudo cliques. Taken from {footcite}koujaku2016dense.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Module 5: Clustering Concepts</span>"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#graph-cut-optimization-approach",
    "href": "m05-clustering/01-concepts.html#graph-cut-optimization-approach",
    "title": "23¬† Module 5: Clustering Concepts",
    "section": "23.4 Graph cut optimization approach",
    "text": "23.4 Graph cut optimization approach\nAnother approach from computer science is to treat a community detection problem as an optimization problem. An early example is the graph cut problem, which asks to find the minimum number of edges to cut the graph into two disconnected components.\nSpecifically, let us consider cutting the network into two communities. Let V_1 and V_2 be the set of nodes in the two communities. Then, the cut is the number of edges between the two communities, which is given by\n\n\\begin{align}\n\\text{Cut}(V_1, V_2) = \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\\end{align}\n\nNow, the community detection problem is translated into an optimization problem, with the goal of finding a cut V_1, V_2 that minimizes \\text{Cut}(V_1, V_2).\nThe description of this problem is not complete üòà. Let‚Äôs find out what is missing by playing with the optimization problem.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCan you identify what is missing in the description of the graph cut problem? Without this, the best cut is trivial. {{ ‚ÄúGraph Cut Problem üéÆ‚Äù.replace(‚ÄòBASE_URL‚Äô, base_url) }}\n\n\n\n\n\n\nClick to reveal the answer!\nThe missing element is a constraint: each community must contain at least one node. Without this, the trivial solution of placing all nodes in a single community would always yield a cut of zero.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Module 5: Clustering Concepts</span>"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#modularity-measuring-assortativity-against-null-models",
    "href": "m05-clustering/01-concepts.html#modularity-measuring-assortativity-against-null-models",
    "title": "23¬† Module 5: Clustering Concepts",
    "section": "23.5 Modularity: measuring assortativity against null models",
    "text": "23.5 Modularity: measuring assortativity against null models\nModularity is by far the most widely used method for community detection. Modularity can be derived in many ways, but we will follow the one derived from assortativity.\nAssortativity is a measure of the tendency of nodes to connect with nodes of the same attribute. The attribute, in our case, is the community that the node belongs to, and we say that a network is assortative if nodes of the same community are more likely to connect with each other than nodes of different communities.\nLet‚Äôs think about assortativity by using color balls and strings! üé®üßµ\nImagine we‚Äôre playing a game as follows:\n\nPicture each connection in our network as two colored balls joined by a piece of string. üî¥üü¢‚Äìüîµüü°\nThe color of each ball shows which community it belongs to.\nNow, let‚Äôs toss all these ball-and-string pairs into a big bag.\nWe‚Äôll keep pulling out strings with replacement and checking if the balls on each end match colors.\n\nThe more color matches we find, the more assortative our network is. But, there‚Äôs a catch! What if we got lots of matches just by luck? For example, if all our balls were the same color, we‚Äôd always get a match. But that doesn‚Äôt tell us much about our communities. So, to be extra clever, we compare our results to a ‚Äúrandom‚Äù version (null model):\n\nWe snip all the strings and mix up all the balls.\nThen we draw pairs of balls at random with replacement and see how often the colors match.\n\nBy comparing our original network to this mixed-up version, we can see if our communities are really sticking together more than we‚Äôd expect by chance. This comparison against the random version is the heart of modularity. Unlike graph cut methods that aim to maximize assortativity directly, modularity measures assortativity relative to a null model.\n\n\n\n\n\n\nFigure¬†23.3: Illustration of how modularity measures assortativity relative to a null model.\n\n\n\nNow, let‚Äôs put on our math hats and make this colorful game a bit more precise. Let‚Äôs introduce some helpful symbols to describe our network: - N: This is our total number of nodes (or balls in our game) - M: The number of edges (or strings) connecting our nodes - A_{ij}: Adjacency matrix. If A_{ij} = 1, it means node i and node j are connected. If A_{ij} = 0, they‚Äôre not connected. - k_i: Degree of node i, i.e., how many edges a node has. - c_i: Community of node i, i.e., which community a node belongs to. - \\delta(c_i, c_j): Kronecker delta function. It gives us 1 if nodes i and j are the same color, and 0 if they‚Äôre different.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nWhat is the probability of color matches for a given network? Derive the probability by using \\sum, M, A_{ij}, \\delta(c_i, c_j).\n\n\n\n\n\n\nHint\n\n\n\n\n\nLet‚Äôs think about our colorful bag of balls and strings! üé®üßµ First, ask yourself: 1. How many strings do we have in total? (This is our M!) 2. Now, out of all these strings, how many are the same color on both ends?\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nWhat is the probability of color matches for the random version? Derive the probability by using \\sum, M, \\delta(c_i, c_j), k_i,k_j.\n\n\n\n\n\n\nHint 1. Imagine a big bag full of colorful balls, but this time without any strings. üî¥üü¢üîµüü° 2. Now, think about picking one ball out of the bag. What are the chances of picking a specific color? 3. Then, put that ball back and pick another one. What are the odds this second ball matches the color of the first one?\n\n\n\n\n\nThe full modularity formula is covered in the coding section üòâ.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Module 5: Clustering Concepts</span>"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#pen-and-paper-exercise",
    "href": "m05-clustering/01-concepts.html#pen-and-paper-exercise",
    "title": "23¬† Module 5: Clustering Concepts",
    "section": "23.6 Pen and Paper Exercise",
    "text": "23.6 Pen and Paper Exercise\n‚úçÔ∏è Pen and Paper Exercise üö¢",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Module 5: Clustering Concepts</span>"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html",
    "href": "m05-clustering/02-coding.html",
    "title": "24¬† Clustering Algorithms and Implementation",
    "section": "",
    "text": "24.1 Balanced Cut Approaches",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Clustering Algorithms and Implementation</span>"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html#balanced-cut-approaches",
    "href": "m05-clustering/02-coding.html#balanced-cut-approaches",
    "title": "24¬† Clustering Algorithms and Implementation",
    "section": "",
    "text": "24.1.1 Ratio Cut\nGraph cut often provide unbalanced communities, e.g., a community consisting of a single node, and another consisting of all other nodes. For example, if the network has a node with degree one (e.g., one edge), an optimal cut will be to place this node in its own community, resulting in a cut of one.\nRatio cut addresses this issue by introducing a normalization factor to balance the cut. Suppose we cut the network into two communities V_1 and V_2, then the ratio cut is defined as\n\n\\text{Ratio cut}(V_1, V_2) = \\frac{1}{|V_1| \\cdot |V_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|V_1| (or |V_2|) is the number of nodes in the community V_1 (or V_2).\n\nThe normalization factor 1/(|V_1| |V_2|) balances the community sizes. It‚Äôs smallest when communities are equal (|V_1| = |V_2|) and largest when one community has only one node (|V_1| = 1 or |V_2| = 1).\n\n\nCode\n:tags: [\"hide-input\"]\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Total number of nodes\ntotal_nodes = 100\n\n# Create an array of possible sizes for V1\nV1_sizes = np.arange(1, total_nodes)\n\n# Calculate corresponding sizes for V2\nV2_sizes = total_nodes - V1_sizes\n\n# Calculate the normalization factor\nnormalization_factor = 1 / (V1_sizes * V2_sizes)\n\n# Create the plot\nfig = plt.figure(figsize=(5, 3))\nplt.plot(V1_sizes, normalization_factor)\nplt.title('Normalization Factor vs. Community Size')\nplt.xlabel('Size of V1')\nplt.ylabel('1 / (|V1| * |V2|)')\nplt.yscale('log')  # Use log scale for y-axis due to large range of values\nplt.grid(True)\n\n\n\n\n24.1.2 Normalized Cut\nNormalized cut{footcite}shi2000normalized balances communities based on edge count, unlike Ratio cut which uses node count. It is defined as:\n\n\\text{Normalized cut}(V_1, V_2) = \\frac{1}{|E_1| \\cdot |E_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|E_1| and |E_2| are the number of edges in the communities V_1 and V_2, respectively.\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCompute the ratio cut and normalized cut for the following network. The red edges should be cut.\n\n\n\n:name: fig-graph-cut\n\n::: {.callout collapse=\"true\"}\n## Click here to reveal the answer\n\nThe graph consists of two cliques, each with 5 nodes ($|V_1| = |V_2| = 5$).\nEach clique has 10 internal edges and 2 edges connecting to the other clique.\nTherefore, $|E_1| = |E_2| = 10 + 2 = 12$.\nWe can now calculate:\n\n- **Ratio cut**: $2 / (5 \\times 5) = 0.08$.\n- **Normalized cut**: $2 / (12 \\times 12) = 0.01388889$.\n\n:::\n\n::: {#61c3cf7c .cell}\n``` {.python .cell-code}\n:tags: [\"hide-input\", \"remove-output\"]\n\nimport igraph as ig\nimport matplotlib.pyplot as plt\nfrom myst_nb import glue\n\n# Create two cliques of size 5\nG1 = ig.Graph.Full(5)\nG2 = ig.Graph.Full(5)\n\n# Combine the two cliques\nG = G1 + G2\n\n# Add an edge between the two cliques\nG.add_edge(0, 5)\nG.add_edge(1, 6)\n\n# Draw the graph\nlayout = G.layout_fruchterman_reingold()\n\n# Set up the plot\nfig, ax = plt.subplots(figsize=(5, 5))\n\n# Draw the connecting edge in red\nig.plot(\n    G,\n    target=ax,\n    layout=layout,\n    vertex_color='lightblue',\n    vertex_size=20,\n    edge_color='gray',\n    edge_width=1\n)\n\n# Draw the connecting edge in red behind the graph\nax.plot([layout[0][0], layout[5][0]], [layout[0][1], layout[5][1]], color='red', linewidth=2, zorder=0)\nax.plot([layout[1][0], layout[6][0]], [layout[1][1], layout[6][1]], color='red', linewidth=2, zorder=0)\n\nig.plot(\n    G,\n    target=ax,\n    layout=layout,\n    vertex_color='white',\n    vertex_size=20,\n    edge_color='black',\n    edge_width=1\n)\n\n# Add labels to the nodes\nfor i, coords in enumerate(layout):\n    ax.annotate(str(i), coords, ha='center', va='center')\n\nplt.title(\"Two Cliques Connected by One Edge\")\nplt.axis('off')\nplt.tight_layout()\n\nglue(\"fig-graph-cut\", fig, display=False)\n\n\nFigure¬†24.1\n\n\n\n\n\n:::\n\n\n24.1.3 Cut into more than two communities\nRatio cut and Normalized cut can be extended to cut into more than two communities. Specifically, we can extend them to cut into k communities, i.e., V_1, V_2, \\dots, V_k by defining\n\n\\begin{align}\n\\text{Ratio cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|V_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right) \\\\\n\\text{Normalized cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|E_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right)\n\\end{align}\n\n\n\n24.1.4 Algorithms to find the best cut\nFor both ratio and normalized cut, finding the best cut is a NP-hard problem. Yet, there are some heuristics to find a good cut. Interested students are encouraged to refer to Ulrike von Luxburg ‚ÄúA Tutorial on Spectral Clustering‚Äù for more details.\n\n\n24.1.5 Issue of Ratio cut and Normalized cut\nWhile Ratio cut and Normalized cut methods are clever approaches, they do come with a couple of challenges we should be aware of.\nFirstly, these methods ask us to decide upfront how many communities we want to find. This can be tricky because, in real-world networks, we often don‚Äôt know this number in advance. It requires us to make a guess on how many different groups of friends we have before actually looking at our social circle.\nSecondly, and perhaps more critically, these methods favor communities of roughly the same size. It‚Äôs as if they‚Äôre assuming all our friend groups should have about the same number of people. But as we know from real life, that‚Äôs not always the case. Some of us might have a large group of college friends and a smaller group of childhood buddies. Research has shown that in many real-world networks, communities can indeed be quite different in size {footcite}palla2005uncovering,clauset2004finding.\nThese limitations don‚Äôt mean these methods should not be used, but they do remind us the importance of understanding the underlying assumptions and limitations of methods we use üòâ. It‚Äôs always good to keep these points in mind when we‚Äôre working with network data. üï∏Ô∏èüí°",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Clustering Algorithms and Implementation</span>"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html#modularity-implementation",
    "href": "m05-clustering/02-coding.html#modularity-implementation",
    "title": "24¬† Clustering Algorithms and Implementation",
    "section": "24.2 Modularity Implementation",
    "text": "24.2 Modularity Implementation\n\n\n\nIllustration of how modularity measures assortativity relative to a null model. {#fig-modularity-game}\n\n\nLet‚Äôs dive into the modularity formula! To put modularity into math terms, we need a few ingredients: - m: The total number of strings (edges) in our bag - n: The total number of balls (nodes) we have - A_{ij}: This tells us if ball i and ball j are connected by a string - \\delta(c_i,c_j): This is our color-checker. It gives us a 1 if balls i and j are the same color (same community), and 0 if they‚Äôre different.\nNow, the probability of pulling out a string out of m string and finding matching colors on both ends is:\n\n\\frac{1}{m} \\sum_{i=1}^n \\sum_{j=i+1}^n A_{ij} \\delta(c_i,c_j) = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j)\n\nWe set A_{ii} = 0 by assuming our network doesn‚Äôt have any ‚Äúselfie strings‚Äù (where a ball is connected to itself). Also, we changed our edge counting a bit. Instead of counting each string once (which gave us m), we‚Äôre now counting each string twice (once from each end). That‚Äôs why we use 2m in the equation.\nNow, imagine we‚Äôve cut all the strings, and we‚Äôre going to draw two balls at random with replacement. Here‚Äôs how our new bag looks: - We have 2m balls in total (1 string has 2 balls, and thus m strings have 2m balls in total). - A node with k edges correspond to the k of 2m balls in the bag. - The color of each ball in our bag matches the color (or community) of its node in the network.\nNow, what‚Äôs the chance of pulling out two balls of the same color?\n\n\\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\nwhere k_i is the degree (i.e., the number of edges) of node i, and C is the total number of communities (i.e., colors).\nHere‚Äôs what it means in simple terms: - We look at each color (c) one by one (the outer sum). - For each color, we figure out how many balls of that color are in our bag (\\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i)). - We divide by 2m to get the probability of drawing a ball of that color. - We then calculate the chance of grabbing that color twice in a row (\\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2). - Finally, we add up these chances for all C colors.\nPutting altogether, the modularity is defined by\n\n\\begin{align}\nQ &=\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\\end{align}\n\nEquivalently, a standard expression is given by\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)\n\n\nAre the two forms of modularity the same formula? Let's see how we can transform one into the other:\n\n1. We start with our first form of modularity:\n\n   $$\n   Q =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n   $$\n\n2. First, let's factor out $\\frac{1}{2m}$ from both terms:\n\n   $$\n   Q =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2 \\right]\n   $$\n\n3. Now, here's a neat trick: $(\\sum_i a_i)^2 = (\\sum_i a_i)( \\sum_j a_j)$. We can use this to expand the squared term:\n\n   $$\n   Q =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n k_i \\delta(c, c_i) \\right) \\left( \\sum_{j=1}^n k_j \\delta(c, c_j) \\right)\\right]\n   $$\n\n4. And here is another trick $(\\sum_i a_i)( \\sum_j a_j) = \\sum_i a_i \\sum_j a_j = \\sum_i \\sum_j a_ia_j$\n\n   $$\n   Q =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n \\sum_{j=1}^n k_i k_j  \\delta(c, c_i)  \\delta(c, c_j) \\right)\\right]\n   $$\n\n5. Here's yet another cool trick, $\\delta(c,c_i) \\delta(c, c_j) = \\delta(c_i,c_j)$. This means we can simplify our expression:\n\n   $$\n   Q =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) -  \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n k_i k_j  \\delta(c_i,c_j) \\right]\n   $$\n\n6. Finally, we can factor out the common parts:\n\n   $$\n   Q =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)\n   $$\n\n24.2.1 Modularity Demo\nLet‚Äôs learn how the modularity works by playing with a community detection game!\n\n\n\n\n\n\nExercise 1\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (two communities) üéÆ\n\n\nOne of the good things about modularity is that it can figure out how many communities there should be all by itself! üïµÔ∏è‚Äç‚ôÄÔ∏è Let‚Äôs have some fun with this idea. We‚Äôre going to play the same game again, but this time, we‚Äôll start with a different number of communities. See how the modularity score changes as we move things around.\n\n\n\n\n\n\nExercise 2\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) üéÆ\n\n\nNow, let‚Äôs take our modularity maximization for a real-world example! ü•ã We‚Äôre going to use the famous karate club network. This network represents friendships between members of a university karate club. It‚Äôs a classic in the world of network science, and it‚Äôs perfect for seeing how modularity works in practice.\n\n\n\n\n\n\nExercise 3\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) üéÆ\n\n\n\n\n24.2.2 Limitation of Modularity\nLike many other community detection methods, modularity is not a silver bullet. Thanks to extensive research, we know many limitations of modularity. Let‚Äôs take a look at a few of them.\n\n\n24.2.3 Resolution limit\nThe modularity finds two cliques connected by a single edge as two separate communities. But what if we add another community to this network? Our intuition tells us that, because communities are local structure, the two cliques should remain separated by the modularity. But is this the case?\n\n\n\n\n\n\nExercise 4\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) üéÆ\n\n\n\n\n\n\nClick here to see the solution\n\n\n\n\n\nThe best modularity score actually comes from merging our two cliques into one big community. This behavior is what we call the Resolution limit {footcite}fortunato2007resolution. Modularity can‚Äôt quite make out communities that are smaller than a certain size!\nThink of it like this: modularity is trying to see the big picture, but it misses the little details. In network terms, the number of edges m_c in a community c has to be bigger than a certain size. This size is related to the total number of edges m in the whole network. We write this mathematically as {\\cal O}(m).\n\n\n\n\n24.2.4 Spurious communities\nWhat if the network does not have any communities at all? Does the modularity find no communities? To find out, let‚Äôs run the modularity on a random network, where each pair of nodes is connected randomly with the same probability.\n\n\n\n\n\n\nExercise 5\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) üéÆ\n\n\n\n\n\n\nClick here to see the solution\n\n\n\n\n\nSurprise, surprise! üòÆ Modularity finds communities even in our random network, and with a very high score too! It‚Äôs like finding shapes in clouds - sometimes our brains (or algorithms) see patterns where there aren‚Äôt any.\nThe wild thing is that the modularity score for this random network is even higher than what we saw for our network with two clear cliques!\nThis teaches us two important lessons: 1. We can‚Äôt compare modularity scores between different networks. It‚Äôs like comparing apples and oranges! üçéüçä 2. A high modularity score doesn‚Äôt always mean we‚Äôve found communities.\nInterested readers can read more about this in this tweet by Tiago Peixoto and the discussion here.\n\n\nModularity maximization is not a reliable method to find communities in networks. Here's a simple example showing why:1. Generate an Erd≈ës-R√©nyi random graph with N nodes and average degree &lt;k&gt;.2. Find the maximum modularity partition. pic.twitter.com/MTt5DdFXSX\n\n‚Äî Tiago Peixoto ((tiagopeixoto?)) December 2, 2021\n\n\n\n\n\n\n\n\n\n24.2.5 So should we avoid modularity?\nThe simple answer is no. Modularity is still a powerful tool for finding communities in networks. Like any other method, it has its limitations. And knowing these limitations is crucial for using it effectively. There is ‚Äúfree lunch‚Äù in community detection {footcite}peel2017ground.\nWhen these implicit assumptions are met, modularity is in fact a very powerful method for community detection. For example, it is in fact an ‚Äúoptimal‚Äù method for a certain class of networks {footcite}nadakuditi2012graph.\nSo, keep modularity in your toolbox. Just remember to use it wisely!\n\n\n24.3 Stochastic Block Model\nLet‚Äôs talk about two ways to look at communities in networks.\nIn modularity maximization, we are given a network and asked to find the best way to group its parts into communities.\nLet‚Äôs flip that idea on its head! üôÉ Instead of starting with a network and looking for communities, we start with the communities and ask, ‚ÄúWhat kind of network would we get if the nodes form these communities?‚Äù. This is the idea of the Stochastic Block Model (SBM).\nWhile modularity maximization is about finding hidden patterns, SBM is about imagining what a network would look like based on a given community structure. Two sides of the same coin, each giving us a unique perspective on community detection.\n\n24.3.1 Model\nIn stochastic block model, we describe a network using probabilities given a community structure. Specifically, let us consider two nodes i and j who belong to community c_i and c_j. Then, the probability of an edge between i and j is given by their community membership.\n\nP(A_{ij}=1|c_i, c_j) = p_{c_i,c_j}\n\nwhere p_{c_i,c_j} is the probability of an edge between nodes in community c_i and c_j, respectively. Notice that the edge probability is fully specified by the community membership of the nodes. This means that nodes in a community are connected with the same probability irrespective of the nodes themselves, and the nodes in different two communities are also connected with the same probability. As a result, when plotting the adjacency matrix, we observe ‚Äúblocks‚Äù of different edge densities, which is why we say that SBM is a ‚Äúblock model‚Äù.\n\n\nCode\n:tags: [hide-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Plot\nplt.figure(figsize=(8, 8))\nplt.imshow(A, cmap='binary')\nplt.title(\"Adjacency Matrix of Stochastic Block Model\")\nplt.xlabel(\"Node Index\")\nplt.ylabel(\"Node Index\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n24.3.2 Characterizing network structures with the SBM\nStochastic Block Model is a flexible model that can be used to describe a wide range of network structures.\nLet‚Äôs start with communities where nodes within a community are more likely to be connected to each other than nodes in different communities. We can describe this using SBM by:\n\nP_{c,c'} = \\begin{cases}\n    p_{\\text{in}} & \\text{if } c = c' \\\\\n    p_{\\text{out}} & \\text{if } c \\neq c'\n\\end{cases}\n\n\np_{\\text{in}} is the chance of a connection between nodes in the same community\np_{\\text{out}} is the chance of a connection between nodes in different communities\n\nUsually, we set p_{\\text{in}} &gt; p_{\\text{out}}, because nodes in the same community tend to be more connected.\nBut, there‚Äôs more SBM can do:\n\nDisassortative communities: What if we flip things around and set p_{\\text{in}} &lt; p_{\\text{out}}? Now we have communities where nodes prefer to connect with nodes from other communities. This is not in line with the communities we have focused on so far. Yet, it is still a valid model of community structure, and SBM allows for this generalization of community structure easily.\nRandom networks: If we make p_{\\text{in}} = p_{\\text{out}}, we get a completely random network where every node has an equal chance of connecting to any other node. This is what we call an Erd≈ës-R√©nyi network.\n\nIn sum, SBM has been used as a playground for network scientists. We can use it to create many interesting network structures and study how they behave.\n\n\n24.3.3 Generating networks with SBM\nIt is easy to generate networks with SBM using igraph. For example, the assortativity communities can be generated as follows.\n\n\nCode\nimport igraph\n\np_in = 0.1\np_out = 0.001\nblock_sizes = [100, 200, 300]\nn = sum(block_sizes)\n\npref_matrix = [\n    [p_in, p_out, p_out],\n    [p_out, p_in, p_out],\n    [p_out, p_out, p_in]\n]\n\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Plot the network\nimport seaborn as sns\npalette = sns.color_palette()\n\ncommunity_colors = sum([[palette[i]] * block_sizes[i] for i in range(len(block_sizes))], [])\nigraph.plot(g, vertex_color=community_colors)\n\n\n\npref_matrix is the matrix of connection probabilities between communities. Its (i,j)th-element is the probability of a connection between nodes in community i and j.\n\n\n\n24.3.4 Detecting communities with SBM\nImagine you‚Äôre a detective trying to figure out how a network was created. You have a hunch about the community structure, and you want to know if it matches the network you see. That‚Äôs exactly what we‚Äôre going to do to find out communities!\nHere‚Äôs how we can describe the probability of seeing a particular network, given a community structure:\n\nP(\\left\\{A_{ij}\\right\\}_{ij}) = \\prod_{i&lt;j} P(A_{ij}=1|c_i, c_j)^{A_{ij}} (1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}\n\nLet‚Äôs break this down into simpler terms:\n\nFirst, \\left\\{A_{ij}\\right\\}_{ij} is just a fancy way of saying ‚Äúall the connections in our network‚Äù. Think of it as a big table showing who‚Äôs connected to whom.\nWe use \\prod_{i &lt; j} instead of \\prod_{i,j} because we‚Äôre dealing with an undirected network. This means if Alice is friends with Bob, Bob is also friends with Alice. We only need to count this friendship once, not twice!\nThe last part, P(A_{ij}=1|c_i, c_j)^A_{ij}(1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}, might look scary, but it‚Äôs actually quite clever. It‚Äôs a shorthand way of saying ‚Äúwhat‚Äôs the chance of this connection existing or not existing?‚Äù If the connection exists (A_{ij}=1), we use the first part. If it doesn‚Äôt (A_{ij}=0), we use the second part. It‚Äôs a two-in-one formula.\n\nHere‚Äôs a neat trick we can use to make our lives easier. We can take the logarithm of both sides of our equation. This turns our big product (multiplication) into a simpler sum (addition).\n\n{\\cal L}=\\log P(\\left\\{A_{ij}\\right\\}_{ij}) = \\sum_{i&lt;j} A_{ij} \\log P(A_{ij}=1|c_i, c_j) + (1-A_{ij}) \\log (1-P(A_{ij}=1|c_i, c_j))\n\nWe call this the likelihood function. It tells us how likely we are to see this network given our community guess. We can play around with different community assignments and edge probabilities to see which one gives us the highest likelihood. To make this game easier, let‚Äôs first figure out the best edge probabilities for a given community assignment.\nOur likelihood function has a special shape - it is a concave function with respect to p_{c,c'}. This means that the likelihood function is a hill with only one peak when we look at it in terms of edge probability p_{c,c'}.\n\n\nCode\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef concave_function(x):\n    return -(x - 0.5)**2 + 0.25\n\nx = np.linspace(0, 1, 100)\ny = concave_function(x)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, 'b-', linewidth=2)\nplt.title('Schematic of Likelihood Function (Concave)')\nplt.xlabel('Edge Probability p_c,c\\'')\nplt.ylabel('Likelihood')\nplt.axvline(x=0.5, color='r', linestyle='--', label='Maximum')\nplt.annotate('Global Maximum', xy=(0.5, 0.25), xytext=(0.6, 0.2),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\nSo, what does this mean for us? The top of this hill (our maximum value) is flat, and there‚Äôs only one flat spot on the whole hill. So if we can find a spot where the hill isn‚Äôt sloping at all (that‚Äôs what we mean by ‚Äúzero gradient‚Äù), we‚Äôve found the very top of the hill! üèîÔ∏è\nIn math terms, we take the derivative of our likelihood function with respect to p_{c,c'} and set it to zero, i.e., \\partial {\\cal L}  / \\partial p_{cc'} = 0. Here is what we get:\n\n\\begin{aligned}\n\\frac{\\partial {\\cal L}}{\\partial p_{c,c'}} &= 0 \\\\\n\\Rightarrow & \\sum_{i&lt;j} \\left[A_{ij} \\frac{1}{p_{c_i,c_j}} \\delta(c_i,c)\\delta(c_j,c') -(1-A_{ij}) \\frac{1}{1-p_{c_i,c_j}}\\delta(c_i,c')\\delta(c_j,c') \\right] = 0 \\\\\n\\Rightarrow &\n\\frac{m_{cc'}}{p_{c_i,c_j}} - \\frac{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') }{1-p_{c_i,c_j}} = 0 & \\text{if } c \\neq  c' \\\\\n\\Rightarrow & p_{c,c'} = \\frac{m_{cc'}}{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c')}\n\\end{aligned}\n\nLet‚Äôs break down these equations:\n\nm_{cc'} is the number of edges between nodes in community c and those in community c'.\nThe derivative \\partial \\log p_{cc} / \\partial p_{cc} is just 1/p_{cc}.\n\nThe denominator \\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') is the total number of pairs of nodes that belong to communities c and c'. It is given by\n\n\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') =\n\\begin{cases}\nn_cn_{c'} & \\text{if } c \\neq c' \\\\\n\\frac{n_c (n_c - 1)}{2} & \\text{if } c = c'\n\\end{cases}\n\nWhy do we have two different equations for p_{c,c'}? It‚Äôs because we are counting each pair of nodes only by once. It is easy to verify when looking at the adjacency matrix:\n\n\nCode\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Create the plot\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Plot the adjacency matrix\nax.matshow(A, cmap='binary')\nmask = np.triu(np.ones_like(A, dtype=bool), k=1)\n\n# Highlight the upper triangle with yellow overlay\nax.matshow(np.ma.masked_array(np.ones_like(A), ~mask), cmap='Reds_r', alpha=0.3)\n\n# Add a title\nplt.title(\"Adjacency Matrix with Highlighted Upper Triangle\")\n\nplt.show()\n\n\nThe upper triangle of the adjacency matrix represents i &lt; j over which we take the sum. When c=c' (the diagonal block), we count only the upper half of the block, resulting in \\frac{n_c (n_c - 1)}{2}. When c \\neq c' (different communities), we count all connections between them, resulting in n_cn_{c'}.\nWe have now obtaind the likelihood function based only on the community assignment. Maximizing {\\cal L} with respect to the community assignment gives us the most likely community assignment for the network.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Clustering Algorithms and Implementation</span>"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html#stochastic-block-model",
    "href": "m05-clustering/02-coding.html#stochastic-block-model",
    "title": "24¬† Clustering Algorithms and Implementation",
    "section": "24.3 Stochastic Block Model",
    "text": "24.3 Stochastic Block Model\nLet‚Äôs talk about two ways to look at communities in networks.\nIn modularity maximization, we are given a network and asked to find the best way to group its parts into communities.\nLet‚Äôs flip that idea on its head! üôÉ Instead of starting with a network and looking for communities, we start with the communities and ask, ‚ÄúWhat kind of network would we get if the nodes form these communities?‚Äù. This is the idea of the Stochastic Block Model (SBM).\nWhile modularity maximization is about finding hidden patterns, SBM is about imagining what a network would look like based on a given community structure. Two sides of the same coin, each giving us a unique perspective on community detection.\n\n24.3.1 Model\nIn stochastic block model, we describe a network using probabilities given a community structure. Specifically, let us consider two nodes i and j who belong to community c_i and c_j. Then, the probability of an edge between i and j is given by their community membership.\n\nP(A_{ij}=1|c_i, c_j) = p_{c_i,c_j}\n\nwhere p_{c_i,c_j} is the probability of an edge between nodes in community c_i and c_j, respectively. Notice that the edge probability is fully specified by the community membership of the nodes. This means that nodes in a community are connected with the same probability irrespective of the nodes themselves, and the nodes in different two communities are also connected with the same probability. As a result, when plotting the adjacency matrix, we observe ‚Äúblocks‚Äù of different edge densities, which is why we say that SBM is a ‚Äúblock model‚Äù.\n\n\nCode\n:tags: [hide-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Plot\nplt.figure(figsize=(8, 8))\nplt.imshow(A, cmap='binary')\nplt.title(\"Adjacency Matrix of Stochastic Block Model\")\nplt.xlabel(\"Node Index\")\nplt.ylabel(\"Node Index\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n24.3.2 Characterizing network structures with the SBM\nStochastic Block Model is a flexible model that can be used to describe a wide range of network structures.\nLet‚Äôs start with communities where nodes within a community are more likely to be connected to each other than nodes in different communities. We can describe this using SBM by:\n\nP_{c,c'} = \\begin{cases}\n    p_{\\text{in}} & \\text{if } c = c' \\\\\n    p_{\\text{out}} & \\text{if } c \\neq c'\n\\end{cases}\n\n\np_{\\text{in}} is the chance of a connection between nodes in the same community\np_{\\text{out}} is the chance of a connection between nodes in different communities\n\nUsually, we set p_{\\text{in}} &gt; p_{\\text{out}}, because nodes in the same community tend to be more connected.\nBut, there‚Äôs more SBM can do:\n\nDisassortative communities: What if we flip things around and set p_{\\text{in}} &lt; p_{\\text{out}}? Now we have communities where nodes prefer to connect with nodes from other communities. This is not in line with the communities we have focused on so far. Yet, it is still a valid model of community structure, and SBM allows for this generalization of community structure easily.\nRandom networks: If we make p_{\\text{in}} = p_{\\text{out}}, we get a completely random network where every node has an equal chance of connecting to any other node. This is what we call an Erd≈ës-R√©nyi network.\n\nIn sum, SBM has been used as a playground for network scientists. We can use it to create many interesting network structures and study how they behave.\n\n\n24.3.3 Generating networks with SBM\nIt is easy to generate networks with SBM using igraph. For example, the assortativity communities can be generated as follows.\n\n\nCode\nimport igraph\n\np_in = 0.1\np_out = 0.001\nblock_sizes = [100, 200, 300]\nn = sum(block_sizes)\n\npref_matrix = [\n    [p_in, p_out, p_out],\n    [p_out, p_in, p_out],\n    [p_out, p_out, p_in]\n]\n\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Plot the network\nimport seaborn as sns\npalette = sns.color_palette()\n\ncommunity_colors = sum([[palette[i]] * block_sizes[i] for i in range(len(block_sizes))], [])\nigraph.plot(g, vertex_color=community_colors)\n\n\n\npref_matrix is the matrix of connection probabilities between communities. Its (i,j)th-element is the probability of a connection between nodes in community i and j.\n\n\n\n24.3.4 Detecting communities with SBM\nImagine you‚Äôre a detective trying to figure out how a network was created. You have a hunch about the community structure, and you want to know if it matches the network you see. That‚Äôs exactly what we‚Äôre going to do to find out communities!\nHere‚Äôs how we can describe the probability of seeing a particular network, given a community structure:\n\nP(\\left\\{A_{ij}\\right\\}_{ij}) = \\prod_{i&lt;j} P(A_{ij}=1|c_i, c_j)^{A_{ij}} (1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}\n\nLet‚Äôs break this down into simpler terms:\n\nFirst, \\left\\{A_{ij}\\right\\}_{ij} is just a fancy way of saying ‚Äúall the connections in our network‚Äù. Think of it as a big table showing who‚Äôs connected to whom.\nWe use \\prod_{i &lt; j} instead of \\prod_{i,j} because we‚Äôre dealing with an undirected network. This means if Alice is friends with Bob, Bob is also friends with Alice. We only need to count this friendship once, not twice!\nThe last part, P(A_{ij}=1|c_i, c_j)^A_{ij}(1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}, might look scary, but it‚Äôs actually quite clever. It‚Äôs a shorthand way of saying ‚Äúwhat‚Äôs the chance of this connection existing or not existing?‚Äù If the connection exists (A_{ij}=1), we use the first part. If it doesn‚Äôt (A_{ij}=0), we use the second part. It‚Äôs a two-in-one formula.\n\nHere‚Äôs a neat trick we can use to make our lives easier. We can take the logarithm of both sides of our equation. This turns our big product (multiplication) into a simpler sum (addition).\n\n{\\cal L}=\\log P(\\left\\{A_{ij}\\right\\}_{ij}) = \\sum_{i&lt;j} A_{ij} \\log P(A_{ij}=1|c_i, c_j) + (1-A_{ij}) \\log (1-P(A_{ij}=1|c_i, c_j))\n\nWe call this the likelihood function. It tells us how likely we are to see this network given our community guess. We can play around with different community assignments and edge probabilities to see which one gives us the highest likelihood. To make this game easier, let‚Äôs first figure out the best edge probabilities for a given community assignment.\nOur likelihood function has a special shape - it is a concave function with respect to p_{c,c'}. This means that the likelihood function is a hill with only one peak when we look at it in terms of edge probability p_{c,c'}.\n\n\nCode\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef concave_function(x):\n    return -(x - 0.5)**2 + 0.25\n\nx = np.linspace(0, 1, 100)\ny = concave_function(x)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, 'b-', linewidth=2)\nplt.title('Schematic of Likelihood Function (Concave)')\nplt.xlabel('Edge Probability p_c,c\\'')\nplt.ylabel('Likelihood')\nplt.axvline(x=0.5, color='r', linestyle='--', label='Maximum')\nplt.annotate('Global Maximum', xy=(0.5, 0.25), xytext=(0.6, 0.2),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\nSo, what does this mean for us? The top of this hill (our maximum value) is flat, and there‚Äôs only one flat spot on the whole hill. So if we can find a spot where the hill isn‚Äôt sloping at all (that‚Äôs what we mean by ‚Äúzero gradient‚Äù), we‚Äôve found the very top of the hill! üèîÔ∏è\nIn math terms, we take the derivative of our likelihood function with respect to p_{c,c'} and set it to zero, i.e., \\partial {\\cal L}  / \\partial p_{cc'} = 0. Here is what we get:\n\n\\begin{aligned}\n\\frac{\\partial {\\cal L}}{\\partial p_{c,c'}} &= 0 \\\\\n\\Rightarrow & \\sum_{i&lt;j} \\left[A_{ij} \\frac{1}{p_{c_i,c_j}} \\delta(c_i,c)\\delta(c_j,c') -(1-A_{ij}) \\frac{1}{1-p_{c_i,c_j}}\\delta(c_i,c')\\delta(c_j,c') \\right] = 0 \\\\\n\\Rightarrow &\n\\frac{m_{cc'}}{p_{c_i,c_j}} - \\frac{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') }{1-p_{c_i,c_j}} = 0 & \\text{if } c \\neq  c' \\\\\n\\Rightarrow & p_{c,c'} = \\frac{m_{cc'}}{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c')}\n\\end{aligned}\n\nLet‚Äôs break down these equations:\n\nm_{cc'} is the number of edges between nodes in community c and those in community c'.\nThe derivative \\partial \\log p_{cc} / \\partial p_{cc} is just 1/p_{cc}.\n\nThe denominator \\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') is the total number of pairs of nodes that belong to communities c and c'. It is given by\n\n\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') =\n\\begin{cases}\nn_cn_{c'} & \\text{if } c \\neq c' \\\\\n\\frac{n_c (n_c - 1)}{2} & \\text{if } c = c'\n\\end{cases}\n\nWhy do we have two different equations for p_{c,c'}? It‚Äôs because we are counting each pair of nodes only by once. It is easy to verify when looking at the adjacency matrix:\n\n\nCode\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Create the plot\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Plot the adjacency matrix\nax.matshow(A, cmap='binary')\nmask = np.triu(np.ones_like(A, dtype=bool), k=1)\n\n# Highlight the upper triangle with yellow overlay\nax.matshow(np.ma.masked_array(np.ones_like(A), ~mask), cmap='Reds_r', alpha=0.3)\n\n# Add a title\nplt.title(\"Adjacency Matrix with Highlighted Upper Triangle\")\n\nplt.show()\n\n\nThe upper triangle of the adjacency matrix represents i &lt; j over which we take the sum. When c=c' (the diagonal block), we count only the upper half of the block, resulting in \\frac{n_c (n_c - 1)}{2}. When c \\neq c' (different communities), we count all connections between them, resulting in n_cn_{c'}.\nWe have now obtaind the likelihood function based only on the community assignment. Maximizing {\\cal L} with respect to the community assignment gives us the most likely community assignment for the network.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Clustering Algorithms and Implementation</span>"
    ]
  },
  {
    "objectID": "m05-clustering/03-exercises.html",
    "href": "m05-clustering/03-exercises.html",
    "title": "25¬† Hands-on: Clustering",
    "section": "",
    "text": "25.1 Modularity maximization\nLet us showcase how to use igraph to detect communities with modularity. We will use the Karate Club Network as an example.\nCode\nimport igraph\ng = igraph.Graph.Famous(\"Zachary\")\nigraph.plot(g, vertex_size=20)\nWhen it comes to maximizing modularity, there are a variety of algorithms to choose from. Two of the most popular ones are the Louvain and Leiden algorithms, both of which are implemented in igraph. The Louvain algorithm has been around for quite some time and is a classic choice, while the Leiden algorithm is a newer bee that often yields better accuracy. For our example, we‚Äôll be using the Leiden algorithm, and I think you‚Äôll find it really effective!\nCode\ncommunities = g.community_leiden(resolution=1, objective_function= \"modularity\")\nWhat is resolution? It is a parameter that helps us tackle the resolution limit of the modularity maximization algorithm {footcite}fortunato2007resolution! In simple terms, when we use the resolution parameter \\rho, the modularity formula can be rewritten as follow:\nQ(M) = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left(A_{ij} - \\rho \\frac{k_i k_j}{2m}\\right) \\delta(c_i, c_j)\nHere, the parameter \\rho plays a crucial role in balancing the positive and negative parts of the equation. The resolution limit comes into play because of the diminishing effect of the negative term as the number of edges m increases. The parameter \\rho can adjust this balance and allow us to circumvent the resolution limit.\nWhat is communities? This is a list of communities, where each community is represented by a list of nodes by their indices.\nCode\nprint(communities)\nLet us visualize the communities by coloring the nodes in the graph.\nCode\nimport seaborn as sns\ncommunity_membership = communities.membership\npalette = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[palette[i] for i in community_membership])",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Hands-on: Clustering</span>"
    ]
  },
  {
    "objectID": "m05-clustering/03-exercises.html#modularity-maximization",
    "href": "m05-clustering/03-exercises.html#modularity-maximization",
    "title": "25¬† Hands-on: Clustering",
    "section": "",
    "text": "community_membership: This is a list of community membership for each node.\npalette: This is a list of colors to use for the communities.\nigraph.plot(g, vertex_color=[palette[i] for i in community_membership]): This plots the graph ‚Äòg‚Äô with nodes colored by their community.\n\n\n25.1.1 Exercise 01 üèãÔ∏è‚Äç‚ôÄÔ∏èüí™üß†\n\nSelect a network of your choice from Netzschleuder. For convenience, choose a network of nodes less than 5000.\nDownload the csv version of the data by clicking something like ‚Äú3KiB‚Äù under csv column.\nUnzip the file and find ‚Äúedges.csv‚Äù, open it with a text editor to familiarize yourself with the format.\nLoad the data using pandas.\nGet the source and target nodes from the data to create an edge list.\nConstruct a graph from the edge list, either using igraph or scipy.\nFind communities by maximizing the modularity and visualize them.\nTry at least three different values of the resolution parameter and observe how the community structure changes.\n\n\n\nCode\n# Your code here",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Hands-on: Clustering</span>"
    ]
  },
  {
    "objectID": "m05-clustering/03-exercises.html#stochstic-block-model",
    "href": "m05-clustering/03-exercises.html#stochstic-block-model",
    "title": "25¬† Hands-on: Clustering",
    "section": "25.2 Stochstic Block Model",
    "text": "25.2 Stochstic Block Model\nLet us turn the SBM as our community detection tool using graph-tool. This is a powerful library for network analysis, with a focus on the stochastic block model.\n\n\nCode\n#\n# Uncomment the following code if you are using Google Colab\n#\n#!wget https://downloads.skewed.de/skewed-keyring/skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n#!dpkg -i skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n#!echo \"deb [signed-by=/usr/share/keyrings/skewed-keyring.gpg] https://downloads.skewed.de/apt $(lsb_release -s -c) main\" &gt; /etc/apt/sources.list.d/skewed.list\n#!apt-get update\n#!apt-get install python3-graph-tool python3-matplotlib python3-cairo\n#!apt purge python3-cairo\n#!apt install libcairo2-dev pkg-config python3-dev\n#!pip install --force-reinstall pycairo\n#!pip install zstandard\n\n\nWe will identify the communities using the stochastic block model as follows. First, we will convert the graph object in igraph to that in graph-tool.\n\n\nCode\nimport graph_tool.all  as gt\nimport numpy as np\nimport igraph\n\n# igraph object\ng = igraph.Graph.Famous(\"Zachary\")\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Convert the graph object in igraph to that in graph-tool\nedges = g.get_edgelist()\nr, c = zip(*edges)\ng_gt = gt.Graph(directed=False)\ng_gt.add_edge_list(np.vstack([r, c]).T)\n\n\nThen, we will fit the stochastic block model to the graph.\n\n\nCode\n# Fit the stochastic block model\nstate = gt.minimize_blockmodel_dl(\n     g_gt,\n     state_args={\"deg_corr\": False, \"B_min\":2, \"B_max\":10},\n)\nb = state.get_blocks()\n\n\n\nB_min and B_max are the minimum and maximum number of communities to consider.\ndeg_corr is a boolean flag to switch to the degree-corrected SBM {footcite}karrer2011stochastic.\n\nHere's a fun fact: the likelihood maximization on its own can't figure out how many communities there should be. But `graph-tool` has a clever trick to circumvent this limitation.\n`graph-tool` actually fits multiple SBMs, each with a different number of communities. Then, it picks the most plausible one based on a model selection criterion.\nLet‚Äôs visualize the communities to see what we got.\n\n\nCode\n:tags: [\"hide-input\"]\n# Convert the block assignments to a list\ncommunity_membership = b.get_array()\n\n# The community labels may consist of non-consecutive integers, e.g., 10, 8, 1, 4, ...\n# So we reassign the community labels to be 0, 1, 2, ...\ncommunity_membership = np.unique(community_membership, return_inverse=True)[1]\ncommunity_membership\n\n\n\n\nCode\n# Create a color palette\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npalette = sns.color_palette().as_hex()\n# Plot the graph with nodes colored by their community\nfig, ax = plt.subplots(figsize=(10, 8))\nigraph.plot(\n    g,\n    target=ax,\n    vertex_color=[palette[i] for i in community_membership],\n)\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\nWhat we‚Äôre seeing here isn‚Äôt a failure at all. In fact, it‚Äôs the best partition according to our stochastic block model. The model has discovered something called a core-periphery structure {footcite}borgatti2000models. Let me break that down:\n\nThink of a major international airport (the core) and smaller regional airports (the periphery).\nMajor international airports have many flights connecting to each other (densely connected).\nSmaller regional airports have fewer connections among themselves (sparsely connected).\nMany regional airports have flights to major hubs (periphery connected to the core).\n\nThat‚Äôs exactly what our model found in this network.\nIf we look at the adjacency matrix, we would see something that looks like an upside-down ‚ÄúL‚Äù. This shape is like a signature for core-periphery structures.\n\n\nCode\n# Convert igraph Graph to adjacency matrix\nA = np.array(g.get_adjacency().data)\n\n# Sort nodes based on their community (core first, then periphery)\nsorted_indices = np.argsort(community_membership)\nA_sorted = A[sorted_indices][:, sorted_indices]\n\n# Plot the sorted adjacency matrix\nplt.figure(figsize=(10, 8))\nplt.imshow(A_sorted, cmap='binary')\nplt.title(\"Sorted Adjacency Matrix: Core-Periphery Structure\")\nplt.xlabel(\"Node Index (sorted)\")\nplt.ylabel(\"Node Index (sorted)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n25.2.1 Exercise 02 üèãÔ∏è‚Äç‚ôÄÔ∏èüí™üß†\n\nSelect a network of your choice from Netzschleuder. For convenience, choose a network of nodes less than 5000.\nDownload the csv version of the data by clicking something like ‚Äú3KiB‚Äù under csv column.\nUnzip the file and find ‚Äúedges.csv‚Äù, open it with a text editor to familiarize yourself with the format.\nLoad the data using pandas.\nGet the source and target nodes from the data to create an edge list.\nConstruct a graph from the edge list, either using igraph or scipy.\nFind communities by fitting the stochastic block model and visualize them.\nTry deg_corr=True and compare the results with those from deg_corr=False.",
    "crumbs": [
      "M05: Clustering",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Hands-on: Clustering</span>"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html",
    "href": "m06-centrality/00-preparation.html",
    "title": "26¬† Preparation: Advanced Linear Algebra for Network Analysis",
    "section": "",
    "text": "26.1 Required Knowledge from Previous Modules\nBefore studying centrality measures, ensure you understand: - From M01-M05: Network representations, eigenvalue concepts from clustering - Linear algebra: Matrix operations, eigenvalue decomposition from M05",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Preparation: Advanced Linear Algebra for Network Analysis</span>"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#advanced-matrix-theory",
    "href": "m06-centrality/00-preparation.html#advanced-matrix-theory",
    "title": "26¬† Preparation: Advanced Linear Algebra for Network Analysis",
    "section": "26.2 Advanced Matrix Theory",
    "text": "26.2 Advanced Matrix Theory\n\n26.2.1 Matrix Powers and Series\n\n26.2.1.1 Matrix Powers\nUnderstanding powers of matrices: - A^k represents k-step relationships in networks - Interpretation: A^k_{ij} = number of walks of length k from node i to j - Convergence: How A^k behaves as k \\to \\infty\n\n\n26.2.1.2 Matrix Series\nInfinite series involving matrices: - Geometric series: (I - \\alpha A)^{-1} = I + \\alpha A + \\alpha^2 A^2 + \\ldots - Convergence conditions: When does the series converge? - Spectral radius: Determines convergence: series converges if |\\alpha| &lt; 1/\\rho(A)\n\n\n\n26.2.2 Spectral Properties\n\n26.2.2.1 Perron-Frobenius Theorem\nFor non-negative matrices (like adjacency matrices): - Largest eigenvalue: Is real and positive - Principal eigenvector: Has all non-negative entries - Uniqueness: Principal eigenvector is unique (up to scaling) - Dominance: Largest eigenvalue strictly dominates others for irreducible matrices\n\n\n26.2.2.2 Spectral Radius\n\nDefinition: \\rho(A) = \\max_i |\\lambda_i| (magnitude of largest eigenvalue)\nSignificance: Controls convergence of matrix powers and series\nComputation: Can be found using power iteration method",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Preparation: Advanced Linear Algebra for Network Analysis</span>"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#normalization-techniques",
    "href": "m06-centrality/00-preparation.html#normalization-techniques",
    "title": "26¬† Preparation: Advanced Linear Algebra for Network Analysis",
    "section": "26.3 Normalization Techniques",
    "text": "26.3 Normalization Techniques\n\n26.3.1 Vector Normalization\nDifferent ways to normalize vectors: - L1 norm: ||v||_1 = \\sum_i |v_i| (sum to 1 for probability distributions) - L2 norm: ||v||_2 = \\sqrt{\\sum_i v_i^2} (unit length vectors) - Max norm: ||v||_\\infty = \\max_i |v_i| (scale largest element to 1)\n\n\n26.3.2 Matrix Normalization\n\nRow stochastic: Each row sums to 1 (transition matrices)\nColumn stochastic: Each column sums to 1\n\nDoubly stochastic: Both rows and columns sum to 1",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Preparation: Advanced Linear Algebra for Network Analysis</span>"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#iterative-methods",
    "href": "m06-centrality/00-preparation.html#iterative-methods",
    "title": "26¬† Preparation: Advanced Linear Algebra for Network Analysis",
    "section": "26.4 Iterative Methods",
    "text": "26.4 Iterative Methods\n\n26.4.1 Power Iteration\nAlgorithm for finding largest eigenvalue and eigenvector: 1. Start with random vector v^{(0)} 2. Iterate: v^{(k+1)} = \\frac{Av^{(k)}}{||Av^{(k)}||} 3. Converges to principal eigenvector\n\n26.4.1.1 Convergence Rate\n\nDepends on ratio |\\lambda_2|/|\\lambda_1|\nFaster convergence when this ratio is small\nAcceleration techniques: Methods to improve convergence\n\n\n\n\n26.4.2 Matrix Decompositions\n\n26.4.2.1 Similarity Transformations\n\nDiagonalization: A = PDP^{-1} where D is diagonal\nApplications: Computing matrix powers efficiently: A^k = PD^kP^{-1}",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Preparation: Advanced Linear Algebra for Network Analysis</span>"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#applications-to-network-analysis",
    "href": "m06-centrality/00-preparation.html#applications-to-network-analysis",
    "title": "26¬† Preparation: Advanced Linear Algebra for Network Analysis",
    "section": "26.5 Applications to Network Analysis",
    "text": "26.5 Applications to Network Analysis\n\n26.5.1 Network Properties via Eigenvalues\n\nConnectivity: Related to eigenvalue gaps\nMixing time: How quickly random walks converge\nExpansion: How well-connected different parts of the network are\n\n\n\n26.5.2 Computational Considerations\n\nSparse matrices: Most real networks are sparse\nEfficient algorithms: Exploiting sparsity for large networks\nNumerical stability: Avoiding computational errors\n\nThese advanced linear algebra concepts provide the mathematical foundation for understanding how centrality measures capture different notions of node importance through matrix operations.",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Preparation: Advanced Linear Algebra for Network Analysis</span>"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html",
    "href": "m06-centrality/01-concepts.html",
    "title": "27¬† Module 6: Centrality Concepts",
    "section": "",
    "text": "27.1 What to learn in this module\nIn this module, we will learn centrality, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is centrality in networks? - How to operationalize centrality? - How to find centrality in networks? - Limitations of centrality - Keywords: degree centrality, closeness centrality, betweenness centrality, eigenvector centrality, PageRank, Katz centrality, HITS, random walk",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Module 6: Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#what-is-centrality",
    "href": "m06-centrality/01-concepts.html#what-is-centrality",
    "title": "27¬† Module 6: Centrality Concepts",
    "section": "27.2 What is centrality?",
    "text": "27.2 What is centrality?\nHave you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone‚Äôs talking about right now? These questions are all about finding out what‚Äôs important in a network of people, ideas, or things. In network science, we call this centrality.\nCentrality or importance is a question of how important a node is in a network. But the notion of importance is somewhat vague. In what sense we say a node is important? Answering this question needs a specific context, and there are many contexts in which the importance is defined.",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Module 6: Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#degree-based-centrality",
    "href": "m06-centrality/01-concepts.html#degree-based-centrality",
    "title": "27¬† Module 6: Centrality Concepts",
    "section": "27.3 Degree-based centrality",
    "text": "27.3 Degree-based centrality\nThe simplest approach to measuring centrality is to count the connections of each node. This gives us degree centrality, which considers a node important if it has many direct connections.\nDegree centrality is just the count of the number of edges connected to a node (i.e., the number of neighbors, or degree in network science terminology). The most important node is thus the one with the highest degree.\n\nc_i = d_i = \\sum_{j} A_{ij}\n\nwhere A_{ij} is the adjacency matrix of the network, and d_i is the degree of node i.",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Module 6: Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#distance-based-centrality",
    "href": "m06-centrality/01-concepts.html#distance-based-centrality",
    "title": "27¬† Module 6: Centrality Concepts",
    "section": "27.4 Distance-based centrality",
    "text": "27.4 Distance-based centrality\n\nLet‚Äôs talk about an ancient Roman monument called the Milliarium Aureum, also known as the Golden Milestone. It was the starting point for measuring distances on all major roads in the Roman Empire. Emperor Augustus built it when Rome changed from a republic to an empire. The monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire. Perhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define centrality in networks.\nThis family of centrality measures is based on shortest path distances between nodes. They consider a node important if it has short distances to other nodes or if it lies on many shortest paths.\nCloseness centrality measures how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N - 1, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n\n\n\nHarmonic centrality adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can‚Äôt reach others, making their distance infinite. This causes all centrality values to become zero, which isn‚Äôt very helpful! To fix this, Beauchamp {footcite:p}beauchamp1965improved came up with a clever solution called harmonic centrality. It works even when the network is disconnected.\n\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n\nEccentricity centrality is based on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\nBetweenness centrality considers that a node is important if it lies on many shortest paths between other nodes.\n\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n\nwhere \\sigma_{jk} is the number of shortest paths between nodes j and k, and \\sigma_{jk}(i) is the number of shortest paths between nodes j and k that pass through node i.\n\n27.5 Walk-based centrality\n‚ÄúA man is known by the company he keeps‚Äù is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire. It suggests that a person‚Äôs character is reflected by the people this person is friends with. This idea can be applied to define the centrality of a node in a network.\nThis family of centrality measures considers that a node is important if it is connected to other important nodes, or if it receives many ‚Äúwalks‚Äù or ‚Äúvotes‚Äù from other nodes in the network. These measures often use recursive definitions and are computed using linear algebra techniques.\nEigenvector centrality considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here‚Äôs the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet‚Äôs think about it for a moment. We want our centrality measure to be positive. It wouldn‚Äôt make much sense to have negative importance! So, we‚Äôre looking for an eigenvector where all the elements are positive. And a good news is that there‚Äôs a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associated with the largest eigenvalue always has all positive elements.\nHyperlink-Induced Topic Search (HITS) centrality\nextends eigenvector centrality to directed networks. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet‚Äôs put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbf{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree d_j of the authority, namely\n\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting x_i = d_i.\n\n\nKatz centrality addresses a limitation of eigenvector centrality, which tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. The solution is to add a little bit of score to all nodes.\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nDerive the solution of the Katz centrality.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe equation can be solved by\n\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n\nwhere \\mathbf{1} is the vector of ones. By rewriting the equation, we get\n\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n\nBy taking the inverse of \\mathbf{I} - \\lambda \\mathbf{A}, we get\n\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n\n\n\n\nPageRank is the celebrated idea behind Google Search and can be seen as a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In the Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers.\n\n27.6 Pen and paper exercises\n\nSchool exercises",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Module 6: Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#walk-based-centrality",
    "href": "m06-centrality/01-concepts.html#walk-based-centrality",
    "title": "27¬† Module 6: Centrality Concepts",
    "section": "27.5 Walk-based centrality",
    "text": "27.5 Walk-based centrality\n‚ÄúA man is known by the company he keeps‚Äù is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire. It suggests that a person‚Äôs character is reflected by the people this person is friends with. This idea can be applied to define the centrality of a node in a network.\nThis family of centrality measures considers that a node is important if it is connected to other important nodes, or if it receives many ‚Äúwalks‚Äù or ‚Äúvotes‚Äù from other nodes in the network. These measures often use recursive definitions and are computed using linear algebra techniques.\nEigenvector centrality considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here‚Äôs the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet‚Äôs think about it for a moment. We want our centrality measure to be positive. It wouldn‚Äôt make much sense to have negative importance! So, we‚Äôre looking for an eigenvector where all the elements are positive. And a good news is that there‚Äôs a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associated with the largest eigenvalue always has all positive elements.\nHyperlink-Induced Topic Search (HITS) centrality\nextends eigenvector centrality to directed networks. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet‚Äôs put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbf{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree d_j of the authority, namely\n\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting x_i = d_i.\n\n\nKatz centrality addresses a limitation of eigenvector centrality, which tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. The solution is to add a little bit of score to all nodes.\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nDerive the solution of the Katz centrality.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe equation can be solved by\n\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n\nwhere \\mathbf{1} is the vector of ones. By rewriting the equation, we get\n\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n\nBy taking the inverse of \\mathbf{I} - \\lambda \\mathbf{A}, we get\n\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n\n\n\n\nPageRank is the celebrated idea behind Google Search and can be seen as a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In the Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers.\n\n27.6 Pen and paper exercises\n\nSchool exercises",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Module 6: Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#pen-and-paper-exercises",
    "href": "m06-centrality/01-concepts.html#pen-and-paper-exercises",
    "title": "27¬† Module 6: Centrality Concepts",
    "section": "27.6 Pen and paper exercises",
    "text": "27.6 Pen and paper exercises\n\nSchool exercises",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Module 6: Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "m06-centrality/02-coding.html",
    "href": "m06-centrality/02-coding.html",
    "title": "28¬† Computing centrality with Python",
    "section": "",
    "text": "28.1 Network of university students\nLet‚Äôs compute the centrality of the network using Python igraph.\nigraph offers a wide range of centrality measures as methods of the igraph.Graph class.\nFor example, the closeness centrality is computed by",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Computing centrality with Python</span>"
    ]
  },
  {
    "objectID": "m06-centrality/02-coding.html#network-of-university-students",
    "href": "m06-centrality/02-coding.html#network-of-university-students",
    "title": "28¬† Computing centrality with Python",
    "section": "",
    "text": "# Uncomment if you use Colab\n#!pip install igraph\nimport igraph\nnames  = ['Sarah', 'Mike', 'Emma', 'Alex', 'Olivia', 'James', 'Sophia', 'Ethan', 'Ava', 'Noah', 'Lily', 'Lucas', 'Henry']\nedge_list = [(0, 1), (0, 2), (1, 2), (2, 3), (3, 4), (3, 5), (3, 6), (4, 5), (6, 7), (6, 8), (6, 9), (7, 8), (7, 9), (8, 9), (9, 10), (9, 11), (9, 12)]\ng = igraph.Graph()\ng.add_vertices(13)\ng.vs[\"name\"] = names\ng.add_edges(edge_list)\nigraph.plot(g, vertex_label=g.vs[\"name\"])\n\n\nDegree centrality: igraph.Graph.degree()\nCloseness centrality: igraph.Graph.closeness()\nBetweenness centrality: igraph.Graph.betweenness()\nHarmonic centrality: igraph.Graph.harmonic_centrality()\nEccentricity: igraph.Graph.eccentricity()\nEigenvector centrality: igraph.Graph.eigenvector_centrality()\nPageRank centrality: igraph.Graph.personalized_pagerank()\n\n\ng.closeness()\n\n28.1.1 Computing Katz centrality\nLet‚Äôs compute the Katz centrality without using igraph. Let us first define the adjacency matrix of the graph\nA = g.get_adjacency_sparse()\nwhich is the scipy CSR sparse matrix. The Katz centrality is given by\n$$\n = + \n$$\nSo, how do we solve this? We can use a linear solver but here we will use a simple method:\n\nInitialize \\mathbf{c} with a random vector.\nCompute the right hand side of the equation and update \\mathbf{c}.\nRepeat the process until \\mathbf{c} converges.\n\nLet‚Äôs implement this.\nimport numpy as np\n\nalpha, beta = 0.1, 0.05 # Hyperparameters\nn_nodes = g.vcount() # number of nodes\nc = np.random.rand(n_nodes, 1) # column random vector\n\nfor _ in range(100):\n    c_next = beta * np.ones((n_nodes, 1)) + alpha * A * c\n    if np.linalg.norm(c_next - c) &lt; 1e-6:\n        break\n    c = c_next\nprint(c)\n\nDoes the centrality converge?\nChange the hyperparameter and see how the result changes üòâ If the centrality diverges, think about why it diverges.\n\nHint: Katz centrality can be analytically computed by\n$$\n = ( - )^{-1} \n$$\n\n\n28.1.2 Exercise (Optional)\nCompute the PageRank centrality of this graph",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Computing centrality with Python</span>"
    ]
  },
  {
    "objectID": "m06-centrality/02-coding.html#network-of-ancient-roman-roads",
    "href": "m06-centrality/02-coding.html#network-of-ancient-roman-roads",
    "title": "28¬† Computing centrality with Python",
    "section": "28.2 Network of ancient Roman roads",
    "text": "28.2 Network of ancient Roman roads\n\n28.2.1 Load the data & construct the network\nimport pandas as pd\n\nroot = \"https://raw.githubusercontent.com/skojaku/adv-net-sci/main/data/roman-roads\"\nnode_table = pd.read_csv(f\"{root}/node_table.csv\")\nedge_table = pd.read_csv(f\"{root}/edge_table.csv\")\nThe node table:\nnode_table.head(3)\nThe edge table:\nedge_table.head(3)\nLet‚Äôs construct a network from the node and edge tables.\nimport igraph\n\ng = igraph.Graph() # create an empty graph\ng.add_vertices(node_table[\"node_id\"].values) # add nodes\ng.add_edges(list(zip(edge_table[\"src\"].values, edge_table[\"trg\"].values))) # add edges\nwhich looks like this:\ncoord = list(zip(node_table[\"lon\"].values, -node_table[\"lat\"].values))\nigraph.plot(g, layout = coord, vertex_size = 5)\n\n\n28.2.2 Exercise üèõÔ∏è\n\nCompute the following centrality measures:\n\nDegree centrality üî¢\nEigenvector centrality\nPageRank centrality\nKatz centrality\nBetweenness centrality\nCloseness centrality\n\nPlot the centrality measures on the map and see in which centrality Rome is the most important node. üó∫Ô∏èüèõÔ∏è (as beautiful as possible!!)",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Computing centrality with Python</span>"
    ]
  },
  {
    "objectID": "m06-centrality/03-exercises.html",
    "href": "m06-centrality/03-exercises.html",
    "title": "29¬† Assignment",
    "section": "",
    "text": "We will compute the various centrality measures for airport networks.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "M06: Centrality",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Assignment</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html",
    "href": "m07-random-walks/00-preparation.html",
    "title": "30¬† Preparation: Markov Chain Theory Prerequisites",
    "section": "",
    "text": "30.1 Required Knowledge from Previous Modules\nBefore studying random walks, ensure you understand: - From M01-M06: Network representations, eigenvalue theory, matrix operations - From M06: Advanced concepts like matrix series convergence and spectral properties",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Preparation: Markov Chain Theory Prerequisites</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#probability-theory-for-stochastic-processes",
    "href": "m07-random-walks/00-preparation.html#probability-theory-for-stochastic-processes",
    "title": "30¬† Preparation: Markov Chain Theory Prerequisites",
    "section": "30.2 Probability Theory for Stochastic Processes",
    "text": "30.2 Probability Theory for Stochastic Processes\n\n30.2.1 Discrete Probability Basics\nFoundation for understanding random processes: - Probability distributions: Discrete probability mass functions - Conditional probability: P(A|B) = \\frac{P(A \\cap B)}{P(B)} - Independence: When events don‚Äôt influence each other - Law of total probability: P(A) = \\sum_i P(A|B_i)P(B_i)\n\n\n30.2.2 Stochastic Processes\nUnderstanding time-dependent random systems: - Random variable sequences: X_0, X_1, X_2, \\ldots - State space: Set of possible values for each X_t - Transition probabilities: P(X_{t+1} = j | X_t = i)",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Preparation: Markov Chain Theory Prerequisites</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#markov-chain-fundamentals",
    "href": "m07-random-walks/00-preparation.html#markov-chain-fundamentals",
    "title": "30¬† Preparation: Markov Chain Theory Prerequisites",
    "section": "30.3 Markov Chain Fundamentals",
    "text": "30.3 Markov Chain Fundamentals\n\n30.3.1 Markov Property\nThe defining characteristic of Markov chains: P(X_{t+1} = j | X_t = i, X_{t-1} = i_{t-1}, \\ldots, X_0 = i_0) = P(X_{t+1} = j | X_t = i)\nInterpretation: Future state depends only on present state, not on history.\n\n\n30.3.2 Transition Matrix Theory\nMatrix representation of state transitions: - Stochastic matrix: Rows sum to 1, all entries non-negative - Chapman-Kolmogorov equation: P^{(n+m)} = P^{(n)} \\cdot P^{(m)} - n-step transition probabilities: (P^n)_{ij} = P(X_n = j | X_0 = i)\n\n\n30.3.3 Classification of States\nUnderstanding different types of states: - Accessible: State j is accessible from state i if P^{(n)}_{ij} &gt; 0 for some n - Communicating: States i and j communicate if each is accessible from the other - Irreducible: All states communicate with each other - Periodic: State i has period d if returns are only possible at multiples of d steps",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Preparation: Markov Chain Theory Prerequisites</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#limit-behavior-and-convergence",
    "href": "m07-random-walks/00-preparation.html#limit-behavior-and-convergence",
    "title": "30¬† Preparation: Markov Chain Theory Prerequisites",
    "section": "30.4 Limit Behavior and Convergence",
    "text": "30.4 Limit Behavior and Convergence\n\n30.4.1 Stationary Distributions\nProbability distributions that don‚Äôt change over time: - Definition: \\pi P = \\pi where \\pi is a row vector - Existence: Guaranteed for finite, irreducible chains - Uniqueness: Unique for irreducible chains\n\n\n30.4.2 Convergence Theorems\nWhen and how chains reach equilibrium: - Ergodic theorem: For irreducible, aperiodic chains: \\lim_{n \\to \\infty} P^{(n)}_{ij} = \\pi_j - Rate of convergence: How quickly the chain approaches stationary distribution - Mixing time: Time needed to get close to stationary distribution",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Preparation: Markov Chain Theory Prerequisites</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#linear-algebra-for-markov-chains",
    "href": "m07-random-walks/00-preparation.html#linear-algebra-for-markov-chains",
    "title": "30¬† Preparation: Markov Chain Theory Prerequisites",
    "section": "30.5 Linear Algebra for Markov Chains",
    "text": "30.5 Linear Algebra for Markov Chains\n\n30.5.1 Eigenvalue Structure\nConnection between eigenvalues and chain behavior: - Dominant eigenvalue: Always equals 1 for stochastic matrices - Subdominant eigenvalue: Controls convergence rate - Spectral gap: Difference between largest and second-largest eigenvalues\n\n\n30.5.2 Perron-Frobenius for Stochastic Matrices\nSpecial properties of transition matrices: - Principal eigenvalue: Always 1 - Principal eigenvector: Corresponds to stationary distribution - Non-negative entries: All eigenvector entries are non-negative",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Preparation: Markov Chain Theory Prerequisites</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#applications-context",
    "href": "m07-random-walks/00-preparation.html#applications-context",
    "title": "30¬† Preparation: Markov Chain Theory Prerequisites",
    "section": "30.6 Applications Context",
    "text": "30.6 Applications Context\n\n30.6.1 Random Walks on Graphs\nSpecific application of Markov chains to networks: - State space: Nodes of the graph - Transition probabilities: Based on edge structure - Uniformity: Equal probability to each neighbor\n\n\n30.6.2 Information Propagation\nUnderstanding how information spreads: - Diffusion processes: How properties spread through networks - Equilibrium: Long-term distribution of walkers or information\nThese probability and linear algebra foundations are essential for understanding how random walks reveal network structure through their stationary distributions and convergence properties.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Preparation: Markov Chain Theory Prerequisites</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html",
    "href": "m07-random-walks/01-concepts.html",
    "title": "31¬† Random Walks: Core Concepts",
    "section": "",
    "text": "31.1 Introduction through Games: Ladder Lottery\nIn this module, we will learn random walks, one of the most fundamental techniques in network analysis. We‚Äôll explore what random walks are, how to simulate them on networks, their behavior patterns, and their connections to community detection and network centralities.\nTo make these concepts tangible, let‚Äôs start with a fun game that perfectly illustrates random walk principles:\nThe Ladder Lottery game is actually a perfect introduction to random walks! In this game, states are the vertical lines, transitions happen when you encounter horizontal connections, randomness comes from not knowing where the horizontal lines are placed, and long-term behavior determines your probability of winning. This simple game illustrates many key concepts we‚Äôll explore in random walks on networks.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Random Walks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#introduction-through-games-ladder-lottery",
    "href": "m07-random-walks/01-concepts.html#introduction-through-games-ladder-lottery",
    "title": "31¬† Random Walks: Core Concepts",
    "section": "",
    "text": "Ladder Lottery\n\n\n\n:class: tip\nLadder Lottery is a fun East Asian game, also known as ‚ÄúÈ¨ºËÖ≥Âúñ‚Äù (Guijiaotu) in Chinese, ‚ÄúÈòøÂº•ÈôÄÁ±§‚Äù (Amida-kuzi) in Japanese, ‚ÄúÏÇ¨Îã§Î¶¨ÌÉÄÍ∏∞‚Äù (Sadaritagi) in Korean, and ‚ÄúLadder Lottery‚Äù in English. The game is played as follows: 1. A player is given a board with a set of vertical lines. 2. The player chooses a line and starts to move along the line 3. When hitting a horizontal line, the player must move along the horizontal line and then continue to move along the next vertical line. 4. The player wins if the player can hit a marked line at the bottom of the board. 5. You cannot see the horizontal lines in advance!\nPlay the {{ ‚ÄòLadder Lottery Game! üéÆ‚ú®‚Äô.replace(‚ÄòBASE_URL‚Äô, base_url) }} and try to answer the following questions:\n\nIs there a strategy to maximize the probability of winning?\nHow does the probability of winning change as the number of horizontal lines increases?",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Random Walks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#understanding-random-walks",
    "href": "m07-random-walks/01-concepts.html#understanding-random-walks",
    "title": "31¬† Random Walks: Core Concepts",
    "section": "31.2 Understanding Random Walks",
    "text": "31.2 Understanding Random Walks\nSuppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network.\nMore formally, a random walk in undirected networks follows this process: 1. Start at a node i 2. Randomly choose an edge to traverse to a neighbor node j 3. Repeat step 2 until you have taken T steps\nIn directed networks, a random walker can only move along the edge direction, and it can be that the random walker is stuck in a so-called \"dead end\" that does not have any outgoing edges.\nWhen studying random walks, we want to understand several key aspects: short-term behavior (where does the walker go in the first few steps?), long-term behavior (after many steps, where does the walker spend most of its time?), structural insights (what does the walker‚Äôs behavior tell us about the network?), and applications (how can we use random walks for centrality and community detection?).",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Random Walks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#pen-and-paper-exercises",
    "href": "m07-random-walks/01-concepts.html#pen-and-paper-exercises",
    "title": "31¬† Random Walks: Core Concepts",
    "section": "31.3 Pen and Paper Exercises",
    "text": "31.3 Pen and Paper Exercises\nBefore diving into the mathematical details and coding, it‚Äôs important to work through some fundamental concepts by hand.\n\n‚úçÔ∏è Pen and paper exercises\n\nThese exercises will help you: - Understand the basic mechanics of random walks - Calculate transition probabilities manually - Explore simple examples of stationary distributions - Connect random walk concepts to network properties",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Random Walks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#preview-whats-coming-next",
    "href": "m07-random-walks/01-concepts.html#preview-whats-coming-next",
    "title": "31¬† Random Walks: Core Concepts",
    "section": "31.4 Preview: What‚Äôs Coming Next",
    "text": "31.4 Preview: What‚Äôs Coming Next\nIn the following sections, we will: 1. Dive into the mathematics behind random walks and their connection to Markov chains 2. Implement random walks in code and visualize their behavior on real networks 3. Explore applications including centrality measures and community detection 4. Work through practical exercises to solidify your understanding\nThe journey from this simple concept to powerful network analysis tools is both fascinating and practical!",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Random Walks: Core Concepts</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html",
    "href": "m07-random-walks/02-coding.html",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "",
    "text": "32.1 Introduction: Random Walks Everywhere\nSuppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network. It is surprising that this seemingly random, brainless behavior can tell us something deep about the structure of the city.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#random-walks-in-a-network",
    "href": "m07-random-walks/02-coding.html#random-walks-in-a-network",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.2 Random walks in a network",
    "text": "32.2 Random walks in a network\nA random walk in undirected networks is the following process: 1. Start at a node i 2. Randomly choose an edge to traverse to a neighbor node j 3. Repeat step 2 until you have taken T steps.\nIn case of directed networks, a random walker can only move along the edge direction, and it can be that the random walker is stuck in a so-called \"dead end\" that does not have any outgoing edges.\nHow does this simple process tell us something about the network structure? To get some insights, let us play with a simple interactive visualization.\n\n\n\n\n\n\nRandom Walk Simulation\n\n\n\n:class: tip\nPlay with the Random Walk Simulator! üéÆ‚ú® and try to answer the following questions:\n\nWhen the random walker makes many steps, where does it tend to visit most frequently?\nWhen the walker makes only a few steps, where does it tend to visit?\nDoes the behavior of the walker inform us about centrality of the nodes?\nDoes the behavior of the walker inform us about communities in the network?",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#implementing-random-walks-in-python",
    "href": "m07-random-walks/02-coding.html#implementing-random-walks-in-python",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.3 Implementing Random Walks in Python",
    "text": "32.3 Implementing Random Walks in Python\n\n32.3.1 Simulating Random Walks\nWe will simulate random walks on a simple graph of five nodes as follows.\n\n\nCode\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n\n\nA random walk is characterized by the transition probabilities between nodes.\n\nP_{ij} = \\frac{A_{ij}}{k_i}\n\nLet us first compute the transition probabilities and store them in a matrix, \\mathbf{P}.\n\n\nCode\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] &gt; 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i-&gt;ij\", A, 1 / k)\n\n\n\n\nCode\nprint(\"Transition probability matrix:\\n\", P)\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n\n\nEach row and column of \\mathbf{P} corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\nNow, let us simulate a random walk on this graph. We represent a position of the walker by a vector, \\mathbf{x}, with five elements, each of which represents a node. We mark the node that the walker is currently at by 1 and others as 0.\n\n\nCode\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n\n\nThis vector representation is convenient to get the probabilities of transitions to other nodes from the current node:\n\n\\mathbf{x} \\mathbf{P}\n\nwhich is translated into the following code:\n\n\nCode\nprobs = x @ P\nprint(\"Position of the walker after one step:\\n\", probs)\n\n\nWe can then draw the next node based on the probabilities\n\n\nCode\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position of the walker after one step:\\n\", x)\n\n\nBy repeating this process, we can simulate the random walk.\n\n\n32.3.2 Exercise 01\nWrite the following function to simulate the random walk for a given number of steps and return the x for each step.\n\n\nCode\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x (np.ndarray): The initial position of the walker.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#expected-behavior-of-random-walks",
    "href": "m07-random-walks/02-coding.html#expected-behavior-of-random-walks",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.4 Expected behavior of random walks",
    "text": "32.4 Expected behavior of random walks\nWhat is the expected position of the walker after multiple steps? It is easy to compute the expected position of the walker after one step from initial position x(0):\n\n\\mathbb{E}[x(1)] = x(0) P\n\nwhere x(t) is the probability distribution of the walker at time t. In Python, the expected position of the walker at time t=1 is given by\n\n\nCode\nx_0 = np.array([1, 0, 0, 0, 0])\nx_1 = x_0 @ P\nprint(\"Expected position of the walker after one step:\\n\", x_1)\n\n\nFor the second step, the expected position of the walker is given by\n\n\\mathbb{E}[x(2)] = \\mathbb{E}[x(1) P] = \\mathbb{E}[x(0) P] P = x(0) P^2\n\nIn other words,\n\n\nCode\nx_2 = x_1 @ P\nprint(\"Expected position of the walker after two steps:\\n\", x_2)\n\n\nFollowing the same argument, the expected position of the walker at time t is given by\n\n\\mathbb{E}[x(t)] = x(0) P^t\n\n\n32.4.1 Exercise 02\nWrite a function to compute the expected position of the walker at time t using the above formula:\n\n\nCode\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n    \"\"\"\n    # Your code here\n    pass\n\n\n\n\n32.4.2 Exercise 03\nPlot each element of x(t) as a function of t for t=0,1,2,\\ldots, 1000. Try different initial positions and compare the results!\nSteps: 1. Define the initial position of the walker. 2. Compute the expected position of the walker at time t using the function you wrote above. 3. Draw a line for each element of x(t), totalling 5 lines. 4. Create multiple such plots for different initial positions and compare them.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#mathematical-foundation-stationary-state",
    "href": "m07-random-walks/02-coding.html#mathematical-foundation-stationary-state",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.5 Mathematical Foundation: Stationary State",
    "text": "32.5 Mathematical Foundation: Stationary State\nLet‚Äôs dive into the math behind random walks in a way that‚Äôs easy to understand.\nImagine you‚Äôre at node i at time t. You randomly move to a neighboring node j. The probability of this move, called the transition probability p_{ij}, is:\n\np_{ij} = \\frac{A_{ij}}{k_i},\n\nHere, A_{ij} is an element of the adjacency matrix, and k_i is the degree of node i. For a network with N nodes, we can represent all transition probabilities in a transition probability matrix P:\n\n\\mathbf{P} = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1N} \\\\\np_{21} & p_{22} & \\cdots & p_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{N1} & p_{N2} & \\cdots & p_{NN}\n\\end{pmatrix}\n\nThis matrix P encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps. For instance:\n\nAfter one step: P_{ij} = p_{ij}\nAfter two steps: \\left(\\mathbf{P}^{2}\\right)_{ij} = \\sum_{k} P_{ik} P_{kj}\nAfter T steps: \\left(\\mathbf{P}^{T}\\right)_{ij}\n\nLet's explore why $\\mathbf{P}^2$ represents the transition probabilities after two steps.\n\nFirst, recall that $\\mathbf{P}_{ij}$ is the probability of moving from node $i$ to node $j$ in one step. Now, consider a two-step walk from $i$ to $j$. We can express this as:\n\n$$(\\mathbf{P}^2)_{ij} = \\sum_k \\mathbf{P}_{ik} \\mathbf{P}_{kj}$$\n\nThis equation encapsulates a key idea: to go from $i$ to $j$ in two steps, we must pass through some intermediate node $k$. Let's break this down step by step:\n\n1. The probability of the first step ($i$ to $k$) is $\\mathbf{P}_{ik}$.\n2. The probability of the second step ($k$ to $j$) is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ ‚Üí $k$ ‚Üí $j$) is the product $\\mathbf{P}_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nLikewise, for three steps, we have:\n\n$$(\\mathbf{P}^3)_{ij} = \\sum_k \\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$$\n\nwhere:\n1. The probability of going from $i$ to $k$ in two steps is $\\left( \\mathbf{P}\\right)^2_{ik}$.\n2. The probability of going from $k$ to $j$ in one step is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ ‚Üí...‚Üí$k$ ‚Üí $j$) is the product $\\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nAnd we can extend this reasoning for any number of steps $t$.\n\nIn summary, for any number of steps $t$, $\\left( \\mathbf{P}^t \\right)_{ij}$ gives the probability of being at node $j$ after $t$ steps, starting from node $i$.\n\nAs T becomes very large, the probability distribution of being at each node, \\mathbf{x}(t), approaches a constant value:\n\n\\mathbf{x}(t+1) =\\mathbf{x}(t) \\mathbf{P}\n\nThis is an eigenvector equation. The solution, given by the Perron-Frobenius theorem, is called the stationary distribution:\n\n\\mathbf{x}(\\infty) = \\mathbb{\\pi}, \\; \\mathbf{\\pi} = [\\pi_1, \\ldots, \\pi_N]\n\nFor undirected networks, this stationary distribution always exists and is proportional to the degree of each node:\n\n\\pi_j = \\frac{k_j}{\\sum_{\\ell} k_\\ell} \\propto k_j\n\nThis means the probability of being at node j in the long run is proportional to the degree of node j. The normalization ensures that the sum of all probabilities is 1, i.e., \\sum_{j=1}^N \\pi_j = 1.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#practical-demonstration",
    "href": "m07-random-walks/02-coding.html#practical-demonstration",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.6 Practical Demonstration",
    "text": "32.6 Practical Demonstration\nLet us demonstrate the above math by using a small network using Python. Let us consider a small network of 5 nodes, which looks like this:\n\n\nCode\nimport igraph as ig\nimport numpy as np\nedge_list = []\nfor i in range(5):\n    for j in range(i+1, 5):\n        edge_list.append((i, j))\n        edge_list.append((i+5, j+5))\nedge_list.append((0, 6))\n\ng = ig.Graph(edge_list)\nig.plot(g, vertex_size=20, vertex_label=np.arange(g.vcount()))\n\n\nThe transition probability matrix P is given by:\n\n\nCode\nimport scipy.sparse as sparse\n\nA = g.get_adjacency_sparse()\ndeg = np.array(A.sum(axis=1)).flatten()\nDinv = sparse.diags(1/deg)\nP = Dinv @ A\nP.toarray()\n\n\nLet us compute the stationary distribution by using the power method.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.zeros(g.vcount())\nx[1] = 1 # Start from node 1\nT = 100\nxt = []\nfor t in range(T):\n    x = x.reshape(1, -1) @ P\n    xt.append(x)\n\nxt = np.vstack(xt) # Stack the results vertically\n\nfig, ax = plt.subplots(figsize=(7,5))\npalette = sns.color_palette().as_hex()\nfor i in range(g.vcount()):\n    sns.lineplot(x=range(T), y=xt[:, i], label=f\"Node {i}\", ax=ax, color=palette[i])\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Probability\")\nax.set_title(\"Stationary distribution of a random walk\")\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\nWe see that the distributions of the walker converges, and there are three characteristic features in the convergence: 1. The distribution of the walker oscillates with a decaying amplitude and eventually converges. 2. Nodes of the same degree converge to the same stationary probability. 3. Nodes with higher degree converge to the higher stationary probability.\nTo validate the last two observation, let us compare the stationary distribution of a random walker with the expected stationary distribution, which is proportional to the degree of the nodes.\n\n\nCode\nimport pandas as pd\n\nn_edges = np.sum(deg) / 2\nexpected_stationary_dist = deg / (2 * n_edges)\n\npd.DataFrame({\n    \"Expected stationary distribution\": expected_stationary_dist,\n    \"Stationary distribution of a random walk\": xt[-1].flatten()\n}).style.format(\"{:.4f}\").set_caption(\"Comparison of Expected and Observed Stationary Distributions\").background_gradient(cmap='cividis', axis = None)",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#community-structure",
    "href": "m07-random-walks/02-coding.html#community-structure",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.7 Community structure",
    "text": "32.7 Community structure\nRandom walks can capture community structure of a network. To see this, let us consider a network of a ring of cliques.\n\n\nCode\nimport networkx as nx\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nn_cliques = 3\nn_nodes_per_clique = 5\n\nG = nx.ring_of_cliques(n_cliques, n_nodes_per_clique)\ng = igraph.Graph().Adjacency(nx.to_numpy_array(G).tolist()).as_undirected()\nmembership = np.repeat(np.arange(n_cliques), n_nodes_per_clique)\n\ncolor_map = [sns.color_palette()[i] for i in membership]\nigraph.plot(g, vertex_size=20, vertex_color=color_map)\n\n\nLet us compute the expected position of the walker after 1 to 10 steps.\nCompute the transition matrix:\n\n\nCode\n:tags: [hide-cell]\nfrom scipy import sparse\n\n# Get the adjacency matrix and degree\nA = g.get_adjacency_sparse()\nk = np.array(g.degree())\n\n# This is an efficient way to compute the transition matrix\n# using scipy.sparse\nP = sparse.diags(1 / k) @ A\n\n\nCompute the expected position of the walker after 1 to 300 steps:\n\n\nCode\n:tags: [hide-cell]\n\nx_t = np.zeros(g.vcount())\nx_t[2] = 1\nx_list = [x_t]\nfor t in range(300):\n    x_t = x_t @ P\n    x_list.append(x_t)\nx_list = np.array(x_list)\n\n\nPlot the expected position of the walker at each step:\n\n\nCode\n:tags: [hide-input]\n\ncmap = sns.color_palette(\"viridis\", as_cmap=True)\n\nsns.set_style('white')\nsns.set(font_scale=1.2)\nsns.set_style('ticks')\n\nfig, axes = plt.subplots(figsize=(15,10), ncols = 3, nrows = 2)\n\nt_list = [0, 1, 3, 5, 10, 299]\nfor i, t in enumerate(t_list):\n    igraph.plot(g, vertex_size=20, vertex_color=[cmap(x_list[t][j] / np.max(x_list[t])) for j in range(g.vcount())], target = axes[i//3][i%3])\n    axes[i//3][i%3].set_title(f\"$t$ = {t}\", fontsize = 25)\n\n\nwhere the color of each node represents the probability of the walker being at that node.\nAn important observation is that the walker spends more time in the clique that it started from and then diffuse to others. Thus, the position of the walker before reaching the steady state tells us the community structure of the network.\n\n32.7.1 Exercise 04\n\nGenerate a network of 100 nodes with 4 communities using a stochastic block model, with inter-community edge probability 0.05 and intra-community edge probability 0.2. Then, compute the expected position of the walker starting from node zero after x steps. Plot the results for x = 0, 5, 10, 1000.\nIncrease the inter-community edge probability to 0.15 and repeat the simulation. Compare the results with the previous simulation.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#advanced-topics-mixing-time-and-spectral-analysis",
    "href": "m07-random-walks/02-coding.html#advanced-topics-mixing-time-and-spectral-analysis",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.8 Advanced Topics: Mixing Time and Spectral Analysis",
    "text": "32.8 Advanced Topics: Mixing Time and Spectral Analysis\n\n32.8.1 Time to reach the stationary state\nLet‚Äôs explore how quickly a random walker reaches its stationary state. The convergence speed is influenced by two main factors: edge density and community structure. In sparse networks, the walker needs more steps to explore the entire network. Additionally, the walker tends to remain within its starting community for some time.\nThe mixing time, denoted as t_{\\text{mix}}, is defined as the minimum number of steps required for a random walk to get close to the stationary distribution, regardless of the starting point, with the maximum error less than \\epsilon:\nt_{\\text{mix}} = \\min\\{t : \\max_{{\\bf x}(0)} \\|{\\bf x}(t) - {\\bf \\pi}\\|_{1} \\leq \\epsilon\\}\nwhere \\|{\\bf x}(t) - {\\bf \\pi}\\|_{1} = 2\\max_{i} |x_i(t) - \\pi_i| represents the L1 distance between two probability distributions. The choice of \\epsilon is arbitrary.\nWe know that the distribution of a walker after t steps is given by:\n\n\\mathbf{x}(t) =  \\mathbf{x}(0) \\mathbf{P} ^{t}\n\nTo find this distribution, we need to compute \\mathbf{P}^t. However, we face a challenge: \\mathbf{P} is not diagonalizable.\nA diagonalizable matrix \\mathbf{S} can be written as \\mathbf{S} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1}, where \\mathbf{\\Lambda} is a diagonal matrix and \\mathbf{Q} is an orthogonal matrix. Visually, it looks like this:\n\nIt is useful because we can then compute the power of the matrix as follows:\n\n\\mathbf{S}^t = \\mathbf{Q} \\mathbf{\\Lambda}^t \\mathbf{Q}^{-1}\n\nAnd it is easy to find {\\bf Q} and {\\bf \\Lambda} by using eigenvalue decomposition if {\\bf S} is symmetric and consists only of real values. Namely, the eigenvectors form {\\cal Q} and the eigenvalues form the diagonal matrix {\\cal \\Lambda}.\nLet us demonstrate the above relation by calculating $\\mathbf{S}^2$.\n$$\n\\begin{align}\n\\mathbf{S}^2 &= \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1} \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1} \\\\\n&= \\mathbf{Q} \\mathbf{\\Lambda}^2 \\mathbf{Q}^{-1}.\n\\end{align}\n$$\n(Note that $\\mathbf{Q} \\mathbf{Q}^{-1} = {\\bf I}$.)\n\n![](../figs/diagonalizable-squared.jpg)\n\n\\mathbf{P} is also diagonalizable but not symmetric like \\mathbf{\\overline A} so that we cannot use the above relation directly. So we do a trick by rewriteing \\mathbf{P} as:\n\n\\mathbf{P} = \\mathbf{D}^{-1} \\mathbf{A} = \\mathbf{D}^{-\\frac{1}{2}} \\overline {\\bf A} \\mathbf{D}^{\\frac{1}{2}}\n\nwhere \\overline{\\bf A} = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} is the normalized adjacency matrix.\nThe advantage is that \\overline{\\bf A} is diagonalizable: \\overline{\\bf A} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^\\top. Using this, we can compute \\mathbf{P}^t:\n\n\\mathbf{P}^t = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q} \\mathbf{\\Lambda}^t \\mathbf{Q}^\\top \\mathbf{D}^{\\frac{1}{2}} = \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R ^\\top\n\nwhere \\mathbf{Q}_L = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q} and \\mathbf{Q}_R = \\mathbf{D}^{\\frac{1}{2}} \\mathbf{Q}.\nLet us demonstrate the above relation by calculating $\\mathbf{P}^2$.\n\n$$\n\\begin{align}\n\\mathbf{P}^2 &= \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} \\mathbf{D}^{\\frac{1}{2}} \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} \\mathbf{D}^{\\frac{1}{2}}\\\\\n&=  \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} ^2 \\mathbf{D}^{\\frac{1}{2}}\\\\\n&= \\mathbf{Q}_L \\mathbf{\\Lambda}^2 \\mathbf{Q}_R ^\\top\n\\end{align}\nThe probability distribution after t steps is then:\n\n\\mathbf{x}(t) = \\mathbf{x}(0) \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R ^\\top\n\nWe can rewrite this in a more intuitive form:\n\n\\begin{pmatrix}\nx_1(t) \\\\\nx_2(t) \\\\\n\\vdots \\\\\nx_N(t)\n\\end{pmatrix}\n=\n\\sum_{\\ell=1}^N\n\\left[\n\\lambda_\\ell^t\n\\begin{pmatrix}\nq^{(L)}_{\\ell 1} \\\\\nq^{(L)}_{\\ell 2} \\\\\n\\vdots \\\\\nq^{(L)}_{\\ell N}\n\\end{pmatrix}\n\\langle\\mathbf{q}^{(R)}_{\\ell},  \\mathbf{x}(0) \\rangle\n\\right]\n\nVisualize the above equation by using the following figure.\n\n![](../figs/diagonalizable-sum.jpg)\n\nThe term \\lambda_\\ell^t represents the contribution of each eigenvalue to the stationary distribution over time. As t increases, all terms decay exponentially except for the largest eigenvalue (\\lambda_1 = 1). This explains how the random walk converges to the stationary distribution:\n\n\\pi_i = \\lim_{t\\to\\infty} x_i(t) = \\begin{pmatrix} q^{(L)}_{1 1} \\\\ q^{(L)}_{1 2} \\\\ \\vdots \\\\ q^{(L)}_{1 N} \\end{pmatrix} \\langle\\mathbf{q}^{(R)}_{1},  \\mathbf{x}(0) \\rangle\n\nThe second largest eigenvalue primarily determines the convergence speed to the stationary distribution. A larger second eigenvalue leads to slower convergence. Thus, the mixing time is closely related to the second largest eigenvalue.\nLevin-Peres-Wilmer theorem states that the mixing time is bounded by the relaxation time as\n\nt_{\\text{mix}} &lt; \\tau \\log \\left( \\frac{1}{\\epsilon \\min_{i} \\pi_i} \\right), \\quad \\tau = \\frac{1}{1-\\lambda_2}\n\nwhere \\lambda_2 is the second largest eigenvalue of the normalized adjacency matrix. The mixing time is known to be bounded by the relaxation time as\nMore commonly, it is expressed using the second smallest eigenvalue \\mu of the normalized laplacian matrix as\n\nt_{\\text{mix}} \\leq \\frac{1}{\\mu}\n\nwhere \\mu = 1-\\lambda_2.\n\n\n32.8.2 Compute the mixing time\nLet us demonstrate the above math by using the network of two cliques.\n\n\n32.8.3 Normalized Adjacency Matrix\nFirst, let us construct the normalized adjacency matrix \\overline{\\bf A} of the network.\n\n\nCode\nDinv_sqrt = sparse.diags(1.0/np.sqrt(deg))\nA_norm = Dinv_sqrt @ A @ Dinv_sqrt\n\n\nNext, let us compute the eigenvalues and eigenvectors of the normalized adjacency matrix.\n\n\nCode\nevals, evecs = np.linalg.eigh(A_norm.toarray())\n\n\n`evals` and `evecs` are sorted in descending order of the eigenvalues. `evecs[:, 0]` is the eigenvector corresponding to the largest eigenvalue, which is always 1.\nThere is a similar function called `np.linalg.eig` which returns the eigenvalues and eigenvectors. It can be used for any matrices, while `np.linalg.eigh` is specifically for symmetric matrices. `np.linalg.eigh` is faster and more stable and therefore preferred if your matrix is symmetric. `np.linalg.eig` is more susceptible to numerical errors and therefore less stable.\nThe eigenvalues and eigenvectors are shown below.\n\n\nCode\npd.DataFrame({\n    \"Eigenvalue\": evals\n}).T.style.background_gradient(cmap='cividis', axis = 1).set_caption(\"Eigenvalues of the normalized adjacency matrix\")\n\n\n\n\nCode\npd.DataFrame({\n    \"Eigenvector %i\" % i: evecs[:, i]\n    for i in range(10)\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Eigenvectors of the normalized adjacency matrix\")\n\n\nNotice that the largest eigenvalue is 1, which is always true for a normalized adjacency matrix. The largest eigenvector (the leftmost one) is associated with the stationary distribution of the random walk.\nThe sign of the eigenvector is indeterminate, which means we can choose the sign of the eigenvector arbitrarily. In fact, `np.linalg.eigh` returns the eigenvector whose sign can vary for a different run.\nWe decompose \\overline{\\bf A} as\n\\overline {\\bf A} = {\\bf Q}{\\bf \\Lambda}{\\bf Q}^\\top\nwhere {\\bf Q} corresponds to eigvecs and {\\bf \\Lambda} corresponds to np.diag(evals) (since {\\bf \\Lambda} is a diagonal matrix). Let‚Äôs see if this is correct:\n\n\nCode\npd.DataFrame(A_norm.toarray()).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Normalized Adjacency Matrix\")\n\n\n\n\nCode\nA_norm_reconstructed = evecs @ np.diag(evals) @ evecs.T\npd.DataFrame(A_norm_reconstructed).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Reconstruction of the Normalized Adjacency Matrix\")\n\n\nNotice that the reconstruction is not perfect due to the numerical error, although overall the structure is correct.\n\n\n32.8.4 Multi-step Transition Probability\nLet us first conform whether we can compute the transition probability after t steps by using the eigenvalues and eigenvectors.\n\n\nCode\nt = 5\nx_0 = np.zeros(g.vcount())\nx_0[0] = 1\n\n# Compute x_t by using the eigenvalues and eigenvectors\nQ_L = np.diag(1.0/np.sqrt(deg)) @ evecs\nQ_R = np.diag(np.sqrt(deg)) @ evecs\nx_t = x_0 @ Q_L @ np.diag(evals**t) @ Q_R.T\n\n# Compute x_t by using the power iteration\nx_t_power = x_0.copy()\nfor i in range(t):\n    x_t_power = x_t_power @ P\n\npd.DataFrame({\n    \"Eigenvector\": x_t.flatten(),\n    \"Power iteration\": x_t_power.flatten()\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Comparison of Eigenvector and Power Iteration\")\n\n\n\n\n32.8.5 Relaxation Time and Mixing Time\nLet us measure the relaxation time of the random walk.\n\n\nCode\nevals, evecs = np.linalg.eigh(A_norm.toarray())\nlambda_2 = -np.sort(-evals)[1]\ntau = 1 / lambda_2\nprint(f\"The relaxation time of the random walk is {tau:.4f}.\")",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#unifying-centrality-and-communities",
    "href": "m07-random-walks/02-coding.html#unifying-centrality-and-communities",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.9 Unifying Centrality and Communities",
    "text": "32.9 Unifying Centrality and Communities\n\n32.9.1 Modularity: Random Walk Perspective\nModularity can be interpreted from a random walk perspective. Modularity is given by\n\nQ = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)\n\nwhere m is the number of edges in the network, A_{ij} is the adjacency matrix, d_i is the degree of node i, c_i is the community of node i, and \\delta(c_i, c_j) is the Kronecker delta function (which is 1 if c_i = c_j and 0 otherwise).\nWe can rewrite the modularity using the language of random walks as follows.\n\n\\begin{aligned}\nQ &= \\sum_{ij} \\left(\\frac{A_{ij}}{2m}  - \\frac{d_i}{2m} \\frac{d_j}{2m} \\right) \\delta(c_i, c_j) \\\\\n&= \\sum_{ij} \\left(\\pi_i P_{ij}  - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)\n\\end{aligned}\n where \\pi_i is the stationary distribution of the random walk given by\n\n\\pi_i = \\frac{d_i}{2m}\n\nand P_{ij} is the transition probability between nodes i and j.\nLet's break down this derivation step by step:\n\n1. We start with the original modularity formula:\n\n   $$Q = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)$$\n\n2. First, we move the constant $1/(2m)$ to the inside of the parentheses:\n\n   $$Q = \\sum_{ij} \\left(\\frac{A_{ij}}{2m} - \\frac{d_i d_j}{2m^2} \\right) \\delta(c_i, c_j)$$\n\n3. Now, we recognize that $\\frac{A_{ij}}{2m}$ can be rewritten as:\n\n   $$\\frac{A_{ij}}{2m} = \\frac{d_i}{2m} \\cdot \\frac{A_{ij}}{d_i} = \\pi_i P_{ij}$$\n\n4. We also recognize that $\\frac{d_i}{2m}$ is the stationary distribution of the random walk, which we denote as $\\pi_i$:\n\n   $$\\frac{d_i}{2m} = \\pi_i$$\n\n5. Substituting these into our equation:\n\n   $$Q = \\sum_{ij} \\left(\\pi_i P_{ij} - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)$$\n\nThe expression suggests that:\n\nThe first term, \\pi_i P_{ij} \\delta(c_i, c_j), represents the probability that a walker is at node i and moves to node j within the same community by one step.\nThe second term, \\pi_i \\pi_j, represents the probability that a walker is at node i and moves to another node j within the same community after long steps.\n\nIn summary, modularity compares short-term and long-term random walk probabilities. High modularity indicates that a random walker is more likely to stay within the same community after one step than after many steps.\nBuilding on this perspective from random walks, Delvenne et al. {footcite}`delvenne2010stability` extends the modularity by comparing multi-step and long-step transition probabilities of a random walk. This approach, known as \"Markov stability\", shows that the number of steps acts as a \"resolution parameter\" that determines the scale of detectable communities.\n\n\n32.9.2 PageRank: Random Walk Perspective\nPageRank can be interpreted from a random walk perspective:\n\nc_i = (1-\\beta) \\sum_j P_{ji} c_j + \\beta \\cdot \\frac{1}{N}\n\nWhere: - c_i is the PageRank of node i - P_{ji} is the transition probability from node j to node i - \\beta is the teleportation probability - N is the total number of nodes\nThis equation represents a random walk where: 1. With probability (1-\\beta), the walker follows a link to the next node. 2. With probability \\beta, the walker teleports to a random node in the network.\nThe PageRank c_i is the stationary distribution of this random walk, representing the long-term probability of finding the walker at node i.\nThis sounds odd at first glance. But it makes sense when you think about what PageRank was invented for, i.e., Web search. It characterizes a web surfer as a random walker that chooses the next page by randomly jumping to a random page with probability $\\beta$ or by following a link to a page with probability $1-\\beta$. The web page with the largest PageRank means that the page is most likely to be visited by this random web surfer.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#summary",
    "href": "m07-random-walks/02-coding.html#summary",
    "title": "32¬† Random Walks: Implementation and Applications",
    "section": "32.10 Summary",
    "text": "32.10 Summary\nRandom walks provide a powerful unified framework for understanding both centrality measures and community structure in networks. Through our exploration, we‚Äôve seen how:\n\nImplementation: Random walks can be efficiently simulated and analyzed using matrix operations\nStationary distributions: Connect to centrality measures, with degree centrality emerging naturally\nTemporal dynamics: Reveal community structure through short-term vs.¬†long-term behavior\nMathematical foundation: Links to spectral graph theory and eigenvalue analysis\nApplications: Provide new interpretations of modularity and PageRank\n\nThis unified perspective opens up new possibilities for network analysis and algorithm design, making random walks one of the most versatile tools in network science.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Random Walks: Implementation and Applications</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html",
    "href": "m07-random-walks/03-exercises.html",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "",
    "text": "33.1 Coding Exercises\nThis section contains all the exercises from the Random Walks module, organized by topic and difficulty level.",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#coding-exercises",
    "href": "m07-random-walks/03-exercises.html#coding-exercises",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "",
    "text": "33.1.1 Exercise 01: Basic Random Walk Simulation\nWrite the following function to simulate the random walk for a given number of steps and return the position for each step.\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass\nHints: - Initialize the walker at a random starting position - Use the transition probability matrix P = A / k (where k is the degree vector) - For each step, randomly choose the next node based on transition probabilities - Store the position at each step\n\n\n33.1.2 Exercise 02: Expected Position Calculation\nWrite a function to compute the expected position of the walker at time t using the formula \\mathbb{E}[x(t)] = x(0) P^t:\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The expected position distribution at time t.\n    \"\"\"\n    # Your code here\n    pass\nHints: - Compute the transition matrix P from adjacency matrix A - Use matrix power P^t to get multi-step transition probabilities - Apply the initial distribution x_0 to get the expected position\n\n\n33.1.3 Exercise 03: Convergence Analysis\nPlot each element of x(t) as a function of t for t=0,1,2,\\ldots, 1000. Try different initial positions and compare the results!\nSteps: 1. Define the initial position of the walker 2. Compute the expected position of the walker at time t using the function from Exercise 02 3. Draw a line for each element of x(t), totaling 5 lines for a 5-node network 4. Create multiple such plots for different initial positions and compare them\nQuestions to explore: - Do all initial positions converge to the same stationary distribution? - How long does it take to converge? - What does the stationary distribution tell us about the network structure?\n\n\n33.1.4 Exercise 04: Community Detection through Random Walks\n\nStochastic Block Model Analysis:\n\nGenerate a network of 100 nodes with 4 communities using a stochastic block model\nSet inter-community edge probability to 0.05 and intra-community edge probability to 0.2\nCompute the expected position of the walker starting from node zero after x steps\nPlot the results for x = 0, 5, 10, 1000\n\nParameter Sensitivity:\n\nIncrease the inter-community edge probability to 0.15 and repeat the simulation\nCompare the results with the previous simulation\nWhat happens to community detection when communities become more connected?\n\n\nImplementation hints:\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nimport networkx as nx\n\n# Example stochastic block model generation\ndef generate_sbm(n_nodes_per_community, p_within, p_between):\n    \"\"\"Generate a stochastic block model network\"\"\"\n    # Your implementation here\n    pass",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#theoretical-exercises",
    "href": "m07-random-walks/03-exercises.html#theoretical-exercises",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "33.2 Theoretical Exercises",
    "text": "33.2 Theoretical Exercises\n\n33.2.1 Exercise 05: HITS Centrality Analysis\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\nSolution Framework: - Consider the HITS equations for undirected networks - Compare with eigenvector centrality equation - Use the symmetry property of undirected networks - Show the mathematical relationship between the two measures\n\n\n33.2.2 Exercise 06: Degree-Normalized HITS\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree d_j of the authority:\n\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n\nShow that the hub centrality becomes equivalent to the degree centrality by substituting x_i = d_i.\nSteps to verify: 1. Substitute x_i = d_i into the first equation 2. Show that this satisfies the system of equations 3. Interpret the result in terms of network centrality",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#mathematical-derivation-exercises",
    "href": "m07-random-walks/03-exercises.html#mathematical-derivation-exercises",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "33.3 Mathematical Derivation Exercises",
    "text": "33.3 Mathematical Derivation Exercises\n\n33.3.1 Exercise 07: Katz Centrality Solution\nDerive the solution of the Katz centrality equation:\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\nSolution steps: - Write the equation in matrix form - Rearrange to isolate the centrality vector - Find the matrix inverse solution - Verify the solution satisfies the original equation\n\n\n33.3.2 Exercise 08: Random Walk Interpretation of PageRank\nShow that PageRank can be written as the stationary distribution of a modified random walk with teleportation.\nStarting equation: \nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nTasks: 1. Identify the transition probabilities in this equation 2. Show that this represents a Markov chain 3. Prove that the solution is a stationary distribution 4. Interpret the teleportation parameter \\beta",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#pen-and-paper-exercises",
    "href": "m07-random-walks/03-exercises.html#pen-and-paper-exercises",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "33.4 Pen and Paper Exercises",
    "text": "33.4 Pen and Paper Exercises\n\n33.4.1 Exercise 09: Manual Calculations\n\n‚úçÔ∏è Pen and paper exercises\n\nThese exercises include: - Hand calculation of transition matrices for small networks - Manual computation of stationary distributions - Step-by-step random walk simulations - Eigenvalue calculations for simple graphs",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#interactive-exercises",
    "href": "m07-random-walks/03-exercises.html#interactive-exercises",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "33.5 Interactive Exercises",
    "text": "33.5 Interactive Exercises\n\n33.5.1 Exercise 10: Ladder Lottery Analysis\nUsing the Ladder Lottery Game! üéÆ‚ú®, explore:\n\nStrategy Development:\n\nIs there a strategy to maximize the probability of winning?\nHow does the starting position affect winning probability?\n\nParameter Effects:\n\nHow does the probability of winning change as the number of horizontal lines increases?\nWhat happens with different numbers of vertical lines?\n\nConnection to Random Walks:\n\nHow does this game relate to random walks on networks?\nWhat type of transition matrix would represent this game?\n\n\n\n\n33.5.2 Exercise 11: Random Walk Simulation\nUsing the Random Walk Simulator! üéÆ‚ú®, investigate:\n\nShort-term vs.¬†Long-term behavior:\n\nWhen the random walker makes many steps, where does it tend to visit most frequently?\nWhen the walker makes only a few steps, where does it tend to visit?\n\nNetwork Structure Analysis:\n\nDoes the behavior of the walker inform us about centrality of the nodes?\nDoes the behavior of the walker inform us about communities in the network?\n\nParameter Exploration:\n\nTry different network topologies (star, ring, complete graph)\nObserve how network structure affects random walk behavior",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#advanced-exercises",
    "href": "m07-random-walks/03-exercises.html#advanced-exercises",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "33.6 Advanced Exercises",
    "text": "33.6 Advanced Exercises\n\n33.6.1 Exercise 12: Mixing Time Analysis\n\nTheoretical Calculation:\n\nFor a given network, compute the second-largest eigenvalue\nCalculate the theoretical mixing time bound\nCompare with empirical convergence time\n\nNetwork Comparison:\n\nCompare mixing times across different network types\nHow does community structure affect mixing time?\nWhat about scale-free vs.¬†random networks?\n\n\n\n\n33.6.2 Exercise 13: Modularity and Random Walks\n\nDerivation Verification:\n\nVerify the random walk interpretation of modularity step by step\nShow that high modularity corresponds to slow mixing between communities\n\nEmpirical Validation:\n\nGenerate networks with known community structure\nCompute modularity using both traditional and random walk approaches\nCompare the results and interpretation\n\n\n\n\n33.6.3 Exercise 14: Custom Centrality Measures\nDesign your own centrality measure based on random walks:\n\nDesign Phase:\n\nChoose a specific aspect of random walk behavior to capture\nDefine your measure mathematically\nJustify why it captures important network properties\n\nImplementation:\n\nImplement your measure in Python\nTest on various network types\nCompare with existing centrality measures\n\nValidation:\n\nEvaluate on networks where you know the ‚Äúground truth‚Äù\nAnalyze computational complexity\nDiscuss practical applications",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#challenge-problems",
    "href": "m07-random-walks/03-exercises.html#challenge-problems",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "33.7 Challenge Problems",
    "text": "33.7 Challenge Problems\n\n33.7.1 Exercise 15: Multi-layer Networks\nExtend random walks to multi-layer networks:\n\nModel Development:\n\nHow would you define transition probabilities between layers?\nWhat does the stationary distribution represent?\n\nImplementation:\n\nCode a multi-layer random walk simulator\nAnalyze convergence properties\nCompare with single-layer results\n\n\n\n\n33.7.2 Exercise 16: Dynamic Networks\nConsider random walks on time-varying networks:\n\nTheoretical Framework:\n\nHow do you handle changing adjacency matrices?\nWhat is the appropriate notion of stationary distribution?\n\nSimulation Study:\n\nImplement random walks on temporal networks\nStudy how network dynamics affect walker behavior\nDevelop time-dependent centrality measures",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#assessment-guidelines",
    "href": "m07-random-walks/03-exercises.html#assessment-guidelines",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "33.8 Assessment Guidelines",
    "text": "33.8 Assessment Guidelines\n\n33.8.1 For Instructors\nBeginner Level (Exercises 1-6): - Focus on understanding basic concepts - Emphasize coding implementation - Check mathematical derivations step-by-step\nIntermediate Level (Exercises 7-11): - Require deeper mathematical understanding - Expect connections between theory and practice - Look for creative interpretations\nAdvanced Level (Exercises 12-16): - Demand original thinking and research - Expect novel implementations - Require critical analysis and comparison\n\n\n33.8.2 Grading Rubric\nCode Quality (40%): - Correctness of implementation - Efficiency and elegance - Documentation and comments\nMathematical Understanding (30%): - Correct derivations - Clear explanations - Proper use of notation\nAnalysis and Interpretation (30%): - Insightful discussion of results - Connections to network science concepts - Critical thinking about limitations and extensions",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#additional-resources",
    "href": "m07-random-walks/03-exercises.html#additional-resources",
    "title": "33¬† Random Walks: Exercises and Practice",
    "section": "33.9 Additional Resources",
    "text": "33.9 Additional Resources\n\nDatasets: Use networks from SNAP, NetworkX, or create synthetic ones\nVisualization: Consider using NetworkX, igraph, or D3.js for interactive plots\nFurther Reading: Consult papers on spectral graph theory and Markov chain analysis\nSoftware: Explore specialized tools like graph-tool or GTNA for large-scale analysis",
    "crumbs": [
      "M07: Random Walks",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Random Walks: Exercises and Practice</span>"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html",
    "href": "m08-embedding/00-preparation.html",
    "title": "34¬† Preparation: Dimensionality Reduction and Optimization Prerequisites",
    "section": "",
    "text": "34.1 Required Knowledge from Previous Modules\nBefore studying network embedding, ensure you understand: - From M01-M07: Network representations, linear algebra, eigenvalue theory, and Markov chain concepts - From M07: Stationary distributions and spectral properties of random walks",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Preparation: Dimensionality Reduction and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#matrix-decomposition-theory",
    "href": "m08-embedding/00-preparation.html#matrix-decomposition-theory",
    "title": "34¬† Preparation: Dimensionality Reduction and Optimization Prerequisites",
    "section": "34.2 Matrix Decomposition Theory",
    "text": "34.2 Matrix Decomposition Theory\n\n34.2.1 Singular Value Decomposition (SVD)\nEssential decomposition for dimensionality reduction: - Definition: For matrix A: A = U \\Sigma V^T - Components: U (left singular vectors), \\Sigma (singular values), V (right singular vectors) - Properties: Provides optimal low-rank approximation in Frobenius norm - Truncated SVD: Using only top-k singular values/vectors for compression\n\n\n34.2.2 Low-Rank Approximation\nMathematical foundation for embedding: - Frobenius norm: ||A||_F = \\sqrt{\\sum_{ij} A_{ij}^2} - Optimal approximation: SVD minimizes ||A - A_k||_F for rank-k matrix A_k - Information preservation: How much structure is retained in low dimensions\n\n\n34.2.3 Principal Component Analysis (PCA)\nClassical dimensionality reduction technique: - Objective: Find directions of maximum variance - Covariance matrix: C = \\frac{1}{n-1}X^TX for centered data matrix X - Solution: Eigenvectors of covariance matrix - Connection to SVD: PCA eigenvectors are SVD right singular vectors",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Preparation: Dimensionality Reduction and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#optimization-fundamentals",
    "href": "m08-embedding/00-preparation.html#optimization-fundamentals",
    "title": "34¬† Preparation: Dimensionality Reduction and Optimization Prerequisites",
    "section": "34.3 Optimization Fundamentals",
    "text": "34.3 Optimization Fundamentals\n\n34.3.1 Objective Functions\nUnderstanding what we optimize in embedding: - Reconstruction error: How well embeddings recreate original data - Preservation metrics: Maintaining distances, similarities, or other properties - Regularization: Preventing overfitting and ensuring generalization\n\n\n34.3.2 Gradient-Based Optimization\nEssential for neural embedding methods: - Gradient descent: \\theta_{t+1} = \\theta_t - \\alpha \\nabla_\\theta L(\\theta_t) - Stochastic gradient descent: Using random samples for efficiency - Learning rate scheduling: Adaptive step sizes - Convergence criteria: When to stop optimization\n\n\n34.3.3 Constrained Optimization\nFor embedding problems with constraints: - Orthogonality constraints: When embedding vectors must be orthogonal - Norm constraints: Limiting embedding vector magnitudes - Lagrange multipliers: Mathematical tool for handling constraints",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Preparation: Dimensionality Reduction and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#distance-and-similarity-measures",
    "href": "m08-embedding/00-preparation.html#distance-and-similarity-measures",
    "title": "34¬† Preparation: Dimensionality Reduction and Optimization Prerequisites",
    "section": "34.4 Distance and Similarity Measures",
    "text": "34.4 Distance and Similarity Measures\n\n34.4.1 Metric Properties\nUnderstanding what makes a good distance measure: - Non-negativity: d(x,y) \\geq 0 - Symmetry: d(x,y) = d(y,x) - Triangle inequality: d(x,z) \\leq d(x,y) + d(y,z) - Identity: d(x,y) = 0 if and only if x = y\n\n\n34.4.2 Common Distance Functions\n\nEuclidean distance: ||x - y||_2\nCosine similarity: \\frac{x \\cdot y}{||x|| ||y||}\nManhattan distance: ||x - y||_1\nJaccard similarity: For set-based comparisons\n\n\n\n34.4.3 Embedding Quality Metrics\nHow to evaluate if embeddings preserve important properties: - Distance preservation: Do similar nodes remain close? - Neighborhood preservation: Are local structures maintained? - Global structure: Are long-range relationships captured?",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Preparation: Dimensionality Reduction and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#high-dimensional-data-analysis",
    "href": "m08-embedding/00-preparation.html#high-dimensional-data-analysis",
    "title": "34¬† Preparation: Dimensionality Reduction and Optimization Prerequisites",
    "section": "34.5 High-Dimensional Data Analysis",
    "text": "34.5 High-Dimensional Data Analysis\n\n34.5.1 Curse of Dimensionality\nUnderstanding challenges with high-dimensional spaces: - Distance concentration: All points become equidistant in high dimensions - Sparsity: High-dimensional spaces are mostly empty - Visualization challenges: Difficulty interpreting high-dimensional data\n\n\n34.5.2 Manifold Learning\nAssumption underlying many embedding methods: - Manifold hypothesis: High-dimensional data lies on lower-dimensional manifolds - Local linearity: Small neighborhoods can be approximated linearly - Intrinsic dimensionality: True degrees of freedom in the data",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Preparation: Dimensionality Reduction and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#computational-considerations",
    "href": "m08-embedding/00-preparation.html#computational-considerations",
    "title": "34¬† Preparation: Dimensionality Reduction and Optimization Prerequisites",
    "section": "34.6 Computational Considerations",
    "text": "34.6 Computational Considerations\n\n34.6.1 Scalability Issues\nChallenges with large networks: - Matrix operations: O(n¬≥) complexity for eigenvalue decomposition - Memory requirements: Storing large adjacency matrices - Approximation methods: Trading accuracy for computational efficiency\n\n\n34.6.2 Sparse Matrix Techniques\nEssential for large network analysis: - Sparse storage: Only storing non-zero entries - Iterative methods: Lanczos algorithm for eigenvalues - Random sampling: Approximating matrix operations\nThese mathematical foundations provide the theoretical basis for understanding how embedding methods transform high-dimensional network structures into meaningful low-dimensional representations.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Preparation: Dimensionality Reduction and Optimization Prerequisites</span>"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html",
    "href": "m08-embedding/01-concepts.html",
    "title": "35¬† Network Embedding Concepts",
    "section": "",
    "text": "35.1 What to Learn in This Module\nIn this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Network Embedding Concepts</span>"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#comparing-spectral-and-neural-embedding-approaches",
    "href": "m08-embedding/01-concepts.html#comparing-spectral-and-neural-embedding-approaches",
    "title": "35¬† Network Embedding Concepts",
    "section": "35.2 Comparing Spectral and Neural Embedding Approaches",
    "text": "35.2 Comparing Spectral and Neural Embedding Approaches\nWe have learned two types of graph embedding methods: spectral methods and neural embedding methods. But which one is better than the other? We will compare the two types of methods from multiple aspects.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Network Embedding Concepts</span>"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#analytical-tractability",
    "href": "m08-embedding/01-concepts.html#analytical-tractability",
    "title": "35¬† Network Embedding Concepts",
    "section": "35.3 Analytical Tractability",
    "text": "35.3 Analytical Tractability\nSpectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized laplacian matrices are shown to be optimal for detecting communities in the stochastic block model {footcite}nadakuditi2012graph.\nNeural embedding methods are less analytically tractable. But still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under a very specific condition {footcite}qiu2018network,kojaku2023network. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact an optimal embedding methods for community detection for the stochatic block model.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Network Embedding Concepts</span>"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#scalability-and-performance",
    "href": "m08-embedding/01-concepts.html#scalability-and-performance",
    "title": "35¬† Network Embedding Concepts",
    "section": "35.4 Scalability and Performance",
    "text": "35.4 Scalability and Performance\nA key limitation of the spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit learn package as TruncatedSVD), they might be unstable depending on the spectrum distribution of the matrix to be decomposed.\nNeural embedding methods are often more stable and scalable, making them particularly suitable for large networks where computational efficiency is critical.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Network Embedding Concepts</span>"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#flexibility-and-extensions",
    "href": "m08-embedding/01-concepts.html#flexibility-and-extensions",
    "title": "35¬† Network Embedding Concepts",
    "section": "35.5 Flexibility and Extensions",
    "text": "35.5 Flexibility and Extensions\nNeural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincar√© embeddings {footcite}nickel2017poincare for embedding networks in hyperbolic space.\n\nThis flexibility extends to implementation choices and software options. There are various software packages for network embeddings, though due to technical complexity, some of them do not faithfully implement the algorithms in the paper. We provide a list of software packages for network embeddings below:\n\nfastnode2vec. This is a very fast implementation of node2vec. However, it uses a uniform probability distribution for the negative sampling, which is different from the original node2vec paper that uses a different distribution. This leads to some degeneracy of the embedding quality in community detection tasks.\npytorch-geometric. This is a very popular package for graph neural networks. It also uses a uniform probability distribution for the negative sampling, potentially having the same issue as fastnode2vec.\ngnn-tools. This is a collection of my experiments on network embedding methods.\nMy collection. This is a lighter version of the gnn-tools collection.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Network Embedding Concepts</span>"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#exercises",
    "href": "m08-embedding/01-concepts.html#exercises",
    "title": "35¬† Network Embedding Concepts",
    "section": "35.6 Exercises",
    "text": "35.6 Exercises\n\n‚úçÔ∏è Pen and paper exercises",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Network Embedding Concepts</span>"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html",
    "href": "m08-embedding/02-coding.html",
    "title": "36¬† Embedding Methods: Implementation and Practice",
    "section": "",
    "text": "36.1 Spectral Embedding",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Embedding Methods: Implementation and Practice</span>"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#spectral-embedding",
    "href": "m08-embedding/02-coding.html#spectral-embedding",
    "title": "36¬† Embedding Methods: Implementation and Practice",
    "section": "",
    "text": "36.1.1 Network Compression Approach\nNetworks are a high-dimensional discrete data that can be difficult to analyze with traditional machine learning methods that assume continuous and smooth data. Spectral embedding is a technique to embed networks into low-dimensional spaces.\nLet us approach the spectral embedding from the perspective of network compression. Suppose we have an adjacency matrix \\mathbf{A} of a network. The adjacency matrix is a high-dimensional data, i.e., a matrix has size N \\times N for a network of N nodes. We want to compress it into a lower-dimensional matrix \\mathbf{U} of size N \\times d for a user-defined small integer d &lt; N. A good \\mathbf{U} should preserve the network structure and thus can reconstruct the original data \\mathbf{A} as closely as possible. This leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nwhere:\n\n\\mathbf{U}\\mathbf{U}^\\top is the outer product of \\mathbf{U} and represents the reconstructed network.\n\\|\\cdot\\|_F is the Frobenius norm, which is the sum of the squares of the elements in the matrix.\nJ(\\mathbf{U}) is the loss function that measures the difference between the original network \\mathbf{A} and the reconstructed network \\mathbf{U}\\mathbf{U}^\\top.\n\nBy minimizing the Frobenius norm with respect to \\mathbf{U}, we obtain the best low-dimensional embedding of the network.\n\n\n36.1.2 An Intuitive Solution\nLet us first understand the solution intuitively. Consider the spectral decomposition of \\mathbf{A}:\n\n\\mathbf{A} = \\sum_{i=1}^N \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top\n\nwhere \\lambda_i are weights and \\mathbf{u}_i are column vectors. Each term \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top is a rank-one matrix that captures a part of the network‚Äôs structure. The larger the weight \\lambda_i, the more important that term is in describing the network.\nTo compress the network, we can select the d terms with the largest weights \\lambda_i. By combining the corresponding \\mathbf{u}_i vectors into a matrix \\mathbf{U}, we obtain a good low-dimensional embedding of the network.\n\nFor a formal proof, please refer to the Appendix section.\n\n\n36.1.3 Example: Spectral Embedding\nLet us demonstrate the results with a simple example as follows.\n\n\nCode\n:tags: [hide-input]\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a small example network\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).toarray()\nlabels = np.unique([d[1]['club'] for d in G.nodes(data=True)], return_inverse=True)[1]\ncmap = sns.color_palette()\nnx.draw(G, with_labels=False, node_color=[cmap[i] for i in labels])\n\n\n\n\nCode\n:tags: [hide-input]\n\n# Compute the spectral decomposition\neigvals, eigvecs = np.linalg.eig(A)\n\n# Find the top d eigenvectors\nd = 2\nsorted_indices = np.argsort(eigvals)[::-1][:d]\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n# Plot the results\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Spectral Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\n\nInterestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes. The second eigenvector captures the community structure of the network, clearly separating the two communities in the network.\n\n\n36.1.4 Modularity Embedding\nIn a similar vein, we can use the modularity matrix to generate a low-dimensional embedding of the network. Namely, let us define the modularity matrix \\mathbf{Q} as follows:\n\nQ_{ij} = \\frac{1}{2m}A_{ij} - \\frac{k_i k_j}{4m^2}\n\nwhere k_i is the degree of node i, and m is the number of edges in the network.\nWe then compute the eigenvectors of \\mathbf{Q} and use them to embed the network into a low-dimensional space just as we did for the adjacency matrix.\n\n\nCode\n:tags: [hide-input]\n\ndeg = np.sum(A, axis=1)\nm = np.sum(deg) / 2\nQ = A - np.outer(deg, deg) / (2 * m)\nQ/= 2*m\n\neigvals, eigvecs = np.linalg.eig(Q)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(-eigvals)[:d]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Modularity Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\n\nThe modularity embedding can be used to bipartition the network into two communities using a simple algorithm: group nodes with the same sign of the second eigenvector {footcite}`newman2006modularity`.\n\n\n36.1.5 Laplacian Eigenmap\nLaplacian Eigenmap {footcite}belkin2003laplacian is another approach to compress a network into a low-dimensional space. The fundamental idea behind this method is to position connected nodes close to each other in the low-dimensional space. This approach leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J_{LE}(\\mathbf{U}),\\quad J_{LE}(\\mathbf{U}) = \\frac{1}{2}\\sum_{i,j} A_{ij} \\| u_i - u_j \\|^2\n\nIn this equation, \\| u_i - u_j \\|^2 represents the squared distance between nodes i and j in the low-dimensional space. The goal is to minimize this distance for connected nodes (where A_{ij} = 1). The factor \\frac{1}{2} is included for mathematical convenience in later calculations.\nTo solve this optimization problem, we rewrite J_{LE}(\\mathbf{U}) as follows:\n\n\\begin{aligned}\nJ_{LE}(\\mathbf{U}) &= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\| u_i - u_j \\|^2 \\\\\n&= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\left( \\| u_i \\|^2 - 2 u_i^\\top u_j + \\| u_j \\|^2 \\right) \\\\\n&= \\sum_{i}\\sum_{j} A_{ij} \\| u_i \\|^2 - \\sum_{i}\\sum_{j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i} k_i \\| u_i \\|^2 - \\sum_{i,j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i,j} L_{ij} u_i^\\top u_j\n\\end{aligned}\n\nwhere\n\nL_{ij} = \\begin{cases}\nk_i & \\text{if } i = j \\\\\n-A_{ij} & \\text{if } i \\neq j\n\\end{cases}\n\nThe minimization problem can be rewritten as:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nwhere\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\mathbf{u}_1 ^\\top \\\\\n\\mathbf{u}_2 ^\\top \\\\\n\\vdots \\\\\n\\mathbf{u}_N ^\\top \\\\\n\\end{bmatrix}\n\nSee the Appendix section for the detailed derivation.\nBy taking the derivative of J_{LE}(\\mathbf{U}) with respect to \\mathbf{U} and set it to zero, we obtain the following equation:\n\n\\frac{\\partial J_{LE}}{\\partial \\mathbf{U}} = 0 \\implies \\mathbf{L} \\mathbf{U} = \\lambda \\mathbf{U}\n\nThe solution is the d eigenvectors associated with the d smallest eigenvalues of \\mathbf{L}.\nIt is important to note that the eigenvector corresponding to the smallest eigenvalue (which is always zero for connected graphs) is trivial - it‚Äôs the all-one vector. Therefore, in practice, we typically compute the d+1 smallest eigenvectors and discard the one corresponding to the zero eigenvalue.\n\n\n36.1.6 Example: Laplacian Eigenmap\nLet us first compute the Laplacian matrix and its eigenvectors.\n\n\nCode\n:tags: [hide-input]\n\nD = np.diag(np.sum(A, axis=1))\nL = D - A\n\neigvals, eigvecs = np.linalg.eig(L)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(eigvals)[1:d+1]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n\nThe eigenvectors corresponding to the d smallest eigenvalues are:\n\n\nCode\n:tags: [hide-input]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Laplacian Eigenmap')\nax.set_xlabel('Eigenvector 2')\nax.set_ylabel('Eigenvector 3')\nplt.show()",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Embedding Methods: Implementation and Practice</span>"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#neural-embedding-with-word2vec",
    "href": "m08-embedding/02-coding.html#neural-embedding-with-word2vec",
    "title": "36¬† Embedding Methods: Implementation and Practice",
    "section": "36.2 Neural Embedding with word2vec",
    "text": "36.2 Neural Embedding with word2vec\n\n36.2.1 Introduction to word2vec\nIn this section, we will introduce word2vec, a powerful technique for learning word embeddings. word2vec is a neural network model that learns words embeddings in a continuous vector space. It was introduced by Tomas Mikolov and his colleagues at Google in 2013 {footcite}mikolov2013distributed.\n\n\n36.2.2 How it works\n‚ÄúYou shall know a word by the company it keeps‚Äù {footcite}church1988word is a famous quote in linguistics. It means that you can understand the meaning of a word by looking at the words that appear in the same context. word2vec operates on the same principle. word2vec identifies a word‚Äôs context by examining the words within a fixed window around it. For example, in the sentence:\n\nThe quick brown fox jumps over a lazy dog\n\nThe context of the word fox includes quick, brown, jumps, over, and lazy. word2vec is trained to predict which words are likely to appear as the context of an input word.\nThere are two main architectures for word2vec:\n1. **Continuous Bag of Words (CBOW)**: Predicts the target word (center word) from the context words (surrounding words).\n2. **Skip-gram**: Predicts the context words (surrounding words) from the target word (center word).\nSo how are word embeddings learned? word2vec is a neural network model that looks like a bow tie. It has two layers of the vocabulary size coupled with a much smaller hidden layer.\n\n\nInput layer: The input layer consists of N neurons, where N is the size of the vocabulary (i.e., the number of unique words in the corpus). Each neuron corresponds to a unique word in the vocabulary. When a word is inputted, its corresponding neuron is activated and the other neurons are inhibited. Thus, the input layer is essentially a lookup mechanism that transforms the input word into a corresponding one-hot vector.\nOutput layer: The output layer also consists of N neurons, each corresponding to a unique word in the vocabulary. Unlike the input layer, multiple neurons can be activated for a single input. The strength of the activation of each neuron (with a normalization by the softmax function) represents the probability of the corresponding word being the input word‚Äôs context.\nHidden layer: The hidden layer is much smaller than the input and output layers. Multiple neurons in the hidden layer can be activated for a single input, and this activation pattern represents the word‚Äôs embedding.\n\nWe can consider word2vec as a dimensionality reduction technique that reduces the dimensionality of the input layer to the hidden layer based on the co-occurrence of words within a short distance. The distance is named the window size, which is a user-defined hyperparameter.\n\n\n36.2.3 What‚Äôs special about word2vec?\nWith word2vec, words are represented as dense vectors, enabling us to explore their relationships using simple linear algebra. This is in contrast to traditional natural language processing (NLP) methods, such as bag-of-words and topic modeling, which represent words as discrete units or high-dimensional vectors.\n\nTo showcase the effectiveness of word2vec, let‚Äôs walk through an example using the gensim library.\n\n\nCode\nimport gensim\nimport gensim.downloader\nfrom gensim.models import Word2Vec\n\n# Load pre-trained word2vec model from Google News\nmodel = gensim.downloader.load('word2vec-google-news-300')\n\n\nOur first example is to find the words most similar to king.\n\n\nCode\n# Example usage\nword = \"king\"\nsimilar_words = model.most_similar(word)\nprint(f\"Words most similar to '{word}':\")\nfor similar_word, similarity in similar_words:\n    print(f\"{similar_word}: {similarity:.4f}\")\n\n\nA cool (yet controversial) application of word embeddings is analogy solving. Let us consider the following puzzle:\n\nman is to woman as king is to ___ ?\n\nWe can use word embeddings to solve this puzzle.\n\n\nCode\n# We solve the puzzle by\n#\n#  vec(king) - vec(man) + vec(woman)\n#\n# To solve this, we use the model.most_similar function, with positive words being \"king\" and \"woman\" (additive), and negative words being \"man\" (subtractive).\n#\nmodel.most_similar(positive=['woman', \"king\"], negative=['man'], topn=5)\n\n\nThe last example is to visualize the word embeddings.\n\n\nCode\n:tags: [hide-input]\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ncountries = ['Germany', 'France', 'Italy', 'Spain', 'Portugal', 'Greece']\ncapital_words = ['Berlin', 'Paris', 'Rome', 'Madrid', 'Lisbon', 'Athens']\n\n# Get the word embeddings for the countries and capitals\ncountry_embeddings = np.array([model[country] for country in countries])\ncapital_embeddings = np.array([model[capital] for capital in capital_words])\n\n# Compute the PCA\npca = PCA(n_components=2)\nembeddings = np.vstack([country_embeddings, capital_embeddings])\nembeddings_pca = pca.fit_transform(embeddings)\n\n# Create a DataFrame for seaborn\ndf = pd.DataFrame(embeddings_pca, columns=['PC1', 'PC2'])\ndf['Label'] = countries + capital_words\ndf['Type'] = ['Country'] * len(countries) + ['Capital'] * len(capital_words)\n\n# Plot the data\nplt.figure(figsize=(12, 10))\n\n# Create a scatter plot with seaborn\nscatter_plot = sns.scatterplot(data=df, x='PC1', y='PC2', hue='Type', style='Type', s=200, palette='deep', markers=['o', 's'])\n\n# Annotate the points\nfor i in range(len(df)):\n    plt.text(df['PC1'][i], df['PC2'][i] + 0.08, df['Label'][i], fontsize=12, ha='center', va='bottom',\n             bbox=dict(facecolor='white', edgecolor='none', alpha=0.8))\n\n# Draw arrows between countries and capitals\nfor i in range(len(countries)):\n    plt.arrow(df['PC1'][i], df['PC2'][i], df['PC1'][i + len(countries)] - df['PC1'][i], df['PC2'][i + len(countries)] - df['PC2'][i],\n              color='gray', alpha=0.6, linewidth=1.5, head_width=0.02, head_length=0.03)\n\nplt.legend(title='Type', title_fontsize='13', fontsize='11')\nplt.title('PCA of Country and Capital Word Embeddings', fontsize=16)\nplt.xlabel('Principal Component 1', fontsize=14)\nplt.ylabel('Principal Component 2', fontsize=14)\nax = plt.gca()\nax.set_axis_off()\n\n\nWe can see that word2vec places the words representing countries close to each other and so do the words representing their capitals. The country-capital relationship is also roughly preserved, e.g., Germany-Berlin vector is roughly parallel to France-Paris vector.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Embedding Methods: Implementation and Practice</span>"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#graph-embedding-with-word2vec",
    "href": "m08-embedding/02-coding.html#graph-embedding-with-word2vec",
    "title": "36¬† Embedding Methods: Implementation and Practice",
    "section": "36.3 Graph Embedding with word2vec",
    "text": "36.3 Graph Embedding with word2vec\nHow can we apply word2vec to graph data? There is a critical challenge: word2vec takes sequence of words as input, while graph data are discrete and unordered. A solution to fill this gap is random walk, which transforms graph data into a sequence of nodes. Once we have a sequence of nodes, we can treat it as a sequence of words and apply word2vec.\n\n36.3.1 DeepWalk\n\nDeepWalk is one of the pioneering works to apply word2vec to graph data {footcite}perozzi2014deepwalk. It views the nodes as words and the nodes random walks on the graph as sentences, and applies word2vec to learn the node embeddings.\nMore specifically, the method contains the following steps:\n\nSample multiple random walks from the graph.\nTreat the random walks as sentences and feed them to word2vev to learn the node embeddings.\n\nThere are some technical details that we need to be aware of, which we will learn by implementing DeepWalk in the following exercise.\n\n\n36.3.2 Exercise 01: Implement DeepWalk\nIn this exercise, we implement DeepWalk step by step.\n\n36.3.2.0.1 Step 1: Data preparation\nWe will use the karate club network as an example.\nLoad the data\n\n\nCode\n:tags: [hide-input]\n\nimport igraph\nimport networkx as nx\nimport numpy as np\nimport seaborn as sns\n\ng = igraph.Graph.Famous(\"Zachary\")\nA = g.get_adjacency_sparse()\n\n# Add the community labels to the nodes for visualization\ng.vs[\"label\"] = np.unique([d[1]['club'] for d in nx.karate_club_graph().nodes(data=True)], return_inverse=True)[1]\n\npalette = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[palette[label] for label in g.vs[\"label\"]], bbox=(300, 300))\n\n\n\n\n36.3.2.0.2 Step 2: Generate random walks\nNext, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network. Let us first implement a function to sample random walks from a given network.\n\n\nCode\ndef random_walk(net, start_node, walk_length):\n    # Initialize the walk with the starting node\n    walk = [start_node]\n\n    # Continue the walk until the desired length is reached\n    while len(walk) &lt; walk_length:\n        # Get the current node (the last node in the walk)\n        cur = walk[-1]\n\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n\n        # If the current node has neighbors, randomly choose one and add it to the walk\n        if len(cur_nbrs) &gt; 0:\n            walk.append(np.random.choice(cur_nbrs))\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    # Return the generated walk\n    return walk\n\n\nGenerate 10 random walks of length 50 starting from each node.\n\n\nCode\nn_nodes = g.vcount()\nn_walkers_per_node = 10\nwalk_length = 50\nwalks = []\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(random_walk(A, i, walk_length))\n\n\n\n\n36.3.2.0.3 Step 3: Train the word2vec model\nThen, we feed the random walks to the word2vec model.\n\n\nCode\nfrom gensim.models import Word2Vec\n\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\n\nHere,\n\nvector_size is the dimension of the embedding vectors.\nwindow indicates the maximum distance between a word and its context words. For example, in the random walk [0, 1, 2, 3, 4, 5, 6, 7], the context words of node 2 are [0, 1, 3, 4, 5] when window=3.\nmin_count is the minimum number of times a word must appear in the training data to be included in the vocabulary.\n\nTwo parameters sg=1 and hs=1 indicate that we are using the skip-gram model with negative sampling. Let us understand what they mean in detail as follows.\n\nSkip-gram model: it trains word2vec by predicting context words given a target word. For example, given the sentence ‚ÄúThe quick brown fox jumps over the lazy dog‚Äù, in the skip-gram model, given the target word ‚Äúfox‚Äù, the model will try to predict the context words ‚Äúquick‚Äù, ‚Äúbrown‚Äù, ‚Äújumps‚Äù, and ‚Äúover‚Äù. If sg=0, the input and output are swapped: the model will predict the target word from the context words, e.g., given the context words ‚Äúquick‚Äù, ‚Äúbrown‚Äù, ‚Äújumps‚Äù, and ‚Äúover‚Äù, the model will predict the target word ‚Äúfox‚Äù.\nHierarchical softmax: To understand hierarchical softmax better, let‚Äôs break down how the word2vec model works. The goal of word2vec is to predict context words given a target word. For example, if our target word is w_t and our context word is w_c, we want to find the probability of w_c given w_t. This probability is calculated using the softmax function:\n\n  P(w_c | w_t) = \\frac{\\exp(\\mathbf{v}_{w_c} \\cdot \\mathbf{v}_{w_t})}{\\sum_{w \\in V} \\exp(\\mathbf{v}_w \\cdot \\mathbf{u}_{w_t})}\n\nHere, \\mathbf{v}_w and \\mathbf{u}_w represent the vector for word w as context and target respectively, and V is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!\nHierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.\n\n\nBy using the skip-gram model with hierarchical softmax, we can efficiently learn high-quality word embeddings even when dealing with large vocabularies.\nNow, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the wv attribute. The embedding of node i is given by model.wv[i].\n\n\nCode\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\n\nembedding is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.\nPrint the first 3 nodes\n\n\nCode\n:tags: [hide-input]\n\nembedding[:3]\n\n\nLet‚Äôs visualize the node embeddings using UMAP.\n\n\nCode\n:tags: [hide-input]\nimport umap\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource, HoverTool\n\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nshow(p)\n\n\n\n\n36.3.2.0.4 Step 4: Clustering\nOne of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as K-means and Gaussian mixture model. Let‚Äôs see what we can get from the node embeddings.\n\n\nCode\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Determine the optimal number of clusters using the silhouette score\ndef Kmeans_with_silhouette(embedding, n_clusters_range=(2, 10)):\n    silhouette_scores = []\n\n    # Iterate over a range of cluster numbers from 2 to 9\n    for n_clusters in range(*n_clusters_range):\n        # Create a KMeans object with the current number of clusters\n        kmeans = KMeans(n_clusters=n_clusters)\n\n        # Fit the KMeans model to the embedding data\n        kmeans.fit(embedding)\n\n        # Calculate the silhouette score for the current clustering\n        score = silhouette_score(embedding, kmeans.labels_)\n\n        # Append the number of clusters and its corresponding silhouette score to the list\n        silhouette_scores.append((n_clusters, score))\n\n    # Find the number of clusters that has the highest silhouette score\n    optimal_n_clusters = max(silhouette_scores, key=lambda x: x[1])[0]\n\n    # Create a KMeans object with the optimal number of clusters\n    kmeans = KMeans(n_clusters=optimal_n_clusters)\n\n    # Fit the KMeans model to the embedding data with the optimal number of clusters\n    kmeans.fit(embedding)\n\n    # Return the labels (cluster assignments) for each data point\n    return kmeans.labels_\n\n\n\n\nCode\nimport seaborn as sns\nlabels = Kmeans_with_silhouette(embedding)\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500))\n\n\n\n\n\n36.3.3 node2vec\nnode2vec is a sibling of DeepWalk proposed by {footcite}grover2016node2vec. Both use word2vec trained on random walks on networks. So, it appears that they are very similar. However, the following two components make them very different.\n\nBiased random walk: node2vec uses biased random walks that can move in different directions. The bias walk is parameterized by two parameters, p and q:\n\n  P(v_{t+1} = x | v_t = v, v_{t-1} = t) \\propto\n  \\begin{cases}\n  \\frac{1}{p} & \\text{if } d(v,t) = 0 \\\\\n  1 & \\text{if } d(v,t) = 1 \\\\\n  \\frac{1}{q} & \\text{if } d(v,t) = 2 \\\\\n  \\end{cases}\n  \nwhere d(v,x) is the shortest path distance between node v and x. A smaller p leads to more biased towards the previous node, v_{t-1} = t. A smaller q leads to more biased towards the nodes that are further away from the previous node, v_{t-1} = t.\nBy adjusting the parameters p and q, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).\n\nBreadth-First Sampling (BFS): This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.\nDepth-First Sampling (DFS): This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.\n\n\nThe embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.\n\nNegative sampling: node2vec uses negative sampling, instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to {footcite}kojaku2021neurips and {footcite}dyer2014notes for more details.\n\n\n\n36.3.4 Exercise 02: Implement node2vec\nLet‚Äôs implement the biased random walk for node2vec\n\n\nCode\ndef node2vec_random_walk(net, start_node, walk_length, p, q):\n    \"\"\"\n    Sample a random walk starting from start_node.\n    \"\"\"\n    # Initialize the walk with the start_node\n    walk = [start_node]\n\n    # Continue the walk until it reaches the desired length\n    while len(walk) &lt; walk_length:\n        # Get the current node in the walk\n        cur = walk[-1]\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n        # Check if the current node has any neighbors\n        if len(cur_nbrs) &gt; 0:\n            # If the walk has just started, randomly choose the next node from the neighbors\n            if len(walk) == 1:\n                walk.append(np.random.choice(cur_nbrs))\n            else:\n                # Get the previous node in the walk\n                prev = walk[-2]\n                # Use the alias sampling method to choose the next node based on the bias parameters p and q\n                next_node = alias_sample(net, cur_nbrs, prev, p, q)\n                # Append the chosen next node to the walk\n                walk.append(next_node)\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    return walk\n\ndef alias_sample(net, neighbors, prev, p, q):\n    \"\"\"\n    Helper function to sample the next node in the walk.\n    \"\"\"\n    # Implement the logic to sample the next node based on the bias parameters p and q\n    # You can use the formula provided in the instructions to calculate the probabilities\n    # and then sample the next node accordingly.\n    # Initialize an empty list to store the unnormalized probabilities for each neighbor\n    unnormalized_probs = []\n\n    # Iterate over each neighbor of the current node\n    for neighbor in neighbors:\n        # If the neighbor is the same as the previous node in the walk\n        if neighbor == prev:\n            # Append the probability 1/p to the unnormalized probabilities list\n            unnormalized_probs.append(1 / p)\n        # If the neighbor is connected to the previous node in the walk\n        elif neighbor in net[prev].indices:\n            # Append the probability 1 to the unnormalized probabilities list\n            unnormalized_probs.append(1)\n        # If the neighbor is not connected to the previous node in the walk\n        else:\n            # Append the probability 1/q to the unnormalized probabilities list\n            unnormalized_probs.append(1 / q)\n\n    # Calculate the normalization constant by summing all unnormalized probabilities\n    norm_const = sum(unnormalized_probs)\n\n    # Normalize the probabilities by dividing each unnormalized probability by the normalization constant\n    normalized_probs = [float(prob) / norm_const for prob in unnormalized_probs]\n\n    # Randomly choose the next node from the neighbors based on the normalized probabilities\n    next_node = np.random.choice(neighbors, size=1, p=normalized_probs)[0]\n\n    # Return the chosen next node\n    return next_node\n\n\nNow, let‚Äôs set up the word2vec model for node2vec.\n\n\nCode\nwalks = []\np = 1\nq = 0.1\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(node2vec_random_walk(A, i, walk_length, p, q))\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\n\nwhere hs=0 indicates that we are using negative sampling. Notice that we set sg=1 and hs=1 instead of sg=1 and hs=0 in DeepWalk. This is because node2vec uses the skip-gram model with negative sampling.\nNow, we extract the node embeddings from the word2vec model.\n\n\nCode\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\n\nLet‚Äôs visualize the node embeddings from node2vec.\n\n\nCode\n:tags: [hide-input]\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]],\n    name = [str(i) for i in range(n_nodes)]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nhover = HoverTool()\nhover.tooltips = [\n    (\"Name\", \"@name\"),\n    (\"Community\", \"@community\")\n]\np.add_tools(hover)\n\nshow(p)\n\n\nThe results for clustering are as follows:\n\n\nCode\nimport seaborn as sns\n\nlabels = Kmeans_with_silhouette(embedding)\n\n\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500), vertex_label=[\"%d\" %  d for d in  np.arange(n_nodes)])\n\n\n\n\n36.3.5 LINE\nLINE {footcite}tang2015line is another pioneering work to learn node embeddings by directly optimizing the graph structure. It is equivalent to node2vec with p=1, q=1, and window size 1.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Embedding Methods: Implementation and Practice</span>"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html",
    "href": "m08-embedding/03-exercises.html",
    "title": "37¬† Exercises",
    "section": "",
    "text": "37.1 Pen and Paper Exercises",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#pen-and-paper-exercises",
    "href": "m08-embedding/03-exercises.html#pen-and-paper-exercises",
    "title": "37¬† Exercises",
    "section": "",
    "text": "‚úçÔ∏è Pen and paper exercises",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#programming-exercises",
    "href": "m08-embedding/03-exercises.html#programming-exercises",
    "title": "37¬† Exercises",
    "section": "37.2 Programming Exercises",
    "text": "37.2 Programming Exercises\n\n37.2.1 Exercise 01: Implement DeepWalk\nIn this exercise, we implement DeepWalk step by step. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand how to generate random walks from a graph - Learn how to apply word2vec to graph data - Practice extracting and visualizing node embeddings - Apply clustering methods to embedded representations\nKey Steps: 1. Data preparation: Load the karate club network 2. Generate random walks: Implement random walk sampling function 3. Train word2vec model: Apply word2vec to the random walks 4. Clustering: Use K-means clustering on the embeddings\n\n\n37.2.2 Exercise 02: Implement node2vec\nIn this exercise, we implement the biased random walk mechanism that makes node2vec different from DeepWalk. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand the biased random walk mechanism in node2vec - Learn about the parameters p and q and their effects - Implement the alias sampling method for biased walks - Compare node2vec results with DeepWalk\nKey Steps: 1. Implement biased random walk: Create functions for node2vec random walks 2. Understand p and q parameters: Learn how they control walk behavior 3. Train node2vec model: Apply word2vec with biased random walks 4. Compare results: Analyze differences between node2vec and DeepWalk",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#additional-practice-exercises",
    "href": "m08-embedding/03-exercises.html#additional-practice-exercises",
    "title": "37¬† Exercises",
    "section": "37.3 Additional Practice Exercises",
    "text": "37.3 Additional Practice Exercises\n\n37.3.1 Exercise 03: Spectral Embedding Comparison\nObjective: Compare different spectral embedding methods on the same network.\nTasks: 1. Implement spectral embedding using the adjacency matrix 2. Implement modularity embedding 3. Implement Laplacian Eigenmap 4. Compare the resulting embeddings visually 5. Analyze which method best captures community structure\n\n\n37.3.2 Exercise 04: Parameter Sensitivity Analysis\nObjective: Understand how different parameters affect embedding quality.\nTasks: 1. Vary the embedding dimension (d) in spectral methods 2. Test different window sizes in word2vec-based methods 3. Experiment with different p and q values in node2vec 4. Compare clustering performance across parameter settings\n\n\n37.3.3 Exercise 05: Real Network Analysis\nObjective: Apply embedding methods to a real-world network.\nTasks: 1. Choose a real network dataset (e.g., social network, citation network) 2. Apply both spectral and neural embedding methods 3. Evaluate embeddings using downstream tasks (clustering, classification) 4. Compare computational efficiency and embedding quality",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#evaluation-questions",
    "href": "m08-embedding/03-exercises.html#evaluation-questions",
    "title": "37¬† Exercises",
    "section": "37.4 Evaluation Questions",
    "text": "37.4 Evaluation Questions\n\nConceptual Understanding:\n\nWhat is the main difference between spectral and neural embedding methods?\nHow do random walks help bridge the gap between word2vec and graph data?\nWhat role do eigenvalues and eigenvectors play in spectral embedding?\n\nTechnical Implementation:\n\nWhy do we exclude the first eigenvector in Laplacian Eigenmap?\nHow does the window size in word2vec affect the final embeddings?\nWhat is the computational complexity of different embedding methods?\n\nPractical Applications:\n\nWhen would you choose spectral methods over neural methods?\nHow do the p and q parameters in node2vec affect the type of structure captured?\nWhat are the trade-offs between embedding dimension and computational cost?",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#additional-resources",
    "href": "m08-embedding/03-exercises.html#additional-resources",
    "title": "37¬† Exercises",
    "section": "37.5 Additional Resources",
    "text": "37.5 Additional Resources\n\nSoftware Packages: Refer to the 01-concepts.md for recommended implementations\nMathematical Details: See 04-appendix.md for formal proofs and derivations\nPreparation Material: Review 00-preparation.md for background on random walks and linear algebra",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "m08-embedding/04-appendix.html",
    "href": "m08-embedding/04-appendix.html",
    "title": "38¬† Appendix",
    "section": "",
    "text": "38.1 Spectral Embedding with the Adjacency Matrix\nThe spectral embedding with the adjacency matrix is given by the following optimization problem:\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\nWe will approach the solution step by step based on the following steps:\nThe result is the collection of the d eigenvectors corresponding to the d largest eigenvalues, and it is one form of the spectral embedding.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "m08-embedding/04-appendix.html#spectral-embedding-with-the-adjacency-matrix",
    "href": "m08-embedding/04-appendix.html#spectral-embedding-with-the-adjacency-matrix",
    "title": "38¬† Appendix",
    "section": "",
    "text": "We start taking a derivative of J(\\mathbf{U}) with respect to \\mathbf{U}.\nWe then set the derivative to zero (i.e., \\nabla J(\\mathbf{U}) = 0) and solve for \\mathbf{U}.\nExpand the Frobenius norm:\nThe Frobenius norm for any matrix \\mathbf{M} is defined as:\n\\|\\mathbf{M}\\|_F^2 = \\sum_{i,j} M_{ij}^2 = \\text{Tr}(\\mathbf{M}\\mathbf{M}^\\top)\nApplying this to our problem:\nJ(\\mathbf{U}) = \\|\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top\\|_F^2 = \\text{Tr}[(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)^\\top]\nExpanding this:\n= \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top - 2\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top + \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nTake the derivative with respect to \\mathbf{U}:\nUsing matrix calculus rules:\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top)}{\\partial \\mathbf{U}} = 0\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 2\\mathbf{A}\\mathbf{U}\n\\frac{\\partial \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nCombining these:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -4\\mathbf{A}\\mathbf{U} + 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSimplifying:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSet the derivative to zero and solve:\n-2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = 0\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nThis equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\nAssume \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{\\Lambda}\nwhere \\mathbf{\\Lambda} is a diagonal matrix of eigenvalues.\nSince eigenvectors are orthonormal:\n\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}\nTherefore:\n\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{U}\nThis shows our equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}.\nTo minimize J(\\mathbf{U}), choose the eigenvectors corresponding to the d largest eigenvalues.\nTo understand why, consider the trace of our objective function:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - 2\\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top) + \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nSince \\mathbf{U} is orthogonal (\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}), and trace is invariant under cyclic permutations, we can simplify:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - \\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U})\nLet \\mathbf{U} = [\\mathbf{u}_1, ..., \\mathbf{u}_d] be the eigenvectors of \\mathbf{A} with corresponding eigenvalues \\lambda_1 \\geq ... \\geq \\lambda_d. Then:\n\\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U}) = \\sum_{i=1}^d \\lambda_i\nTo minimize J(\\mathbf{U}), maximize \\sum_{i=1}^d \\lambda_i by selecting the eigenvectors corresponding to the d largest eigenvalues.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "m08-embedding/04-appendix.html#the-proof-of-the-laplacian-eigenmap",
    "href": "m08-embedding/04-appendix.html#the-proof-of-the-laplacian-eigenmap",
    "title": "38¬† Appendix",
    "section": "38.2 The proof of the Laplacian Eigenmap",
    "text": "38.2 The proof of the Laplacian Eigenmap\nThe Laplacian Eigenmap is given by the following optimization problem:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nThe step where we rewrite J_{LE}(\\mathbf{U}) as \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U}) is crucial for leveraging matrix derivatives. Let‚Äôs break down this transformation step by step:\n\nFirst, we rewrite \\mathbf{U} by column vectors:\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\vert & \\vert & & \\vert \\\\\n\\mathbf{x}_1 & \\mathbf{x}_2 & \\cdots & \\mathbf{x}_d \\\\\n\\vert & \\vert & & \\vert\n\\end{bmatrix}\n\nwhere \\mathbf{x}_i is the i-th column of \\mathbf{U}.\nWe can expand the loss function J_{LE}(\\mathbf{U}):\n\nJ_{LE}(\\mathbf{U}) = \\sum_{i} \\sum_{j} L_{ij} u_i^\\top u_j = \\sum_{i} \\sum_{j} \\sum_{d'} L_{ij} u_{i,d'} u_{j,d'}\n\nRearranging the order of summation:\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\sum_{i} \\sum_{j} L_{ij} u_{i,d'} u_{j,d'}\n\nWe can rewrite this as a matrix multiplication for each d':\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\mathbf{x}_{d'}^\\top \\mathbf{L} \\mathbf{x}_{d'}\n\nwhere \\mathbf{x}_{d'} is the d'-th column of \\mathbf{U}.\nFinally, we can express this as a trace:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\n\nThis final form expresses our objective function in terms of matrix operations, which allows us to use matrix calculus to find the optimal solution. The trace representation is a useful technique to leverage matrix calculus.",
    "crumbs": [
      "M08: Embedding",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html",
    "href": "m09-graph-neural-networks/00-preparation.html",
    "title": "39¬† Preparation: Neural Networks and Deep Learning Prerequisites",
    "section": "",
    "text": "39.1 Required Knowledge from Previous Modules\nBefore studying Graph Neural Networks, ensure you understand: - From M01-M08: Network representations, linear algebra, optimization, and embedding concepts - From M08: Matrix decomposition techniques and dimensionality reduction principles",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Preparation: Neural Networks and Deep Learning Prerequisites</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#neural-network-fundamentals",
    "href": "m09-graph-neural-networks/00-preparation.html#neural-network-fundamentals",
    "title": "39¬† Preparation: Neural Networks and Deep Learning Prerequisites",
    "section": "39.2 Neural Network Fundamentals",
    "text": "39.2 Neural Network Fundamentals\n\n39.2.1 Basic Architecture Components\n\n39.2.1.1 Perceptron and Multi-Layer Networks\n\nPerceptron: y = \\sigma(w^T x + b) where \\sigma is an activation function\nMulti-layer: Composition of linear transformations and nonlinear activations\nUniversal approximation: Neural networks can approximate arbitrary functions\n\n\n\n39.2.1.2 Activation Functions\nEssential nonlinear functions: - ReLU: \\text{ReLU}(x) = \\max(0, x) - most common, helps with gradient flow - Sigmoid: \\sigma(x) = \\frac{1}{1 + e^{-x}} - outputs in (0,1) range - Tanh: \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} - outputs in (-1,1) range - Softmax: \\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}} - for probability distributions\n\n\n\n39.2.2 Forward and Backward Propagation\n\n39.2.2.1 Forward Pass\nComputing network output: - Layer computation: h^{(l+1)} = \\sigma(W^{(l)} h^{(l)} + b^{(l)}) - Composition: Output is function composition through all layers - Vectorization: Efficient batch processing\n\n\n39.2.2.2 Backpropagation\nComputing gradients for optimization: - Chain rule: \\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial h^{(l+1)}} \\frac{\\partial h^{(l+1)}}{\\partial W^{(l)}} - Gradient flow: How gradients propagate backward through layers - Vanishing gradients: Challenge in deep networks",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Preparation: Neural Networks and Deep Learning Prerequisites</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#optimization-for-neural-networks",
    "href": "m09-graph-neural-networks/00-preparation.html#optimization-for-neural-networks",
    "title": "39¬† Preparation: Neural Networks and Deep Learning Prerequisites",
    "section": "39.3 Optimization for Neural Networks",
    "text": "39.3 Optimization for Neural Networks\n\n39.3.1 Loss Functions\nDifferent objectives for different tasks: - Mean Squared Error: \\text{MSE} = \\frac{1}{n}\\sum_i (y_i - \\hat{y}_i)^2 for regression - Cross-entropy: \\text{CE} = -\\sum_i y_i \\log(\\hat{y}_i) for classification - Custom losses: Task-specific objectives for graph problems\n\n\n39.3.2 Gradient-Based Optimization\nAdvanced optimization techniques: - SGD with momentum: v_t = \\gamma v_{t-1} + \\alpha \\nabla_\\theta L - Adam optimizer: Adaptive learning rates with momentum - Learning rate scheduling: Decreasing rates over time - Batch normalization: Normalizing layer inputs for stable training\n\n\n39.3.3 Regularization Techniques\nPreventing overfitting: - L1/L2 regularization: Adding penalty terms to loss function - Dropout: Randomly setting some neurons to zero during training - Early stopping: Stopping training when validation loss stops improving",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Preparation: Neural Networks and Deep Learning Prerequisites</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#representation-learning",
    "href": "m09-graph-neural-networks/00-preparation.html#representation-learning",
    "title": "39¬† Preparation: Neural Networks and Deep Learning Prerequisites",
    "section": "39.4 Representation Learning",
    "text": "39.4 Representation Learning\n\n39.4.1 Feature Learning vs.¬†Feature Engineering\n\nManual features: Hand-crafted features based on domain knowledge\nLearned features: Features discovered automatically by neural networks\nEnd-to-end learning: Learning features jointly with final task\n\n\n\n39.4.2 Embedding Spaces\nUnderstanding learned representations: - Distributed representations: Dense vectors vs.¬†one-hot encodings - Semantic similarity: Similar inputs have similar representations - Linear relationships: Arithmetic in embedding space (e.g., king - man + woman ‚âà queen)",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Preparation: Neural Networks and Deep Learning Prerequisites</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#convolutional-neural-networks-cnns",
    "href": "m09-graph-neural-networks/00-preparation.html#convolutional-neural-networks-cnns",
    "title": "39¬† Preparation: Neural Networks and Deep Learning Prerequisites",
    "section": "39.5 Convolutional Neural Networks (CNNs)",
    "text": "39.5 Convolutional Neural Networks (CNNs)\n\n39.5.1 Convolution Operation\nFoundation for understanding graph convolutions: - Local connectivity: Neurons connect to local regions of input - Parameter sharing: Same filters applied across different positions - Translation invariance: Feature detection regardless of position\n\n\n39.5.2 Pooling Operations\nDimensionality reduction and invariance: - Max pooling: Taking maximum value in local regions - Average pooling: Taking average value in local regions - Global pooling: Reducing to single value per feature map",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Preparation: Neural Networks and Deep Learning Prerequisites</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#attention-mechanisms",
    "href": "m09-graph-neural-networks/00-preparation.html#attention-mechanisms",
    "title": "39¬† Preparation: Neural Networks and Deep Learning Prerequisites",
    "section": "39.6 Attention Mechanisms",
    "text": "39.6 Attention Mechanisms\n\n39.6.1 Basic Attention\nComputing weighted combinations: - Query-key-value: \\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V - Self-attention: When queries, keys, and values come from same source - Multi-head attention: Multiple attention mechanisms in parallel\n\n\n39.6.2 Applications to Graphs\n\nNode attention: Weighting importance of different neighbors\nGraph-level attention: Weighting importance of different nodes\nDynamic weights: Learned attention weights vs.¬†fixed graph structure",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Preparation: Neural Networks and Deep Learning Prerequisites</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#deep-learning-for-irregular-data",
    "href": "m09-graph-neural-networks/00-preparation.html#deep-learning-for-irregular-data",
    "title": "39¬† Preparation: Neural Networks and Deep Learning Prerequisites",
    "section": "39.7 Deep Learning for Irregular Data",
    "text": "39.7 Deep Learning for Irregular Data\n\n39.7.1 Challenges with Graph Data\n\nVariable size: Graphs have different numbers of nodes and edges\nNo natural ordering: Nodes don‚Äôt have canonical ordering like pixels\nIrregular structure: Unlike grids or sequences\n\n\n\n39.7.2 Permutation Invariance\nEssential property for graph neural networks: - Node permutation: Network output shouldn‚Äôt change if nodes are reordered - Symmetric functions: Functions that respect permutation invariance - Aggregation operations: Sum, max, mean preserve invariance\nThese deep learning foundations provide the necessary background for understanding how Graph Neural Networks adapt neural network concepts to work with the irregular structure of graphs and networks.",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Preparation: Neural Networks and Deep Learning Prerequisites</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/01-concepts.html",
    "href": "m09-graph-neural-networks/01-concepts.html",
    "title": "40¬† Concepts: Graph Neural Networks",
    "section": "",
    "text": "40.1 What to learn in this module\nIn this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Concepts: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/01-concepts.html#theoretical-exercises",
    "href": "m09-graph-neural-networks/01-concepts.html#theoretical-exercises",
    "title": "40¬† Concepts: Graph Neural Networks",
    "section": "40.2 Theoretical Exercises",
    "text": "40.2 Theoretical Exercises\n\n40.2.1 Pen and paper exercises\n\n‚úçÔ∏è Pen and paper exercises\n\nThe pen and paper exercises will help you understand the mathematical foundations of graph neural networks, including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures\n\nThese exercises provide the theoretical foundation necessary to understand how graph neural networks process and learn from graph-structured data.",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Concepts: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html",
    "href": "m09-graph-neural-networks/02-coding.html",
    "title": "41¬† Coding: Graph Neural Networks Implementation",
    "section": "",
    "text": "41.1 Preliminaries: Image Processing\nGraph Neural Networks are a type of neural network for graph data. node2vec and deepwalk stem from the idea of language modeling. In this module, we will focus on another branch of graph neural networks that stem from image processing.",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Coding: Graph Neural Networks Implementation</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#preliminaries-image-processing",
    "href": "m09-graph-neural-networks/02-coding.html#preliminaries-image-processing",
    "title": "41¬† Coding: Graph Neural Networks Implementation",
    "section": "",
    "text": "41.1.1 Edge Detection Problem in Image Processing\nEdge detection is a classical problem in image processing. The goal is to identify the boundaries of objects in an image.\n\nTo approach the problem, let us first remind that an image is a matrix of pixels. Each pixel has RGB values, each of which represents the intensity of red, green, and blue color. To simplify the problem, we focus on grayscale images, in which each pixel has only one value representing the brightness. In this case, an image can be represented as a 2D matrix, where each element in the matrix represents the brightness of a pixel.\n\n\n\n41.1.2 An example\nHuman eyes are very sensitive to brightness changes. An edge in an image appears when there is a significant brightness change between adjacent pixels. To be more concrete, let‚Äôs consider a small example consisting of 6x6 pixels, with a vertical line from the top to the bottom, where the brightness is higher than the neighboring pixels. This is an edge we want to detect.\n\nX = \\begin{bmatrix}\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10\n\\end{bmatrix}\n\nLet‚Äôs zoom on the pixel at (3, 3) and its surrounding pixels.\n\nZ = \\begin{bmatrix}\n10 & 80 & 10 \\\\\n\\textcolor{blue}{10} & \\textcolor{red}{80} & \\textcolor{purple}{10} \\\\\n10 & 80 & 10\n\\end{bmatrix}\n\nwhere the central pixel is highlighted in red. Since we are interested in the edge which is a sudden change in brightness along the horizontal direction, we take a derivative at the central pixel by\n\n\\nabla Z_{22} = \\textcolor{blue}{Z_{2,1}} - \\textcolor{purple}{Z_{2,3}}\n\nFollowing the same process, we can compute the derivative at all pixels, which gives us the (horizontal) derivative of the image.\n\n\\begin{bmatrix}\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & -\n\\end{bmatrix}\n\nThe symbol - indicates that the derivative is not defined because one of the neighboring pixels is out of the image boundary. We observe that the derivative is high at the edge and low elsewhere. This is a simple but effective way to detect edges in an image.\nWe can consider a derivative operator along the vertical direction that computes the difference between the vertical neighboring pixels.\n\n\\nabla Z_{22} = Z_{1,2} - Z_{3,2}\n\nAnd, when applied to the entire image, the result is\n\n\\begin{bmatrix}\n- & - & - & - & -  & - \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n- & - & - & - & - & -\n\\end{bmatrix}\n\nThe all entries are zero, meaning that there is no edge in the vertical direction.\nWe can combine the horizontal and vertical derivatives to get the gradient of the image. For example,\n\n\\nabla Z_{22} = Z_{12} - Z_{32} + Z_{21} - Z_{23}\n\nWhen applied to the entire image, the result is the same as the horizontal derivative.\n\n\n41.1.3 Convolution\nWe observe that there is a repeated pattern in the derivative computation: we are taking addition and subtraction of neighbiring pixels. This motivates us to generalize the operation to a more general form.\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j}\n\nwhere K is a 3 \\times 3 matrix, and w=h=3 represent the width and height of the kernel.\n\nK_{\\text{horizontal}} = \\begin{bmatrix}\n0 & 0 & 0 \\\\\n-1 & 0 & 1 \\\\\n0 & 0 & 0\n\\end{bmatrix},\\quad\nK_{\\text{vertical}} = \\begin{bmatrix}\n0 & -1 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{bmatrix}\n\nThe operation of K on the image is called convolution, and K is called the kernel or filter. More generally, the convolution of a kernel K and an image X is defined as\n\nY_{ij} = \\sum_{p}\\sum_{q} K_{pq} X_{i+p-\\frac{h+1}{2}, j+q-\\frac{w+1}{2}}\n\nwhere h and w are the height and width of the kernel, respectively.",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Coding: Graph Neural Networks Implementation</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#from-image-to-graph",
    "href": "m09-graph-neural-networks/02-coding.html#from-image-to-graph",
    "title": "41¬† Coding: Graph Neural Networks Implementation",
    "section": "41.2 From Image to Graph",
    "text": "41.2 From Image to Graph\n\n41.2.1 Analogy between image and graph data\nWe can think of a convolution of an image from the perspective of networks. In the convolution of an image, a pixel is convolved with its neighbors. We can regard each pixel as a node, and each node is connected to its neighboring nodes (pixels) that are involved in the convolution.\n\nBuilding on this analogy, we can extend the idea of convolution to general graph data. Each node has a pixel value(s) (e.g., feature vector), which is convolved with the values of its neighbors in the graph. This is the key idea of graph convolutional networks. But, there is a key difference: while the number of neighbors for an image is homogeneous, the number of neighbors for a node in a graph can be heterogeneous. Each pixel has the same number of neighbors (except for the boundary pixels), but nodes in a graph can have very different numbers of neighbors. This makes it non-trivial to define the ‚Äúkernel‚Äù for graph convolution.\n\n\n41.2.2 Spectral filter on graphs\nJust like we can define a convolution on images in the frequency domain, we can also define a ‚Äò‚Äôfrequency domain‚Äô‚Äô for graphs.\nConsider a network of N nodes, where each node has a feature variable {\\mathbf x}_i \\in \\mathbb{R}. We are interested in:\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2,\n\nwhere A_{ij} is the adjacency matrix of the graph. The quantity J represents the total variation of x between connected nodes; a small J means that connected nodes have similar x (low variation; low frequency), while a large J means that connected nodes have very different x (high variation; high frequency).\nWe can rewrite J as\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 = {\\bf x}^\\top {\\bf L} {\\bf x},\n\nwhere {\\bf L} is the Laplacian matrix of the graph given by\n\nL_{ij} = \\begin{cases}\n-1 & \\text{if } i \\text{ and } j \\text{ are connected} \\\\\nk_i & \\text{if } i = j \\\\\n0 & \\text{otherwise}\n\\end{cases}.\n\nand {\\bf x} = [x_1,x_2,\\ldots, x_N]^\\top is a column vector of feature variables.\n\n\n\n\n\n\nDetailed derivation\n\n\n\n:tag: note :class: dropdown\nThe above derivation shows that the total variation of x between connected nodes is proportional to {\\bf x}^\\top {\\bf L} {\\bf x}.\n\n\\begin{aligned}\nJ &= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 \\\\\n&= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\underbrace{A_{ij}\\left( x_i^2 +x_j^2\\right)}_{\\text{symmetric}} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2\\underbrace{\\sum_{j=1}^N A_{ij}}_{\\text{degree of node } i, k_i} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2 k_i - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\underbrace{[x_1,x_2,\\ldots, x_N]}_{{\\bf x}} \\underbrace{\\begin{bmatrix} k_1 & 0 & \\cdots & 0 \\\\ 0 & k_2 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & k_N \\end{bmatrix}}_{{\\bf D}} \\underbrace{\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N \\end{bmatrix}}_{{\\bf x}} - 2\\underbrace{\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}}_{{\\bf x}^\\top {\\mathbf A} {\\bf x}} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf D} {\\bf x} - {\\bf x}^\\top {\\mathbf A} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf L} {\\bf x},\n\\end{aligned}\n\n\n\nLet us showcase the analogy between the Fourier transform and the Laplacian matrix. In the Fourier transform, a signal is decomposed into sinusoidal basis functions. Similarly, for a graph, we can decompose the variation J into eigenvector bases.\n\nJ = \\sum_{i=1}^N \\lambda_i  {\\bf x}^\\top {\\mathbf u}_i {\\mathbf u}_i^\\top {\\bf x} = \\sum_{i=1}^N \\lambda_i  ||{\\bf x}^\\top {\\mathbf u}_i||^2.\n\nwhere {\\mathbf u}_i is the eigenvector corresponding to the eigenvalue \\lambda_i. - The term ({\\bf x}^\\top {\\mathbf u}_i) is a dot-product between the feature vector {\\bf x} and the eigenvector {\\mathbf u}_i, which measures how much {\\bf x} coheres with eigenvector {\\mathbf u}_i, similar to how Fourier coefficients measure coherency with sinusoids. - Each ||{\\bf x}^\\top {\\mathbf u}_i||^2 is the ‚Äò‚Äôstrength‚Äô‚Äô of {\\bf x} with respect to the eigenvector {\\mathbf u}_i, and the total variation J is a weighted sum of these strengths.\nSome eigenvectors correspond to low-frequency components, while others correspond to high-frequency components. For example, the total variation J for an eigenvector {\\mathbf u}_i is given by\n\nJ = \\frac{1}{2} \\sum_{j}\\sum_{\\ell} A_{j\\ell}(u_{ij} - u_{i\\ell})^2 = {\\mathbf u}_i^\\top {\\mathbf L} {\\mathbf u}_i = \\lambda_i.\n\nThis equation provides key insight into the meaning of eigenvalues:\n\nFor an eigenvector {\\mathbf u}_i, its eigenvalue \\lambda_i measures the total variation for {\\mathbf u}_i.\nLarge eigenvalues mean large differences between neighbors (high frequency), while small eigenvalues mean small differences (low frequency).\n\nThus, if {\\bf x} aligns well with {\\mathbf u}_i with a large \\lambda_i, then {\\bf x} has a strong high-frequency component; if {\\bf x} aligns well with {\\mathbf u}_i with a small \\lambda_i, then {\\bf x} has strong low-frequency component.\n\n\n41.2.3 Spectral Filtering\nEigenvalues \\lambda_i can be thought of as a filter that controls which frequency components pass through. Instead of using the filter associated with the Laplacian matrix, we can design a filter h(\\lambda_i) to control which frequency components pass through. This leads to the idea of spectral filtering. Two common filters are:\n\nLow-pass Filter: h_{\\text{low}}(\\lambda) = \\frac{1}{1 + \\alpha\\lambda}\n\nPreserves low frequencies (small Œª)\nSuppresses high frequencies (large Œª)\nResults in smoother signals\n\nHigh-pass Filter: h_{\\text{high}}(\\lambda) = \\frac{\\alpha\\lambda}{1 + \\alpha\\lambda}\n\nPreserves high frequencies\nSuppresses low frequencies\nEmphasizes differences between neighbors\n\n\n\n\nCode\n:tags: [remove-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context(\"talk\")\n\nalpha = 1\nlambdas = np.linspace(0, 10, 100)\nh_low = 1 / (1 + alpha * lambdas)\nh_high = (alpha * lambdas) / (1 + alpha * lambdas)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\nsns.lineplot(x=lambdas, y=h_low, label=\"Low-pass filter\", ax=axes[0])\naxes[0].legend(frameon=False).remove()\nsns.lineplot(x=lambdas, y=h_high, label=\"High-pass filter\", ax=axes[1])\naxes[1].legend(frameon=False).remove()\naxes[0].set_title(\"Low-pass filter\")\naxes[1].set_title(\"High-pass filter\")\nfig.text(0.5, 0.01, \"Eigenvalue $\\lambda$\", ha=\"center\")\naxes[0].set_ylabel(\"Filter response $h(\\lambda)$\")\nsns.despine()\nplt.tight_layout()\n\n\n\n\n41.2.4 Example\nLet us showcase the idea of spectral filtering with a simple example with the karate club network.\n\n\nCode\n:tags: [remove-input]\nimport igraph as ig\nimport numpy as np\nfrom scipy import sparse\nimport matplotlib as mpl\n\nG = ig.Graph.Famous(\"Zachary\")\nA = G.get_adjacency_sparse()\n\n\nWe will first compute the laplacian matrix and its eigendecomposition.\n\n\nCode\n# Compute Laplacian matrix\ndeg = np.array(A.sum(axis=1)).reshape(-1)\nD = sparse.diags(deg)\nL = D - A\n\n# Compute eigendecomposition\nevals, evecs = np.linalg.eigh(L.toarray())\n\n# Sort eigenvalues and eigenvectors\norder = np.argsort(evals)\nevals = evals[order]\nevecs = evecs[:, order]\n\n\nNow, let‚Äôs create a low-pass and high-pass filter.\n\n\nCode\nalpha = 2\nL_low = evecs @ np.diag(1 / (1 + alpha * evals)) @ evecs.T\nL_high = evecs @ np.diag(alpha * evals / (1 + alpha * evals)) @ evecs.T\n\nprint(\"Size of low-pass filter:\", L_low.shape)\nprint(\"Size of high-pass filter:\", L_high.shape)\n\n\nNotice that the high-pass filter and low-pass filter are matrices of the same size as the adjacency matrix A, which defines a ‚Äòconvolution‚Äô on the graph as follows:\n\n{\\bf x}' = {\\bf L}_{\\text{low}} {\\bf x} \\quad \\text{or} \\quad {\\bf x}' = {\\bf L}_{\\text{high}} {\\bf x}.\n\nwhere {\\bf L}_{\\text{low}} and {\\bf L}_{\\text{high}} are the low-pass and high-pass filters, respectively, and {\\bf x}' is the convolved feature vector.\nNow, let‚Äôs see how these filters work. Our first example is a random feature vector.\n\n\nCode\n# Random feature vector\nx = np.random.randn(A.shape[0], 1)\n\n# Convolve with low-pass filter\nx_low = L_low @ x\n\n# Convolve with high-pass filter\nx_high = L_high @ x\n\n\nLet us visualize the results.\n\n\nCode\n:tags: [hide-input]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\nnorm = mpl.colors.Normalize(vmin=-0.3, vmax=0.3)\n\n# Original\nvalues = x.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\n# Low-pass filter applied\nvalues = L_low @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\n# High-pass filter applied\nvalues = L_high @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\n\nWe observe that the low-pass filter results in smoother {\\bf x} between connected nodes (i.e., neighboring nodes have similar {\\bf x}). The original {\\bf x} and {\\bf x}'_{\\text{low}} are very similar because random variables are high-frequency components. In contrast, when we apply the high-pass filter, {\\bf x}'_{\\text{high}} is similar to {\\bf x} because the high-frequency components are not filtered.\nLet‚Äôs now use an eigenvector as our feature vector {\\bf x}.\n\n\nCode\n:tags: [hide-input]\neigen_centrality = np.array(G.eigenvector_centrality()).reshape(-1, 1)\nlow_pass_eigen = L_low @ eigen_centrality\nhigh_pass_eigen = L_high @ eigen_centrality\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\n\nnorm = mpl.colors.Normalize(vmin=-0, vmax=0.3)\nvalues = eigen_centrality.reshape(-1)# high_pass_random.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\nvalues = low_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\nvalues = high_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\n\nThe high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality.",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Coding: Graph Neural Networks Implementation</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#graph-convolutional-networks",
    "href": "m09-graph-neural-networks/02-coding.html#graph-convolutional-networks",
    "title": "41¬† Coding: Graph Neural Networks Implementation",
    "section": "41.3 Graph Convolutional Networks",
    "text": "41.3 Graph Convolutional Networks\nWe have seen that spectral filters give us a principled way to think about ‚Äúconvolution‚Äù on irregular graph structures, and controlling the frequency components brings out different aspects of the data. We now go one step further: instead of designing filters by hand, we can learn them from data for specific tasks.\n\n41.3.1 Spectral Graph Convolutional Networks\nA simplest form of learnable spectral filter is given by\n\n{\\bf L}_{\\text{learn}} = \\sum_{k=1}^K \\theta_k {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\nwhere {\\mathbf u}_k are the eigenvectors and \\theta_k are the learnable parameters. The variable K is the number of eigenvectors used (i.e., the rank of the filter). The weight \\theta_k is learned to maximize the performance of the task at hand.\nBuilding on this idea, {footcite}bruna2014spectral added a nonlinearity to the filter and proposed a spectral convolutional neural network (GCN) by\n\n{\\bf x}^{(\\ell+1)} = h\\left( L_{\\text{learn}} {\\bf x}^{(\\ell)}\\right),\n\nwhere h is an activation function, and {\\bf x}^{(\\ell)} is the feature vector of the \\ell-th convolution. They further extend this idea to convolve on multidimensional feature vectors, {\\bf X} \\in \\mathbb{R}^{N \\times f_{\\text{in}}} to produce new feature vectors of different dimensionality, {\\bf X}' \\in \\mathbb{R}^{N \\times f_{\\text{out}}}.\n\n\\begin{aligned}\n{\\bf X}^{(\\ell+1)}_i &= h\\left( \\sum_j L_{\\text{learn}}^{(i,j)} {\\bf X}^{(\\ell)}_j\\right),\\quad \\text{where} \\quad L^{(i,j)}_{\\text{learn}} = \\sum_{k=1}^K \\theta_{k, (i,j)} {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\\end{aligned}\n\nNotice that the learnable filter L_{\\text{learn}}^{(i,j)} is defined for each pair of input i and output j dimensions.\nMany GCNs simple when it comes to implementation despite the complicated formula. And this is one of my ways to learn GNNs. Check out the [Appendix for the Python implementation](appendix.md).\n\n\n\n41.3.2 From Spectral to Spatial\nSpectral GCNs are mathematically elegant but have two main limitations: 1. Computational Limitation: Computing the spectra of the Laplacian is expensive {\\cal O}(N^3) and prohibitive for large graphs 2. Spatial Locality: The learned filters are not spatially localized. A node can be influenced by all other nodes in the graph.\nThese two limitations motivate the development of spatial GCNs.\n\n\n41.3.3 ChebNet\nChebNet {footcite}defferrard2016convolutional is one of the earliest spatial GCNs that bridges the gap between spectral and spatial domains. The key idea is to leverage Chebyshev polynomials to approximate {\\bf L}_{\\text{learn}} by\n\n{\\bf L}_{\\text{learn}} \\approx \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}), \\quad \\text{where} \\quad \\tilde{{\\bf L}} = \\frac{2}{\\lambda_{\\text{max}}}{\\bf L} - {\\bf I},\n\nwhere \\tilde{{\\bf L}} is the scaled and normalized Laplacian matrix in order to have eigenvalues in the range of [-1,1]. The Chebyshev polynomials T_k(\\tilde{{\\bf L}}) transforms the eigenvalues \\tilde{{\\bf L}} to the following recursively:\n\n\\begin{aligned}\nT_0(\\tilde{{\\bf L}}) &= {\\bf I} \\\\\nT_1(\\tilde{{\\bf L}}) &= \\tilde{{\\bf L}} \\\\\nT_k(\\tilde{{\\bf L}}) &= 2\\tilde{{\\bf L}} T_{k-1}(\\tilde{{\\bf L}}) - T_{k-2}(\\tilde{{\\bf L}})\n\\end{aligned}\n\nWe then replace {\\bf L}_{\\text{learn}} in the original spectral GCN with the Chebyshev polynomial approximation:\n\n{\\bf x}^{(\\ell+1)} = h\\left( \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}){\\bf x}^{(\\ell)}\\right),\n\nwhere: - T_k(\\tilde{{\\bf L}}) applies the k-th Chebyshev polynomial to the scaled Laplacian matrix - \\theta_k are the learnable parameters - K is the order of the polynomial (typically small, e.g., K=3)\n\n\n41.3.4 Graph Convolutional Networks by Kipf and Welling\nWhile ChebNet offers a principled way to approximate spectral convolutions, Kipf and Welling (2017) {footcite}kipf2017semi proposed an even simpler and highly effective variant called Graph Convolutional Networks (GCN).\n\n41.3.4.0.1 First-order Approximation\nThe key departure is to use the first-order approximation of the Chebyshev polynomials.\n\ng_{\\theta'} * x \\approx \\theta'_0x + \\theta'_1(L - I_N)x = \\theta'_0x - \\theta'_1D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}x\n\nThis is crude approximation but it leads to a much simpler form, leaving only two learnable parameters, instead of K parameters in the original ChebNet.\nAdditionally, they further simplify the formula by using the same \\theta for both remaining parameters (i.e., \\theta_0 = \\theta and \\theta_1 = -\\theta). The result is the following convolutional filter:\n\ng_{\\theta} * x \\approx \\theta(I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}})x\n\nWhile this is a very simple filter, one can stack multiple layers of convolutions to perform high-order graph convolutions.\n\n\n41.3.4.0.2 Deep GCNs can suffer from over-smoothing\nGCN models can be deep, and when they are too deep, they start suffering from an ill-posed problem called gradient vanishing/exploding, where the gradients of the loss function becomes too small or too large to update the model parameters. It is a common problem in deep learning.\nTo facilitate the training of deep GCNs, the authors introduce a very simple trick called renormalization. The idea is to add self-connections to the graph:\n\n\\tilde{A} = A + I_N, \\quad \\text{and} \\quad \\tilde{D}_{ii} = \\sum_j \\tilde{A}_{ij}\n\nAnd use \\tilde{A} and \\tilde{D} to form the convolutional filter.\nAltogether, this leads to the following layer-wise propagation rule:\nX^{(\\ell+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}X^{(\\ell)}W^{(\\ell)})\nwhere: - X^{(\\ell)} is the matrix of node features at layer \\ell - W^{(\\ell)} is the layer‚Äôs trainable weight matrix - \\sigma is a nonlinear activation function (e.g., ReLU)\nThese simplifications offer several advantages: - Efficiency: Linear complexity in number of edges - Localization: Each layer only aggregates information from immediate neighbors - Depth: Fewer parameters allow building deeper models - Performance: Despite (or perhaps due to) its simplicity, it often outperforms more complex models\n\n\n\n\n\n\nExercise\n\n\n\n:class: note\nLet‚Äôs implement a simple GCN model for node classification. Coding Exercise",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Coding: Graph Neural Networks Implementation</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#popular-graph-neural-networks",
    "href": "m09-graph-neural-networks/02-coding.html#popular-graph-neural-networks",
    "title": "41¬† Coding: Graph Neural Networks Implementation",
    "section": "41.4 Popular Graph Neural Networks",
    "text": "41.4 Popular Graph Neural Networks\nIn this section, we will introduce three popular GNNs: GraphSAGE, Graph Attention Networks (GAT), and Graph Isomorphism Network (GIN).\n\n41.4.1 GraphSAGE: Sample and Aggregate\nGraphSAGE {footcite}hamilton2017graphsage introduced a different GCN that can be generalized to unseen nodes (they called it ‚Äúinductive‚Äù). While previous approaches like ChebNet and GCN operate on the entire graph, GraphSAGE proposes an inductive framework that generates embeddings by sampling and aggregating features from a node‚Äôs neighborhood.\n\n\n\n41.4.2 Key Ideas\nGraphSAGE involves two key ideas: (1) sampling and (2) aggregation.\n\n41.4.2.0.1 Neighborhood Sampling\nThe key idea is the neighborhood sampling. Instead of using all neighbors, GraphSAGE samples a fixed-size set of neighbors for each node. This controls memory complexity, a key limitation of the previous GNNs.\nAnother key advantage of neighborhood sampling is that it enables GraphSAGE to handle dynamic, growing networks. Consider a citation network where new papers (nodes) are continuously added. Traditional GCNs would need to recompute filters for the entire network with each new addition. In contrast, GraphSAGE can immediately generate embeddings for new nodes by simply sampling their neighbors, without any retraining or recomputation.\n\n\n41.4.2.0.2 Aggregation\nAnother key idea is the aggregation. GraphSAGE makes a distinction between self-information and neighborhood information. While previous GNNs treat them equally and aggregate them, GraphSAGE treats them differently. Specifically, GraphSAGE introduces an additional step: it concatenates the self-information and the neighborhood information as the input of the convolution.\n\nZ_v = \\text{CONCAT}(X_v, X_{\\mathcal{N}(v)})\n\nwhere X_v is the feature of the node itself and X_{\\mathcal{N}(v)} is the aggregation of the features of its neighbors. GraphSAGE introduces different ways to aggregate information from neighbors:\nX_{\\mathcal{N}(v)} = \\text{AGGREGATE}_k(\\{X_u, \\forall u \\in \\mathcal{N}(v)\\})\nCommon aggregation functions include: - Mean aggregator: \\text{AGGREGATE} = \\text{mean}(\\{h_u, \\forall u \\in \\mathcal{N}(v)\\}) - Max-pooling: \\text{AGGREGATE} = \\max(\\{\\sigma(W_{\\text{pool}}h_u + b), \\forall u \\in \\mathcal{N}(v)\\}) - LSTM aggregator: Apply LSTM to randomly permuted neighbors\nThe concatenated feature Z_v is normalized by the L2 norm.\n\n\\hat{Z}_v = \\frac{Z_v}{\\|Z_v\\|_2}\n\nand then fed into the convolution.\n\nX_v^k = \\sigma(W^k \\hat{Z}_v + b^k)\n\n\n\n\n41.4.3 Graph Attention Networks (GAT): Differentiate Individual Neighbors\nA key innovation of GraphSAGE is to treat the self and neighborhood information differently. But should all neighbors be treated equally? Graph Attention Networks (GAT) address this by letting the model learn which neighbors to pay attention to.\n\n\n41.4.4 Attention Mechanism\n\nThe core idea is beautifully simple: instead of using fixed weights like GCN, let‚Äôs learn attention weights \\alpha_{ij} that determine how much node i should attend to node j. These weights are computed dynamically based on node features:\n\n\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik})}\n\nwhere e_{ij} represents the importance of the edge between node i and node j. Variable e_{ij} is a learnable parameter and can be negative, and the exponential function is applied to transform it to a non-negative value, with the normalization term \\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik}) to ensure the weights sum to 1.\nHow to compute e_{ij}? One simple choice is to use a neural network with a shared weight matrix W and a LeakyReLU activation function. Specifically:\n\nLet‚Äôs focus on computing e_{ij} for node i and its neighbor j.\nWe use a shared weight matrix W to transform the features of node i and j. \n\\mathbf{\\tilde h}_i  = \\mathbf{h}_i, \\quad \\mathbf{\\tilde h}_j  = W\\mathbf{h}_j\n\nWe concatenate the transformed features and apply a LeakyReLU activation function.\n\n\ne_{ij} = \\text{LeakyReLU}(\\mathbf{a}^T[\\mathbf{\\tilde h}_i, \\mathbf{\\tilde h}_j])\n\nwhere \\mathbf{a} is a trainable parameter vector that sums the two transformed features.\nOnce we have these attention weights, the node update is straightforward - just a weighted sum of neighbor features:\n\\mathbf{h}'_i = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}{\\bf W}_{\\text{feature}}\\mathbf{h}_j\\right)\nwhere {\\bf W}_{\\text{feature}} is a trainable weight matrix. To stabilize training, GAT uses multiple attention heads and concatenates their outputs:\n\\mathbf{h}'_i = \\parallel_{k=1}^K \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}^k{\\bf W}^k_{\\text{feature}}\\mathbf{h}_j\\right)\n\n\n41.4.5 Graph Isomorphism Network (GIN): Differentiate the Aggregation\nGraph Isomorphism Networks (GIN) is another popular GNN that born out of a question: what is the maximum discriminative power achievable by Graph Neural Networks? The answer lies in its theoretical connection to the Weisfeiler-Lehman (WL) test, a powerful algorithm for graph isomorphism testing.\n\n\n41.4.6 Weisfeiler-Lehman Test\nAre two graphs structurally identical? Graph isomorphism testing determines if two graphs are structurally identical, with applications in graph classification, clustering, and other tasks.\n\nWhile the general problem has no known polynomial-time solution, the WL test is an efficient heuristic that works well in practice. The WL test iteratively refines node labels by hashing the multiset of neighboring labels\n\nThe WL test works as follows:\n\nAssign all nodes the same initial label.\nFor each node, collect the labels of all its neighbors and aggregate them into a hash (e.g., new label). For example, the top node gets {0} from its neighbors, resulting in a collection {0,0}. A new label is created via a hash function h that maps {0, {0, 0}} to a new label 1.\nRepeat the process for a fixed number of iterations or until convergence.\n\nHere is the implementation of the WL test in Python:\n\n\nCode\n:tags: [hide-input]\n\nimport numpy as np\nfrom scipy import sparse\n\ndef weisfeiler_lehman_test(A, num_iterations):\n    n_nodes = A.shape[0]\n    labels = np.zeros(n_nodes, dtype=int)\n    color_map = {}\n    hash_fn = lambda x: color_map.setdefault(x, len(color_map))\n    for _ in range(num_iterations):\n\n        # Go through each node\n        labels_old = labels.copy()\n        for i in range(n_nodes):\n\n            # Collect the labels of all neighbors\n            neighbors = A[i].nonzero()[1]\n            neighbor_labels = labels_old[neighbors]\n\n            # Count the frequency of each label\n            unique, counts = np.unique(neighbor_labels, return_counts=True)\n\n            # Create a hash key by converting the frequency dictionary to a string\n            hash_key = str({unique[j]: counts[j] for j in range(len(unique))})\n\n            # Create a new label by hashing the frequency dictionary\n            label = hash_fn(hash_key)\n            labels[i] = label\n\n        # Check convergence\n        unique, counts = np.unique(labels, return_counts=True)\n        unique_old, counts_old = np.unique(labels_old, return_counts=True)\n        if np.array_equal(np.sort(counts), np.sort(counts_old)):\n            break\n    return labels\n\n\nedge_list = [(0, 1), (1, 2), (2, 0), (3, 4), (4, 5), (5, 3)]\n\nA = sparse.csr_matrix(\n    ([1] * len(edge_list), ([e[0] for e in edge_list], [e[1] for e in edge_list])),\n    shape=(6, 6),\n)\nA = A + A.T\nA.sort_indices()\n\nweisfeiler_lehman_test(A, A.shape[0])\n\n\nAfter these iterations: - Nodes with the same label are structurally identical, meaning that they are indistinguishable unless we label them differently. - Two graphs are structurally identical if and only if they have the same node labels after the WL test.\nThe WL test is a heuristic and can fail on some graphs. For example, it cannot distinguish regular graphs with the same number of nodes and edges.\nThe WL test above is called the 1-WL test. There are higher-order WL tests that can distinguish more graphs, which are the basis of advanced GNNs.\nCheck out [this note](https://www.moldesk.net/blog/weisfeiler-lehman-isomorphism-test/)\n\n\n41.4.7 GIN\nGIN {footcite}xu2018how is a GNN that is based on the WL test. The key idea is to focus on the parallel between the WL test and the GNN update rule. - In the WL test, we iteratively collect the labels of neighbors and aggregate them through a hash function. - In the GraphSAGE and GAT, the labels are the nodes‚Äô features, and the aggregation is some arithmetic operations such as mean or max.\nThe key difference is that the hash function in the WL test always distinguishes different sets of neighbors‚Äô labels, while the aggregation in GraphSAGE and GAT does not always do so. For example, if all nodes have the same feature (e.g., all 1), the aggregation by the mean or max will result in the same value for all nodes, whereas the hash function in the WL test can still distinguish different sets of neighbors‚Äô labels by the count of each label.\nThe resulting convolution update rule is:\n\nh_v^{(k+1)} = \\text{MLP}^{(k)}\\left((1 + \\epsilon^{(k)}) \\cdot h_v^{(k)} + \\sum_{u \\in \\mathcal{N}(v)} h_u^{(k)}\\right)\n\nwhere \\text{MLP}^{(k)} is a multi-layer perceptron (MLP) with k layers, and \\epsilon^{(k)} is a fixed or trainable parameter.",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Coding: Graph Neural Networks Implementation</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html",
    "href": "m09-graph-neural-networks/03-exercises.html",
    "title": "42¬† Exercises: Graph Neural Networks",
    "section": "",
    "text": "42.1 Theoretical Exercises",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Exercises: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html#theoretical-exercises",
    "href": "m09-graph-neural-networks/03-exercises.html#theoretical-exercises",
    "title": "42¬† Exercises: Graph Neural Networks",
    "section": "",
    "text": "42.1.1 Pen and Paper Exercises\n\n‚úçÔ∏è Pen and paper exercises\n\nThe pen and paper exercises cover fundamental concepts including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\n\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Exercises: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html#programming-exercises",
    "href": "m09-graph-neural-networks/03-exercises.html#programming-exercises",
    "title": "42¬† Exercises: Graph Neural Networks",
    "section": "42.2 Programming Exercises",
    "text": "42.2 Programming Exercises\n\n42.2.1 Coding Exercise: GCN Implementation\n\n\n\n\n\n\nExercise\n\n\n\n:class: note\nLet‚Äôs implement a simple GCN model for node classification. Coding Exercise\n\n\nThis coding exercise will guide you through:\n\nBuilding a GCN from Scratch: Implementing the basic GCN layer\nNode Classification: Training GCN for semi-supervised node classification\nSpectral Filtering: Understanding how GCNs relate to spectral graph theory\nComparison with Other Methods: Benchmarking against traditional approaches\n\n\n\n42.2.2 Key Learning Objectives\nThrough these exercises, you will:\n\nUnderstand the Mathematics: Connect spectral graph theory to practical GNN implementations\nImplement Core Algorithms: Build GCN, GraphSAGE, GAT, and GIN from fundamental principles\nApply to Real Problems: Use GNNs for node classification, graph classification, and link prediction\nAnalyze Performance: Compare different GNN architectures and understand their strengths/weaknesses\nDebug and Optimize: Learn common pitfalls and optimization strategies for GNNs\n\n\n\n42.2.3 Exercise Topics\n\nBasic GCN Implementation\n\nImplement the GCN layer forward pass\nAdd self-loops and normalization\nTrain on Cora dataset for node classification\n\nSpectral Analysis\n\nVisualize graph spectra and eigenvectors\nImplement spectral filtering\nCompare low-pass vs high-pass filters\n\nAdvanced Architectures\n\nImplement GraphSAGE with different aggregators\nBuild GAT with attention visualization\nCreate GIN and test on graph isomorphism\n\nPractical Applications\n\nSocial network analysis\nCitation network node classification\nMolecular property prediction\n\n\nThese exercises bridge theory and practice, ensuring you understand both the mathematical foundations and practical implementation details of Graph Neural Networks.",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Exercises: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/04-appendix.html",
    "href": "m09-graph-neural-networks/04-appendix.html",
    "title": "43¬† Appendix",
    "section": "",
    "text": "43.1 Bruna‚Äôs Spectral GCN\nLet‚Äôs first implement Bruna‚Äôs spectral GCN.\nCode\n:tags: [hide-input]\n\nimport numpy as np\nimport scipy.sparse as sp\nimport torch\nimport torch.nn as nn\nimport scipy.sparse.linalg as slinalg\n\nclass BrunaGraphConv(nn.Module):\n    \"\"\"\n    Bruna's Spectral Graph Convolution Layer\n\n    This implementation follows the original formulation by Joan Bruna et al.,\n    using the eigendecomposition of the graph Laplacian for spectral convolution.\n    \"\"\"\n\n    def __init__(self, in_features, out_features, n_nodes):\n        \"\"\"\n        Initialize the Bruna Graph Convolution layer\n\n        Args:\n            in_features (int): Number of input features\n            out_features (int): Number of output features\n        \"\"\"\n        super(BrunaGraphConv, self).__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        # Learnable spectral filter parameters\n        self.weight = nn.Parameter(\n            torch.FloatTensor(in_features, out_features, n_nodes-1)\n        )\n\n        # Initialize parameters\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        \"\"\"Initialize weights using Glorot initialization\"\"\"\n        nn.init.xavier_uniform_(self.weight)\n\n\n    @staticmethod\n    def get_laplacian_eigenvectors(adj):\n        \"\"\"\n        Compute eigendecomposition of the normalized graph Laplacian\n\n        Args:\n            adj: Adjacency matrix\n\n        Returns:\n            eigenvalues, eigenvectors of the normalized Laplacian\n        \"\"\"\n        # Compute normalized Laplacian\n        # Add self-loops\n        adj = adj + sp.eye(adj.shape[0])\n\n        # Compute degree matrix\n        deg = np.array(adj.sum(axis=1))\n        Dsqrt_inv = sp.diags(1.0 / np.sqrt(deg).flatten())\n\n        # Compute normalized Laplacian: D^(-1/2) A D^(-1/2)\n        laplacian = sp.eye(adj.shape[0]) - Dsqrt_inv @ adj @ Dsqrt_inv\n\n        # Compute eigendecomposition\n        # Using k=adj.shape[0]-1 to get all non-zero eigenvalues\n        eigenvals, eigenvecs = slinalg.eigsh(laplacian.tocsc(), k=adj.shape[0]-1,which='SM', tol=1e-6)\n\n        return torch.FloatTensor(eigenvals), torch.FloatTensor(eigenvecs)\n\n    def forward(self, x, eigenvecs):\n        \"\"\"\n        Forward pass implementing Bruna's spectral convolution\n\n        Args:\n            x: Input features [num_nodes, in_features]\n            eigenvecs: Eigenvectors of the graph Laplacian [num_nodes, num_nodes-1]\n\n        Returns:\n            Output features [num_nodes, out_features]\n        \"\"\"\n        # Transform to spectral domain\n        x_spectral = torch.matmul(eigenvecs.t(), x)  # [num_nodes-1, in_features]\n\n        # Initialize output tensor\n        out = torch.zeros(x.size(0), self.out_features, device=x.device)\n\n        # For each input-output feature pair\n        for i in range(self.in_features):\n            for j in range(self.out_features):\n                # Element-wise multiplication in spectral domain\n                # This is the actual spectral filtering operation\n                filtered = x_spectral[:, i] * self.weight[i, j, :]  # [num_spectrum]\n\n                # Transform back to spatial domain and accumulate\n                out[:, j] += torch.matmul(eigenvecs, filtered)\n\n        return out\nNext, we will train the model on the karate club network to predict the given node labels indicating nodes‚Äô community memberships. We load the data by\nCode\n:tags: [hide-input]\n\nimport networkx as nx\nimport torch\nimport matplotlib.pyplot as plt\n\n# Load karate club network\nG = nx.karate_club_graph()\nadj = nx.to_scipy_sparse_array(G)\nfeatures = torch.eye(G.number_of_nodes())\nlabels = torch.tensor([G.nodes[i]['club'] == 'Officer' for i in G.nodes()], dtype=torch.long)\nWe apply the convolution twice with ReLu activation in between. This can be implemented by preparing two independent BrunaGraphConv layers, applying them consecutively, and adding a ReLu activation in between.\nCode\n:tags: [hide-input]\n\n# Define a simple GCN model\nclass SimpleGCN(nn.Module):\n    def __init__(self, in_features, out_features, hidden_features, n_nodes):\n        super(SimpleGCN, self).__init__()\n        self.conv1 = BrunaGraphConv(in_features, hidden_features, n_nodes)\n        self.relu = nn.ReLU()\n        self.conv2 = BrunaGraphConv(hidden_features, out_features, n_nodes)\n\n    def forward(self, x, eigenvecs):\n        x = self.conv1(x, eigenvecs)\n        x = self.relu(x)\n        x = self.conv2(x, eigenvecs)\n        return x\nWe then train the model by\nCode\n:tags: [hide-input]\n\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Get eigenvectors of the Laplacian\neigenvals, eigenvecs = BrunaGraphConv.get_laplacian_eigenvectors(adj)\n\n# Initialize the model\nhidden_features = 10\ninput_features = features.shape[1]\noutput_features = 2\nn_nodes = G.number_of_nodes()\nmodel = SimpleGCN(input_features, output_features, hidden_features, n_nodes)\n\n# Train the model\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Split the data into training and testing sets\ntrain_idx, test_idx = train_test_split(np.arange(G.number_of_nodes()), test_size=0.2, random_state=42)\ntrain_features = features[train_idx]\ntrain_labels = labels[train_idx]\ntest_features = features[test_idx]\ntest_labels = labels[test_idx]\n\n\nn_train = 100\nfor epoch in range(n_train):\n    model.train()\n    optimizer.zero_grad()\n    output = model(train_features, eigenvecs[train_idx, :])\n    loss = criterion(output, train_labels)\n    loss.backward()\n    optimizer.step()\n\n    # Evaluate the model\n    if epoch == 0 or (epoch+1) % 25 == 0:\n        model.eval()\n        with torch.no_grad():\n            output = model(test_features, eigenvecs[test_idx, :])\n            _, predicted = torch.max(output, 1)\n            accuracy = (predicted == test_labels).float().mean()\n            print(f'Epoch {epoch+1}/{n_train}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}')\nObserve that the accuracy increases as the training progresses. We can use the model to predict the labels. The model has a hidden layer, and let‚Äôs visualize the data in the hidden space.\nCode\n:tags: [hide-input]\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\n# Visualize the learned embeddings\nembeddings = model.conv1(features, eigenvecs).detach().numpy()\n\nxy = TSNE(n_components=2).fit_transform(embeddings)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.scatterplot(x = xy[:, 0].reshape(-1), y = xy[:, 1].reshape(-1), hue=labels.numpy(), palette='tab10', ax = ax)\nax.set_title(\"Learned Node Embeddings\")\nplt.show()",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/04-appendix.html#chebnet",
    "href": "m09-graph-neural-networks/04-appendix.html#chebnet",
    "title": "43¬† Appendix",
    "section": "43.2 ChebNet",
    "text": "43.2 ChebNet\nLet‚Äôs implement the ChebNet layer.\n\n\nCode\n:tags: [hide-input]\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport scipy.sparse as sp\nfrom typing import Optional\n\n\ndef sparse_mx_to_torch_sparse(sparse_mx):\n    \"\"\"Convert scipy sparse matrix to torch sparse tensor.\"\"\"\n    sparse_mx = sparse_mx.tocoo()\n    indices = torch.from_numpy(\n        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n    )\n    values = torch.from_numpy(sparse_mx.data.astype(np.float32))\n    shape = torch.Size(sparse_mx.shape)\n    return torch.sparse_coo_tensor(indices, values, shape)\n\n\nclass ChebConv(nn.Module):\n    \"\"\"\n    Chebyshev Spectral Graph Convolutional Layer\n    \"\"\"\n\n    def __init__(self, in_channels: int, out_channels: int, K: int, bias: bool = True):\n        super(ChebConv, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.K = K\n\n        # Trainable parameters\n        self.weight = nn.Parameter(torch.Tensor(K, in_channels, out_channels))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(out_channels))\n        else:\n            self.register_parameter(\"bias\", None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        \"\"\"Initialize parameters.\"\"\"\n        nn.init.xavier_uniform_(self.weight)\n        if self.bias is not None:\n            nn.init.zeros_(self.bias)\n\n    def _normalize_laplacian(self, adj_matrix):\n        \"\"\"\n        Compute normalized Laplacian L = I - D^(-1/2)AD^(-1/2)\n        \"\"\"\n        # Convert to scipy if it's not already\n        if not sp.isspmatrix(adj_matrix):\n            adj_matrix = sp.csr_matrix(adj_matrix)\n\n        adj_matrix = adj_matrix.astype(float)\n\n        # Compute degree matrix D\n        rowsum = np.array(adj_matrix.sum(1)).flatten()\n        d_inv_sqrt = np.power(rowsum, -0.5)\n        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.0\n        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n\n        # Compute L = I - D^(-1/2)AD^(-1/2)\n        n = adj_matrix.shape[0]\n        L = sp.eye(n) - d_mat_inv_sqrt @ adj_matrix @ d_mat_inv_sqrt\n        return L\n\n    def _scale_laplacian(self, L):\n        \"\"\"\n        Scale Laplacian eigenvalues to [-1, 1] interval\n        L_scaled = 2L/lambda_max - I\n        \"\"\"\n        try:\n            # Compute largest eigenvalue\n            eigenval, _ = sp.linalg.eigsh(L, k=1, which=\"LM\", return_eigenvectors=False)\n            lambda_max = eigenval[0]\n        except:\n            # Approximate lambda_max = 2 if eigenvalue computation fails\n            lambda_max = 2.0\n\n        n = L.shape[0]\n        L_scaled = (2.0 / lambda_max) * L - sp.eye(n)\n        return L_scaled\n\n    def chebyshev_basis(self, L_sparse: torch.sparse.Tensor, X: torch.Tensor):\n        \"\"\"\n        Compute Chebyshev polynomials basis up to order K.\n        \"\"\"\n        # List to store Chebyshev polynomials\n        cheb_polynomials = []\n\n        # T_0(L) = I\n        cheb_polynomials.append(X)\n\n        if self.K &gt; 1:\n            # T_1(L) = L\n            X_1 = torch.sparse.mm(L_sparse, X)\n            cheb_polynomials.append(X_1)\n\n        # Recurrence T_k(L) = 2L¬∑T_{k-1}(L) - T_{k-2}(L)\n        for k in range(2, self.K):\n            X_k = (\n                2 * torch.sparse.mm(L_sparse, cheb_polynomials[k - 1])\n                - cheb_polynomials[k - 2]\n            )\n            cheb_polynomials.append(X_k)\n\n        return torch.stack(cheb_polynomials, dim=0)  # [K, num_nodes, in_channels]\n\n    def forward(self, X: torch.Tensor, adj_matrix: sp.spmatrix):\n        \"\"\"\n        Forward pass.\n\n        Args:\n            X: Node features tensor of shape [num_nodes, in_channels]\n            adj_matrix: Adjacency matrix in scipy sparse format\n\n        Returns:\n            Output tensor of shape [num_nodes, out_channels]\n        \"\"\"\n        # Compute normalized and scaled Laplacian\n        L_norm = self._normalize_laplacian(adj_matrix)\n        L_scaled = self._scale_laplacian(L_norm)\n\n        # Convert to torch sparse tensor\n        L_scaled = sparse_mx_to_torch_sparse(L_scaled).to(X.device)\n\n        # Compute Chebyshev polynomials basis\n        Tx = self.chebyshev_basis(L_scaled, X)  # [K, num_nodes, in_channels]\n\n        # Perform convolution using learned weights\n        out = torch.einsum(\"kni,kio-&gt;no\", Tx, self.weight)\n\n        if self.bias is not None:\n            out += self.bias\n\n        return out\n\n\nWe stack the layers to form a simple GCN model.\n\n\nCode\n:tags: [hide-input]\n\nclass ChebNet(nn.Module):\n    \"\"\"\n    ChebNet model for node classification\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        hidden_channels: int,\n        out_channels: int,\n        K: int,\n        num_layers: int,\n        dropout: float = 0.5,\n    ):\n        super(ChebNet, self).__init__()\n\n        self.convs = nn.ModuleList()\n\n        # First layer\n        self.convs.append(ChebConv(in_channels, hidden_channels, K))\n\n        # Hidden layers\n        for _ in range(num_layers - 2):\n            self.convs.append(ChebConv(hidden_channels, hidden_channels, K))\n\n        # Output layer\n        self.convs.append(ChebConv(hidden_channels, out_channels, K))\n\n        self.dropout = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, X: torch.Tensor, adj_matrix: sp.spmatrix):\n        \"\"\"\n        Forward pass through all layers\n        \"\"\"\n        for i, conv in enumerate(self.convs[:-1]):\n            X = conv(X, adj_matrix)\n            X = self.activation(X)\n            X = self.dropout(X)\n\n        # Output layer\n        X = self.convs[-1](X, adj_matrix)\n        return X\n\n\nLet‚Äôs train the model on the karate club network.\n\n\nCode\n:tags: [hide-input]\n\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\nimport networkx as nx\nimport torch\nimport matplotlib.pyplot as plt\n\n# Load karate club network\nG = nx.karate_club_graph()\nadj = nx.to_scipy_sparse_array(G)\nfeatures = torch.eye(G.number_of_nodes())\nlabels = torch.tensor(\n    [G.nodes[i][\"club\"] == \"Officer\" for i in G.nodes()], dtype=torch.long\n)\n\n# Initialize the model\nhidden_features = 10\ninput_features = features.shape[1]\noutput_features = 2\nn_nodes = G.number_of_nodes()\nK = 3\nnum_layers = 2\ndropout = 0.5\n\nmodel = ChebNet(\n    input_features, hidden_features, output_features, K, num_layers, dropout\n)\n\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Train the model\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Split the data into training and testing sets\ntrain_idx, test_idx = train_test_split(\n    np.arange(G.number_of_nodes()), test_size=0.2, random_state=42\n)\ntrain_features = features[train_idx]\ntrain_labels = labels[train_idx]\ntest_features = features[test_idx]\ntest_labels = labels[test_idx]\n\n\nn_train = 100\nfor epoch in range(n_train):\n    model.train()\n    optimizer.zero_grad()\n    output = model(features, adj)\n    loss = criterion(output[train_idx], train_labels)\n    loss.backward()\n    optimizer.step()\n\n    # Evaluate the model\n    if epoch == 0 or (epoch + 1) % 25 == 0:\n        model.eval()\n        with torch.no_grad():\n            output = model(features, adj)\n            _, predicted = torch.max(output[test_idx], 1)\n            accuracy = (predicted == test_labels).float().mean()\n            print(\n                f\"Epoch {epoch+1}/{n_train}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}\"\n            )\n\n\nLet‚Äôs visualize the learned embeddings.\n\n\nCode\n:tags: [hide-input]\n\nmodel.eval()\nwith torch.no_grad():\n    # Get embeddings from the last hidden layer\n    X_hidden = features\n    for conv in model.convs[:-1]:\n        X_hidden = conv(X_hidden, adj)\n        X_hidden = model.activation(X_hidden)\n\n# Reduce dimensionality for visualization\nxy = TSNE(n_components=2).fit_transform(X_hidden.numpy())\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.scatterplot(\n    x=xy[:, 0].reshape(-1),\n    y=xy[:, 1].reshape(-1),\n    hue=labels.numpy(),\n    palette=\"tab10\",\n    ax=ax,\n)\nax.set_title(\"Learned Node Embeddings\")\nplt.show()",
    "crumbs": [
      "M09: Graph Neural Networks",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  }
]