<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sadamori Kojaku">
<meta name="dcterms.date" content="2025-07-27">

<title>Graph embedding with word2vec</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e6dc204ec8b52f55243daf2cac742210.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "|"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/custom.css">
</head>

<body class="nav-sidebar docked nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../logo.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Advanced Topics in Network Science</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-course" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Course</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-course">    
        <li>
    <a class="dropdown-item" href="../course/welcome.html">
 <span class="dropdown-text">Welcome</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../course/about.html">
 <span class="dropdown-text">About</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../course/discord.html">
 <span class="dropdown-text">Discord</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../course/minidora-usage.html">
 <span class="dropdown-text">Minidora</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../course/setup.html">
 <span class="dropdown-text">Setup</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-intro">    
        <li>
    <a class="dropdown-item" href="../intro/why-networks.html">
 <span class="dropdown-text">Why Networks?</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-foundations" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Foundations</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-foundations">    
        <li class="dropdown-header">─── M01: Euler Path ───</li>
        <li>
    <a class="dropdown-item" href="../m01-euler_tour/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-euler_tour/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-euler_tour/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-euler_tour/04-advanced.html">
 <span class="dropdown-text">Advanced</span></a>
  </li>  
        <li class="dropdown-header">─── M02: Small World ───</li>
        <li>
    <a class="dropdown-item" href="../m02-small-world/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-small-world/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-small-world/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-small-world/04-appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
        <li class="dropdown-header">─── M03: Robustness ───</li>
        <li>
    <a class="dropdown-item" href="../m03-robustness/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-robustness/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-robustness/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-robustness/04-appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-core-topics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Core Topics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-core-topics">    
        <li class="dropdown-header">─── M04: Friendship Paradox ───</li>
        <li>
    <a class="dropdown-item" href="../m04-node-degree/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-node-degree/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-node-degree/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li class="dropdown-header">─── M05: Clustering ───</li>
        <li>
    <a class="dropdown-item" href="../m05-clustering/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-clustering/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-clustering/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li class="dropdown-header">─── M06: Centrality ───</li>
        <li>
    <a class="dropdown-item" href="../m06-centrality/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-centrality/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-centrality/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-advanced-topics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Advanced Topics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-advanced-topics">    
        <li class="dropdown-header">─── M07: Random Walks ───</li>
        <li>
    <a class="dropdown-item" href="../m07-random-walks/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m07-random-walks/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m07-random-walks/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li class="dropdown-header">─── M08: Embedding ───</li>
        <li>
    <a class="dropdown-item" href="../m08-embedding/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-embedding/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-embedding/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-embedding/04-appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
        <li class="dropdown-header">─── M09: Graph Neural Networks ───</li>
        <li>
    <a class="dropdown-item" href="../m09-graph-neural-networks/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m09-graph-neural-networks/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m09-graph-neural-networks/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m09-graph-neural-networks/04-appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Graph embedding with word2vec</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About us</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/discord.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discord</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/minidora-usage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Using Minidora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/how-to-submit-assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to submit assignment</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Introduction</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro/why-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">M01: Euler Path</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-euler_tour/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A Stroll, Seven Bridges, and a Mathematical Revolution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-euler_tour/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Networks in Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-euler_tour/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-euler_tour/04-advanced.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced: Sparse Matrices for Large-Scale Networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">M02: Small World</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-small-world/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-small-world/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient Network Representation and Computing Paths</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-small-world/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises and Assignments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-small-world/04-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix - Brief Introduction to igraph</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">M03: Robustness</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-robustness/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-robustness/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding - Network Robustness Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-robustness/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises and Assignments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-robustness/04-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises and Assignments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">M04: Friendship Paradox</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-node-degree/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-node-degree/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Degree Distributions in Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-node-degree/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">M05: Clustering</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-clustering/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-clustering/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering Algorithms and Implementation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-clustering/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises and Assignments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">M06: Centrality</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-centrality/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-centrality/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-centrality/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">M07: Random Walks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-random-walks/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-random-walks/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-random-walks/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">M08: Embedding</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-embedding/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-embedding/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-embedding/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-embedding/04-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">M09: Graph Neural Networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/04-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Graph embedding with word2vec</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sadamori Kojaku </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 27, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>How can we apply word2vec to graph data? There is a critical challenge: word2vec takes sequence of words as input, while graph data are discrete and unordered. A solution to fill this gap is <em>random walk</em>, which transforms graph data into a sequence of nodes. Once we have a sequence of nodes, we can treat it as a sequence of words and apply word2vec.</p>
<section id="deepwalk" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="deepwalk"><span class="header-section-number">1</span> DeepWalk</h2>
<p><img src="https://dt5vp8kor0orz.cloudfront.net/7c56c256b9fbf06693da47737ac57fae803a5a4f/1-Figure1-1.png" class="img-fluid"></p>
<p>DeepWalk is one of the pioneering works to apply word2vec to graph data {footcite}<code>perozzi2014deepwalk</code>. It views the nodes as words and the nodes random walks on the graph as sentences, and applies word2vec to learn the node embeddings.</p>
<p>More specifically, the method contains the following steps:</p>
<ol type="1">
<li>Sample multiple random walks from the graph.</li>
<li>Treat the random walks as sentences and feed them to word2vev to learn the node embeddings.</li>
</ol>
<p>There are some technical details that we need to be aware of, which we will learn by implementing DeepWalk in the following exercise.</p>
<section id="exercise-01-implement-deepwalk" class="level3">
<h3 class="anchored" data-anchor-id="exercise-01-implement-deepwalk">Exercise 01: Implement DeepWalk</h3>
<p>In this exercise, we implement DeepWalk step by step.</p>
</section>
<section id="step-1-data-preparation" class="level3">
<h3 class="anchored" data-anchor-id="step-1-data-preparation">Step 1: Data preparation</h3>
<p>We will use the karate club network as an example.</p>
<p><strong>Load the data</strong></p>
<div id="1ce4920c" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>:tags: [hide<span class="op">-</span><span class="bu">input</span>]</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> igraph</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> igraph.Graph.Famous(<span class="st">"Zachary"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> g.get_adjacency_sparse()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the community labels to the nodes for visualization</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>g.vs[<span class="st">"label"</span>] <span class="op">=</span> np.unique([d[<span class="dv">1</span>][<span class="st">'club'</span>] <span class="cf">for</span> d <span class="kw">in</span> nx.karate_club_graph().nodes(data<span class="op">=</span><span class="va">True</span>)], return_inverse<span class="op">=</span><span class="va">True</span>)[<span class="dv">1</span>]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette().as_hex()</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>igraph.plot(g, vertex_color<span class="op">=</span>[palette[label] <span class="cf">for</span> label <span class="kw">in</span> g.vs[<span class="st">"label"</span>]], bbox<span class="op">=</span>(<span class="dv">300</span>, <span class="dv">300</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-2-generate-random-walks" class="level3">
<h3 class="anchored" data-anchor-id="step-2-generate-random-walks">Step 2: Generate random walks</h3>
<p>Next, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network. Let us first implement a function to sample random walks from a given network.</p>
<div id="b5730104" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_walk(net, start_node, walk_length):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the walk with the starting node</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    walk <span class="op">=</span> [start_node]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Continue the walk until the desired length is reached</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(walk) <span class="op">&lt;</span> walk_length:</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the current node (the last node in the walk)</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        cur <span class="op">=</span> walk[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the neighbors of the current node</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        cur_nbrs <span class="op">=</span> <span class="bu">list</span>(net[cur].indices)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the current node has neighbors, randomly choose one and add it to the walk</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(cur_nbrs) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>            walk.append(np.random.choice(cur_nbrs))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the current node has no neighbors, terminate the walk</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the generated walk</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> walk</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Generate 10 random walks of length 50 starting from each node.</p>
<div id="d972d15d" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>n_nodes <span class="op">=</span> g.vcount()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>n_walkers_per_node <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>walk_length <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>walks <span class="op">=</span> []</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_walkers_per_node):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        walks.append(random_walk(A, i, walk_length))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-3-train-the-word2vec-model" class="level3">
<h3 class="anchored" data-anchor-id="step-3-train-the-word2vec-model">Step 3: Train the word2vec model</h3>
<p>Then, we feed the random walks to the word2vec model.</p>
<div id="5bc7ba41" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> Word2Vec</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Word2Vec(walks, vector_size<span class="op">=</span><span class="dv">32</span>, window<span class="op">=</span><span class="dv">3</span>, min_count<span class="op">=</span><span class="dv">1</span>, sg<span class="op">=</span><span class="dv">1</span>, hs <span class="op">=</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here,</p>
<ul>
<li><code>vector_size</code> is the dimension of the embedding vectors.</li>
<li><code>window</code> indicates the maximum distance between a word and its context words. For example, in the random walk <code>[0, 1, 2, 3, 4, 5, 6, 7]</code>, the context words of node 2 are <code>[0, 1, 3, 4, 5]</code> when <code>window=3</code>.</li>
<li><code>min_count</code> is the minimum number of times a word must appear in the training data to be included in the vocabulary.</li>
</ul>
<p>Two parameters <code>sg=1</code> and <code>hs=1</code> indicate that we are using the skip-gram model with negative sampling. Let us understand what they mean in detail as follows.</p>
<ul>
<li><p><strong>Skip-gram model</strong>: it trains word2vec by predicting context words given a target word. For example, given the sentence “The quick brown fox jumps over the lazy dog”, in the skip-gram model, given the target word “fox”, the model will try to predict the context words “quick”, “brown”, “jumps”, and “over”. If <code>sg=0</code>, the input and output are swapped: the model will predict the target word from the context words, e.g., given the context words “quick”, “brown”, “jumps”, and “over”, the model will predict the target word “fox”.</p></li>
<li><p><strong>Hierarchical softmax</strong>: To understand hierarchical softmax better, let’s break down how the word2vec model works. The goal of word2vec is to predict context words given a target word. For example, if our target word is <span class="math inline">w_t</span> and our context word is <span class="math inline">w_c</span>, we want to find the probability of <span class="math inline">w_c</span> given <span class="math inline">w_t</span>. This probability is calculated using the softmax function:</p>
<p><span class="math display">
  P(w_c | w_t) = \frac{\exp(\mathbf{v}_{w_c} \cdot \mathbf{v}_{w_t})}{\sum_{w \in V} \exp(\mathbf{v}_w \cdot \mathbf{u}_{w_t})}
</span></p>
<p>Here, <span class="math inline">\mathbf{v}_w</span> and <span class="math inline">\mathbf{u}_w</span> represent the vector for word <span class="math inline">w</span> as context and target respectively, and <span class="math inline">V</span> is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!</p>
<p>Hierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.</p>
<p><img src="https://lh5.googleusercontent.com/proxy/_omrC8G6quTl2SGarwFe57qzbIs-PtGkEA5yODFE5I0Ny2IHGiJwsUhMrcuUqg5o-R2nD9hkgMuZsQJKoCggP29zXtj-Vz-X8BE.png" class="img-fluid"></p></li>
</ul>
<p>By using the skip-gram model with hierarchical softmax, we can efficiently learn high-quality word embeddings even when dealing with large vocabularies.</p>
<p>Now, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the <code>wv</code> attribute. The embedding of node <span class="math inline">i</span> is given by <code>model.wv[i]</code>.</p>
<div id="3e8dc99a" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> []</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    embedding.append(model.wv[i])</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> np.array(embedding)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>embedding</code> is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.</p>
<p><strong>Print the first 3 nodes</strong></p>
<div id="47897386" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>:tags: [hide<span class="op">-</span><span class="bu">input</span>]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>embedding[:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s visualize the node embeddings using UMAP.</p>
<div id="8c4e225f" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>:tags: [hide<span class="op">-</span><span class="bu">input</span>]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bokeh.plotting <span class="im">import</span> figure, show</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bokeh.io <span class="im">import</span> output_notebook</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bokeh.models <span class="im">import</span> ColumnDataSource, HoverTool</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_neighbors<span class="op">=</span><span class="dv">15</span>, metric<span class="op">=</span><span class="st">"cosine"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> reducer.fit_transform(embedding)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>output_notebook()</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the degree of each node</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>degrees <span class="op">=</span> A.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).A1</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> ColumnDataSource(data<span class="op">=</span><span class="bu">dict</span>(</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span>xy[:, <span class="dv">0</span>],</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>xy[:, <span class="dv">1</span>],</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span>np.sqrt(degrees <span class="op">/</span> np.<span class="bu">max</span>(degrees)) <span class="op">*</span> <span class="dv">30</span>,</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    community<span class="op">=</span>[palette[label] <span class="cf">for</span> label <span class="kw">in</span> g.vs[<span class="st">"label"</span>]]</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> figure(title<span class="op">=</span><span class="st">"Node Embeddings from Word2Vec"</span>, x_axis_label<span class="op">=</span><span class="st">"X"</span>, y_axis_label<span class="op">=</span><span class="st">"Y"</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>p.scatter(<span class="st">'x'</span>, <span class="st">'y'</span>, size<span class="op">=</span><span class="st">'size'</span>, source<span class="op">=</span>source, line_color<span class="op">=</span><span class="st">"black"</span>, color<span class="op">=</span><span class="st">"community"</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>show(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-4-clustering" class="level3">
<h3 class="anchored" data-anchor-id="step-4-clustering">Step 4: Clustering</h3>
<p>One of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as <span class="math inline">K</span>-means and Gaussian mixture model. Let’s see what we can get from the node embeddings.</p>
<div id="c8dcc973" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the optimal number of clusters using the silhouette score</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Kmeans_with_silhouette(embedding, n_clusters_range<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">10</span>)):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    silhouette_scores <span class="op">=</span> []</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over a range of cluster numbers from 2 to 9</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n_clusters <span class="kw">in</span> <span class="bu">range</span>(<span class="op">*</span>n_clusters_range):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a KMeans object with the current number of clusters</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>n_clusters)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit the KMeans model to the embedding data</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        kmeans.fit(embedding)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the silhouette score for the current clustering</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> silhouette_score(embedding, kmeans.labels_)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append the number of clusters and its corresponding silhouette score to the list</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        silhouette_scores.append((n_clusters, score))</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the number of clusters that has the highest silhouette score</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    optimal_n_clusters <span class="op">=</span> <span class="bu">max</span>(silhouette_scores, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>])[<span class="dv">0</span>]</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a KMeans object with the optimal number of clusters</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>optimal_n_clusters)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the KMeans model to the embedding data with the optimal number of clusters</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(embedding)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the labels (cluster assignments) for each data point</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> kmeans.labels_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="81d8aa0e" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> Kmeans_with_silhouette(embedding)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>cmap <span class="op">=</span> sns.color_palette().as_hex()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>igraph.plot(g, vertex_color<span class="op">=</span>[cmap[label] <span class="cf">for</span> label <span class="kw">in</span> labels], bbox<span class="op">=</span>(<span class="dv">500</span>, <span class="dv">500</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="node2vec" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="node2vec"><span class="header-section-number">2</span> node2vec</h2>
<p>node2vec is a sibling of DeepWalk proposed by {footcite}<code>grover2016node2vec</code>. Both use word2vec trained on random walks on networks. So, it appears that they are very similar. However, the following two components make them very different.</p>
<ul>
<li><p><strong>Biased random walk</strong>: node2vec uses biased random walks that can move in different directions. The bias walk is parameterized by two parameters, <span class="math inline">p</span> and <span class="math inline">q</span>:</p>
<p><span class="math display">
  P(v_{t+1} = x | v_t = v, v_{t-1} = t) \propto
  \begin{cases}
  \frac{1}{p} &amp; \text{if } d(v,t) = 0 \\
  1 &amp; \text{if } d(v,t) = 1 \\
  \frac{1}{q} &amp; \text{if } d(v,t) = 2 \\
  \end{cases}
  </span></p>
<p>where <span class="math inline">d(v,x)</span> is the shortest path distance between node <span class="math inline">v</span> and <span class="math inline">x</span>. A smaller <span class="math inline">p</span> leads to more biased towards the previous node, <span class="math inline">v_{t-1} = t</span>. A smaller <span class="math inline">q</span> leads to more biased towards the nodes that are further away from the previous node, <span class="math inline">v_{t-1} = t</span>.</p>
<p>By adjusting the parameters <span class="math inline">p</span> and <span class="math inline">q</span>, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).</p>
<ul>
<li><p><strong>Breadth-First Sampling (BFS)</strong>: This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.</p></li>
<li><p><strong>Depth-First Sampling (DFS)</strong>: This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.</p></li>
</ul>
<p><img src="https://www.researchgate.net/publication/354654762/figure/fig3/AS:1069013035655173@1631883977008/A-biased-random-walk-procedure-of-node2vec-B-BFS-and-DFS-search-strategies-from-node-u.png" class="img-fluid"></p>
<p>The embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*nCyF5jFSU5uJVdAPdf-0HA.png" class="img-fluid"></p></li>
<li><p><strong>Negative sampling</strong>: node2vec uses negative sampling, instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to {footcite}<code>kojaku2021neurips</code> and {footcite}<code>dyer2014notes</code> for more details.</p></li>
</ul>
<section id="exercise-02-implement-node2vec" class="level3">
<h3 class="anchored" data-anchor-id="exercise-02-implement-node2vec">Exercise 02: Implement node2vec</h3>
<p>Let’s implement the biased random walk for node2vec</p>
<div id="d65e2b6c" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> node2vec_random_walk(net, start_node, walk_length, p, q):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Sample a random walk starting from start_node.</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the walk with the start_node</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    walk <span class="op">=</span> [start_node]</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Continue the walk until it reaches the desired length</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(walk) <span class="op">&lt;</span> walk_length:</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the current node in the walk</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        cur <span class="op">=</span> walk[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the neighbors of the current node</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        cur_nbrs <span class="op">=</span> <span class="bu">list</span>(net[cur].indices)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the current node has any neighbors</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(cur_nbrs) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the walk has just started, randomly choose the next node from the neighbors</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(walk) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>                walk.append(np.random.choice(cur_nbrs))</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Get the previous node in the walk</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>                prev <span class="op">=</span> walk[<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Use the alias sampling method to choose the next node based on the bias parameters p and q</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>                next_node <span class="op">=</span> alias_sample(net, cur_nbrs, prev, p, q)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Append the chosen next node to the walk</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>                walk.append(next_node)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the current node has no neighbors, terminate the walk</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> walk</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> alias_sample(net, neighbors, prev, p, q):</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a><span class="co">    Helper function to sample the next node in the walk.</span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implement the logic to sample the next node based on the bias parameters p and q</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You can use the formula provided in the instructions to calculate the probabilities</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and then sample the next node accordingly.</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize an empty list to store the unnormalized probabilities for each neighbor</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    unnormalized_probs <span class="op">=</span> []</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over each neighbor of the current node</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> neighbor <span class="kw">in</span> neighbors:</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the neighbor is the same as the previous node in the walk</span></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> neighbor <span class="op">==</span> prev:</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Append the probability 1/p to the unnormalized probabilities list</span></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>            unnormalized_probs.append(<span class="dv">1</span> <span class="op">/</span> p)</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the neighbor is connected to the previous node in the walk</span></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> neighbor <span class="kw">in</span> net[prev].indices:</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Append the probability 1 to the unnormalized probabilities list</span></span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>            unnormalized_probs.append(<span class="dv">1</span>)</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the neighbor is not connected to the previous node in the walk</span></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Append the probability 1/q to the unnormalized probabilities list</span></span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>            unnormalized_probs.append(<span class="dv">1</span> <span class="op">/</span> q)</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the normalization constant by summing all unnormalized probabilities</span></span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>    norm_const <span class="op">=</span> <span class="bu">sum</span>(unnormalized_probs)</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize the probabilities by dividing each unnormalized probability by the normalization constant</span></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>    normalized_probs <span class="op">=</span> [<span class="bu">float</span>(prob) <span class="op">/</span> norm_const <span class="cf">for</span> prob <span class="kw">in</span> unnormalized_probs]</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Randomly choose the next node from the neighbors based on the normalized probabilities</span></span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>    next_node <span class="op">=</span> np.random.choice(neighbors, size<span class="op">=</span><span class="dv">1</span>, p<span class="op">=</span>normalized_probs)[<span class="dv">0</span>]</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the chosen next node</span></span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> next_node</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, let’s set up the word2vec model for node2vec.</p>
<div id="f4f666fd" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>walks <span class="op">=</span> []</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes):</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_walkers_per_node):</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        walks.append(node2vec_random_walk(A, i, walk_length, p, q))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Word2Vec(walks, vector_size<span class="op">=</span><span class="dv">32</span>, window<span class="op">=</span><span class="dv">3</span>, min_count<span class="op">=</span><span class="dv">1</span>, sg<span class="op">=</span><span class="dv">1</span>, hs <span class="op">=</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>where <code>hs=0</code> indicates that we are using negative sampling. Notice that we set <code>sg=1</code> and <code>hs=1</code> instead of <code>sg=1</code> and <code>hs=0</code> in DeepWalk. This is because node2vec uses the skip-gram model with negative sampling.</p>
<p>Now, we extract the node embeddings from the word2vec model.</p>
<div id="a4b0b314" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> []</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    embedding.append(model.wv[i])</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> np.array(embedding)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s visualize the node embeddings from node2vec.</p>
<div id="f101ac76" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>:tags: [hide<span class="op">-</span><span class="bu">input</span>]</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_neighbors<span class="op">=</span><span class="dv">15</span>, metric<span class="op">=</span><span class="st">"cosine"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> reducer.fit_transform(embedding)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>output_notebook()</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the degree of each node</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>degrees <span class="op">=</span> A.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).A1</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> ColumnDataSource(data<span class="op">=</span><span class="bu">dict</span>(</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span>xy[:, <span class="dv">0</span>],</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>xy[:, <span class="dv">1</span>],</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span>np.sqrt(degrees <span class="op">/</span> np.<span class="bu">max</span>(degrees)) <span class="op">*</span> <span class="dv">30</span>,</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    community<span class="op">=</span>[palette[label] <span class="cf">for</span> label <span class="kw">in</span> g.vs[<span class="st">"label"</span>]],</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> [<span class="bu">str</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes)]</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> figure(title<span class="op">=</span><span class="st">"Node Embeddings from Word2Vec"</span>, x_axis_label<span class="op">=</span><span class="st">"X"</span>, y_axis_label<span class="op">=</span><span class="st">"Y"</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>p.scatter(<span class="st">'x'</span>, <span class="st">'y'</span>, size<span class="op">=</span><span class="st">'size'</span>, source<span class="op">=</span>source, line_color<span class="op">=</span><span class="st">"black"</span>, color<span class="op">=</span><span class="st">"community"</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>hover <span class="op">=</span> HoverTool()</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>hover.tooltips <span class="op">=</span> [</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Name"</span>, <span class="st">"@name"</span>),</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Community"</span>, <span class="st">"@community"</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>p.add_tools(hover)</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>show(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The results for clustering are as follows:</p>
<div id="100494d0" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> Kmeans_with_silhouette(embedding)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>cmap <span class="op">=</span> sns.color_palette().as_hex()</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>igraph.plot(g, vertex_color<span class="op">=</span>[cmap[label] <span class="cf">for</span> label <span class="kw">in</span> labels], bbox<span class="op">=</span>(<span class="dv">500</span>, <span class="dv">500</span>), vertex_label<span class="op">=</span>[<span class="st">"</span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span>  d <span class="cf">for</span> d <span class="kw">in</span>  np.arange(n_nodes)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="line" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="line"><span class="header-section-number">3</span> LINE</h2>
<p>LINE {footcite}<code>tang2015line</code> is another pioneering work to learn node embeddings by directly optimizing the graph structure. It is equivalent to node2vec with <span class="math inline">p=1</span>, <span class="math inline">q=1</span>, and window size 1.</p>
<pre class="{footbibliography}"><code></code></pre>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/skojaku\.github\.io\/adv-net-sci\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb16" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Graph embedding with word2vec</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>How can we apply word2vec to graph data? There is a critical challenge: word2vec takes sequence of words as input, while graph data are discrete and unordered. A solution to fill this gap is *random walk*, which transforms graph data into a sequence of nodes. Once we have a sequence of nodes, we can treat it as a sequence of words and apply word2vec.</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="fu">## DeepWalk</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="al">![](https://dt5vp8kor0orz.cloudfront.net/7c56c256b9fbf06693da47737ac57fae803a5a4f/1-Figure1-1.png)</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>DeepWalk is one of the pioneering works to apply word2vec to graph data {footcite}<span class="in">`perozzi2014deepwalk`</span>. It views the nodes as words and the nodes random walks on the graph as sentences, and applies word2vec to learn the node embeddings.</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>More specifically, the method contains the following steps:</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Sample multiple random walks from the graph.</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Treat the random walks as sentences and feed them to word2vev to learn the node embeddings.</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>There are some technical details that we need to be aware of, which we will learn by implementing DeepWalk in the following exercise.</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 01: Implement DeepWalk</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>In this exercise, we implement DeepWalk step by step.</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 1: Data preparation</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>We will use the karate club network as an example.</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>**Load the data**</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>:tags: [hide<span class="op">-</span><span class="bu">input</span>]</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> igraph</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> igraph.Graph.Famous(<span class="st">"Zachary"</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> g.get_adjacency_sparse()</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the community labels to the nodes for visualization</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>g.vs[<span class="st">"label"</span>] <span class="op">=</span> np.unique([d[<span class="dv">1</span>][<span class="st">'club'</span>] <span class="cf">for</span> d <span class="kw">in</span> nx.karate_club_graph().nodes(data<span class="op">=</span><span class="va">True</span>)], return_inverse<span class="op">=</span><span class="va">True</span>)[<span class="dv">1</span>]</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette().as_hex()</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>igraph.plot(g, vertex_color<span class="op">=</span>[palette[label] <span class="cf">for</span> label <span class="kw">in</span> g.vs[<span class="st">"label"</span>]], bbox<span class="op">=</span>(<span class="dv">300</span>, <span class="dv">300</span>))</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 2: Generate random walks</span></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>Next, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network.</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>Let us first implement a function to sample random walks from a given network.</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_walk(net, start_node, walk_length):</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the walk with the starting node</span></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    walk <span class="op">=</span> [start_node]</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Continue the walk until the desired length is reached</span></span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(walk) <span class="op">&lt;</span> walk_length:</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the current node (the last node in the walk)</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>        cur <span class="op">=</span> walk[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the neighbors of the current node</span></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>        cur_nbrs <span class="op">=</span> <span class="bu">list</span>(net[cur].indices)</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the current node has neighbors, randomly choose one and add it to the walk</span></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(cur_nbrs) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>            walk.append(np.random.choice(cur_nbrs))</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the current node has no neighbors, terminate the walk</span></span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the generated walk</span></span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> walk</span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a>Generate 10 random walks of length 50 starting from each node.</span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>n_nodes <span class="op">=</span> g.vcount()</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a>n_walkers_per_node <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>walk_length <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>walks <span class="op">=</span> []</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes):</span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_walkers_per_node):</span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>        walks.append(random_walk(A, i, walk_length))</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 3: Train the word2vec model</span></span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a>Then, we feed the random walks to the word2vec model.</span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> Word2Vec</span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Word2Vec(walks, vector_size<span class="op">=</span><span class="dv">32</span>, window<span class="op">=</span><span class="dv">3</span>, min_count<span class="op">=</span><span class="dv">1</span>, sg<span class="op">=</span><span class="dv">1</span>, hs <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a>Here,</span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`vector_size`</span> is the dimension of the embedding vectors.</span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`window`</span> indicates the maximum distance between a word and its context words. For example, in the random walk <span class="in">`[0, 1, 2, 3, 4, 5, 6, 7]`</span>, the context words of node 2 are <span class="in">`[0, 1, 3, 4, 5]`</span> when <span class="in">`window=3`</span>.</span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`min_count`</span> is the minimum number of times a word must appear in the training data to be included in the vocabulary.</span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a>Two parameters <span class="in">`sg=1`</span> and <span class="in">`hs=1`</span> indicate that we are using the skip-gram model with negative sampling. Let us understand what they mean in detail as follows.</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Skip-gram model**: it trains word2vec by predicting context words given a target word. For example, given the sentence "The quick brown fox jumps over the lazy dog", in the skip-gram model, given the target word "fox", the model will try to predict the context words "quick", "brown", "jumps", and "over". If <span class="in">`sg=0`</span>, the input and output are swapped: the model will predict the target word from the context words, e.g., given the context words "quick", "brown", "jumps", and "over", the model will predict the target word "fox".</span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Hierarchical softmax**: To understand hierarchical softmax better, let's break down how the word2vec model works. The goal of word2vec is to predict context words given a target word. For example, if our target word is $w_t$ and our context word is $w_c$, we want to find the probability of $w_c$ given $w_t$. This probability is calculated using the softmax function:</span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a>    $$</span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a>    P(w_c | w_t) = \frac{\exp(\mathbf{v}_{w_c} \cdot \mathbf{v}_{w_t})}{\sum_{w \in V} \exp(\mathbf{v}_w \cdot \mathbf{u}_{w_t})}</span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a>   $$</span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a>    Here, $\mathbf{v}_w$ and $\mathbf{u}_w$ represent the vector for word $w$ as context and target respectively, and $V$ is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!</span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a>    Hierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.</span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a>    <span class="al">![](https://lh5.googleusercontent.com/proxy/_omrC8G6quTl2SGarwFe57qzbIs-PtGkEA5yODFE5I0Ny2IHGiJwsUhMrcuUqg5o-R2nD9hkgMuZsQJKoCggP29zXtj-Vz-X8BE)</span></span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a>By using the skip-gram model with hierarchical softmax, we can efficiently learn high-quality word embeddings even when dealing with large vocabularies.</span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-130"><a href="#cb16-130" aria-hidden="true" tabindex="-1"></a>Now, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the <span class="in">`wv`</span> attribute. The embedding of node $i$ is given by <span class="in">`model.wv[i]`</span>.</span>
<span id="cb16-131"><a href="#cb16-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-134"><a href="#cb16-134" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-135"><a href="#cb16-135" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> []</span>
<span id="cb16-136"><a href="#cb16-136" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes):</span>
<span id="cb16-137"><a href="#cb16-137" aria-hidden="true" tabindex="-1"></a>    embedding.append(model.wv[i])</span>
<span id="cb16-138"><a href="#cb16-138" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> np.array(embedding)</span>
<span id="cb16-139"><a href="#cb16-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-140"><a href="#cb16-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-141"><a href="#cb16-141" aria-hidden="true" tabindex="-1"></a><span class="in">`embedding`</span> is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.</span>
<span id="cb16-142"><a href="#cb16-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-143"><a href="#cb16-143" aria-hidden="true" tabindex="-1"></a>**Print the first 3 nodes**</span>
<span id="cb16-146"><a href="#cb16-146" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-147"><a href="#cb16-147" aria-hidden="true" tabindex="-1"></a>:tags: [hide<span class="op">-</span><span class="bu">input</span>]</span>
<span id="cb16-148"><a href="#cb16-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-149"><a href="#cb16-149" aria-hidden="true" tabindex="-1"></a>embedding[:<span class="dv">3</span>]</span>
<span id="cb16-150"><a href="#cb16-150" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-151"><a href="#cb16-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-152"><a href="#cb16-152" aria-hidden="true" tabindex="-1"></a>Let's visualize the node embeddings using UMAP.</span>
<span id="cb16-153"><a href="#cb16-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-156"><a href="#cb16-156" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-157"><a href="#cb16-157" aria-hidden="true" tabindex="-1"></a>:tags: [hide<span class="op">-</span><span class="bu">input</span>]</span>
<span id="cb16-158"><a href="#cb16-158" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb16-159"><a href="#cb16-159" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bokeh.plotting <span class="im">import</span> figure, show</span>
<span id="cb16-160"><a href="#cb16-160" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bokeh.io <span class="im">import</span> output_notebook</span>
<span id="cb16-161"><a href="#cb16-161" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bokeh.models <span class="im">import</span> ColumnDataSource, HoverTool</span>
<span id="cb16-162"><a href="#cb16-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-163"><a href="#cb16-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-164"><a href="#cb16-164" aria-hidden="true" tabindex="-1"></a>reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_neighbors<span class="op">=</span><span class="dv">15</span>, metric<span class="op">=</span><span class="st">"cosine"</span>)</span>
<span id="cb16-165"><a href="#cb16-165" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> reducer.fit_transform(embedding)</span>
<span id="cb16-166"><a href="#cb16-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-167"><a href="#cb16-167" aria-hidden="true" tabindex="-1"></a>output_notebook()</span>
<span id="cb16-168"><a href="#cb16-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-169"><a href="#cb16-169" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the degree of each node</span></span>
<span id="cb16-170"><a href="#cb16-170" aria-hidden="true" tabindex="-1"></a>degrees <span class="op">=</span> A.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).A1</span>
<span id="cb16-171"><a href="#cb16-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-172"><a href="#cb16-172" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> ColumnDataSource(data<span class="op">=</span><span class="bu">dict</span>(</span>
<span id="cb16-173"><a href="#cb16-173" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span>xy[:, <span class="dv">0</span>],</span>
<span id="cb16-174"><a href="#cb16-174" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>xy[:, <span class="dv">1</span>],</span>
<span id="cb16-175"><a href="#cb16-175" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span>np.sqrt(degrees <span class="op">/</span> np.<span class="bu">max</span>(degrees)) <span class="op">*</span> <span class="dv">30</span>,</span>
<span id="cb16-176"><a href="#cb16-176" aria-hidden="true" tabindex="-1"></a>    community<span class="op">=</span>[palette[label] <span class="cf">for</span> label <span class="kw">in</span> g.vs[<span class="st">"label"</span>]]</span>
<span id="cb16-177"><a href="#cb16-177" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb16-178"><a href="#cb16-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-179"><a href="#cb16-179" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> figure(title<span class="op">=</span><span class="st">"Node Embeddings from Word2Vec"</span>, x_axis_label<span class="op">=</span><span class="st">"X"</span>, y_axis_label<span class="op">=</span><span class="st">"Y"</span>)</span>
<span id="cb16-180"><a href="#cb16-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-181"><a href="#cb16-181" aria-hidden="true" tabindex="-1"></a>p.scatter(<span class="st">'x'</span>, <span class="st">'y'</span>, size<span class="op">=</span><span class="st">'size'</span>, source<span class="op">=</span>source, line_color<span class="op">=</span><span class="st">"black"</span>, color<span class="op">=</span><span class="st">"community"</span>)</span>
<span id="cb16-182"><a href="#cb16-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-183"><a href="#cb16-183" aria-hidden="true" tabindex="-1"></a>show(p)</span>
<span id="cb16-184"><a href="#cb16-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-185"><a href="#cb16-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-186"><a href="#cb16-186" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 4: Clustering</span></span>
<span id="cb16-187"><a href="#cb16-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-188"><a href="#cb16-188" aria-hidden="true" tabindex="-1"></a>One of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as $K$-means and Gaussian mixture model. Let's see what we can get from the node embeddings.</span>
<span id="cb16-189"><a href="#cb16-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-190"><a href="#cb16-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-193"><a href="#cb16-193" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-194"><a href="#cb16-194" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb16-195"><a href="#cb16-195" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb16-196"><a href="#cb16-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-197"><a href="#cb16-197" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the optimal number of clusters using the silhouette score</span></span>
<span id="cb16-198"><a href="#cb16-198" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Kmeans_with_silhouette(embedding, n_clusters_range<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">10</span>)):</span>
<span id="cb16-199"><a href="#cb16-199" aria-hidden="true" tabindex="-1"></a>    silhouette_scores <span class="op">=</span> []</span>
<span id="cb16-200"><a href="#cb16-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-201"><a href="#cb16-201" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over a range of cluster numbers from 2 to 9</span></span>
<span id="cb16-202"><a href="#cb16-202" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n_clusters <span class="kw">in</span> <span class="bu">range</span>(<span class="op">*</span>n_clusters_range):</span>
<span id="cb16-203"><a href="#cb16-203" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a KMeans object with the current number of clusters</span></span>
<span id="cb16-204"><a href="#cb16-204" aria-hidden="true" tabindex="-1"></a>        kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>n_clusters)</span>
<span id="cb16-205"><a href="#cb16-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-206"><a href="#cb16-206" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit the KMeans model to the embedding data</span></span>
<span id="cb16-207"><a href="#cb16-207" aria-hidden="true" tabindex="-1"></a>        kmeans.fit(embedding)</span>
<span id="cb16-208"><a href="#cb16-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-209"><a href="#cb16-209" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the silhouette score for the current clustering</span></span>
<span id="cb16-210"><a href="#cb16-210" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> silhouette_score(embedding, kmeans.labels_)</span>
<span id="cb16-211"><a href="#cb16-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-212"><a href="#cb16-212" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append the number of clusters and its corresponding silhouette score to the list</span></span>
<span id="cb16-213"><a href="#cb16-213" aria-hidden="true" tabindex="-1"></a>        silhouette_scores.append((n_clusters, score))</span>
<span id="cb16-214"><a href="#cb16-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-215"><a href="#cb16-215" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the number of clusters that has the highest silhouette score</span></span>
<span id="cb16-216"><a href="#cb16-216" aria-hidden="true" tabindex="-1"></a>    optimal_n_clusters <span class="op">=</span> <span class="bu">max</span>(silhouette_scores, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>])[<span class="dv">0</span>]</span>
<span id="cb16-217"><a href="#cb16-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-218"><a href="#cb16-218" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a KMeans object with the optimal number of clusters</span></span>
<span id="cb16-219"><a href="#cb16-219" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>optimal_n_clusters)</span>
<span id="cb16-220"><a href="#cb16-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-221"><a href="#cb16-221" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the KMeans model to the embedding data with the optimal number of clusters</span></span>
<span id="cb16-222"><a href="#cb16-222" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(embedding)</span>
<span id="cb16-223"><a href="#cb16-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-224"><a href="#cb16-224" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the labels (cluster assignments) for each data point</span></span>
<span id="cb16-225"><a href="#cb16-225" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> kmeans.labels_</span>
<span id="cb16-226"><a href="#cb16-226" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-227"><a href="#cb16-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-230"><a href="#cb16-230" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-231"><a href="#cb16-231" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb16-232"><a href="#cb16-232" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> Kmeans_with_silhouette(embedding)</span>
<span id="cb16-233"><a href="#cb16-233" aria-hidden="true" tabindex="-1"></a>cmap <span class="op">=</span> sns.color_palette().as_hex()</span>
<span id="cb16-234"><a href="#cb16-234" aria-hidden="true" tabindex="-1"></a>igraph.plot(g, vertex_color<span class="op">=</span>[cmap[label] <span class="cf">for</span> label <span class="kw">in</span> labels], bbox<span class="op">=</span>(<span class="dv">500</span>, <span class="dv">500</span>))</span>
<span id="cb16-235"><a href="#cb16-235" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-236"><a href="#cb16-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-237"><a href="#cb16-237" aria-hidden="true" tabindex="-1"></a><span class="fu">## node2vec</span></span>
<span id="cb16-238"><a href="#cb16-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-239"><a href="#cb16-239" aria-hidden="true" tabindex="-1"></a>node2vec is a sibling of DeepWalk proposed by {footcite}<span class="in">`grover2016node2vec`</span>. Both use word2vec trained on random walks on networks. So, it appears that they are very similar. However, the following two components make them very different.</span>
<span id="cb16-240"><a href="#cb16-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-241"><a href="#cb16-241" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Biased random walk**: node2vec uses biased random walks that can move in different directions. The bias walk is parameterized by two parameters, $p$ and $q$:</span>
<span id="cb16-242"><a href="#cb16-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-243"><a href="#cb16-243" aria-hidden="true" tabindex="-1"></a>    $$</span>
<span id="cb16-244"><a href="#cb16-244" aria-hidden="true" tabindex="-1"></a>    P(v_{t+1} = x | v_t = v, v_{t-1} = t) \propto</span>
<span id="cb16-245"><a href="#cb16-245" aria-hidden="true" tabindex="-1"></a>    \begin{cases}</span>
<span id="cb16-246"><a href="#cb16-246" aria-hidden="true" tabindex="-1"></a>    \frac{1}{p} &amp; \text{if } d(v,t) = 0 <span class="sc">\\</span></span>
<span id="cb16-247"><a href="#cb16-247" aria-hidden="true" tabindex="-1"></a>    1 &amp; \text{if } d(v,t) = 1 <span class="sc">\\</span></span>
<span id="cb16-248"><a href="#cb16-248" aria-hidden="true" tabindex="-1"></a>    \frac{1}{q} &amp; \text{if } d(v,t) = 2 <span class="sc">\\</span></span>
<span id="cb16-249"><a href="#cb16-249" aria-hidden="true" tabindex="-1"></a>    \end{cases}</span>
<span id="cb16-250"><a href="#cb16-250" aria-hidden="true" tabindex="-1"></a>    $$</span>
<span id="cb16-251"><a href="#cb16-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-252"><a href="#cb16-252" aria-hidden="true" tabindex="-1"></a>    where $d(v,x)$ is the shortest path distance between node $v$ and $x$. A smaller $p$ leads to more biased towards the previous node, $v_{t-1} = t$. A smaller $q$ leads to more biased towards the nodes that are further away from the previous node, $v_{t-1} = t$.</span>
<span id="cb16-253"><a href="#cb16-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-254"><a href="#cb16-254" aria-hidden="true" tabindex="-1"></a>    By adjusting the parameters $p$ and $q$, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).</span>
<span id="cb16-255"><a href="#cb16-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-256"><a href="#cb16-256" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>**Breadth-First Sampling (BFS)**: This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.</span>
<span id="cb16-257"><a href="#cb16-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-258"><a href="#cb16-258" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>**Depth-First Sampling (DFS)**: This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.</span>
<span id="cb16-259"><a href="#cb16-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-260"><a href="#cb16-260" aria-hidden="true" tabindex="-1"></a>    <span class="al">![](https://www.researchgate.net/publication/354654762/figure/fig3/AS:1069013035655173@1631883977008/A-biased-random-walk-procedure-of-node2vec-B-BFS-and-DFS-search-strategies-from-node-u.png)</span></span>
<span id="cb16-261"><a href="#cb16-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-262"><a href="#cb16-262" aria-hidden="true" tabindex="-1"></a><span class="in">    The embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.</span></span>
<span id="cb16-263"><a href="#cb16-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-264"><a href="#cb16-264" aria-hidden="true" tabindex="-1"></a><span class="in">    ![](https://miro.medium.com/v2/resize:fit:1138/format:webp/1*nCyF5jFSU5uJVdAPdf-0HA.png)</span></span>
<span id="cb16-265"><a href="#cb16-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-266"><a href="#cb16-266" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Negative sampling**: node2vec uses negative sampling, instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to {footcite}<span class="in">`kojaku2021neurips`</span> and {footcite}<span class="in">`dyer2014notes`</span> for more details.</span>
<span id="cb16-267"><a href="#cb16-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-268"><a href="#cb16-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-269"><a href="#cb16-269" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 02: Implement node2vec</span></span>
<span id="cb16-270"><a href="#cb16-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-271"><a href="#cb16-271" aria-hidden="true" tabindex="-1"></a>Let's implement the biased random walk for node2vec</span>
<span id="cb16-274"><a href="#cb16-274" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-275"><a href="#cb16-275" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> node2vec_random_walk(net, start_node, walk_length, p, q):</span>
<span id="cb16-276"><a href="#cb16-276" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-277"><a href="#cb16-277" aria-hidden="true" tabindex="-1"></a><span class="co">    Sample a random walk starting from start_node.</span></span>
<span id="cb16-278"><a href="#cb16-278" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-279"><a href="#cb16-279" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the walk with the start_node</span></span>
<span id="cb16-280"><a href="#cb16-280" aria-hidden="true" tabindex="-1"></a>    walk <span class="op">=</span> [start_node]</span>
<span id="cb16-281"><a href="#cb16-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-282"><a href="#cb16-282" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Continue the walk until it reaches the desired length</span></span>
<span id="cb16-283"><a href="#cb16-283" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(walk) <span class="op">&lt;</span> walk_length:</span>
<span id="cb16-284"><a href="#cb16-284" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the current node in the walk</span></span>
<span id="cb16-285"><a href="#cb16-285" aria-hidden="true" tabindex="-1"></a>        cur <span class="op">=</span> walk[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb16-286"><a href="#cb16-286" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the neighbors of the current node</span></span>
<span id="cb16-287"><a href="#cb16-287" aria-hidden="true" tabindex="-1"></a>        cur_nbrs <span class="op">=</span> <span class="bu">list</span>(net[cur].indices)</span>
<span id="cb16-288"><a href="#cb16-288" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the current node has any neighbors</span></span>
<span id="cb16-289"><a href="#cb16-289" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(cur_nbrs) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb16-290"><a href="#cb16-290" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the walk has just started, randomly choose the next node from the neighbors</span></span>
<span id="cb16-291"><a href="#cb16-291" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(walk) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb16-292"><a href="#cb16-292" aria-hidden="true" tabindex="-1"></a>                walk.append(np.random.choice(cur_nbrs))</span>
<span id="cb16-293"><a href="#cb16-293" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb16-294"><a href="#cb16-294" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Get the previous node in the walk</span></span>
<span id="cb16-295"><a href="#cb16-295" aria-hidden="true" tabindex="-1"></a>                prev <span class="op">=</span> walk[<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb16-296"><a href="#cb16-296" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Use the alias sampling method to choose the next node based on the bias parameters p and q</span></span>
<span id="cb16-297"><a href="#cb16-297" aria-hidden="true" tabindex="-1"></a>                next_node <span class="op">=</span> alias_sample(net, cur_nbrs, prev, p, q)</span>
<span id="cb16-298"><a href="#cb16-298" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Append the chosen next node to the walk</span></span>
<span id="cb16-299"><a href="#cb16-299" aria-hidden="true" tabindex="-1"></a>                walk.append(next_node)</span>
<span id="cb16-300"><a href="#cb16-300" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb16-301"><a href="#cb16-301" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the current node has no neighbors, terminate the walk</span></span>
<span id="cb16-302"><a href="#cb16-302" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb16-303"><a href="#cb16-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-304"><a href="#cb16-304" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> walk</span>
<span id="cb16-305"><a href="#cb16-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-306"><a href="#cb16-306" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> alias_sample(net, neighbors, prev, p, q):</span>
<span id="cb16-307"><a href="#cb16-307" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-308"><a href="#cb16-308" aria-hidden="true" tabindex="-1"></a><span class="co">    Helper function to sample the next node in the walk.</span></span>
<span id="cb16-309"><a href="#cb16-309" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-310"><a href="#cb16-310" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implement the logic to sample the next node based on the bias parameters p and q</span></span>
<span id="cb16-311"><a href="#cb16-311" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You can use the formula provided in the instructions to calculate the probabilities</span></span>
<span id="cb16-312"><a href="#cb16-312" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and then sample the next node accordingly.</span></span>
<span id="cb16-313"><a href="#cb16-313" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize an empty list to store the unnormalized probabilities for each neighbor</span></span>
<span id="cb16-314"><a href="#cb16-314" aria-hidden="true" tabindex="-1"></a>    unnormalized_probs <span class="op">=</span> []</span>
<span id="cb16-315"><a href="#cb16-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-316"><a href="#cb16-316" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over each neighbor of the current node</span></span>
<span id="cb16-317"><a href="#cb16-317" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> neighbor <span class="kw">in</span> neighbors:</span>
<span id="cb16-318"><a href="#cb16-318" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the neighbor is the same as the previous node in the walk</span></span>
<span id="cb16-319"><a href="#cb16-319" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> neighbor <span class="op">==</span> prev:</span>
<span id="cb16-320"><a href="#cb16-320" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Append the probability 1/p to the unnormalized probabilities list</span></span>
<span id="cb16-321"><a href="#cb16-321" aria-hidden="true" tabindex="-1"></a>            unnormalized_probs.append(<span class="dv">1</span> <span class="op">/</span> p)</span>
<span id="cb16-322"><a href="#cb16-322" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the neighbor is connected to the previous node in the walk</span></span>
<span id="cb16-323"><a href="#cb16-323" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> neighbor <span class="kw">in</span> net[prev].indices:</span>
<span id="cb16-324"><a href="#cb16-324" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Append the probability 1 to the unnormalized probabilities list</span></span>
<span id="cb16-325"><a href="#cb16-325" aria-hidden="true" tabindex="-1"></a>            unnormalized_probs.append(<span class="dv">1</span>)</span>
<span id="cb16-326"><a href="#cb16-326" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the neighbor is not connected to the previous node in the walk</span></span>
<span id="cb16-327"><a href="#cb16-327" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb16-328"><a href="#cb16-328" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Append the probability 1/q to the unnormalized probabilities list</span></span>
<span id="cb16-329"><a href="#cb16-329" aria-hidden="true" tabindex="-1"></a>            unnormalized_probs.append(<span class="dv">1</span> <span class="op">/</span> q)</span>
<span id="cb16-330"><a href="#cb16-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-331"><a href="#cb16-331" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the normalization constant by summing all unnormalized probabilities</span></span>
<span id="cb16-332"><a href="#cb16-332" aria-hidden="true" tabindex="-1"></a>    norm_const <span class="op">=</span> <span class="bu">sum</span>(unnormalized_probs)</span>
<span id="cb16-333"><a href="#cb16-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-334"><a href="#cb16-334" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize the probabilities by dividing each unnormalized probability by the normalization constant</span></span>
<span id="cb16-335"><a href="#cb16-335" aria-hidden="true" tabindex="-1"></a>    normalized_probs <span class="op">=</span> [<span class="bu">float</span>(prob) <span class="op">/</span> norm_const <span class="cf">for</span> prob <span class="kw">in</span> unnormalized_probs]</span>
<span id="cb16-336"><a href="#cb16-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-337"><a href="#cb16-337" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Randomly choose the next node from the neighbors based on the normalized probabilities</span></span>
<span id="cb16-338"><a href="#cb16-338" aria-hidden="true" tabindex="-1"></a>    next_node <span class="op">=</span> np.random.choice(neighbors, size<span class="op">=</span><span class="dv">1</span>, p<span class="op">=</span>normalized_probs)[<span class="dv">0</span>]</span>
<span id="cb16-339"><a href="#cb16-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-340"><a href="#cb16-340" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the chosen next node</span></span>
<span id="cb16-341"><a href="#cb16-341" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> next_node</span>
<span id="cb16-342"><a href="#cb16-342" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-343"><a href="#cb16-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-344"><a href="#cb16-344" aria-hidden="true" tabindex="-1"></a>Now, let's set up the word2vec model for node2vec.</span>
<span id="cb16-345"><a href="#cb16-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-348"><a href="#cb16-348" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-349"><a href="#cb16-349" aria-hidden="true" tabindex="-1"></a>walks <span class="op">=</span> []</span>
<span id="cb16-350"><a href="#cb16-350" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb16-351"><a href="#cb16-351" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb16-352"><a href="#cb16-352" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes):</span>
<span id="cb16-353"><a href="#cb16-353" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_walkers_per_node):</span>
<span id="cb16-354"><a href="#cb16-354" aria-hidden="true" tabindex="-1"></a>        walks.append(node2vec_random_walk(A, i, walk_length, p, q))</span>
<span id="cb16-355"><a href="#cb16-355" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Word2Vec(walks, vector_size<span class="op">=</span><span class="dv">32</span>, window<span class="op">=</span><span class="dv">3</span>, min_count<span class="op">=</span><span class="dv">1</span>, sg<span class="op">=</span><span class="dv">1</span>, hs <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-356"><a href="#cb16-356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-357"><a href="#cb16-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-358"><a href="#cb16-358" aria-hidden="true" tabindex="-1"></a>where <span class="in">`hs=0`</span> indicates that we are using negative sampling.</span>
<span id="cb16-359"><a href="#cb16-359" aria-hidden="true" tabindex="-1"></a>Notice that we set <span class="in">`sg=1`</span> and <span class="in">`hs=1`</span> instead of <span class="in">`sg=1`</span> and <span class="in">`hs=0`</span> in DeepWalk. This is because node2vec uses the skip-gram model with negative sampling.</span>
<span id="cb16-360"><a href="#cb16-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-361"><a href="#cb16-361" aria-hidden="true" tabindex="-1"></a>Now, we extract the node embeddings from the word2vec model.</span>
<span id="cb16-362"><a href="#cb16-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-365"><a href="#cb16-365" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-366"><a href="#cb16-366" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> []</span>
<span id="cb16-367"><a href="#cb16-367" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes):</span>
<span id="cb16-368"><a href="#cb16-368" aria-hidden="true" tabindex="-1"></a>    embedding.append(model.wv[i])</span>
<span id="cb16-369"><a href="#cb16-369" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> np.array(embedding)</span>
<span id="cb16-370"><a href="#cb16-370" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-371"><a href="#cb16-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-372"><a href="#cb16-372" aria-hidden="true" tabindex="-1"></a>Let's visualize the node embeddings from node2vec.</span>
<span id="cb16-373"><a href="#cb16-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-376"><a href="#cb16-376" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-377"><a href="#cb16-377" aria-hidden="true" tabindex="-1"></a>:tags: [hide<span class="op">-</span><span class="bu">input</span>]</span>
<span id="cb16-378"><a href="#cb16-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-379"><a href="#cb16-379" aria-hidden="true" tabindex="-1"></a>reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_neighbors<span class="op">=</span><span class="dv">15</span>, metric<span class="op">=</span><span class="st">"cosine"</span>)</span>
<span id="cb16-380"><a href="#cb16-380" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> reducer.fit_transform(embedding)</span>
<span id="cb16-381"><a href="#cb16-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-382"><a href="#cb16-382" aria-hidden="true" tabindex="-1"></a>output_notebook()</span>
<span id="cb16-383"><a href="#cb16-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-384"><a href="#cb16-384" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the degree of each node</span></span>
<span id="cb16-385"><a href="#cb16-385" aria-hidden="true" tabindex="-1"></a>degrees <span class="op">=</span> A.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).A1</span>
<span id="cb16-386"><a href="#cb16-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-387"><a href="#cb16-387" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> ColumnDataSource(data<span class="op">=</span><span class="bu">dict</span>(</span>
<span id="cb16-388"><a href="#cb16-388" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span>xy[:, <span class="dv">0</span>],</span>
<span id="cb16-389"><a href="#cb16-389" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>xy[:, <span class="dv">1</span>],</span>
<span id="cb16-390"><a href="#cb16-390" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span>np.sqrt(degrees <span class="op">/</span> np.<span class="bu">max</span>(degrees)) <span class="op">*</span> <span class="dv">30</span>,</span>
<span id="cb16-391"><a href="#cb16-391" aria-hidden="true" tabindex="-1"></a>    community<span class="op">=</span>[palette[label] <span class="cf">for</span> label <span class="kw">in</span> g.vs[<span class="st">"label"</span>]],</span>
<span id="cb16-392"><a href="#cb16-392" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> [<span class="bu">str</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes)]</span>
<span id="cb16-393"><a href="#cb16-393" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb16-394"><a href="#cb16-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-395"><a href="#cb16-395" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> figure(title<span class="op">=</span><span class="st">"Node Embeddings from Word2Vec"</span>, x_axis_label<span class="op">=</span><span class="st">"X"</span>, y_axis_label<span class="op">=</span><span class="st">"Y"</span>)</span>
<span id="cb16-396"><a href="#cb16-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-397"><a href="#cb16-397" aria-hidden="true" tabindex="-1"></a>p.scatter(<span class="st">'x'</span>, <span class="st">'y'</span>, size<span class="op">=</span><span class="st">'size'</span>, source<span class="op">=</span>source, line_color<span class="op">=</span><span class="st">"black"</span>, color<span class="op">=</span><span class="st">"community"</span>)</span>
<span id="cb16-398"><a href="#cb16-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-399"><a href="#cb16-399" aria-hidden="true" tabindex="-1"></a>hover <span class="op">=</span> HoverTool()</span>
<span id="cb16-400"><a href="#cb16-400" aria-hidden="true" tabindex="-1"></a>hover.tooltips <span class="op">=</span> [</span>
<span id="cb16-401"><a href="#cb16-401" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Name"</span>, <span class="st">"@name"</span>),</span>
<span id="cb16-402"><a href="#cb16-402" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Community"</span>, <span class="st">"@community"</span>)</span>
<span id="cb16-403"><a href="#cb16-403" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb16-404"><a href="#cb16-404" aria-hidden="true" tabindex="-1"></a>p.add_tools(hover)</span>
<span id="cb16-405"><a href="#cb16-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-406"><a href="#cb16-406" aria-hidden="true" tabindex="-1"></a>show(p)</span>
<span id="cb16-407"><a href="#cb16-407" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-408"><a href="#cb16-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-409"><a href="#cb16-409" aria-hidden="true" tabindex="-1"></a>The results for clustering are as follows:</span>
<span id="cb16-410"><a href="#cb16-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-413"><a href="#cb16-413" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-414"><a href="#cb16-414" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb16-415"><a href="#cb16-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-416"><a href="#cb16-416" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> Kmeans_with_silhouette(embedding)</span>
<span id="cb16-417"><a href="#cb16-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-418"><a href="#cb16-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-419"><a href="#cb16-419" aria-hidden="true" tabindex="-1"></a>cmap <span class="op">=</span> sns.color_palette().as_hex()</span>
<span id="cb16-420"><a href="#cb16-420" aria-hidden="true" tabindex="-1"></a>igraph.plot(g, vertex_color<span class="op">=</span>[cmap[label] <span class="cf">for</span> label <span class="kw">in</span> labels], bbox<span class="op">=</span>(<span class="dv">500</span>, <span class="dv">500</span>), vertex_label<span class="op">=</span>[<span class="st">"</span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span>  d <span class="cf">for</span> d <span class="kw">in</span>  np.arange(n_nodes)])</span>
<span id="cb16-421"><a href="#cb16-421" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-422"><a href="#cb16-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-423"><a href="#cb16-423" aria-hidden="true" tabindex="-1"></a><span class="fu">## LINE</span></span>
<span id="cb16-424"><a href="#cb16-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-425"><a href="#cb16-425" aria-hidden="true" tabindex="-1"></a>LINE {footcite}<span class="in">`tang2015line`</span> is another pioneering work to learn node embeddings by directly optimizing the graph structure.</span>
<span id="cb16-426"><a href="#cb16-426" aria-hidden="true" tabindex="-1"></a>It is equivalent to node2vec with $p=1$, $q=1$, and window size 1.</span>
<span id="cb16-427"><a href="#cb16-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-428"><a href="#cb16-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-431"><a href="#cb16-431" aria-hidden="true" tabindex="-1"></a><span class="in">```{footbibliography}</span></span>
<span id="cb16-432"><a href="#cb16-432" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024, Sadamori Kojaku</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions"><ul><li><a href="https://github.com/skojaku/adv-net-sci/edit/main/m08-embedding/graph-embedding-w-word2vec.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/skojaku/adv-net-sci/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/skojaku/adv-net-sci">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>