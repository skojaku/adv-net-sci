{
  "hash": "92384915d9af096cca8c41a08e31e222",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Centrality Concepts\"\njupyter: advnetsci\nexecute:\n    enabled: true\n---\n\n\n## What is centrality?\n\nHave you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone's talking about right now?\nThese questions are all about finding out what's important in a network of people, ideas, or things. In network science, we call this *centrality*.\n\nCentrality or *importance* is a question of how important a node is in a network.\nBut the notion of *importance* is somewhat vague.\nIn what sense we say a node is important?\n\n::: {.callout-note title=\"Exercise\"}\n\nTry out the pen and paper exercise below to get a sense of centrality: [School exercises](./pen-and-paper/exercise.pdf)\n\n:::\n\n![](../figs/centrality.jpg){width=\"50%\" fig-align=\"center\"}\n\n## Distance-based centrality\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Milliarium_Aureum_op_het_Forum_Romanum_te_Rome_Columna_Miliaria_in_Foro_Romano_%28titel_op_object%29_Antieke_monumenten_%28serietitel%29_Antiquae_Urbis_Splendor_%28serietitel%29%2C_RP-P-2016-345-28-1.jpg/1546px-thumbnail.jpg?20191217151048\" alt=\"Roma Foro Romano Miliarium Aureum\" width=\"80%\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n\nLet's talk about an ancient Roman monument called the *Milliarium Aureum*, also known as the *Golden Milestone*.\nIt was the starting point for measuring distances on all major roads in the Roman Empire.\nEmperor Augustus built it when Rome changed from a republic to an empire.\nThe monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire.\nPerhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define *centrality* in networks.\n\nThis family of centrality measures is based on shortest path distances between nodes. They consider a node important if it has short distances to other nodes or if it lies on many shortest paths.\n\n\n### Closeness centrality\n\n**Closeness centrality** measures how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\n::: {#cell-fig-closeness .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![Closeness Centrality Visualization. Nodes with higher centrality (brighter colors) are closer to all other nodes on average.](01-concepts_files/figure-html/fig-closeness-output-1.png){#fig-closeness}\n:::\n:::\n\n\nwhere $N$ is the number of nodes in the network. The numerator, $N - 1$, is the normalization factor to make the centrality have a maximum value of 1.\n\n::: {.column-margin}\n\nQuestion: What would be a graph where a node has the maximum closeness centrality of value 1?\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Star_network_7.svg/1920px-Star_network_7.svg.png\" alt=\"Star graph S7\" width=\"50%\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n\n:::\n:::\n\n### Harmonic centrality\n\nThe closeness centrality falls short for disconnected networks. This is because the shortest distance between two nodes in different connected components is infinite, making the closeness centrality of all nodes in the disconnected components zero.\n\nA remedy is **Harmonic centrality** which adjusts closeness centrality [@beauchamp1965improved] which is defined as\n\n$$\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n$$\n\n::: {#cell-fig-harmonic .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![Harmonic Centrality Visualization. A variant of closeness that works well with disconnected components.](01-concepts_files/figure-html/fig-harmonic-output-1.png){#fig-harmonic}\n:::\n:::\n\n\nThe distance between two nodes in different connected components has zero contribution to the harmonic centrality, making it a useful measure for disconnected networks.\n\n### Eccentricity centrality\n\nWhile the closeness and harmonic centralities focus on \"average\" distance, eccentricity centrality focuses on the farthest distance from a node to any other node. It is defined as\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n::: {#cell-fig-eccentricity .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![Eccentricity Centrality Visualization. High-centrality nodes (brighter colors) have the smallest maximum distance to any other node.](01-concepts_files/figure-html/fig-eccentricity-output-1.png){#fig-eccentricity}\n:::\n:::\n\n\n::: {.column-margin}\n::: {.callout-note title=\"When is eccentricity centrality useful?\"}\nUnlike closeness or harmonic centrality, eccentricity centrality optimizes for the worst-case scenario, making it ideal when equity and maximum response times are critical. For example, placing emergency services or facilities to ensure no location is too far from help, designing robust communication or transportation networks that remain connected even if parts fail, and positioning distribution centers to guarantee reasonable delivery times to the most remote customers.\n\n:::\n:::\n\n### Betweenness centrality\n\n**Betweenness centrality** considers that a node is important if it lies on many shortest paths between other nodes.\n\n$$\nc_i = \\sum_{j < k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n$$\n\n::: {#cell-fig-betweenness .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![Betweenness Centrality Visualization. Brighter nodes lie on a larger number of shortest paths between other nodes.](01-concepts_files/figure-html/fig-betweenness-output-1.png){#fig-betweenness}\n:::\n:::\n\n\nwhere $\\sigma_{jk}$ is the number of shortest paths between nodes $j$ and $k$, and $\\sigma_{jk}(i)$ is the number of shortest paths between nodes $j$ and $k$ that pass through node $i$.\n\n## Walk-based centrality\n\n\"A man is known by the company he keeps\" is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire.\nIt suggests that a person's character is reflected by the people this person is friends with.\nThis idea can be applied to define the *centrality* of a node in a network.\n\nThis family of centrality measures considers that a node is important if it is connected to other important nodes, or if it receives many \"walks\" or \"votes\" from other nodes in the network. These measures often use recursive definitions and are computed using linear algebra techniques.\n\n::: {.column-margin}\n**Aesop** was an ancient Greek storyteller believed to have lived around the 6th century BCE. He is famous for his fablesâ€”short stories that use animals and everyday situations to teach moral lessons.\n\n\n![The Wolf and the Kid. Taken from [Aesop's Fables from Heritage History](https://www.heritage-history.com/index.php?c=read&author=winter&book=aesop&story=wolf)](https://www.heritage-history.com/books/winter/aesop/zpage010.gif)\n:::\n\n\n\n### Eigenvector centrality\n\n**Eigenvector centrality** considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\n$$\n\\lambda c_i = \\sum_{j} A_{ij} c_j\n$$\n\nwhere $\\lambda$ is a constant. It suggests that the centrality of a node ($c_i$), when multiplied by a constant $\\lambda$, is the sum of the centralities of its neighbors ($A_{ij} c_j$; note that $A_{ij}=1$ if $j$ is a neighbor, and otherwise $A_{ij}=0$).\nUsing vector notation, we can rewrite the equation as\n\n$$\n\\lambda\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} =\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n$$\n\nor equivalently,\n\n$$\n\\lambda \\mathbf{c} = \\mathbf{A} \\mathbf{c}\n$$\n\nOkay, but how do we solve this? Well, this is the standard eigenvector equation! The solution $\\mathbf{c}$ is an eigenvector of the adjacency matrix $\\mathbf{A}$, and $\\lambda$ is its corresponding eigenvalue. But here's the tricky part - a matrix can have multiple eigenvectors. So which one should we choose?\n\nLet's think about what we want again. We want our centrality measure to be positive. It wouldn't make much sense to have negative importance! So, we're looking for an eigenvector where all the elements are positive. And a good news is that there's a special eigenvector that fits the bill perfectly.\nThe Perron-Frobenius theorem guarantees that the eigenvector associated with the largest eigenvalue always has all positive elements.\n\n::: {#cell-fig-eigenvector .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Eigenvector Centrality Visualization. Brighter nodes are connected to other highly central nodes.](01-concepts_files/figure-html/fig-eigenvector-output-1.png){#fig-eigenvector}\n:::\n:::\n\n\n::: {.column-margin}\n**Perron-Frobenius theorem**: For a regular matrix $\\mathbf{A}$ with and non-negative entries ($A_{ij} \\geq 0$), there exists a unique largest eigenvalue $r > 0$ such that its corresponding eigenvector $\\mathbf{v}$ has all positive entries: $v_i > 0$ for all $i$.\n:::\n\nThus, the eigenvector centrality is the eigenvector of the adjacency matrix associated with the largest eigenvalue.\n\n### Hyperlink-Induced Topic Search (HITS) centrality\n\n**HITS centrality** extends eigenvector centrality to directed networks. It introduces two notions of importance: *hub* and *authority*. A node is an important hub if it points to many important *authorities*. A node is an important authority if it is pointed by many important *hubs*.\n\nLet's put on a math hat to concretely define the hub and authority centralities.\nWe introduce two vectors, $x_i$ and $y_i$, to denote the hub and authority centralities of node $i$, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\n$$\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n$$\n\nOr equivalently,\n\n$$\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n$$\n\nSubstituting $\\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}$ into the first equation and similar for $\\mathbf{x}$, we get\n\n$$\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n$$\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of $\\mathbf{A}^T \\mathbf{A}$ and $\\mathbf{A} \\mathbf{A}^T$ for $\\mathbf{x}$ and $\\mathbf{y}$, respectively.\n\n::: {.column-margin}\n\nIf the original network is *undirected*, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n::: {.callout collapse=\"true\" title=\"Click to see the answer\"}\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of $\\mathbf{A} \\mathbf{A}^T$. Now, let us consider the eigenvector equation for the adjacency matrix $\\mathbf{A}$.\n\n$$\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n$$\n\nBy multiplying $\\mathbf{A}$ on the both sides, we get\n\n$$\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n$$\n\nwhere we used the fact that $\\mathbf{A}$ is symmetric. It suggests that the eigenvector of $\\mathbf{A}^\\top \\mathbf{A}$ is the same as that of $\\mathbf{A}$, and that the eigenvalue of $\\mathbf{A}^\\top \\mathbf{A}$ is the square of that of $\\mathbf{A}$.\nThus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n:::\n:::\n\n### Katz centrality\n\n**Katz centrality** addresses a limitation of eigenvector centrality, which tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. The solution is to add a little bit of score to all nodes.\n\n$$\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n$$\n\nThe equation can be solved by\n\n$$\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n$$\n\nwhere $\\mathbf{1}$ is the vector of ones. By rewriting the equation, we get\n\n$$\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n$$\n\nBy taking the inverse of $\\mathbf{I} - \\lambda \\mathbf{A}$, we get\n\n$\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n$$\n\n::: {#cell-fig-katz .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![Katz Centrality Visualization. A measure of influence that accounts for both direct and indirect connections.](01-concepts_files/figure-html/fig-katz-output-1.png){#fig-katz}\n:::\n:::\n\n\n### PageRank\n\n**PageRank** is the celebrated idea behind Google Search and can be seen as a cousin of Katz centrality.\n\n$$\nc_i = \\underbrace{(1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j}}_{\\text{Random walk from neighbors}} + \\underbrace{\\beta \\cdot \\frac{1}{N}}_{\\text{teleportation}}\n$$\n\n::: {#cell-fig-pagerank .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![PageRank Centrality Visualization. Brighter nodes have a higher probability of being visited by a random walker.](01-concepts_files/figure-html/fig-pagerank-output-1.png){#fig-pagerank}\n:::\n:::\n\n\nwhere $d^{\\text{out}}_j$ is the out-degree of node $j$ (the number of edges pointing out from node $j$).\nThe term $c_j/d^{\\text{out}}_j$ represents that the score of node $j$ is divided by the number of nodes to which node $j$ points. In the Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers.\n\n\n::: {.column-margin}\nSee the following video for more details on PageRank:\n\n<iframe width=\"220\" height=\"158\" src=\"https://www.youtube.com/embed/v7n7wZhHJj8?si=qVfcEBCc-DEiiZ9w\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n:::\n\n\n### Personalized PageRank\n\n**Personalized PageRank** extends the standard PageRank algorithm by contextualizing the importance of nodes from a specific perspective in a network.\nTo understand this, imagine you have a network of movies connected by similarity (sharing genres, actors, directors, etc.). Standard PageRank would rank movies based on their overall centrality in this similarity network. But suppose a student just watched \"The Matrix\" and wants to find similar movies. Personalized PageRank would start random walks from \"The Matrix\" and measure which movies are most reachable from it, effectively finding movies that are similar to \"The Matrix\" rather than just globally popular movies.\n\nPut it more formarmally, suppose a random walker starting from a node $\\ell$. The walker moves to the neighboring nodes just like in PageRank, but with a probability $\\beta$, it goes back to the starting node $\\ell$ at every step.\n\nThus,\n$$\nc_i = \\underbrace{(1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j}}_{\\text{Random walk from neighbors}} + \\underbrace{\\beta \\cdot p_{\\ell}}_{\\text{Teleport to the starting node}}\n$$\n\nwhere $p_{\\ell}$ is a one-hot vector that is 1 at the $\\ell$-th position and 0 elsewhere.\nThe first term represents\nThis equation can be solved numerically by taking the power iteration like we do for the PageRank. Alternatively, we can solve it by solving the linear system of equations.\n\n::: {.column-margin}\n\nPersonalized PageRank can also be interpreted as the sum of probabilities of reaching each node from a focal set of nodes, where the probability decreases exponentially with distance.\nLet $p_{\\ell i}^{(k)}$ be the probability of reaching node $i$ from node $\\ell$ in $k$ steps. Then,\nthe personalized PageRank is given by\n\n$$\nc_i = \\sum_{k=0}^{\\infty} \\beta (1-\\beta)^k p_{\\ell i}^{(k)}\n$$\n\nwhere ther term $\\beta (1-\\beta)^k$ is the probability of reaching a node that is exactly $k$ steps away.\nThink of it as a \"weight\" that decreases with distance. As $i$ gets further away from the starting node $\\ell$.\nIn other words, centrality of node $i$ tends to be higher if it is closer to the starting node $\\ell$.\n\n:::\n\n::: {.column-margin}\n\nPageRank and Personalized PageRank have been one of the most influential ideas in network science.\nThere are many variants and extensions of these ideas. Here are some of my favorites:\n\n1. [@lambiotte2012ranking] proposes a teleportation method that corrects the bias coming from the degree of the starting node of PageRank.\n\n2. [@wu2017second] proposes a second-order random walk-based proximity measure that considers the importance of a node in the context of a ranking problem.\n\n3. [@tong2006fast] proposes a random walk with restart that considers the importance of a node in the context of a ranking problem.\n\n\n:::\n\n\n## Degree-based centrality\n\nThe simplest approach to measuring centrality is to count the connections of each node. This gives us *degree centrality*, which considers a node important if it has many direct connections.\n**Degree centrality** is just the count of the number of edges connected to a node (i.e., the number of neighbors, or *degree* in network science terminology). The most important node is thus the one with the highest degree.\n\n$$\nc_i = d_i = \\sum_{j} A_{ij}\n$$\n\n::: {#cell-fig-degree .cell execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![Degree Centrality Visualization. The simplest measure: brighter nodes have more direct connections.](01-concepts_files/figure-html/fig-degree-output-1.png){#fig-degree}\n:::\n:::\n\n\nwhere $A_{ij}$ is the adjacency matrix of the network, and $d_i$ is the degree of node $i$.\n\nDegree centrality is a no brainer measure of centrality. Interestingly, degree centralities are often strongly correlated with other centrality measures, such as the eigenvector centrality, pagerank, along with distance-based centralities (e.g., closeness centrality). Of course, degree centrality is a crude importance measure as it only focuses on the direct connections of a node and ignores who these connections are to.\n\nto.\n\n",
    "supporting": [
      "01-concepts_files"
    ],
    "filters": [],
    "includes": {}
  }
}