{
  "hash": "8b7ec1f3485c9dce2d6a8df3c5009ced",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Coding - Random Walks\"\njupyter: advnetsci\nexecute:\n    enabled: true\n---\n\n# Random Walks: Implementation and Applications\n\n## Introduction: From Theory to Practice\n\nIn the previous section, we learned the theoretical foundations of random walks. Now we'll implement these concepts in Python and explore their practical applications for network analysis.\n\nRecall that a random walk is a process where we:\n1. Start at a node $i$\n2. Randomly choose an edge to traverse to a neighbor node $j$\n3. Repeat until we've taken $T$ steps\n\nLet's see how this simple process can reveal deep insights about network structure.\n\n## Implementing Random Walks in Python\n\n### Setting Up: Simple Graph\n\nWe'll start by implementing random walks on a simple graph of five nodes.\n\n::: {#bdfa076a .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](02-coding_files/figure-html/cell-2-output-1.svg){}\n:::\n:::\n\n\n### Computing Transition Probabilities\n\nA random walk is characterized by the transition probabilities between nodes:\n\n$$P_{ij} = \\frac{A_{ij}}{k_i}$$\n\nLet's compute and visualize the transition probability matrix $\\mathbf{P}$:\n\n::: {#b6e7e023 .cell execution_count=2}\n``` {.python .cell-code}\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] > 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i->ij\", A, 1 / k)\n```\n:::\n\n\n::: {#6f3f957a .cell execution_count=3}\n``` {.python .cell-code}\nprint(\"Transition probability matrix:\\n\", P)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTransition probability matrix:\n [[0.         0.33333333 0.33333333 0.33333333 0.        ]\n [0.5        0.         0.         0.5        0.        ]\n [0.33333333 0.         0.         0.33333333 0.33333333]\n [0.25       0.25       0.25       0.         0.25      ]\n [0.         0.         0.5        0.5        0.        ]]\n```\n:::\n:::\n\n\n::: {#17814821 .cell execution_count=4}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](02-coding_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\nEach row and column of $\\mathbf{P}$ corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\n\n### Simulating Random Walk Steps\n\nNow let's simulate a random walk step by step. We represent the position of the walker using a vector $\\mathbf{x}$ with five elements, where we mark the current node with `1` and others as `0`:\n\n::: {#37fa1647 .cell execution_count=5}\n``` {.python .cell-code}\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInitial position of the walker:\n [1 0 0 0 0]\n```\n:::\n:::\n\n\nThis vector representation lets us compute transition probabilities to other nodes:\n\n$$\\mathbf{x} \\mathbf{P}$$\n\n::: {#bed6a4aa .cell execution_count=6}\n``` {.python .cell-code}\nprobs = x @ P\nprint(\"Transition probabilities from current position:\\n\", probs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTransition probabilities from current position:\n [0.         0.33333333 0.33333333 0.33333333 0.        ]\n```\n:::\n:::\n\n\nWe can then draw the next node based on these probabilities:\n\n::: {#746efcc1 .cell execution_count=7}\n``` {.python .cell-code}\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position after one step:\\n\", x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPosition after one step:\n [0 1 0 0 0]\n```\n:::\n:::\n\n\n### Exercise 01\n\nWrite the following function to simulate the random walk for a given number of steps and return the $x$ for each step:\n\n```python\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n    n_nodes = A.shape[0]\n\n    # Initialize position\n    x = np.zeros(n_nodes)\n    x[0] = 1  # Start at node 0\n\n    positions = [x.copy()]\n\n    for step in range(n_steps):\n        probs = x @ P\n        next_node = ... # fill in the missing code\n        x[:] = 0\n        x[next_node] = 1\n        positions.append(x.copy())\n\n    return np.array(positions)\n\n# Test the function\nwalk_positions = random_walk(A, 10)\nprint(\"Walker positions over 10 steps:\")\nprint(walk_positions)\n```\n\n## Expected Behavior of Random Walks\n\n### Computing Expected Positions\n\nWhat is the expected position of the walker after multiple steps? For the first step from initial position $\\mathbf{x}(0)$:\n\n$$\\mathbb{E}[\\mathbf{x}(1)] = \\mathbf{x}(0) \\mathbf{P}$$\n\n::: {#ac2c5f13 .cell execution_count=8}\n``` {.python .cell-code}\nx_0 = np.array([1, 0, 0, 0, 0])\nx_1 = x_0 @ P\nprint(\"Expected position after one step:\\n\", x_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nExpected position after one step:\n [0.         0.33333333 0.33333333 0.33333333 0.        ]\n```\n:::\n:::\n\n\nFor the second step:\n\n$$\\mathbb{E}[\\mathbf{x}(2)] = \\mathbf{x}(0) \\mathbf{P}^2$$\n\n::: {#9ff32402 .cell execution_count=9}\n``` {.python .cell-code}\nx_2 = x_1 @ P\nprint(\"Expected position after two steps:\\n\", x_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nExpected position after two steps:\n [0.36111111 0.08333333 0.08333333 0.27777778 0.19444444]\n```\n:::\n:::\n\n\nIn general, the expected position at time $t$ is:\n\n$$\\mathbb{E}[\\mathbf{x}(t)] = \\mathbf{x}(0) \\mathbf{P}^t$$\n\n### Exercise 02\n\nWrite a function to compute the expected position of the walker at time $t$:\n\n```python\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The expected position at time t.\n    \"\"\"\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n\n    # Compute P^t\n    P_t = ... # fill in the missing code\n\n    return x_0 @ P_t\n\n# Test the function\nx_0 = np.array([1, 0, 0, 0, 0])\nfor t in [1, 2, 5, 10]:\n    x_t = expected_position(A, x_0, t)\n    print(f\"Expected position at time {t}: {x_t}\")\n```\n\n### Exercise 03\n\nPlot each element of $\\mathbf{x}(t)$ as a function of $t$ for $t=0,1,2,\\ldots, 100$. Try different initial positions and compare the results!\n\n::: {#791f6e94 .cell execution_count=10}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_convergence(A, x_0, max_t=100):\n    \"\"\"Plot the convergence to stationary distribution.\"\"\"\n\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n    n_nodes = A.shape[0]\n\n    # Compute expected positions over time\n    positions = []\n    x_t = x_0.copy()\n    positions.append(x_t.copy())\n\n    for t in range(max_t):\n        x_t = x_t @ P\n        positions.append(x_t.copy())\n\n    positions = np.array(positions)\n\n    # Plot\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    for i in range(n_nodes):\n        ax.plot(range(max_t + 1), positions[:, i], label=f\"Node {i}\", linewidth=2)\n\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Probability\")\n    ax.set_title(\"Random Walk Convergence to Stationary Distribution\")\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    plt.show()\n\n# Test with different starting positions\nstarting_positions = [\n    [1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 0, 0, 1]\n]\n\nfor i, x_0 in enumerate(starting_positions):\n    print(f\"\\nStarting from node {np.argmax(x_0)}:\")\n    plot_convergence(A, np.array(x_0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nStarting from node 0:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](02-coding_files/figure-html/cell-11-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nStarting from node 1:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](02-coding_files/figure-html/cell-11-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nStarting from node 4:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](02-coding_files/figure-html/cell-11-output-6.png){}\n:::\n:::\n\n\n## Practical Demonstration with Real Networks\n\nLet's demonstrate random walks on a more complex network structure.\n\n::: {#9a094d51 .cell execution_count=11}\n``` {.python .cell-code}\nimport igraph as ig\nimport numpy as np\n\n# Create a network with two communities\nedge_list = []\nfor i in range(5):\n    for j in range(i+1, 5):\n        edge_list.append((i, j))\n        edge_list.append((i+5, j+5))\nedge_list.append((0, 6))\n\ng = ig.Graph(edge_list)\nig.plot(g, vertex_size=20, vertex_label=np.arange(g.vcount()))\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n![](02-coding_files/figure-html/cell-12-output-1.svg){}\n:::\n:::\n\n\n### Computing Stationary Distribution\n\nThe transition probability matrix $\\mathbf{P}$ is:\n\n::: {#7387230a .cell execution_count=12}\n``` {.python .cell-code}\nimport scipy.sparse as sparse\n\nA = g.get_adjacency_sparse()\ndeg = np.array(A.sum(axis=1)).flatten()\nDinv = sparse.diags(1/deg)\nP = Dinv @ A\n```\n:::\n\n\nLet's compute the stationary distribution using the power method:\n\n::: {#0f1550d6 .cell execution_count=13}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.zeros(g.vcount())\nx[1] = 1 # Start from node 1\nT = 100\nxt = []\nfor t in range(T):\n    x = x.reshape(1, -1) @ P\n    xt.append(x)\n\nxt = np.vstack(xt) # Stack the results vertically\n\nfig, ax = plt.subplots(figsize=(10, 6))\npalette = sns.color_palette().as_hex()\nfor i in range(g.vcount()):\n    sns.lineplot(x=range(T), y=xt[:, i], label=f\"Node {i}\", ax=ax, color=palette[i % len(palette)])\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Probability\")\nax.set_title(\"Stationary distribution of a random walk\")\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](02-coding_files/figure-html/cell-14-output-1.png){}\n:::\n:::\n\n\nWe observe three key features:\n1. The distribution oscillates with decaying amplitude before converging\n2. Nodes of the same degree converge to the same stationary probability\n3. Nodes with higher degree have higher stationary probability\n\nLet's verify this by comparing with the theoretical stationary distribution:\n\n::: {#3a5fe0db .cell execution_count=14}\n``` {.python .cell-code}\nimport pandas as pd\n\nn_edges = np.sum(deg) / 2\nexpected_stationary_dist = deg / (2 * n_edges)\n\npd.DataFrame({\n    \"Expected stationary distribution\": expected_stationary_dist,\n    \"Observed stationary distribution\": xt[-1].flatten()\n}).style.format(\"{:.4f}\").set_caption(\"Comparison of Expected and Observed Stationary Distributions\").background_gradient(cmap='cividis', axis=None)\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<style type=\"text/css\">\n#T_2fb03_row0_col0, #T_2fb03_row0_col1, #T_2fb03_row6_col0 {\n  background-color: #fee838;\n  color: #000000;\n}\n#T_2fb03_row1_col0, #T_2fb03_row2_col0, #T_2fb03_row3_col0, #T_2fb03_row4_col0, #T_2fb03_row5_col0, #T_2fb03_row5_col1, #T_2fb03_row7_col0, #T_2fb03_row7_col1, #T_2fb03_row8_col0, #T_2fb03_row8_col1, #T_2fb03_row9_col0, #T_2fb03_row9_col1 {\n  background-color: #00224e;\n  color: #f1f1f1;\n}\n#T_2fb03_row1_col1, #T_2fb03_row2_col1, #T_2fb03_row3_col1, #T_2fb03_row4_col1 {\n  background-color: #00234f;\n  color: #f1f1f1;\n}\n#T_2fb03_row6_col1 {\n  background-color: #fee636;\n  color: #000000;\n}\n</style>\n<table id=\"T_2fb03\">\n  <caption>Comparison of Expected and Observed Stationary Distributions</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_2fb03_level0_col0\" class=\"col_heading level0 col0\" >Expected stationary distribution</th>\n      <th id=\"T_2fb03_level0_col1\" class=\"col_heading level0 col1\" >Observed stationary distribution</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_2fb03_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_2fb03_row0_col0\" class=\"data row0 col0\" >0.1190</td>\n      <td id=\"T_2fb03_row0_col1\" class=\"data row0 col1\" >0.1191</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_2fb03_row1_col0\" class=\"data row1 col0\" >0.0952</td>\n      <td id=\"T_2fb03_row1_col1\" class=\"data row1 col1\" >0.0953</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_2fb03_row2_col0\" class=\"data row2 col0\" >0.0952</td>\n      <td id=\"T_2fb03_row2_col1\" class=\"data row2 col1\" >0.0953</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_2fb03_row3_col0\" class=\"data row3 col0\" >0.0952</td>\n      <td id=\"T_2fb03_row3_col1\" class=\"data row3 col1\" >0.0953</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_2fb03_row4_col0\" class=\"data row4 col0\" >0.0952</td>\n      <td id=\"T_2fb03_row4_col1\" class=\"data row4 col1\" >0.0953</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_2fb03_row5_col0\" class=\"data row5 col0\" >0.0952</td>\n      <td id=\"T_2fb03_row5_col1\" class=\"data row5 col1\" >0.0952</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_2fb03_row6_col0\" class=\"data row6 col0\" >0.1190</td>\n      <td id=\"T_2fb03_row6_col1\" class=\"data row6 col1\" >0.1190</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_2fb03_row7_col0\" class=\"data row7 col0\" >0.0952</td>\n      <td id=\"T_2fb03_row7_col1\" class=\"data row7 col1\" >0.0952</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_2fb03_row8_col0\" class=\"data row8 col0\" >0.0952</td>\n      <td id=\"T_2fb03_row8_col1\" class=\"data row8 col1\" >0.0952</td>\n    </tr>\n    <tr>\n      <th id=\"T_2fb03_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_2fb03_row9_col0\" class=\"data row9 col0\" >0.0952</td>\n      <td id=\"T_2fb03_row9_col1\" class=\"data row9 col1\" >0.0952</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n## Community Structure Detection\n\nRandom walks can capture community structure. Let's explore this with a ring of cliques:\n\n::: {#51cd0fb8 .cell execution_count=15}\n``` {.python .cell-code}\nimport networkx as nx\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nn_cliques = 3\nn_nodes_per_clique = 5\n\nG = nx.ring_of_cliques(n_cliques, n_nodes_per_clique)\ng = igraph.Graph().Adjacency(nx.to_numpy_array(G).tolist()).as_undirected()\nmembership = np.repeat(np.arange(n_cliques), n_nodes_per_clique)\n\ncolor_map = [sns.color_palette()[i] for i in membership]\nigraph.plot(g, vertex_size=20, vertex_color=color_map)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n![](02-coding_files/figure-html/cell-16-output-1.svg){}\n:::\n:::\n\n\n### Visualizing Random Walk Dynamics\n\nLet's compute the expected position over time and visualize how the walker explores communities:\n\n::: {#c19304fa .cell execution_count=16}\n``` {.python .cell-code}\nfrom scipy import sparse\n\n# Get the adjacency matrix and degree\nA = g.get_adjacency_sparse()\nk = np.array(g.degree())\n\n# Compute the transition matrix efficiently using scipy.sparse\nP = sparse.diags(1 / k) @ A\n```\n:::\n\n\n::: {#1234f313 .cell execution_count=17}\n``` {.python .cell-code}\n# Compute the expected position from node 2 over 300 steps\nx_t = np.zeros(g.vcount())\nx_t[2] = 1\nx_list = [x_t]\nfor t in range(300):\n    x_t = x_t @ P\n    x_list.append(x_t)\nx_list = np.array(x_list)\n```\n:::\n\n\n::: {#24a69237 .cell execution_count=18}\n``` {.python .cell-code}\n# Plot the network at different time steps\ncmap = sns.color_palette(\"viridis\", as_cmap=True)\n\nsns.set_style('white')\nsns.set(font_scale=1.2)\nsns.set_style('ticks')\n\nfig, axes = plt.subplots(figsize=(15,10), ncols = 3, nrows = 2)\n\nt_list = [0, 1, 3, 5, 10, 299]\nfor i, t in enumerate(t_list):\n    igraph.plot(g, vertex_size=20, vertex_color=[cmap(x_list[t][j] / np.max(x_list[t])) for j in range(g.vcount())], target = axes[i//3][i%3])\n    axes[i//3][i%3].set_title(f\"$t$ = {t}\", fontsize = 25)\n```\n\n::: {.cell-output .cell-output-display}\n![](02-coding_files/figure-html/cell-19-output-1.png){}\n:::\n:::\n\n\nThe color intensity represents the probability of the walker being at each node. Notice how:\n- Initially, the walker is concentrated at the starting node\n- It gradually diffuses within its community\n- Only later does it spread to other communities\n- Eventually, it reaches the stationary distribution\n\nThis temporal behavior reveals the community structure!\n\n## Mixing Time and Spectral Analysis\n\n### Computing Eigenvalues and Mixing Time\n\nLet's demonstrate the spectral analysis of random walks:\n\n::: {#e4ba3241 .cell execution_count=19}\n``` {.python .cell-code}\n# Using the two-clique network from before\nA_norm = g.get_adjacency_sparse()\ndeg = np.array(A_norm.sum(axis=1)).flatten()\n\n# Normalized adjacency matrix\nDinv_sqrt = sparse.diags(1.0/np.sqrt(deg))\nA_norm = Dinv_sqrt @ A_norm @ Dinv_sqrt\n```\n:::\n\n\n::: {#a65652e9 .cell execution_count=20}\n``` {.python .cell-code}\n# Compute eigenvalues and eigenvectors\nevals, evecs = np.linalg.eigh(A_norm.toarray())\n```\n:::\n\n\n::: {#f7e6a35b .cell execution_count=21}\n``` {.python .cell-code}\n# Display eigenvalues\npd.DataFrame({\n    \"Eigenvalue\": evals\n}).T.style.background_gradient(cmap='cividis', axis = 1).set_caption(\"Eigenvalues of the normalized adjacency matrix\")\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<style type=\"text/css\">\n#T_dac7b_row0_col0 {\n  background-color: #00224e;\n  color: #f1f1f1;\n}\n#T_dac7b_row0_col1, #T_dac7b_row0_col2 {\n  background-color: #002758;\n  color: #f1f1f1;\n}\n#T_dac7b_row0_col3, #T_dac7b_row0_col4, #T_dac7b_row0_col5, #T_dac7b_row0_col6, #T_dac7b_row0_col7, #T_dac7b_row0_col8 {\n  background-color: #0f3570;\n  color: #f1f1f1;\n}\n#T_dac7b_row0_col9 {\n  background-color: #39486c;\n  color: #f1f1f1;\n}\n#T_dac7b_row0_col10, #T_dac7b_row0_col11 {\n  background-color: #46516c;\n  color: #f1f1f1;\n}\n#T_dac7b_row0_col12, #T_dac7b_row0_col13 {\n  background-color: #ebd44b;\n  color: #000000;\n}\n#T_dac7b_row0_col14 {\n  background-color: #fee838;\n  color: #000000;\n}\n</style>\n<table id=\"T_dac7b\">\n  <caption>Eigenvalues of the normalized adjacency matrix</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_dac7b_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n      <th id=\"T_dac7b_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n      <th id=\"T_dac7b_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n      <th id=\"T_dac7b_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n      <th id=\"T_dac7b_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n      <th id=\"T_dac7b_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n      <th id=\"T_dac7b_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n      <th id=\"T_dac7b_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n      <th id=\"T_dac7b_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n      <th id=\"T_dac7b_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n      <th id=\"T_dac7b_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n      <th id=\"T_dac7b_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n      <th id=\"T_dac7b_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n      <th id=\"T_dac7b_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n      <th id=\"T_dac7b_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_dac7b_level0_row0\" class=\"row_heading level0 row0\" >Eigenvalue</th>\n      <td id=\"T_dac7b_row0_col0\" class=\"data row0 col0\" >-0.400000</td>\n      <td id=\"T_dac7b_row0_col1\" class=\"data row0 col1\" >-0.362289</td>\n      <td id=\"T_dac7b_row0_col2\" class=\"data row0 col2\" >-0.362289</td>\n      <td id=\"T_dac7b_row0_col3\" class=\"data row0 col3\" >-0.250000</td>\n      <td id=\"T_dac7b_row0_col4\" class=\"data row0 col4\" >-0.250000</td>\n      <td id=\"T_dac7b_row0_col5\" class=\"data row0 col5\" >-0.250000</td>\n      <td id=\"T_dac7b_row0_col6\" class=\"data row0 col6\" >-0.250000</td>\n      <td id=\"T_dac7b_row0_col7\" class=\"data row0 col7\" >-0.250000</td>\n      <td id=\"T_dac7b_row0_col8\" class=\"data row0 col8\" >-0.250000</td>\n      <td id=\"T_dac7b_row0_col9\" class=\"data row0 col9\" >-0.100000</td>\n      <td id=\"T_dac7b_row0_col10\" class=\"data row0 col10\" >-0.030903</td>\n      <td id=\"T_dac7b_row0_col11\" class=\"data row0 col11\" >-0.030903</td>\n      <td id=\"T_dac7b_row0_col12\" class=\"data row0 col12\" >0.893192</td>\n      <td id=\"T_dac7b_row0_col13\" class=\"data row0 col13\" >0.893192</td>\n      <td id=\"T_dac7b_row0_col14\" class=\"data row0 col14\" >1.000000</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\nThe largest eigenvalue is always 1 for a normalized adjacency matrix. The associated eigenvector gives the stationary distribution.\n\n### Relaxation Time\n\n::: {#30e367bf .cell execution_count=22}\n``` {.python .cell-code}\nlambda_2 = -np.sort(-evals)[1]  # Second largest eigenvalue\ntau = 1 / (1 - lambda_2)  # Relaxation time\nprint(f\"The second largest eigenvalue is {lambda_2:.4f}\")\nprint(f\"The relaxation time of the random walk is {tau:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe second largest eigenvalue is 0.8932\nThe relaxation time of the random walk is 9.3626\n```\n:::\n:::\n\n\n### Verifying Spectral Decomposition\n\nLet's verify we can compute multi-step transitions using eigenvalues:\n\n::: {#b5ded83e .cell execution_count=23}\n``` {.python .cell-code}\nt = 5\nx_0 = np.zeros(g.vcount())\nx_0[0] = 1\n\n# Method 1: Using eigenvalues and eigenvectors\nQ_L = np.diag(1.0/np.sqrt(deg)) @ evecs\nQ_R = np.diag(np.sqrt(deg)) @ evecs\nx_t_spectral = x_0 @ Q_L @ np.diag(evals**t) @ Q_R.T\n\n# Method 2: Using power iteration\nP_matrix = sparse.diags(1/deg) @ g.get_adjacency_sparse()\nx_t_power = x_0.copy()\nfor i in range(t):\n    x_t_power = x_t_power @ P_matrix\n\npd.DataFrame({\n    \"Spectral method\": x_t_spectral.flatten(),\n    \"Power iteration\": x_t_power.flatten()\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Comparison of Spectral and Power Iteration Methods\")\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<style type=\"text/css\">\n#T_5f7c1_row0_col0, #T_5f7c1_row0_col1 {\n  background-color: #fee636;\n  color: #000000;\n}\n#T_5f7c1_row1_col0, #T_5f7c1_row1_col1 {\n  background-color: #fee838;\n  color: #000000;\n}\n#T_5f7c1_row2_col0, #T_5f7c1_row2_col1, #T_5f7c1_row3_col0, #T_5f7c1_row3_col1, #T_5f7c1_row4_col0, #T_5f7c1_row4_col1 {\n  background-color: #e4ce53;\n  color: #000000;\n}\n#T_5f7c1_row5_col0, #T_5f7c1_row5_col1, #T_5f7c1_row10_col0, #T_5f7c1_row10_col1 {\n  background-color: #34456c;\n  color: #f1f1f1;\n}\n#T_5f7c1_row6_col0, #T_5f7c1_row6_col1 {\n  background-color: #002e6a;\n  color: #f1f1f1;\n}\n#T_5f7c1_row7_col0, #T_5f7c1_row7_col1, #T_5f7c1_row8_col0, #T_5f7c1_row8_col1, #T_5f7c1_row9_col0, #T_5f7c1_row9_col1 {\n  background-color: #00224e;\n  color: #f1f1f1;\n}\n#T_5f7c1_row11_col0, #T_5f7c1_row11_col1 {\n  background-color: #686a71;\n  color: #f1f1f1;\n}\n#T_5f7c1_row12_col0, #T_5f7c1_row12_col1, #T_5f7c1_row13_col0, #T_5f7c1_row13_col1, #T_5f7c1_row14_col0, #T_5f7c1_row14_col1 {\n  background-color: #273e6e;\n  color: #f1f1f1;\n}\n</style>\n<table id=\"T_5f7c1\">\n  <caption>Comparison of Spectral and Power Iteration Methods</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_5f7c1_level0_col0\" class=\"col_heading level0 col0\" >Spectral method</th>\n      <th id=\"T_5f7c1_level0_col1\" class=\"col_heading level0 col1\" >Power iteration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_5f7c1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_5f7c1_row0_col0\" class=\"data row0 col0\" >0.138150</td>\n      <td id=\"T_5f7c1_row0_col1\" class=\"data row0 col1\" >0.138150</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_5f7c1_row1_col0\" class=\"data row1 col0\" >0.138670</td>\n      <td id=\"T_5f7c1_row1_col1\" class=\"data row1 col1\" >0.138670</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_5f7c1_row2_col0\" class=\"data row2 col0\" >0.126020</td>\n      <td id=\"T_5f7c1_row2_col1\" class=\"data row2 col1\" >0.126020</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_5f7c1_row3_col0\" class=\"data row3 col0\" >0.126020</td>\n      <td id=\"T_5f7c1_row3_col1\" class=\"data row3 col1\" >0.126020</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_5f7c1_row4_col0\" class=\"data row4 col0\" >0.126020</td>\n      <td id=\"T_5f7c1_row4_col1\" class=\"data row4 col1\" >0.126020</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_5f7c1_row5_col0\" class=\"data row5 col0\" >0.042000</td>\n      <td id=\"T_5f7c1_row5_col1\" class=\"data row5 col1\" >0.042000</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_5f7c1_row6_col0\" class=\"data row6 col0\" >0.026300</td>\n      <td id=\"T_5f7c1_row6_col1\" class=\"data row6 col1\" >0.026300</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_5f7c1_row7_col0\" class=\"data row7 col0\" >0.018400</td>\n      <td id=\"T_5f7c1_row7_col1\" class=\"data row7 col1\" >0.018400</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_5f7c1_row8_col0\" class=\"data row8 col0\" >0.018400</td>\n      <td id=\"T_5f7c1_row8_col1\" class=\"data row8 col1\" >0.018400</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_5f7c1_row9_col0\" class=\"data row9 col0\" >0.018400</td>\n      <td id=\"T_5f7c1_row9_col1\" class=\"data row9 col1\" >0.018400</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n      <td id=\"T_5f7c1_row10_col0\" class=\"data row10 col0\" >0.042000</td>\n      <td id=\"T_5f7c1_row10_col1\" class=\"data row10 col1\" >0.042000</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n      <td id=\"T_5f7c1_row11_col0\" class=\"data row11 col0\" >0.067420</td>\n      <td id=\"T_5f7c1_row11_col1\" class=\"data row11 col1\" >0.067420</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n      <td id=\"T_5f7c1_row12_col0\" class=\"data row12 col0\" >0.037400</td>\n      <td id=\"T_5f7c1_row12_col1\" class=\"data row12 col1\" >0.037400</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n      <td id=\"T_5f7c1_row13_col0\" class=\"data row13 col0\" >0.037400</td>\n      <td id=\"T_5f7c1_row13_col1\" class=\"data row13 col1\" >0.037400</td>\n    </tr>\n    <tr>\n      <th id=\"T_5f7c1_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n      <td id=\"T_5f7c1_row14_col0\" class=\"data row14 col0\" >0.037400</td>\n      <td id=\"T_5f7c1_row14_col1\" class=\"data row14 col1\" >0.037400</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n### Key Takeaways\n\n- Random walks converge to stationary distributions proportional to node degrees\n- Community structure is revealed through short-term vs. long-term behavior\n- Spectral properties control convergence speed and mixing times\n- Implementation requires careful attention to matrix operations and numerical stability\n- Applications span centrality measures, community detection, and network characterization\n\nThis foundation prepares you to apply random walks to real-world network analysis problems and understand their connections to other network science techniques.\n\n",
    "supporting": [
      "02-coding_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}