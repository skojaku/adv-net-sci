{
  "hash": "a3e7d1f8cfb20fcdaaa75970536d18b3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Random Walks Concepts\"\njupyter: advnetsci\nexecute:\n    enabled: true\n---\n\n## What is a random walk?\n\nSuppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\n\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network.\n\n::: {.column-margin title=\"Real-World Random Walk Examples\"}\nRandom walks appear everywhere in daily life:\n\n- **Netflix browsing**: You click on a movie, then another recommended movie, then another... Your viewing pattern follows a random walk through the recommendation network!\n- **Wikipedia surfing**: Starting from \"Coffee\", you click links to \"Brazil\" ‚Üí \"Soccer\" ‚Üí \"Mathematics\" ‚Üí \"Physics\"... Each click is a step in a random walk through knowledge.\n- **Stock market movements**: Daily price changes can be modeled as random walks, where each day's price depends on the previous day plus some random fluctuation.\n\n:::\n\n## Introduction through Games: Ladder Lottery\n\nTo make random walk concepts tangible, let's start with a fun game that perfectly illustrates random walk principles:\n\n::: {.callout-note title=\"Ladder Lottery\"}\n\nLadder Lottery is a fun East Asian game, also known as \"È¨ºËÖ≥Âúñ\" (Guijiaotu) in Chinese, \"ÈòøÂº•ÈôÄÁ±§\" (Amida-kuzi) in Japanese, \"ÏÇ¨Îã§Î¶¨ÌÉÄÍ∏∞\" (Sadaritagi) in Korean, and \"Ladder Lottery\" in English. The game is played as follows:\n1. A player is given a board with a set of vertical lines.\n2. The player chooses a line and starts to move along the line\n3. When hitting a horizontal line, the player must move along the horizontal line and then continue to move along the next vertical line.\n4. The player wins if the player can hit a marked line at the bottom of the board.\n5. You cannot see the horizontal lines in advance!\n\nPlay the [Ladder Lottery Game! üéÆ‚ú®]( https://skojaku.github.io/adv-net-sci/assets/vis/amida-kuji.html?) and try to answer the following questions:\n\n1. Is there a strategy to maximize the probability of winning?\n2. How does the probability of winning change as the number of horizontal lines increases?\n\n![](https://upload.wikimedia.org/wikipedia/commons/6/64/Amidakuji_2022-05-10.gif)\n\n:::\n\nThe Ladder Lottery game is actually a perfect introduction to random walks! In this game, **states** are the vertical lines, **transitions** happen when you encounter horizontal connections, **randomness** comes from not knowing where the horizontal lines are placed, and **long-term behavior** determines your probability of winning. This simple game illustrates many key concepts we'll explore in random walks on networks.\n\nA random walk in undirected networks follows this process:\n1. Start at a node $i$\n2. Randomly choose an edge to traverse to a neighbor node $j$\n3. Repeat step 2 until you have taken $T$ steps\n\n::: {.column-margin}\nIn directed networks, a random walker can only move along the edge direction, and it can be that the random walker is stuck in a so-called \"dead end\" that does not have any outgoing edges.\n:::\n\n<img src=\"../figs/random-walk.png\" alt=\"Random walk on a network\" width=\"50%\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n\nWhen studying random walks, we want to understand several key aspects: **short-term behavior** (where does the walker go in the first few steps?), **long-term behavior** (after many steps, where does the walker spend most of its time?), **structural insights** (what does the walker's behavior tell us about the network?), and **applications** (how can we use random walks for centrality and community detection?).\n\n::: {.callout-note title=\"Interactive Exploration\"}\n\nPlay with the [Random Walk Simulator! üéÆ‚ú®](vis/random-walks/index.html) and try to answer the following questions:\n\n1. When the random walker makes many steps, where does it tend to visit most frequently?\n2. When the walker makes only a few steps, where does it tend to visit?\n3. Does the behavior of the walker inform us about centrality of the nodes?\n4. Does the behavior of the walker inform us about communities in the network?\n\n:::\n\n### Pen and Paper Exercises\n\nBefore diving into the mathematical details and coding, it's important to work through some fundamental concepts by hand.\n\n- [‚úçÔ∏è Pen and paper exercises](pen-and-paper/exercise.pdf)\n\nThese exercises will help you:\n- Understand the basic mechanics of random walks\n- Calculate transition probabilities manually\n- Explore simple examples of stationary distributions\n- Connect random walk concepts to network properties\n\n## Transition Probabilities\n\n::: {.column-margin}\nLet's see how this works with a more complex example. Consider a network with 10 nodes:\n\n\n\nLet us consider the following graph.\n\n::: {#b2702914 .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](01-concepts_files/figure-html/cell-3-output-1.png){}\n:::\n:::\n\n\nThe transition matrix is given by:\n\n::: {#ae4069d9 .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](01-concepts_files/figure-html/cell-4-output-1.png){}\n:::\n:::\n\n\n:::\n\nA random walk is characterized by the transition probabilities between nodes. The transition probability from node $i$ to node $j$ is:\n\n$$\nP_{ij} = \\frac{A_{ij}}{k_i}\n$$\n\nwhere $A_{ij}$ is the adjacency matrix element and $k_i$ is the degree of node $i$.\n\n\nWe can represent all transition probabilities in a transition probability matrix $\\mathbf{P}$:\n\n$$\n\\mathbf{P} = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1N} \\\\\np_{21} & p_{22} & \\cdots & p_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{N1} & p_{N2} & \\cdots & p_{NN}\n\\end{pmatrix}\n$$\n\nThis matrix $\\mathbf{P}$ encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps:\n\n- After one step: $P_{ij} = p_{ij}$\n- After two steps: $\\left(\\mathbf{P}^{2}\\right)_{ij} = \\sum_{k} P_{ik} P_{kj}$\n- After $T$ steps: $\\left(\\mathbf{P}^{T}\\right)_{ij}$\n\nLet's understand why $\\mathbf{P}^2$ represents the transition probabilities after two steps.\n\nFirst, recall that $\\mathbf{P}_{ij}$ is the probability of moving from node $i$ to node $j$ in one step. Now, consider a two-step walk from $i$ to $j$. We can express this as:\n\n$(\\mathbf{P}^2)_{ij} = \\sum_k \\mathbf{P}_{ik} \\mathbf{P}_{kj}$\n\nThis equation encapsulates a key idea: to go from $i$ to $j$ in two steps, we must pass through some intermediate node $k$. Let's break this down step by step:\n\n1. The probability of the first step ($i$ to $k$) is $\\mathbf{P}_{ik}$.\n2. The probability of the second step ($k$ to $j$) is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ ‚Üí $k$ ‚Üí $j$) is the product $\\mathbf{P}_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nAnd we can extend this reasoning for any number of steps $t$. In summary, for any number of steps $t$, $\\left( \\mathbf{P}^t \\right)_{ij}$ gives the probability of being at node $j$ after $t$ steps, starting from node $i$.\n\n## Stationary Distribution\n\n::: {.column-margin}\n\nLet's compute $\\mathbf{P}^2$ for our larger network to see what happens after 2 steps:\n\n::: {#6c0ee97b .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](01-concepts_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\nThis is after 10 steps.\n\n::: {#2c5fc0c8 .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](01-concepts_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\nThis is after 1000 steps.\n\n::: {#cell-fig-long-term-P .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Transition Matrix after 100 steps](01-concepts_files/figure-html/fig-long-term-p-output-1.png){#fig-long-term-p}\n:::\n:::\n\n\n:::\n\n\nStationary distribution is the probability distribtion of the walker after infinite steps, representing the long-term behavior of the walker.\n\nAssuming that a stationary distribution exists (i.e., which is always true for undirected networks),\nthe random walker at the stationary state must satisfy the following balance condition:\n\n$$\nx(t+1) = x(t) \\; \\text{for a large } t,\n$$\nwhere $x(t)$ is the probability distribution of the walker at time $t$, represented as a column vector, where\n\n$$\nx(t) =\n\\begin{pmatrix}\nx_{i}(t) \\\\\nx_{j}(t) \\\\\n\\vdots \\\\\nx_{N}(t)\n\\end{pmatrix}\n$$\n\nwhere $x_{i}(t)$ is the probability of being at node $i$ at time $t$. The balance condition means that the system becomes time invariant, meaning that the probability of being at node $i$ at time $t$ is the same as the probability of being at node $i$ at time $t+1$.\n\nWhat does $x(t)$ look like in the stationary state? To understand this, let us represent $x(t)$ using $P$ and an initial distribution $x(0)$, i.e.,\n\n$$\nx(t) = x^\\top(t-1) P = x^\\top(0) P^t.\n$$\n\nTo see how $P^t$ looks like, see the figure on the right column.\nNotice that each column of $P^t$ has the same values across all rows. Remind also that $P_{ij}$ represents the transition probability from node $i$ (row) to node $j$ (column).\nThis means that a random walker at time $t$, not matter where it was at time $t-1$, it will have the same probability of being at any node at time $t$!\n\nNow, why $P^t$ has this peculiar property? This is because of the spectral property of matrix, $P$.\n\nFirst of all, we can rewrite the balance condition as the following eigenvalue equation:\n$$\n\\pi = \\pi P\n$$\nwhere $\\pi=\\lim_{t\\to\\infty} x(t)$ is the stationary distribution. This means that the stationary distribution vector $\\pi$ is parallel to the left eigenvector of $P$.\n\n::: {.callout-note}\nNote that $\\pi$ is **parallel** to but not necessarily equal to the left eigenvector of $P$, as $\\pi$ is a probability whose sum is 1 while the left eigenvector has unit norm (i.e., the sum of the squared elements is 1).\n:::\n\n\nThe left-eigenvector associated with the stationary distribution $\\pi$ is in fact associated with the largest eigenvalue of $P$, as per the Perron-Frobenius theorem.\nAn intuition behind this is that the number of walkers in a graph remains invariant after a transition, which is evident from the fact $\\sum_{j} P_{ij}=1$ (if it's greater than 1, the number of walkers increases and explodes to infinity).\nIn language of spectra of matrices, this means that the eigenvalue is not rescaled by the transition matrix, which mathematically corresponds to having eigenvalue 1.\n\n\n::: {.column-margin}\n\n::: {#cell-fig-spectrum .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![Spectrum of Transition Matrix $P$](01-concepts_files/figure-html/fig-spectrum-output-1.png){#fig-spectrum}\n:::\n:::\n\n\n:::\n\nThe other eigenvalues are less than one in magnitude and describes the short-term behavior of random walks, which we will discuss in the next section.\n\n## Spectral Analysis and Mixing Time\n\nNow, let's turn our attention to the short-term dynamics of random walks. These are governed by the non-dominant (non-principal) eigenvectors of the transition probability matrix $P$. To analyze this behavior, we'll need to use some concepts from linear algebra.\n\nThe short-term behavior of random walks is described as:\n\n$$\nx(t) = P^t  x(0)\n$$\n\nThus, it is determined by the initial distribution $x(0)$ and the power of the transition probability matrix $P^t$. In long term, $P^t$ approaches to that for the stationary distribution $\\pi$. Here we focus on the ehavior before the equilibrium is reached.\n\nTo understand the short-term behavior, we represent $P$ as:\n$$\nP = \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\mathbf{A}} \\mathbf{D}^{\\frac{1}{2}}\n$$\n\nwhere $\\overline{\\mathbf{A}}$ is a symmetric matrix and $\\mathbf{D}^{-\\frac{1}{2}}$ is a diagonal matrix. These are defined respectively as follows.\n\n- **Diagonal degree matrix, $\\mathbf{D}$**: we define a diagonal matrix whose diagonal elements are the degrees of the nodes, i.e.,\n$$\n\\mathbf{D} = \\begin{pmatrix}\nd_1 & 0 & \\cdots & 0 \\\\\n0 & d_2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & d_N\n\\end{pmatrix}\n$$\nwhere $d_i$ is the degree of node $i$.\n\n- **Normalized adjacency matrix, $\\overline{\\mathbf{A}}$**: we define a normalized adjacency matrix whose elements are the normalized adjacency matrix, i.e.,\n$$\n\\overline{\\mathbf{A}} = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}\n$$\nwhere $\\mathbf{A}$ is the adjacency matrix. It is normalized in the sense that each entry is normalized by the squared root of the degree of the nodes.\n\nThe key property we will leverage is that the normalized adjacency matrix is diagonalizable, i.e.,\n$$\n\\overline{\\mathbf{A}} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^T\n$$\n\nwhere $\\mathbf{Q}$ is an orthogonal matrix and $\\mathbf{\\Lambda}$ is a diagonal matrix.\nThe transition matrix $\\mathbf{P}$ can be written as:\n$$\n\\mathbf{P} = \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R^T\n$$\n\n::: {.column-margin}\n\n::: {#fig-diagonalizable}\n\n![](../figs/diagonalizable.jpg)\n\nA visual representation of diagonalizable matrix.\n:::\n\n\nSymmetric matrices are diagonalizable. And $\\overline{\\mathbf{A}}$ is symmetric as far as the undirected network is considered.\n:::\n\n\nwhere\n$$\n\\mathbf{Q}_L = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q}, \\quad \\mathbf{Q}_R = \\mathbf{D}^{\\frac{1}{2}} \\mathbf{Q}.\n$$\nImportantly, $\\mathbf{Q}$ is an orthogonal matrix, i.e., $\\mathbf{Q} \\mathbf{Q}^T = \\mathbf{I}$.\nPutting all together, we can compute $\\mathbf{P}^t$ as:\n\n$$\n\\mathbf{P}^t = \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R^T\n$$\n\n::: {.column-margin}\nThis could be understood by thinking of $\\mathbf{P}^2$, i.e.,\n\n$$\n\\begin{aligned}\n\\mathbf{P}^2 & = \\mathbf{Q}_L \\mathbf{\\Lambda} \\underbrace{\\mathbf{Q}_R^T \\mathbf{Q}_L}_{= \\mathbf{I}} \\mathbf{\\Lambda} \\mathbf{Q}_R^T \\\\\n& = \\mathbf{Q}_L \\mathbf{\\Lambda}^2 \\mathbf{Q}_R^T \\\\\n\\end{aligned}\n$$\n:::\n\n\n::: {#fig-diagonalizable-sum}\n\n![](../figs/diagonalizable-sum.jpg)\n\nA visual representation of the short term behavior of random walks.\nWe can see that $x(t)$ can be edcomposed into the row of $\\mathbf{Q}_R$ scaled by a dot-product of the initial distribution $x(0)$ and the column of $\\mathbf{Q}_L$, along with the eigenvalues of the normalized adjacency matrix $\\overline{\\mathbf{A}}$.\nIn this view, the short term distribution $x(t)$ is more strongly influenced by the second largest eigenvalue $\\lambda_2$ followed by the other remaining eigenvalues.\n\n\n:::\n\nArmed with this result, let us understand the short-term behavior of random walks.\nA key property is the *mixing time*, which is the time it takes for the random walk to reach the stationary distribution.\nFormally, the **mixing time** $t_{\\text{mix}}$ is defined as\n$$\nt_{\\text{mix}} = \\min\\{t : \\max_{\\mathbf{x}(0)} \\|\\mathbf{x}(t) - \\boldsymbol{\\pi}\\|_{1} \\leq \\epsilon\\}\n$$\n\nIt is not trivial to connect with this definition to the spectral properties of $\\overline{\\mathbf{A}}$.\nBut, since the transition matrix $\\mathbf{P}$ is determined by the eigenvalues and eigenvectors of the normalizsed adjacency matrix $\\overline{\\mathbf{A}}$, the mixing time is determined by the eigenvalues of $\\overline{\\mathbf{A}}$, in particular the second largest eigenvalue $\\lambda_2$, which dominates in $\\mathbf{P}^t$ following the principal eigenvector $\\pi$. In fact, the mixing time is bounded by the second largest eigenvalue.\n\n\n$$\nt_{\\text{mix}} < \\frac{1}{1-\\lambda_2} \\log \\left( \\frac{1}{\\epsilon \\min_{i} \\pi_i} \\right)\n$$\n\n::: {.column-margin}\nAn alternative represention is to use the second smallest eigenvalue $\\mu$ of the normalized Laplacian matrix:\n\n$$\nt_{\\text{mix}} \\leq \\frac{1}{\\mu}\n$$\n\nwhere $\\mu = 1-\\lambda_2$.\n:::\n\n\n## Community Detection through Random Walks\n\nRandom walks can reveal community structure in networks. Before reaching the steady state, walkers tend to remain within their starting community, then gradually diffuse to other communities. This temporal behavior provides insights into the network's modular structure.\n\n### Random Walk Interpretation of Modularity\n\nModularity can be interpreted through random walks [@delvenne2010stability]:\n\n$$\nQ = \\sum_{ij} \\left(\\pi_i P_{ij} - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)\n$$\n\nwhere:\n- $\\pi_i = \\frac{d_i}{2m}$ is the stationary distribution of the random walk\n- $P_{ij}$ is the transition probability between nodes $i$ and $j$\n- $\\delta(c_i, c_j)$ is 1 if nodes $i$ and $j$ are in the same community, 0 otherwise\n\nThe expression suggests that:\n1. The first term, $\\pi_i P_{ij} \\delta(c_i, c_j)$, represents the probability that a walker is at node $i$ and moves to node $j$ within the same community **by one step**.\n2. The second term, $\\pi_i \\pi_j$, represents the probability that a walker is at node $i$ and moves to another node $j$ within the same community **after long steps**.\n\nHigh modularity indicates walkers are more likely to stay within communities in the short term than in the long term.\n\n\n::: {.column-margin}\n[@delvenne2010stability] extends the modularity to the case of multi-step random walks, which can identify communities across different resolution scales.\n:::\n\n### Infomap: Information-Theoretic Community Detection\n\nWhile modularity provides one approach to community detection through random walks, **Infomap** offers an information-theoretic perspective [@rosvall2008maps; @rosvall2009map].\n\nInfomap asks: *How can we most efficiently describe the path of a random walker through a network?* The key insight is that if a network has strong community structure, a random walker will spend most of its time within communities, making short jumps between communities. This pattern can be *compressed efficiently* using a two-level code:\n\n1. **Module code**: A unique identifier for each community\n2. **Exit code**: A special symbol indicating when the walker leaves a community\n3. **Node code**: Identifiers for nodes within each community\n\nBy compressing the trajectory of random walks, Infomap can find a community structure that minimizes the average bits needed to describe the random walk.\n\n::: {#fig-infomap}\n\n![](https://www.mapequation.org/assets/img/metadatamapequation.svg)\n\nInfomap finds community detection by compressing the trajectory of random walks. (a) shows a random walker's trajectory through a network, while (d) demonstrates the hierarchical encoding scheme that minimizes description length by assigning short, reusable codewords to nodes within modules (colored regions) and special transition codes (pentagons/triangles) for movements between modules, with the optimal community structure being the partition that minimizes the average bits needed to describe the random walk\n\n:::\n\n",
    "supporting": [
      "01-concepts_files"
    ],
    "filters": [],
    "includes": {}
  }
}