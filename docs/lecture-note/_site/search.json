[
  {
    "objectID": "m09-graph-neural-networks/what-to-learn.html",
    "href": "m09-graph-neural-networks/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)"
  },
  {
    "objectID": "m09-graph-neural-networks/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m09-graph-neural-networks/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)"
  },
  {
    "objectID": "m09-graph-neural-networks/01-concepts.html",
    "href": "m09-graph-neural-networks/01-concepts.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)\n\n\n\n\n\n\n✍️ Pen and paper exercises\n\nThe pen and paper exercises will help you understand the mathematical foundations of graph neural networks, including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures\n\nThese exercises provide the theoretical foundation necessary to understand how graph neural networks process and learn from graph-structured data.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/01-concepts.html#what-to-learn-in-this-module",
    "href": "m09-graph-neural-networks/01-concepts.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/01-concepts.html#theoretical-exercises",
    "href": "m09-graph-neural-networks/01-concepts.html#theoretical-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\nThe pen and paper exercises will help you understand the mathematical foundations of graph neural networks, including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures\n\nThese exercises provide the theoretical foundation necessary to understand how graph neural networks process and learn from graph-structured data.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/what-to-learn.html",
    "href": "m08-embedding/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec"
  },
  {
    "objectID": "m08-embedding/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m08-embedding/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec"
  },
  {
    "objectID": "m08-embedding/software.html",
    "href": "m08-embedding/software.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Software for Network Embedding\nThere are various software packages for network embeddings. But due to technical complexity, some of them do not faithfully implement the algorithms in the paper. We provide a list of software packages for network embeddings below.\n\nfastnode2vec. This is a very fast implementation of node2vec. However, it uses a uniform probability distribution for the negative sampling, which is different from the original node2vec paper that uses a different distribution. This leads to some degeneracy of the embedding quality in community detection tasks.\npytorch-geometric. This is a very popular package for graph neural networks. It also uses a uniform probability distribution for the negative sampling, potentially having the same issue as fastnode2vec.\ngnn-tools. This is a collection of my experiments on network embedding methods.\nMy collection. This is a lighter version of the gnn-tools collection."
  },
  {
    "objectID": "m08-embedding/04-appendix.html",
    "href": "m08-embedding/04-appendix.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The spectral embedding with the adjacency matrix is given by the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nWe will approach the solution step by step based on the following steps:\n\nWe start taking a derivative of J(\\mathbf{U}) with respect to \\mathbf{U}.\nWe then set the derivative to zero (i.e., \\nabla J(\\mathbf{U}) = 0) and solve for \\mathbf{U}.\nExpand the Frobenius norm:\nThe Frobenius norm for any matrix \\mathbf{M} is defined as:\n\\|\\mathbf{M}\\|_F^2 = \\sum_{i,j} M_{ij}^2 = \\text{Tr}(\\mathbf{M}\\mathbf{M}^\\top)\nApplying this to our problem:\nJ(\\mathbf{U}) = \\|\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top\\|_F^2 = \\text{Tr}[(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)^\\top]\nExpanding this:\n= \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top - 2\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top + \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nTake the derivative with respect to \\mathbf{U}:\nUsing matrix calculus rules:\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top)}{\\partial \\mathbf{U}} = 0\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 2\\mathbf{A}\\mathbf{U}\n\\frac{\\partial \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nCombining these:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -4\\mathbf{A}\\mathbf{U} + 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSimplifying:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSet the derivative to zero and solve:\n-2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = 0\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nThis equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\nAssume \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{\\Lambda}\nwhere \\mathbf{\\Lambda} is a diagonal matrix of eigenvalues.\nSince eigenvectors are orthonormal:\n\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}\nTherefore:\n\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{U}\nThis shows our equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}.\nTo minimize J(\\mathbf{U}), choose the eigenvectors corresponding to the d largest eigenvalues.\nTo understand why, consider the trace of our objective function:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - 2\\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top) + \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nSince \\mathbf{U} is orthogonal (\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}), and trace is invariant under cyclic permutations, we can simplify:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - \\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U})\nLet \\mathbf{U} = [\\mathbf{u}_1, ..., \\mathbf{u}_d] be the eigenvectors of \\mathbf{A} with corresponding eigenvalues \\lambda_1 \\geq ... \\geq \\lambda_d. Then:\n\\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U}) = \\sum_{i=1}^d \\lambda_i\nTo minimize J(\\mathbf{U}), maximize \\sum_{i=1}^d \\lambda_i by selecting the eigenvectors corresponding to the d largest eigenvalues.\n\nThe result is the collection of the d eigenvectors corresponding to the d largest eigenvalues, and it is one form of the spectral embedding.\n\n\n\nThe Laplacian Eigenmap is given by the following optimization problem:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nThe step where we rewrite J_{LE}(\\mathbf{U}) as \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U}) is crucial for leveraging matrix derivatives. Let’s break down this transformation step by step:\n\nFirst, we rewrite \\mathbf{U} by column vectors:\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\vert & \\vert & & \\vert \\\\\n\\mathbf{x}_1 & \\mathbf{x}_2 & \\cdots & \\mathbf{x}_d \\\\\n\\vert & \\vert & & \\vert\n\\end{bmatrix}\n\nwhere \\mathbf{x}_i is the i-th column of \\mathbf{U}.\nWe can expand the loss function J_{LE}(\\mathbf{U}):\n\nJ_{LE}(\\mathbf{U}) = \\sum_{i} \\sum_{j} L_{ij} u_i^\\top u_j = \\sum_{i} \\sum_{j} \\sum_{d'} L_{ij} u_{i,d'} u_{j,d'}\n\nRearranging the order of summation:\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\sum_{i} \\sum_{j} L_{ij} u_{i,d'} u_{j,d'}\n\nWe can rewrite this as a matrix multiplication for each d':\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\mathbf{x}_{d'}^\\top \\mathbf{L} \\mathbf{x}_{d'}\n\nwhere \\mathbf{x}_{d'} is the d'-th column of \\mathbf{U}.\nFinally, we can express this as a trace:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\n\nThis final form expresses our objective function in terms of matrix operations, which allows us to use matrix calculus to find the optimal solution. The trace representation is a useful technique to leverage matrix calculus.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/04-appendix.html#spectral-embedding-with-the-adjacency-matrix",
    "href": "m08-embedding/04-appendix.html#spectral-embedding-with-the-adjacency-matrix",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The spectral embedding with the adjacency matrix is given by the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nWe will approach the solution step by step based on the following steps:\n\nWe start taking a derivative of J(\\mathbf{U}) with respect to \\mathbf{U}.\nWe then set the derivative to zero (i.e., \\nabla J(\\mathbf{U}) = 0) and solve for \\mathbf{U}.\nExpand the Frobenius norm:\nThe Frobenius norm for any matrix \\mathbf{M} is defined as:\n\\|\\mathbf{M}\\|_F^2 = \\sum_{i,j} M_{ij}^2 = \\text{Tr}(\\mathbf{M}\\mathbf{M}^\\top)\nApplying this to our problem:\nJ(\\mathbf{U}) = \\|\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top\\|_F^2 = \\text{Tr}[(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)^\\top]\nExpanding this:\n= \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top - 2\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top + \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nTake the derivative with respect to \\mathbf{U}:\nUsing matrix calculus rules:\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top)}{\\partial \\mathbf{U}} = 0\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 2\\mathbf{A}\\mathbf{U}\n\\frac{\\partial \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nCombining these:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -4\\mathbf{A}\\mathbf{U} + 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSimplifying:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSet the derivative to zero and solve:\n-2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = 0\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nThis equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\nAssume \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{\\Lambda}\nwhere \\mathbf{\\Lambda} is a diagonal matrix of eigenvalues.\nSince eigenvectors are orthonormal:\n\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}\nTherefore:\n\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{U}\nThis shows our equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}.\nTo minimize J(\\mathbf{U}), choose the eigenvectors corresponding to the d largest eigenvalues.\nTo understand why, consider the trace of our objective function:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - 2\\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top) + \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nSince \\mathbf{U} is orthogonal (\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}), and trace is invariant under cyclic permutations, we can simplify:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - \\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U})\nLet \\mathbf{U} = [\\mathbf{u}_1, ..., \\mathbf{u}_d] be the eigenvectors of \\mathbf{A} with corresponding eigenvalues \\lambda_1 \\geq ... \\geq \\lambda_d. Then:\n\\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U}) = \\sum_{i=1}^d \\lambda_i\nTo minimize J(\\mathbf{U}), maximize \\sum_{i=1}^d \\lambda_i by selecting the eigenvectors corresponding to the d largest eigenvalues.\n\nThe result is the collection of the d eigenvectors corresponding to the d largest eigenvalues, and it is one form of the spectral embedding.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/04-appendix.html#the-proof-of-the-laplacian-eigenmap",
    "href": "m08-embedding/04-appendix.html#the-proof-of-the-laplacian-eigenmap",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The Laplacian Eigenmap is given by the following optimization problem:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nThe step where we rewrite J_{LE}(\\mathbf{U}) as \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U}) is crucial for leveraging matrix derivatives. Let’s break down this transformation step by step:\n\nFirst, we rewrite \\mathbf{U} by column vectors:\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\vert & \\vert & & \\vert \\\\\n\\mathbf{x}_1 & \\mathbf{x}_2 & \\cdots & \\mathbf{x}_d \\\\\n\\vert & \\vert & & \\vert\n\\end{bmatrix}\n\nwhere \\mathbf{x}_i is the i-th column of \\mathbf{U}.\nWe can expand the loss function J_{LE}(\\mathbf{U}):\n\nJ_{LE}(\\mathbf{U}) = \\sum_{i} \\sum_{j} L_{ij} u_i^\\top u_j = \\sum_{i} \\sum_{j} \\sum_{d'} L_{ij} u_{i,d'} u_{j,d'}\n\nRearranging the order of summation:\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\sum_{i} \\sum_{j} L_{ij} u_{i,d'} u_{j,d'}\n\nWe can rewrite this as a matrix multiplication for each d':\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\mathbf{x}_{d'}^\\top \\mathbf{L} \\mathbf{x}_{d'}\n\nwhere \\mathbf{x}_{d'} is the d'-th column of \\mathbf{U}.\nFinally, we can express this as a trace:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\n\nThis final form expresses our objective function in terms of matrix operations, which allows us to use matrix calculus to find the optimal solution. The trace representation is a useful technique to leverage matrix calculus.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html",
    "href": "m08-embedding/01-concepts.html",
    "title": "Network Embedding Concepts",
    "section": "",
    "text": "In this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec"
  },
  {
    "objectID": "m08-embedding/01-concepts.html#what-to-learn-in-this-module",
    "href": "m08-embedding/01-concepts.html#what-to-learn-in-this-module",
    "title": "Network Embedding Concepts",
    "section": "",
    "text": "In this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec"
  },
  {
    "objectID": "m08-embedding/01-concepts.html#comparing-spectral-and-neural-embedding-approaches",
    "href": "m08-embedding/01-concepts.html#comparing-spectral-and-neural-embedding-approaches",
    "title": "Network Embedding Concepts",
    "section": "6 Comparing Spectral and Neural Embedding Approaches",
    "text": "6 Comparing Spectral and Neural Embedding Approaches\nWe have learned two types of graph embedding methods: spectral methods and neural embedding methods. But which one is better than the other? We will compare the two types of methods from multiple aspects.\n\nAnalytical Tractability\nSpectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized Laplacian matrices are shown to be optimal for detecting communities in the stochastic block model {footcite}nadakuditi2012graph.\nNeural embedding methods are less analytically tractable. But it is still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under very specific conditions {footcite}qiu2018network,kojaku2023network. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact optimal embedding methods for community detection for the stochastic block model.\n\n\nScalability and Performance\nA key limitation of spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit-learn package as TruncatedSVD), they might be unstable depending on the spectrum distribution of the matrix to be decomposed.\nNeural embedding methods are often more stable and scalable, making them particularly suitable for large networks where computational efficiency is critical.\n\n\nFlexibility and Extensions\nNeural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincaré embeddings {footcite}nickel2017poincare for embedding networks in hyperbolic space.\n\nThis flexibility extends to implementation choices and software options. There are various software packages for network embeddings, though due to technical complexity, some of them do not faithfully implement the algorithms in the paper. We provide a list of software packages for network embeddings below:\n\nfastnode2vec. This is a very fast implementation of node2vec. However, it uses a uniform probability distribution for the negative sampling, which is different from the original node2vec paper that uses a different distribution. This leads to some degeneracy of the embedding quality in community detection tasks.\npytorch-geometric. This is a very popular package for graph neural networks. It also uses a uniform probability distribution for the negative sampling, potentially having the same issue as fastnode2vec.\ngnn-tools. This is a collection of my experiments on network embedding methods.\nMy collection. This is a lighter version of the gnn-tools collection."
  },
  {
    "objectID": "m08-embedding/01-concepts.html#analytical-tractability",
    "href": "m08-embedding/01-concepts.html#analytical-tractability",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Spectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized laplacian matrices are shown to be optimal for detecting communities in the stochastic block model {footcite}nadakuditi2012graph.\nNeural embedding methods are less analytically tractable. But still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under a very specific condition {footcite}qiu2018network,kojaku2023network. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact an optimal embedding methods for community detection for the stochatic block model.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#scalability-and-performance",
    "href": "m08-embedding/01-concepts.html#scalability-and-performance",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "A key limitation of the spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit learn package as TruncatedSVD), they might be unstable depending on the spectrum distribution of the matrix to be decomposed.\nNeural embedding methods are often more stable and scalable, making them particularly suitable for large networks where computational efficiency is critical.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#flexibility-and-extensions",
    "href": "m08-embedding/01-concepts.html#flexibility-and-extensions",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Neural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincaré embeddings {footcite}nickel2017poincare for embedding networks in hyperbolic space.\n\nThis flexibility extends to implementation choices and software options. There are various software packages for network embeddings, though due to technical complexity, some of them do not faithfully implement the algorithms in the paper. We provide a list of software packages for network embeddings below:\n\nfastnode2vec. This is a very fast implementation of node2vec. However, it uses a uniform probability distribution for the negative sampling, which is different from the original node2vec paper that uses a different distribution. This leads to some degeneracy of the embedding quality in community detection tasks.\npytorch-geometric. This is a very popular package for graph neural networks. It also uses a uniform probability distribution for the negative sampling, potentially having the same issue as fastnode2vec.\ngnn-tools. This is a collection of my experiments on network embedding methods.\nMy collection. This is a lighter version of the gnn-tools collection.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#exercises",
    "href": "m08-embedding/01-concepts.html#exercises",
    "title": "Network Embedding Concepts",
    "section": "7 Exercises",
    "text": "7 Exercises\n\n✍️ Pen and paper exercises"
  },
  {
    "objectID": "m07-random-walks/pen-and-paper.html",
    "href": "m07-random-walks/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and paper exercises\n\n✍️ Pen and paper exercises"
  },
  {
    "objectID": "m06-centrality/pen-and-paper.html",
    "href": "m06-centrality/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and paper exercises\n\n️️School"
  },
  {
    "objectID": "m05-clustering/04-appendix.html",
    "href": "m05-clustering/04-appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "In the main text, we derived the modularity formula as follows:\n\n\\begin{align}\nQ &=\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\\end{align}\n\nBy rearranging the terms, we get the standard expression for modularity as follows:\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)\n\nBut are the two forms of modularity the same? Let’s see how we can transform one into the other:\nWe start with our first form of modularity:\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\nFirst, let’s factor out \\frac{1}{2m} from both terms:\n\nQ =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2 \\right]\n\nNow, here’s a neat trick: (\\sum_i a_i)^2 = (\\sum_i a_i)( \\sum_j a_j). We can use this to expand the squared term:\n\nQ =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n k_i \\delta(c, c_i) \\right) \\left( \\sum_{j=1}^n k_j \\delta(c, c_j) \\right)\\right]\n\nAnd here is another trick (\\sum_i a_i)( \\sum_j a_j) = \\sum_i a_i \\sum_j a_j = \\sum_i \\sum_j a_ia_j\n\nQ =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n \\sum_{j=1}^n k_i k_j  \\delta(c, c_i)  \\delta(c, c_j) \\right)\\right]\n\nHere’s yet another cool trick, \\delta(c,c_i) \\delta(c, c_j) = \\delta(c_i,c_j). This means we can simplify our expression:\n\nQ =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) -  \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n k_i k_j  \\delta(c_i,c_j) \\right]\n\nFinally, we can factor out the common parts:\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)"
  },
  {
    "objectID": "m05-clustering/04-appendix.html#derivation-of-modularity-formula",
    "href": "m05-clustering/04-appendix.html#derivation-of-modularity-formula",
    "title": "Appendix",
    "section": "",
    "text": "In the main text, we derived the modularity formula as follows:\n\n\\begin{align}\nQ &=\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\\end{align}\n\nBy rearranging the terms, we get the standard expression for modularity as follows:\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)\n\nBut are the two forms of modularity the same? Let’s see how we can transform one into the other:\nWe start with our first form of modularity:\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\nFirst, let’s factor out \\frac{1}{2m} from both terms:\n\nQ =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2 \\right]\n\nNow, here’s a neat trick: (\\sum_i a_i)^2 = (\\sum_i a_i)( \\sum_j a_j). We can use this to expand the squared term:\n\nQ =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n k_i \\delta(c, c_i) \\right) \\left( \\sum_{j=1}^n k_j \\delta(c, c_j) \\right)\\right]\n\nAnd here is another trick (\\sum_i a_i)( \\sum_j a_j) = \\sum_i a_i \\sum_j a_j = \\sum_i \\sum_j a_ia_j\n\nQ =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n \\sum_{j=1}^n k_i k_j  \\delta(c, c_i)  \\delta(c, c_j) \\right)\\right]\n\nHere’s yet another cool trick, \\delta(c,c_i) \\delta(c, c_j) = \\delta(c_i,c_j). This means we can simplify our expression:\n\nQ =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) -  \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n k_i k_j  \\delta(c_i,c_j) \\right]\n\nFinally, we can factor out the common parts:\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)"
  },
  {
    "objectID": "m04-node-degree/03-exercises.html",
    "href": "m04-node-degree/03-exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Objective: Experience the friendship paradox interactively\n\n🎉 Fun Challenge: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this Friendship Paradox Game! 🎮✨\n\nQuestions to consider: - Can you create a network where the friendship paradox is absent? - In other words, can you create a graph where your friends have the same number of friends as you? - What network structures minimize or maximize the friendship paradox effect?\n\n\n\nObjective: Apply the friendship paradox to disease control strategies\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this Vaccination Game! 🎮✨\n\nQuestions to explore: - How does random vaccination compare to targeted vaccination? - Why is vaccinating highly connected individuals more effective? - What happens when vaccination resources are limited?",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m04-node-degree/03-exercises.html#interactive-exercises",
    "href": "m04-node-degree/03-exercises.html#interactive-exercises",
    "title": "Exercises",
    "section": "",
    "text": "Objective: Experience the friendship paradox interactively\n\n🎉 Fun Challenge: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this Friendship Paradox Game! 🎮✨\n\nQuestions to consider: - Can you create a network where the friendship paradox is absent? - In other words, can you create a graph where your friends have the same number of friends as you? - What network structures minimize or maximize the friendship paradox effect?\n\n\n\nObjective: Apply the friendship paradox to disease control strategies\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this Vaccination Game! 🎮✨\n\nQuestions to explore: - How does random vaccination compare to targeted vaccination? - Why is vaccinating highly connected individuals more effective? - What happens when vaccination resources are limited?",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m04-node-degree/03-exercises.html#pen-and-paper-exercises",
    "href": "m04-node-degree/03-exercises.html#pen-and-paper-exercises",
    "title": "Exercises",
    "section": "2 Pen and Paper Exercises",
    "text": "2 Pen and Paper Exercises\nObjective: Understand the fundamentals of network data visualization\n📝 Exercise: Data Visualization Basics\nThis exercise covers: - Principles of effective data visualization - Common pitfalls in network visualization - Best practices for degree distribution plots",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m04-node-degree/03-exercises.html#assignment",
    "href": "m04-node-degree/03-exercises.html#assignment",
    "title": "Exercises",
    "section": "3 Assignment",
    "text": "3 Assignment\n\nFor students enrolled in SSIE 641, you will receive a dedicated link to the assignment repository from the instructor.\nFor those who are not enrolled, fork this assignment repository at Github.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html",
    "href": "m02-small-world/03-exercises.html",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "✍️ It’s a small world!! 6 degrees of separation (Moro 2017)",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html#pen-and-paper-exercise-why-is-our-social-network-small-world",
    "href": "m02-small-world/03-exercises.html#pen-and-paper-exercise-why-is-our-social-network-small-world",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "✍️ It’s a small world!! 6 degrees of separation (Moro 2017)",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html#assignment",
    "href": "m02-small-world/03-exercises.html#assignment",
    "title": "Exercises and Assignments",
    "section": "2 Assignment",
    "text": "2 Assignment\n\nFor students enrolled in SSIE 641, you will receive a dedicated link to the assignment repository from the instructor.\nFor those who are not enrolled, fork this assignment repository at Github.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "course/how-to-submit-assignment.html",
    "href": "course/how-to-submit-assignment.html",
    "title": "How to submit assignment",
    "section": "",
    "text": "In this course, we will use GitHub Classroom to submit & grade assignments. Please follow the instructions below to submit your assignment.\n\n\nSee the slides for the detailed instructions.\n\nClone the repository from GitHub.\nEdit the assignment.py with marimo editor. Type marimo edit assignment/assignment.py\nSubmit the assignment.py via git. (You can use GitHub Desktop, or command line)\nCheck the grading on the GitHub Classroom.\n\n\n\n\nSee the slides for the detailed instructions.\n\nGo to your assignment repository on GitHub\nClick the green “Code” button\nClick the “Open with Codespaces” button\nWait for the Codespaces to be ready.\nType ‘marimo edit assignment/assignment.py’. If you cannot find marimo, type “uv run marimo edit assignment/assignment.py” which should work.\nYou will be redirected to a webpage and prompted to enter the access token. The access token can be found on the terminal window in the Codespaces.\nTake the access token in the url “the alphabets after”?access_token=” and enter the token in the webpage.\n\n\n\n\nSee the slides for the detailed instructions.\n\nInstall Docker Desktop\nInstall GitHub Desktop\nInstall VS Code\n\n\n\n\nClone the repository from GitHub.\nOpen with the VS Code, and click “Reopen in Container”\nOpen the assignment.py with marimo editor.\nSubmit the assignment.py to the repository.",
    "crumbs": [
      "Home",
      "Course Information",
      "How to submit assignment"
    ]
  },
  {
    "objectID": "course/how-to-submit-assignment.html#option-1-a-simple-workflow-full-local",
    "href": "course/how-to-submit-assignment.html#option-1-a-simple-workflow-full-local",
    "title": "How to submit assignment",
    "section": "",
    "text": "See the slides for the detailed instructions.\n\nClone the repository from GitHub.\nEdit the assignment.py with marimo editor. Type marimo edit assignment/assignment.py\nSubmit the assignment.py via git. (You can use GitHub Desktop, or command line)\nCheck the grading on the GitHub Classroom.",
    "crumbs": [
      "Home",
      "Course Information",
      "How to submit assignment"
    ]
  },
  {
    "objectID": "course/how-to-submit-assignment.html#option-2-github-codespaces-full-cloud",
    "href": "course/how-to-submit-assignment.html#option-2-github-codespaces-full-cloud",
    "title": "How to submit assignment",
    "section": "",
    "text": "See the slides for the detailed instructions.\n\nGo to your assignment repository on GitHub\nClick the green “Code” button\nClick the “Open with Codespaces” button\nWait for the Codespaces to be ready.\nType ‘marimo edit assignment/assignment.py’. If you cannot find marimo, type “uv run marimo edit assignment/assignment.py” which should work.\nYou will be redirected to a webpage and prompted to enter the access token. The access token can be found on the terminal window in the Codespaces.\nTake the access token in the url “the alphabets after”?access_token=” and enter the token in the webpage.",
    "crumbs": [
      "Home",
      "Course Information",
      "How to submit assignment"
    ]
  },
  {
    "objectID": "course/how-to-submit-assignment.html#preparations-local-but-with-docker-machine",
    "href": "course/how-to-submit-assignment.html#preparations-local-but-with-docker-machine",
    "title": "How to submit assignment",
    "section": "",
    "text": "See the slides for the detailed instructions.\n\nInstall Docker Desktop\nInstall GitHub Desktop\nInstall VS Code\n\n\n\n\nClone the repository from GitHub.\nOpen with the VS Code, and click “Reopen in Container”\nOpen the assignment.py with marimo editor.\nSubmit the assignment.py to the repository.",
    "crumbs": [
      "Home",
      "Course Information",
      "How to submit assignment"
    ]
  },
  {
    "objectID": "course/activities.html",
    "href": "course/activities.html",
    "title": "Learning activities",
    "section": "",
    "text": "Quiz: Each lecture begins with a short paper‑based quiz reviewing the previous week’s material, graded immediately when possible, followed by a discussion of common mistakes at the end of the lecture.\nPen‑and‑Paper Exercise: Before the lecture, students complete a brief exercise to practice key concepts, then discuss solutions in class while the instructor synthesizes the answers.\nLecture: In class lectures are delivered by the instructor.\nNetwork of the Week: Weekly, a student or group presents a 10‑minute paper on a network‑related topic of their choice.\nCoding: Each module includes a Python coding exercise (using Marimo notebooks) to apply the concepts to real data."
  },
  {
    "objectID": "course/activities.html#in-class-activities",
    "href": "course/activities.html#in-class-activities",
    "title": "Learning activities",
    "section": "",
    "text": "Quiz: Each lecture begins with a short paper‑based quiz reviewing the previous week’s material, graded immediately when possible, followed by a discussion of common mistakes at the end of the lecture.\nPen‑and‑Paper Exercise: Before the lecture, students complete a brief exercise to practice key concepts, then discuss solutions in class while the instructor synthesizes the answers.\nLecture: In class lectures are delivered by the instructor.\nNetwork of the Week: Weekly, a student or group presents a 10‑minute paper on a network‑related topic of their choice.\nCoding: Each module includes a Python coding exercise (using Marimo notebooks) to apply the concepts to real data."
  },
  {
    "objectID": "course/activities.html#homework",
    "href": "course/activities.html#homework",
    "title": "Learning activities",
    "section": "2 Homework",
    "text": "2 Homework\n\nCoding assignment: Every module comes with a coding assignment. The assignment will be distributed via GitHub Classroom. Students will submit their solutions to the assignment via GitHub and get automatic grading.\nLLM Quiz Challenge: Every assignment also includes a task of formulating two quiz questions and correct answers. These quiz questions will be taken by a large language model that learns the course content without seeing the correct answers. The students pass the test if they can generate questions that LLM fails to answer correctly."
  },
  {
    "objectID": "course/activities.html#project",
    "href": "course/activities.html#project",
    "title": "Learning activities",
    "section": "3 Project",
    "text": "3 Project\n\nProject Proposal: The students will submit a project proposal on the course content.\nProject Paper: The students will submit a project paper on the course content.\nProject Presentation: The students will present their project."
  },
  {
    "objectID": "course/activities.html#exam",
    "href": "course/activities.html#exam",
    "title": "Learning activities",
    "section": "4 Exam",
    "text": "4 Exam\nA final exam will be given at the end of the course during the exam period. This exam will be a take-home exam, and will be distributed via Brightspace."
  },
  {
    "objectID": "course/activities.html#resources",
    "href": "course/activities.html#resources",
    "title": "Learning activities",
    "section": "5 Resources",
    "text": "5 Resources\n\nMark Newman, Networks (Second Edition), Oxford University Press, 2018\nFilippo Menczer, Santo Fortunato, and Clayton A. Davis, A First Course in Network Science, Cambridge University Press, 2020\nJames Bagrow and Yong-Yeol Ahn, Working with Network Data: A Data Science Perspective, Cambridge University Press, 2024"
  },
  {
    "objectID": "assets/slides/m02/archive/slide02.html",
    "href": "assets/slides/m02/archive/slide02.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Check list - [ ] Microphone turned on - [ ] Zoom room open - [ ] Sound Volume on - [ ] Open Discord - [ ] Quiz\n\n\n1 Advanced Topics in Network Science\nLecture 02: Small World Networks Sadamori Kojaku\n\n\n\n\nbg right:100% width:70%\n\n\n\n\n\n\nbg right:100% width:70%\n\n\n\n\n\n\nbg right:100% width:70%\n\n\n\n\n\n\nbg right:100% width:70%\n\n\n\n\n\n2 Small World Networks 🌎🔗\nWhat we’ll learn: - 🧪 Small-world experiments - 📏 Network distance concepts - 💾 Efficient network data handling - 🔬 Measuring node distances\n\n\n\n3 Milgram’s Small World Experiment 📬\n\n📤 Packets sent to random people in Nebraska & Kansas\n🎯 Goal: Reach target person in Boston\n📊 Results: ~6 people to reach target (64/160 successful)\n🌐 “Six degrees of separation” coined later\n\n\n\n\nbg right:50% width:100%\n\n\n\n\n\n4 Modern Small World Confirmations 📱\n\n📧 Yahoo email experiment: ~4-7 steps (2009)\n👥 Facebook study: 4.74 avg. path length (2012)\n\n\n\n\n5 Wikirace Game 🏁\n\n🕹️ Navigate Wikipedia from start to end page\n🔗 Find shortest path through hyperlinks\n👀 Experience “small world” phenomenon firsthand\n\n\n\n\nbg right:40% width:90%\n\n\nhttps://wiki-race.com/\n\n\n\n6 Why is the world small?\n\n📐 Explore “6 degrees of separation” concept\n🤔 Understand small world network properties\n🖊️ Practice network analysis without computer\n\nhttps://skojaku.github.io/adv-net-sci/m02-small-world/pen-and-paper.html\n\n\n\n7 Handling Large Networks\n\n\n\n8 Tools for Network Analysis 🛠️\n\nnetworkx\nigraph\ngraph-tool\nscipy\npytorch-geometric\n…\n\n\n\n\nbg right:50% width:100%\n\n\n\n\n\n9 networkx vs igraph 🤔\n\nnetworkx: Beginner-friendly library\nigraph: Mature library. Originally an R package.\nnetworkx is great! But there are persistent bugs in some algorithms.\nigraph is a more reliable and faithful implementation of algorithms.\n\n\n\n\nbg right:50% width:100%\n\n\n\n\nOther Python package\n\ngraph-tool: A rich library for stochastic block modeling\npytorch-geometric: A library for deep learning on graphs\nscipy: Provides efficient functions for sparse matrices\n\n\n\nGUI tools\n\nNetworks + Analytics: Gephi, Cytoscape, Pajek\nVisualization: HeliosWeb\n\n\n\n\nbg right:50% width:100%\n\n\n\n\n\n\n10 Efficient Network Representation 💾\n\n🧮 Challenge: Storing large adjacency matrices\n💡 Solution: Compressed Sparse Row (CSR) format\n📊 Stores only non-zero entries\n🚀 Memory efficient for sparse networks\n\nPen and Paper Exercise\n\n\n\nbg right:50% width:100%\n\n\n\n\n\n11 Walk, Trail, Path, Circuit, Cycle\n\n\n\nright:100% width:80%\n\n\n\n\n\n12 Walk, Trail, Path, Circuit, Cycle\n\n🚶 Walk: Sequence of connected nodes\n🛤️ Trail: Walk with no repeated edges\n🛣️ Path: Walk with no repeated nodes\n🔄 Loop, Circuit, Cycle: Special closed walks\n\n\n\n\n13 Connectedness in Networks\n\n🔗 Connected vs Disconnected networks\n🧩 Connected components\n🌟 Giant component\n\n\n\n\nbg right:40% width:90%\n\n\n\n\n\n14 Directed Network Connectedness 🔀\n\n💪 Strongly connected: Path between all node pairs\n🤝 Weakly connected: Path ignoring edge direction\n\n\n\n\nbg right:40% width:90%\n\n\n\n\n\n15 Hands-on: Network Analysis with igraph 🛠️\n\n📊 Create and visualize graphs\n🔍 Find shortest paths\n🧩 Identify connected components\n🔀 Analyze directed networks\n\nhttps://skojaku.github.io/adv-net-sci/m02-small-world/connectedness-hands-on.html\n\n\n\n16 Assignment: Small World Experiment 📝\n\n🔬 Compute average path length in scientist network\n💻 Use efficient CSR format\n🧮 Apply igraph for network analysis\n\nhttps://skojaku.github.io/adv-net-sci/m02-small-world/assignment.html\n\n\n\n17 Thank You! Questions? 🤔"
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html",
    "href": "m09-graph-neural-networks/image-processing.html",
    "title": "Preliminaries: Image Processing",
    "section": "",
    "text": "Graph Neural Networks are a type of neural network for graph data. node2vec and deepwalk stem from the idea of language modeling. In this module, we will focus on another branch of graph neural networks that stem from image processing."
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html#edge-detection-problem-in-image-processing",
    "href": "m09-graph-neural-networks/image-processing.html#edge-detection-problem-in-image-processing",
    "title": "Preliminaries: Image Processing",
    "section": "1 Edge Detection Problem in Image Processing",
    "text": "1 Edge Detection Problem in Image Processing\nEdge detection is a classical problem in image processing. The goal is to identify the boundaries of objects in an image.\n\nTo approach the problem, let us first remind that an image is a matrix of pixels. Each pixel has RGB values, each of which represents the intensity of red, green, and blue color. To simplify the problem, we focus on grayscale images, in which each pixel has only one value representing the brightness. In this case, an image can be represented as a 2D matrix, where each element in the matrix represents the brightness of a pixel.\n\n\nAn example\nHuman eyes are very sensitive to brightness changes. An edge in an image appears when there is a significant brightness change between adjacent pixels. To be more concrete, let’s consider a small example consisting of 6x6 pixels, with a vertical line from the top to the bottom, where the brightness is higher than the neighboring pixels. This is an edge we want to detect.\n\nX = \\begin{bmatrix}\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10\n\\end{bmatrix}\n\nLet’s zoom on the pixel at (3, 3) and its surrounding pixels.\n\nZ = \\begin{bmatrix}\n10 & 80 & 10 \\\\\n\\textcolor{blue}{10} & \\textcolor{red}{80} & \\textcolor{purple}{10} \\\\\n10 & 80 & 10\n\\end{bmatrix}\n\nwhere the central pixel is highlighted in red. Since we are interested in the edge which is a sudden change in brightness along the horizontal direction, we take a derivative at the central pixel by\n\n\\nabla Z_{22} = \\textcolor{blue}{Z_{2,1}} - \\textcolor{purple}{Z_{2,3}}\n\nFollowing the same process, we can compute the derivative at all pixels, which gives us the (horizontal) derivative of the image.\n\n\\begin{bmatrix}\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & -\n\\end{bmatrix}\n\nThe symbol - indicates that the derivative is not defined because one of the neighboring pixels is out of the image boundary. We observe that the derivative is high at the edge and low elsewhere. This is a simple but effective way to detect edges in an image.\nWe can consider a derivative operator along the vertical direction that computes the difference between the vertical neighboring pixels.\n\n\\nabla Z_{22} = Z_{1,2} - Z_{3,2}\n\nAnd, when applied to the entire image, the result is\n\n\\begin{bmatrix}\n- & - & - & - & -  & - \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n- & - & - & - & - & -\n\\end{bmatrix}\n\nThe all entries are zero, meaning that there is no edge in the vertical direction.\nWe can combine the horizontal and vertical derivatives to get the gradient of the image. For example,\n\n\\nabla Z_{22} = Z_{12} - Z_{32} + Z_{21} - Z_{23}\n\nWhen applied to the entire image, the result is the same as the horizontal derivative.\n\n\nConvolution\nWe observe that there is a repeated pattern in the derivative computation: we are taking addition and subtraction of neighbiring pixels. This motivates us to generalize the operation to a more general form.\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j}\n\nwhere K is a 3 \\times 3 matrix, and w=h=3 represent the width and height of the kernel.\n\nK = \\begin{bmatrix}\nK_{11} & K_{12} & K_{13} \\\\\nK_{21} & K_{22} & K_{23} \\\\\nK_{31} & K_{32} & K_{33}\n\\end{bmatrix}\n\nThe matrix K is called a kernel, and applying it to the image is called convolution.\nThe index of the kernel is conventionally reversed. Namely, we reorder the entries of the kernel such that\n\n$$\n\\begin{bmatrix}\nK_{33} & K_{32} & K_{31} \\\\\nK_{23} & K_{22} & K_{21} \\\\\nK_{13} & K_{12} & K_{11}\n\\end{bmatrix}\n$$\n\nThen, take the element-wise product with $Z$\n\n$$\n\\begin{bmatrix}\nZ_{11} K_{33} & Z_{12} K_{32} & Z_{13} K_{31} \\\\\nZ_{21} K_{23} & Z_{22} K_{22} & Z_{23} K_{21} \\\\\nZ_{31} K_{13} & Z_{32} K_{12} & Z_{33} K_{11}\n\\end{bmatrix}\n$$\n\nand sum up all the elements to get the new pixel value $\\nabla Z_{22}$.\nWhy do we reverse the kernel? This is to match with the mathematical definition of convolution, which will be introduced later.\nIn the previous example, we used a $3 \\times 3$ kernels called the Prewitt operator, which in terms of $K$ is\n\n$$\nK_h = \\begin{bmatrix}\n-1 & 0 & 1 \\\\\n-1 & 0 & 1 \\\\\n-1 & 0 & 1\n\\end{bmatrix}\n\\quad \\text{or} \\quad\nK_v = \\begin{bmatrix}\n-1 & -1 & -1 \\\\\n0 & 0 & 0 \\\\\n1 & 1 & 1\n\\end{bmatrix}\n$$\n\nwhere $K_h$ is the horizontal Prewitt operator and $K_v$ is the vertical Prewitt operator.\nA kernel represents a local pattern we want to detect. The new pixel value after the convolution is maximized when the pattern is most similar to the kernel in terms of the inner product. This can be confirmed by:\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j} = \\langle \\hat K, Z \\rangle\n\nwhere \\langle \\cdot, \\cdot \\rangle is the inner product, and \\hat K is the order-reversed kernel.\nCheck out this awesome interactive demo to see how different kernels work: [Demo](https://setosa.io/ev/image-kernels/)"
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html#fourier-transform",
    "href": "m09-graph-neural-networks/image-processing.html#fourier-transform",
    "title": "Preliminaries: Image Processing",
    "section": "2 Fourier Transform",
    "text": "2 Fourier Transform\n\nConvolution computes the new pixel values by sliding a kernel over an image. How is the resulting image related to the original image?\nTo answer this question, let us consider a row of an image and convolve it with a kernel K.\n\n\\begin{aligned}\nX &= \\begin{bmatrix}\nX_1 & X_2 & X_3 & X_4 & X_5 & X_6\n\\end{bmatrix} \\\\\nK &= \\begin{bmatrix}\nK_1 & K_2 & K_3\n\\end{bmatrix}\n\\end{aligned}\n\nThe convolution of X and K is\n\nX * K = \\begin{bmatrix}\nX_1 K_3 + X_2 K_2 + X_3 K_1 & X_2 K_3 + X_3 K_2 + X_4 K_1 & X_3 K_3 + X_4 K_2 + X_5 K_1 & X_4 K_3 + X_5 K_2 + X_6 K_1\n\\end{bmatrix}\n\n…which is complicated, right? 😅 So let’s make it simple by using a useful theorem called the convolution theorem.\nThe convolution theorem gives us a simpler way to think about convolution. Instead of doing the complex sliding window operation in the original domain (like pixel values), we can:\n\nTransform both signals to the frequency domain using Fourier transform\nMultiply them together (much simpler!)\nTransform back to get the same result\n\nMathematically, the above steps can be written as:\n\n\\mathcal{F}(X), \\mathcal{F}(K) - Transform both signals to frequency domain (Fourier transform)\n\\mathcal{F}(X) \\cdot \\mathcal{F}(K) - Multiply the transformed signals\n\\mathcal{F}^{-1}(\\mathcal{F}(X) \\cdot \\mathcal{F}(K)) - Transform back to get X * K\n\nwhere \\mathcal{F}^{-1} is the inverse Fourier transform that brings us back to the original domain. This is much easier than computing the convolution directly!\nFor a discrete signal x[n] with N points, the Fourier transform \\mathcal{F} is defined as:\n\n\\mathcal{F}(x)[k] = \\sum_{n=0}^{N-1} x[n] \\cdot e^{-2\\pi i \\frac{nk}{N}}\n\nwhere i is the imaginary unit. Or equivalently,\n\n\\mathcal{F}(x)[k] = \\sum_{n=0}^{N-1} x[n] \\cdot \\left[ \\cos\\left(2\\pi \\frac{nk}{N}\\right) - i \\sin\\left(2\\pi \\frac{nk}{N}\\right) \\right]\n\nusing Euler’s formula e^{ix} = \\cos(x) + i\\sin(x).\nComplex number can be thought of as a way to represent a 2D vector using a single value (which is a computer science perspective; mathematically, it is a bit more subtle). For example, $e^{i\\pi/2} = \\cos(\\pi/2) + i\\sin(\\pi/2)$ represents the 2D vector $(\\cos(\\pi/2), \\sin(\\pi/2))$. In the context of Fourier transform, we interpret $e^{-2\\pi i \\frac{nk}{N}}$ as two *base waves*, i.e., sine and cosine, with phase $\\frac{2\\pi k}{N}$.\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Euler%27s_formula.svg/360px-Euler%27s_formula.svg.png)\nIn simple terms, \\mathcal{F} takes a signal (like our row of pixel values) and breaks it down into sine and cosine waves of different frequencies. Each frequency component k tells us “how much” of that frequency exists in our original signal. Don’t worry too much about the complex math. The key idea is that \\mathcal{F} represents a signal as a sum of multiple waves with different frequencies, so we can understand the signal in terms of its frequencies rather than its original values.\n\n3Blue1Brown makes a beautiful video explaining Fourier transform: [Video](https://www.youtube.com/watch?v=spUNpyF58BY). Here is a great interactive demo on Fourier transform by Jez Swanson: [Demo](https://www.jezzamon.com/fourier/).\n\nAn example for the Fourier transform\nNow, let’s perform the convolution using the Fourier transform using an example.\n\nimport numpy as np\nX = np.array([10, 10, 80, 10, 10, 10])\nK = np.array([-1, 0, 1])\n\nLet us first perform the convolution directly.\n\n# Pad X with zeros on both sides to handle boundary\nn_conv = len(X) - len(K) + 1  # Now we get full length output\nXKconv = np.zeros(n_conv)\n\nfor i in range(n_conv):\n    XKconv[i] = np.sum(X[i:(i+len(K))] * K[::-1]) # Reverse the kernel and take element-wise product and sum up\nXKconv\n\nLet us now perform the convolution using the Fourier transform. We compute the Fourier transform of X and K.\n\n# Step 1: Transform X and K to frequency domain\nFX = np.fft.fft(X)\n# Pad K with zeros to match the length of X before FFT\nK_padded = np.pad(K, (0, len(X) - len(K)), 'constant') # [-1  0  1  0  0  0]\nFK = np.fft.fft(K_padded)\nprint(\"FX:\", FX)\n\n\nWe add zeros to K to make it the same length as X before applying the Fourier transform. This is necessary because the convolution theorem requires the signals to have the same length.\nFX is the Fourier transform of X, which is a complex number. Each entry FX[k] represents the weight of the cosine wave in its real part and the weight of the sine wave in its imaginary part, with phase 2\\pi k / N. Similarly for FK.\n\nNext, we multiply the transformed signals.\n\nFXKconv = FX * FK\n\nThis is the convolution in the frequency domain. Finally, we transform back to get the convolution.\n\nXKconv_ft = np.real(np.fft.ifft(FXKconv))\nXKconv_ft\n\n\nWe take the real part. The imaginary part is due to numerical artifacts that do not matter in practice.\nThe Fourier transform convolution produces a longer output than direct convolution because it includes partial overlaps between K and X at the boundaries. Since we only want the full overlaps, we need to truncate the first two elements of XKconv_ft (as K has length 3) to match the length of the direct convolution result.\nFor example, let’s look at what happens at the beginning of the convolution:\n\nAt position -2: Only the last element of K overlaps with X: [0, 0, 10] * [-1, 0, 1] = 10\nAt position -1: Two elements of K overlap with X: [0, 10, 10] * [-1, 0, 1] = 10\nAt position 0: Full overlap begins: [10, 10, 80] * [-1, 0, 1] = 70\n\nThe Fourier transform method gives us all these positions (-2, -1, 0, …), but we only want the full overlaps starting from position 0, which is why we truncate the first two elements.\n\n\nXKconv_ft = XKconv_ft[2:]\nXKconv_ft\n\nThis gives us the same result as the direct convolution up to numerical errors."
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html#fourier-transform-of-images",
    "href": "m09-graph-neural-networks/image-processing.html#fourier-transform-of-images",
    "title": "Preliminaries: Image Processing",
    "section": "3 Fourier Transform of Images",
    "text": "3 Fourier Transform of Images\nLet’s extend the above example to an image which is a 2D matrix. The idea is the same: we take the Fourier transform of each row and column of the image, and then multiply them together to get the convolution in the frequency domain. More specifically, for an image X with size H \\times W, the Fourier transform of X is\n\n\\begin{aligned}\n\\mathcal{F}(X)[h, w] &= \\sum_{k=0}^{H-1} \\sum_{\\ell=0}^{W-1} X[k, \\ell] \\cdot e^{-2\\pi i \\frac{hk}{H}} \\cdot e^{-2\\pi i \\frac{w\\ell}{W}} \\\\\n&= \\sum_{k=0}^{H-1} \\sum_{\\ell=0}^{W-1} X[k, \\ell] e^{-2\\pi i \\left(\\frac{hk}{H} + \\frac{w\\ell}{W}\\right)}\n\\end{aligned}\n\nComparing with the 1D case, we see that the 2D Fourier transform is functionally the same as the 1D Fourier transform, except that we now have two indices h and w to represent the frequency in both dimensions. The basis waves are 2D waves as shown below.\nCosine waves\n\n:tags: [hide-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef basis_function(img_size=256, u=0, v=0):\n  '''\n  img_size : square size of image f(x,y)\n  u,v : spatial space indice\n  '''\n  N = img_size\n  x = np.linspace(0, N-1, N)\n  y = np.linspace(0, N-1, N)\n  x_, y_ = np.meshgrid(x, y)\n  bf = np.exp(-1j*2*np.pi*(u*x_/N+v*y_/N))\n  if u == 0 and v == 0:\n    bf = np.round(bf)\n  real = np.real(bf) # The cosine part\n  imag = np.imag(bf) # The sine part\n  return real, imag\n\nsize = 16\nbf_arr_real = np.zeros((size*size,size,size))\nbf_arr_imag = np.zeros((size*size,size,size))\nind = 0\nfor col in range(size):\n  for row in range(size):\n    re,imag = basis_function(img_size=size, u=row, v=col)\n    bf_arr_real[ind] = re\n    bf_arr_imag[ind] = imag\n    ind += 1\n\n# real part\n_, axs = plt.subplots(size, size, figsize=(7, 7))\naxs = axs.flatten()\nfor img, ax in zip(bf_arr_real, axs):\n  ax.set_axis_off()\n  ax.imshow(img,cmap='gray')\n\nSine waves\n\n:tags: [hide-input]\n# imaginary part\n_, axs = plt.subplots(size, size, figsize=(7, 7))\naxs = axs.flatten()\nfor img, ax in zip(bf_arr_imag, axs):\n  ax.set_axis_off()\n  ax.imshow(img,cmap='gray')\n\nThe Fourier transform of an image is a decomposition of an image into the sum of these basis waves.\n\nAn example of Fourier transform\nLet us apply the Fourier transform to an image.\n\n:tags: [hide-input]\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Read image from URL\ndef read_jpeg_from_url(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    # Convert to RGB mode if needed (in case it's RGBA)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    return img\n\ndef image_to_numpy(img):\n    return np.array(img)\n\ndef to_gray_scale(img_np):\n    return np.mean(img_np, axis=2)\n\n# URL of the image\nurl = \"https://www.binghamton.edu/news/images/uploads/features/20180815_peacequad02_jwc.jpg\"\n\nimg = read_jpeg_from_url(url)\nimg_np = image_to_numpy(img)\nimg_gray = to_gray_scale(img_np)\n\nplt.imshow(img_gray, cmap='gray')\n\nTake the Fourier transform of the image.\n\nft_img_gray = np.fft.fft2(img_gray)\n\nThis decomposes the image into a sum of basis waves. Let’s see the weights of the basis waves.\n\n:tags: [hide-input]\nimport matplotlib\n\nweight = np.abs(ft_img_gray)\n\n# real part\nfig1, ax1 = plt.subplots(figsize=(5, 5))\n\nax1.imshow(weight, cmap='gray', norm=matplotlib.colors.LogNorm(), aspect='equal')\ncbar = fig1.colorbar(ax1.images[0], ax=ax1, orientation='horizontal')\ncbar.set_label('Fourier transform magnitude')\n\nThe corresponding basis waves look like this:\n\n:tags: [hide-input]\nsize = 16\nbf_arr_real = np.zeros((size*size,size,size))\nbf_arr_imag = np.zeros((size*size,size,size))\nind = 0\nfor col in range(-size//2, size//2):\n  for row in range(-size//2, size//2):\n    re,imag = basis_function(img_size=size, u=row, v=col)\n    bf_arr_real[ind] = re\n    bf_arr_imag[ind] = imag\n    ind += 1\n\n# real part\nfig, axs = plt.subplots(size, size, figsize=(7, 7))\naxs = axs.flatten()\nfor img, ax in zip(bf_arr_real, axs):\n  ax.set_axis_off()\n  ax.imshow(img,cmap='gray')\n\nfig.suptitle('Real Part of Basis Functions')\n\n\n# imaginary part\nfig, axs = plt.subplots(size, size, figsize=(7, 7))\naxs = axs.flatten()\nfor img, ax in zip(bf_arr_imag, axs):\n  ax.set_axis_off()\n  ax.imshow(img,cmap='gray')\n\nfig.suptitle('Imaginary Part of Basis Functions')\n\nNow, let’s see the convolution of the image with a Prewitt operator.\n\nK = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]]) # Prewitt operator\n\nK_padd = np.zeros((img_gray.shape[0], img_gray.shape[1]))\nK_padd[:K.shape[0], :K.shape[1]] = K\n\n# convolution\nFK = np.fft.fft2(K_padd)\n\nThe Fourier transform of the Prewitt operator looks like this:\n\nplt.imshow(np.abs(FK), cmap='gray')\ncbar = plt.colorbar()\n\nWe can think of the frequency domain of the kernel as a filter that suppresses some frequencies and allows others to pass through. In the example of the Prewitt operator, the kernel FK has a low value around the center of the image. The product FX \\cdot FK then suppresses the low-frequency components of the image, and we are left with the high-frequency components that correspond to the horizontal edges. We can think of this as a high-pass filter that only allows high-frequency components to pass through.\nLet’s see the convolution result.\n\n:tags: [hide-input]\nFX = np.fft.fft2(img_gray)\nconv_img_gray = np.real(np.fft.ifft2(FX * FK))\nplt.imshow(conv_img_gray, cmap='gray')\n\nWe observe that the horizontal edges are highlighted.\nA widespread application of the 2D Fourier transform is JPEG format. Here's how it works:\n\n(1) It first breaks the image into small 8x8 squares.\n(2) It converts each square into frequencies using the Discrete Cosine Transform. The sine part is discarded for compression.\n(3) It keeps the important low frequencies that our eyes can see well.\n(4) It throws away most of the high frequencies that our eyes don't notice much.\n\nThese steps make the file much smaller while still looking good to us."
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html#a-key-lesson-from-image-processing",
    "href": "m09-graph-neural-networks/image-processing.html#a-key-lesson-from-image-processing",
    "title": "Preliminaries: Image Processing",
    "section": "4 A key lesson from image processing",
    "text": "4 A key lesson from image processing\nWe have seen an equivalence between convolution in the pixel (spatial) domain and multiplication in the frequency domain. Using the Fourier transform, an image is decomposed into a sum of basis waves. The kernel can be thought of as a filter that suppresses some basis waves and allows others to pass through.\nThis idea is the key to understand graph convolutional networks we will see in the next page."
  },
  {
    "objectID": "m09-graph-neural-networks/from-image-to-graph.html",
    "href": "m09-graph-neural-networks/from-image-to-graph.html",
    "title": "From Image to Graph",
    "section": "",
    "text": "We can think of a convolution of an image from the perspective of networks. In the convolution of an image, a pixel is convolved with its neighbors. We can regard each pixel as a node, and each node is connected to its neighboring nodes (pixels) that are involved in the convolution.\n\nBuilding on this analogy, we can extend the idea of convolution to general graph data. Each node has a pixel value(s) (e.g., feature vector), which is convolved with the values of its neighbors in the graph. This is the key idea of graph convolutional networks. But, there is a key difference: while the number of neighbors for an image is homogeneous, the number of neighbors for a node in a graph can be heterogeneous. Each pixel has the same number of neighbors (except for the boundary pixels), but nodes in a graph can have very different numbers of neighbors. This makes it non-trivial to define the “kernel” for graph convolution."
  },
  {
    "objectID": "m09-graph-neural-networks/from-image-to-graph.html#analogy-between-image-and-graph-data",
    "href": "m09-graph-neural-networks/from-image-to-graph.html#analogy-between-image-and-graph-data",
    "title": "From Image to Graph",
    "section": "",
    "text": "We can think of a convolution of an image from the perspective of networks. In the convolution of an image, a pixel is convolved with its neighbors. We can regard each pixel as a node, and each node is connected to its neighboring nodes (pixels) that are involved in the convolution.\n\nBuilding on this analogy, we can extend the idea of convolution to general graph data. Each node has a pixel value(s) (e.g., feature vector), which is convolved with the values of its neighbors in the graph. This is the key idea of graph convolutional networks. But, there is a key difference: while the number of neighbors for an image is homogeneous, the number of neighbors for a node in a graph can be heterogeneous. Each pixel has the same number of neighbors (except for the boundary pixels), but nodes in a graph can have very different numbers of neighbors. This makes it non-trivial to define the “kernel” for graph convolution."
  },
  {
    "objectID": "m09-graph-neural-networks/from-image-to-graph.html#spectral-filter-on-graphs",
    "href": "m09-graph-neural-networks/from-image-to-graph.html#spectral-filter-on-graphs",
    "title": "From Image to Graph",
    "section": "2 Spectral filter on graphs",
    "text": "2 Spectral filter on graphs\nJust like we can define a convolution on images in the frequency domain, we can also define a ‘’frequency domain’’ for graphs.\nConsider a network of N nodes, where each node has a feature variable {\\mathbf x}_i \\in \\mathbb{R}. We are interested in:\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2,\n\nwhere A_{ij} is the adjacency matrix of the graph. The quantity J represents the total variation of x between connected nodes; a small J means that connected nodes have similar x (low variation; low frequency), while a large J means that connected nodes have very different x (high variation; high frequency).\nWe can rewrite J as\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 = {\\bf x}^\\top {\\bf L} {\\bf x},\n\nwhere {\\bf L} is the Laplacian matrix of the graph given by\n\nL_{ij} = \\begin{cases}\n-1 & \\text{if } i \\text{ and } j \\text{ are connected} \\\\\nk_i & \\text{if } i = j \\\\\n0 & \\text{otherwise}\n\\end{cases}.\n\nand {\\bf x} = [x_1,x_2,\\ldots, x_N]^\\top is a column vector of feature variables.\n\n\n\n\n\n\nDetailed derivation\n\n\n\n:tag: note :class: dropdown\nThe above derivation shows that the total variation of x between connected nodes is proportional to {\\bf x}^\\top {\\bf L} {\\bf x}.\n\n\\begin{aligned}\nJ &= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 \\\\\n&= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\underbrace{A_{ij}\\left( x_i^2 +x_j^2\\right)}_{\\text{symmetric}} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2\\underbrace{\\sum_{j=1}^N A_{ij}}_{\\text{degree of node } i, k_i} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2 k_i - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\underbrace{[x_1,x_2,\\ldots, x_N]}_{{\\bf x}} \\underbrace{\\begin{bmatrix} k_1 & 0 & \\cdots & 0 \\\\ 0 & k_2 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & k_N \\end{bmatrix}}_{{\\bf D}} \\underbrace{\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N \\end{bmatrix}}_{{\\bf x}} - 2\\underbrace{\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}}_{{\\bf x}^\\top {\\mathbf A} {\\bf x}} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf D} {\\bf x} - {\\bf x}^\\top {\\mathbf A} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf L} {\\bf x},\n\\end{aligned}\n\n\n\nLet us showcase the analogy between the Fourier transform and the Laplacian matrix. In the Fourier transform, a signal is decomposed into sinusoidal basis functions. Similarly, for a graph, we can decompose the variation J into eigenvector bases.\n\nJ = \\sum_{i=1}^N \\lambda_i  {\\bf x}^\\top {\\mathbf u}_i {\\mathbf u}_i^\\top {\\bf x} = \\sum_{i=1}^N \\lambda_i  ||{\\bf x}^\\top {\\mathbf u}_i||^2.\n\nwhere {\\mathbf u}_i is the eigenvector corresponding to the eigenvalue \\lambda_i. - The term ({\\bf x}^\\top {\\mathbf u}_i) is a dot-product between the feature vector {\\bf x} and the eigenvector {\\mathbf u}_i, which measures how much {\\bf x} coheres with eigenvector {\\mathbf u}_i, similar to how Fourier coefficients measure coherency with sinusoids. - Each ||{\\bf x}^\\top {\\mathbf u}_i||^2 is the ‘’strength’’ of {\\bf x} with respect to the eigenvector {\\mathbf u}_i, and the total variation J is a weighted sum of these strengths.\nSome eigenvectors correspond to low-frequency components, while others correspond to high-frequency components. For example, the total variation J for an eigenvector {\\mathbf u}_i is given by\n\nJ = \\frac{1}{2} \\sum_{j}\\sum_{\\ell} A_{j\\ell}(u_{ij} - u_{i\\ell})^2 = {\\mathbf u}_i^\\top {\\mathbf L} {\\mathbf u}_i = \\lambda_i.\n\nThis equation provides key insight into the meaning of eigenvalues:\n\nFor an eigenvector {\\mathbf u}_i, its eigenvalue \\lambda_i measures the total variation for {\\mathbf u}_i.\nLarge eigenvalues mean large differences between neighbors (high frequency), while small eigenvalues mean small differences (low frequency).\n\nThus, if {\\bf x} aligns well with {\\mathbf u}_i with a large \\lambda_i, then {\\bf x} has a strong high-frequency component; if {\\bf x} aligns well with {\\mathbf u}_i with a small \\lambda_i, then {\\bf x} has strong low-frequency component.\n\nSpectral Filtering\nEigenvalues \\lambda_i can be thought of as a filter that controls which frequency components pass through. Instead of using the filter associated with the Laplacian matrix, we can design a filter h(\\lambda_i) to control which frequency components pass through. This leads to the idea of spectral filtering. Two common filters are:\n\nLow-pass Filter: h_{\\text{low}}(\\lambda) = \\frac{1}{1 + \\alpha\\lambda}\n\nPreserves low frequencies (small λ)\nSuppresses high frequencies (large λ)\nResults in smoother signals\n\nHigh-pass Filter: h_{\\text{high}}(\\lambda) = \\frac{\\alpha\\lambda}{1 + \\alpha\\lambda}\n\nPreserves high frequencies\nSuppresses low frequencies\nEmphasizes differences between neighbors\n\n\n\n:tags: [remove-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context(\"talk\")\n\nalpha = 1\nlambdas = np.linspace(0, 10, 100)\nh_low = 1 / (1 + alpha * lambdas)\nh_high = (alpha * lambdas) / (1 + alpha * lambdas)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\nsns.lineplot(x=lambdas, y=h_low, label=\"Low-pass filter\", ax=axes[0])\naxes[0].legend(frameon=False).remove()\nsns.lineplot(x=lambdas, y=h_high, label=\"High-pass filter\", ax=axes[1])\naxes[1].legend(frameon=False).remove()\naxes[0].set_title(\"Low-pass filter\")\naxes[1].set_title(\"High-pass filter\")\nfig.text(0.5, 0.01, \"Eigenvalue $\\lambda$\", ha=\"center\")\naxes[0].set_ylabel(\"Filter response $h(\\lambda)$\")\nsns.despine()\nplt.tight_layout()\n\n\n\nExample\nLet us showcase the idea of spectral filtering with a simple example with the karate club network.\n\n:tags: [remove-input]\nimport igraph as ig\nimport numpy as np\nfrom scipy import sparse\nimport matplotlib as mpl\n\nG = ig.Graph.Famous(\"Zachary\")\nA = G.get_adjacency_sparse()\n\nWe will first compute the laplacian matrix and its eigendecomposition.\n\n# Compute Laplacian matrix\ndeg = np.array(A.sum(axis=1)).reshape(-1)\nD = sparse.diags(deg)\nL = D - A\n\n# Compute eigendecomposition\nevals, evecs = np.linalg.eigh(L.toarray())\n\n# Sort eigenvalues and eigenvectors\norder = np.argsort(evals)\nevals = evals[order]\nevecs = evecs[:, order]\n\nNow, let’s create a low-pass and high-pass filter.\n\nalpha = 2\nL_low = evecs @ np.diag(1 / (1 + alpha * evals)) @ evecs.T\nL_high = evecs @ np.diag(alpha * evals / (1 + alpha * evals)) @ evecs.T\n\nprint(\"Size of low-pass filter:\", L_low.shape)\nprint(\"Size of high-pass filter:\", L_high.shape)\n\nNotice that the high-pass filter and low-pass filter are matrices of the same size as the adjacency matrix A, which defines a ‘convolution’ on the graph as follows:\n\n{\\bf x}' = {\\bf L}_{\\text{low}} {\\bf x} \\quad \\text{or} \\quad {\\bf x}' = {\\bf L}_{\\text{high}} {\\bf x}.\n\nwhere {\\bf L}_{\\text{low}} and {\\bf L}_{\\text{high}} are the low-pass and high-pass filters, respectively, and {\\bf x}' is the convolved feature vector.\nNow, let’s see how these filters work. Our first example is a random feature vector.\n\n# Random feature vector\nx = np.random.randn(A.shape[0], 1)\n\n# Convolve with low-pass filter\nx_low = L_low @ x\n\n# Convolve with high-pass filter\nx_high = L_high @ x\n\nLet us visualize the results.\n\n:tags: [hide-input]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\nnorm = mpl.colors.Normalize(vmin=-0.3, vmax=0.3)\n\n# Original\nvalues = x.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\n# Low-pass filter applied\nvalues = L_low @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\n# High-pass filter applied\nvalues = L_high @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\nWe observe that the low-pass filter results in smoother {\\bf x} between connected nodes (i.e., neighboring nodes have similar {\\bf x}). The original {\\bf x} and {\\bf x}'_{\\text{low}} are very similar because random variables are high-frequency components. In contrast, when we apply the high-pass filter, {\\bf x}'_{\\text{high}} is similar to {\\bf x} because the high-frequency components are not filtered.\nLet’s now use an eigenvector as our feature vector {\\bf x}.\n\n:tags: [hide-input]\neigen_centrality = np.array(G.eigenvector_centrality()).reshape(-1, 1)\nlow_pass_eigen = L_low @ eigen_centrality\nhigh_pass_eigen = L_high @ eigen_centrality\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\n\nnorm = mpl.colors.Normalize(vmin=-0, vmax=0.3)\nvalues = eigen_centrality.reshape(-1)# high_pass_random.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\nvalues = low_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\nvalues = high_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\nThe high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality."
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html",
    "href": "m09-graph-neural-networks/03-exercises.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\nThe pen and paper exercises cover fundamental concepts including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: note\nLet’s implement a simple GCN model for node classification. Coding Exercise\n\n\nThis coding exercise will guide you through:\n\nBuilding a GCN from Scratch: Implementing the basic GCN layer\nNode Classification: Training GCN for semi-supervised node classification\nSpectral Filtering: Understanding how GCNs relate to spectral graph theory\nComparison with Other Methods: Benchmarking against traditional approaches\n\n\n\n\nThrough these exercises, you will:\n\nUnderstand the Mathematics: Connect spectral graph theory to practical GNN implementations\nImplement Core Algorithms: Build GCN, GraphSAGE, GAT, and GIN from fundamental principles\nApply to Real Problems: Use GNNs for node classification, graph classification, and link prediction\nAnalyze Performance: Compare different GNN architectures and understand their strengths/weaknesses\nDebug and Optimize: Learn common pitfalls and optimization strategies for GNNs\n\n\n\n\n\nBasic GCN Implementation\n\nImplement the GCN layer forward pass\nAdd self-loops and normalization\nTrain on Cora dataset for node classification\n\nSpectral Analysis\n\nVisualize graph spectra and eigenvectors\nImplement spectral filtering\nCompare low-pass vs high-pass filters\n\nAdvanced Architectures\n\nImplement GraphSAGE with different aggregators\nBuild GAT with attention visualization\nCreate GIN and test on graph isomorphism\n\nPractical Applications\n\nSocial network analysis\nCitation network node classification\nMolecular property prediction\n\n\nThese exercises bridge theory and practice, ensuring you understand both the mathematical foundations and practical implementation details of Graph Neural Networks.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html#theoretical-exercises",
    "href": "m09-graph-neural-networks/03-exercises.html#theoretical-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\nThe pen and paper exercises cover fundamental concepts including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html#programming-exercises",
    "href": "m09-graph-neural-networks/03-exercises.html#programming-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Exercise\n\n\n\n:class: note\nLet’s implement a simple GCN model for node classification. Coding Exercise\n\n\nThis coding exercise will guide you through:\n\nBuilding a GCN from Scratch: Implementing the basic GCN layer\nNode Classification: Training GCN for semi-supervised node classification\nSpectral Filtering: Understanding how GCNs relate to spectral graph theory\nComparison with Other Methods: Benchmarking against traditional approaches\n\n\n\n\nThrough these exercises, you will:\n\nUnderstand the Mathematics: Connect spectral graph theory to practical GNN implementations\nImplement Core Algorithms: Build GCN, GraphSAGE, GAT, and GIN from fundamental principles\nApply to Real Problems: Use GNNs for node classification, graph classification, and link prediction\nAnalyze Performance: Compare different GNN architectures and understand their strengths/weaknesses\nDebug and Optimize: Learn common pitfalls and optimization strategies for GNNs\n\n\n\n\n\nBasic GCN Implementation\n\nImplement the GCN layer forward pass\nAdd self-loops and normalization\nTrain on Cora dataset for node classification\n\nSpectral Analysis\n\nVisualize graph spectra and eigenvectors\nImplement spectral filtering\nCompare low-pass vs high-pass filters\n\nAdvanced Architectures\n\nImplement GraphSAGE with different aggregators\nBuild GAT with attention visualization\nCreate GIN and test on graph isomorphism\n\nPractical Applications\n\nSocial network analysis\nCitation network node classification\nMolecular property prediction\n\n\nThese exercises bridge theory and practice, ensuring you understand both the mathematical foundations and practical implementation details of Graph Neural Networks.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/word2vec.html",
    "href": "m08-embedding/word2vec.html",
    "title": "word2vec",
    "section": "",
    "text": "In this section, we will introduce word2vec, a powerful technique for learning word embeddings. word2vec is a neural network model that learns words embeddings in a continuous vector space. It was introduced by Tomas Mikolov and his colleagues at Google in 2013 {footcite}mikolov2013distributed."
  },
  {
    "objectID": "m08-embedding/word2vec.html#how-it-works",
    "href": "m08-embedding/word2vec.html#how-it-works",
    "title": "word2vec",
    "section": "1 How it works",
    "text": "1 How it works\n“You shall know a word by the company it keeps” {footcite}church1988word is a famous quote in linguistics. It means that you can understand the meaning of a word by looking at the words that appear in the same context. word2vec operates on the same principle. word2vec identifies a word’s context by examining the words within a fixed window around it. For example, in the sentence:\n\nThe quick brown fox jumps over a lazy dog\n\nThe context of the word fox includes quick, brown, jumps, over, and lazy. word2vec is trained to predict which words are likely to appear as the context of an input word.\nThere are two main architectures for word2vec:\n1. **Continuous Bag of Words (CBOW)**: Predicts the target word (center word) from the context words (surrounding words).\n2. **Skip-gram**: Predicts the context words (surrounding words) from the target word (center word).\nSo how are word embeddings learned? word2vec is a neural network model that looks like a bow tie. It has two layers of the vocabulary size coupled with a much smaller hidden layer.\n\n\nInput layer: The input layer consists of N neurons, where N is the size of the vocabulary (i.e., the number of unique words in the corpus). Each neuron corresponds to a unique word in the vocabulary. When a word is inputted, its corresponding neuron is activated and the other neurons are inhibited. Thus, the input layer is essentially a lookup mechanism that transforms the input word into a corresponding one-hot vector.\nOutput layer: The output layer also consists of N neurons, each corresponding to a unique word in the vocabulary. Unlike the input layer, multiple neurons can be activated for a single input. The strength of the activation of each neuron (with a normalization by the softmax function) represents the probability of the corresponding word being the input word’s context.\nHidden layer: The hidden layer is much smaller than the input and output layers. Multiple neurons in the hidden layer can be activated for a single input, and this activation pattern represents the word’s embedding.\n\nWe can consider word2vec as a dimensionality reduction technique that reduces the dimensionality of the input layer to the hidden layer based on the co-occurrence of words within a short distance. The distance is named the window size, which is a user-defined hyperparameter."
  },
  {
    "objectID": "m08-embedding/word2vec.html#whats-special-about-word2vec",
    "href": "m08-embedding/word2vec.html#whats-special-about-word2vec",
    "title": "word2vec",
    "section": "2 What’s special about word2vec?",
    "text": "2 What’s special about word2vec?\nWith word2vec, words are represented as dense vectors, enabling us to explore their relationships using simple linear algebra. This is in contrast to traditional natural language processing (NLP) methods, such as bag-of-words and topic modeling, which represent words as discrete units or high-dimensional vectors.\n\nTo showcase the effectiveness of word2vec, let’s walk through an example using the gensim library.\n\nimport gensim\nimport gensim.downloader\nfrom gensim.models import Word2Vec\n\n# Load pre-trained word2vec model from Google News\nmodel = gensim.downloader.load('word2vec-google-news-300')\n\nOur first example is to find the words most similar to king.\n\n# Example usage\nword = \"king\"\nsimilar_words = model.most_similar(word)\nprint(f\"Words most similar to '{word}':\")\nfor similar_word, similarity in similar_words:\n    print(f\"{similar_word}: {similarity:.4f}\")\n\nA cool (yet controversial) application of word embeddings is analogy solving. Let us consider the following puzzle:\n\nman is to woman as king is to ___ ?\n\nWe can use word embeddings to solve this puzzle.\n\n# We solve the puzzle by\n#\n#  vec(king) - vec(man) + vec(woman)\n#\n# To solve this, we use the model.most_similar function, with positive words being \"king\" and \"woman\" (additive), and negative words being \"man\" (subtractive).\n#\nmodel.most_similar(positive=['woman', \"king\"], negative=['man'], topn=5)\n\nThe last example is to visualize the word embeddings.\n\n:tags: [hide-input]\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ncountries = ['Germany', 'France', 'Italy', 'Spain', 'Portugal', 'Greece']\ncapital_words = ['Berlin', 'Paris', 'Rome', 'Madrid', 'Lisbon', 'Athens']\n\n# Get the word embeddings for the countries and capitals\ncountry_embeddings = np.array([model[country] for country in countries])\ncapital_embeddings = np.array([model[capital] for capital in capital_words])\n\n# Compute the PCA\npca = PCA(n_components=2)\nembeddings = np.vstack([country_embeddings, capital_embeddings])\nembeddings_pca = pca.fit_transform(embeddings)\n\n# Create a DataFrame for seaborn\ndf = pd.DataFrame(embeddings_pca, columns=['PC1', 'PC2'])\ndf['Label'] = countries + capital_words\ndf['Type'] = ['Country'] * len(countries) + ['Capital'] * len(capital_words)\n\n# Plot the data\nplt.figure(figsize=(12, 10))\n\n# Create a scatter plot with seaborn\nscatter_plot = sns.scatterplot(data=df, x='PC1', y='PC2', hue='Type', style='Type', s=200, palette='deep', markers=['o', 's'])\n\n# Annotate the points\nfor i in range(len(df)):\n    plt.text(df['PC1'][i], df['PC2'][i] + 0.08, df['Label'][i], fontsize=12, ha='center', va='bottom',\n             bbox=dict(facecolor='white', edgecolor='none', alpha=0.8))\n\n# Draw arrows between countries and capitals\nfor i in range(len(countries)):\n    plt.arrow(df['PC1'][i], df['PC2'][i], df['PC1'][i + len(countries)] - df['PC1'][i], df['PC2'][i + len(countries)] - df['PC2'][i],\n              color='gray', alpha=0.6, linewidth=1.5, head_width=0.02, head_length=0.03)\n\nplt.legend(title='Type', title_fontsize='13', fontsize='11')\nplt.title('PCA of Country and Capital Word Embeddings', fontsize=16)\nplt.xlabel('Principal Component 1', fontsize=14)\nplt.ylabel('Principal Component 2', fontsize=14)\nax = plt.gca()\nax.set_axis_off()\n\nWe can see that word2vec places the words representing countries close to each other and so do the words representing their capitals. The country-capital relationship is also roughly preserved, e.g., Germany-Berlin vector is roughly parallel to France-Paris vector."
  },
  {
    "objectID": "m08-embedding/graph-embedding-w-word2vec.html",
    "href": "m08-embedding/graph-embedding-w-word2vec.html",
    "title": "Graph embedding with word2vec",
    "section": "",
    "text": "How can we apply word2vec to graph data? There is a critical challenge: word2vec takes sequence of words as input, while graph data are discrete and unordered. A solution to fill this gap is random walk, which transforms graph data into a sequence of nodes. Once we have a sequence of nodes, we can treat it as a sequence of words and apply word2vec."
  },
  {
    "objectID": "m08-embedding/graph-embedding-w-word2vec.html#deepwalk",
    "href": "m08-embedding/graph-embedding-w-word2vec.html#deepwalk",
    "title": "Graph embedding with word2vec",
    "section": "1 DeepWalk",
    "text": "1 DeepWalk\n\nDeepWalk is one of the pioneering works to apply word2vec to graph data {footcite}perozzi2014deepwalk. It views the nodes as words and the nodes random walks on the graph as sentences, and applies word2vec to learn the node embeddings.\nMore specifically, the method contains the following steps:\n\nSample multiple random walks from the graph.\nTreat the random walks as sentences and feed them to word2vev to learn the node embeddings.\n\nThere are some technical details that we need to be aware of, which we will learn by implementing DeepWalk in the following exercise.\n\nExercise 01: Implement DeepWalk\nIn this exercise, we implement DeepWalk step by step.\n\n\nStep 1: Data preparation\nWe will use the karate club network as an example.\nLoad the data\n\n:tags: [hide-input]\n\nimport igraph\nimport networkx as nx\nimport numpy as np\nimport seaborn as sns\n\ng = igraph.Graph.Famous(\"Zachary\")\nA = g.get_adjacency_sparse()\n\n# Add the community labels to the nodes for visualization\ng.vs[\"label\"] = np.unique([d[1]['club'] for d in nx.karate_club_graph().nodes(data=True)], return_inverse=True)[1]\n\npalette = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[palette[label] for label in g.vs[\"label\"]], bbox=(300, 300))\n\n\n\nStep 2: Generate random walks\nNext, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network. Let us first implement a function to sample random walks from a given network.\n\ndef random_walk(net, start_node, walk_length):\n    # Initialize the walk with the starting node\n    walk = [start_node]\n\n    # Continue the walk until the desired length is reached\n    while len(walk) &lt; walk_length:\n        # Get the current node (the last node in the walk)\n        cur = walk[-1]\n\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n\n        # If the current node has neighbors, randomly choose one and add it to the walk\n        if len(cur_nbrs) &gt; 0:\n            walk.append(np.random.choice(cur_nbrs))\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    # Return the generated walk\n    return walk\n\nGenerate 10 random walks of length 50 starting from each node.\n\nn_nodes = g.vcount()\nn_walkers_per_node = 10\nwalk_length = 50\nwalks = []\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(random_walk(A, i, walk_length))\n\n\n\nStep 3: Train the word2vec model\nThen, we feed the random walks to the word2vec model.\n\nfrom gensim.models import Word2Vec\n\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\nHere,\n\nvector_size is the dimension of the embedding vectors.\nwindow indicates the maximum distance between a word and its context words. For example, in the random walk [0, 1, 2, 3, 4, 5, 6, 7], the context words of node 2 are [0, 1, 3, 4, 5] when window=3.\nmin_count is the minimum number of times a word must appear in the training data to be included in the vocabulary.\n\nTwo parameters sg=1 and hs=1 indicate that we are using the skip-gram model with negative sampling. Let us understand what they mean in detail as follows.\n\nSkip-gram model: it trains word2vec by predicting context words given a target word. For example, given the sentence “The quick brown fox jumps over the lazy dog”, in the skip-gram model, given the target word “fox”, the model will try to predict the context words “quick”, “brown”, “jumps”, and “over”. If sg=0, the input and output are swapped: the model will predict the target word from the context words, e.g., given the context words “quick”, “brown”, “jumps”, and “over”, the model will predict the target word “fox”.\nHierarchical softmax: To understand hierarchical softmax better, let’s break down how the word2vec model works. The goal of word2vec is to predict context words given a target word. For example, if our target word is w_t and our context word is w_c, we want to find the probability of w_c given w_t. This probability is calculated using the softmax function:\n\n  P(w_c | w_t) = \\frac{\\exp(\\mathbf{v}_{w_c} \\cdot \\mathbf{v}_{w_t})}{\\sum_{w \\in V} \\exp(\\mathbf{v}_w \\cdot \\mathbf{u}_{w_t})}\n\nHere, \\mathbf{v}_w and \\mathbf{u}_w represent the vector for word w as context and target respectively, and V is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!\nHierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.\n\n\nBy using the skip-gram model with hierarchical softmax, we can efficiently learn high-quality word embeddings even when dealing with large vocabularies.\nNow, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the wv attribute. The embedding of node i is given by model.wv[i].\n\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\nembedding is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.\nPrint the first 3 nodes\n\n:tags: [hide-input]\n\nembedding[:3]\n\nLet’s visualize the node embeddings using UMAP.\n\n:tags: [hide-input]\nimport umap\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource, HoverTool\n\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nshow(p)\n\n\n\nStep 4: Clustering\nOne of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as K-means and Gaussian mixture model. Let’s see what we can get from the node embeddings.\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Determine the optimal number of clusters using the silhouette score\ndef Kmeans_with_silhouette(embedding, n_clusters_range=(2, 10)):\n    silhouette_scores = []\n\n    # Iterate over a range of cluster numbers from 2 to 9\n    for n_clusters in range(*n_clusters_range):\n        # Create a KMeans object with the current number of clusters\n        kmeans = KMeans(n_clusters=n_clusters)\n\n        # Fit the KMeans model to the embedding data\n        kmeans.fit(embedding)\n\n        # Calculate the silhouette score for the current clustering\n        score = silhouette_score(embedding, kmeans.labels_)\n\n        # Append the number of clusters and its corresponding silhouette score to the list\n        silhouette_scores.append((n_clusters, score))\n\n    # Find the number of clusters that has the highest silhouette score\n    optimal_n_clusters = max(silhouette_scores, key=lambda x: x[1])[0]\n\n    # Create a KMeans object with the optimal number of clusters\n    kmeans = KMeans(n_clusters=optimal_n_clusters)\n\n    # Fit the KMeans model to the embedding data with the optimal number of clusters\n    kmeans.fit(embedding)\n\n    # Return the labels (cluster assignments) for each data point\n    return kmeans.labels_\n\n\nimport seaborn as sns\nlabels = Kmeans_with_silhouette(embedding)\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500))"
  },
  {
    "objectID": "m08-embedding/graph-embedding-w-word2vec.html#node2vec",
    "href": "m08-embedding/graph-embedding-w-word2vec.html#node2vec",
    "title": "Graph embedding with word2vec",
    "section": "2 node2vec",
    "text": "2 node2vec\nnode2vec is a sibling of DeepWalk proposed by {footcite}grover2016node2vec. Both use word2vec trained on random walks on networks. So, it appears that they are very similar. However, the following two components make them very different.\n\nBiased random walk: node2vec uses biased random walks that can move in different directions. The bias walk is parameterized by two parameters, p and q:\n\n  P(v_{t+1} = x | v_t = v, v_{t-1} = t) \\propto\n  \\begin{cases}\n  \\frac{1}{p} & \\text{if } d(v,t) = 0 \\\\\n  1 & \\text{if } d(v,t) = 1 \\\\\n  \\frac{1}{q} & \\text{if } d(v,t) = 2 \\\\\n  \\end{cases}\n  \nwhere d(v,x) is the shortest path distance between node v and x. A smaller p leads to more biased towards the previous node, v_{t-1} = t. A smaller q leads to more biased towards the nodes that are further away from the previous node, v_{t-1} = t.\nBy adjusting the parameters p and q, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).\n\nBreadth-First Sampling (BFS): This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.\nDepth-First Sampling (DFS): This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.\n\n\nThe embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.\n\nNegative sampling: node2vec uses negative sampling, instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to {footcite}kojaku2021neurips and {footcite}dyer2014notes for more details.\n\n\nExercise 02: Implement node2vec\nLet’s implement the biased random walk for node2vec\n\ndef node2vec_random_walk(net, start_node, walk_length, p, q):\n    \"\"\"\n    Sample a random walk starting from start_node.\n    \"\"\"\n    # Initialize the walk with the start_node\n    walk = [start_node]\n\n    # Continue the walk until it reaches the desired length\n    while len(walk) &lt; walk_length:\n        # Get the current node in the walk\n        cur = walk[-1]\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n        # Check if the current node has any neighbors\n        if len(cur_nbrs) &gt; 0:\n            # If the walk has just started, randomly choose the next node from the neighbors\n            if len(walk) == 1:\n                walk.append(np.random.choice(cur_nbrs))\n            else:\n                # Get the previous node in the walk\n                prev = walk[-2]\n                # Use the alias sampling method to choose the next node based on the bias parameters p and q\n                next_node = alias_sample(net, cur_nbrs, prev, p, q)\n                # Append the chosen next node to the walk\n                walk.append(next_node)\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    return walk\n\ndef alias_sample(net, neighbors, prev, p, q):\n    \"\"\"\n    Helper function to sample the next node in the walk.\n    \"\"\"\n    # Implement the logic to sample the next node based on the bias parameters p and q\n    # You can use the formula provided in the instructions to calculate the probabilities\n    # and then sample the next node accordingly.\n    # Initialize an empty list to store the unnormalized probabilities for each neighbor\n    unnormalized_probs = []\n\n    # Iterate over each neighbor of the current node\n    for neighbor in neighbors:\n        # If the neighbor is the same as the previous node in the walk\n        if neighbor == prev:\n            # Append the probability 1/p to the unnormalized probabilities list\n            unnormalized_probs.append(1 / p)\n        # If the neighbor is connected to the previous node in the walk\n        elif neighbor in net[prev].indices:\n            # Append the probability 1 to the unnormalized probabilities list\n            unnormalized_probs.append(1)\n        # If the neighbor is not connected to the previous node in the walk\n        else:\n            # Append the probability 1/q to the unnormalized probabilities list\n            unnormalized_probs.append(1 / q)\n\n    # Calculate the normalization constant by summing all unnormalized probabilities\n    norm_const = sum(unnormalized_probs)\n\n    # Normalize the probabilities by dividing each unnormalized probability by the normalization constant\n    normalized_probs = [float(prob) / norm_const for prob in unnormalized_probs]\n\n    # Randomly choose the next node from the neighbors based on the normalized probabilities\n    next_node = np.random.choice(neighbors, size=1, p=normalized_probs)[0]\n\n    # Return the chosen next node\n    return next_node\n\nNow, let’s set up the word2vec model for node2vec.\n\nwalks = []\np = 1\nq = 0.1\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(node2vec_random_walk(A, i, walk_length, p, q))\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\nwhere hs=0 indicates that we are using negative sampling. Notice that we set sg=1 and hs=1 instead of sg=1 and hs=0 in DeepWalk. This is because node2vec uses the skip-gram model with negative sampling.\nNow, we extract the node embeddings from the word2vec model.\n\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\nLet’s visualize the node embeddings from node2vec.\n\n:tags: [hide-input]\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]],\n    name = [str(i) for i in range(n_nodes)]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nhover = HoverTool()\nhover.tooltips = [\n    (\"Name\", \"@name\"),\n    (\"Community\", \"@community\")\n]\np.add_tools(hover)\n\nshow(p)\n\nThe results for clustering are as follows:\n\nimport seaborn as sns\n\nlabels = Kmeans_with_silhouette(embedding)\n\n\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500), vertex_label=[\"%d\" %  d for d in  np.arange(n_nodes)])"
  },
  {
    "objectID": "m08-embedding/graph-embedding-w-word2vec.html#line",
    "href": "m08-embedding/graph-embedding-w-word2vec.html#line",
    "title": "Graph embedding with word2vec",
    "section": "3 LINE",
    "text": "3 LINE\nLINE {footcite}tang2015line is another pioneering work to learn node embeddings by directly optimizing the graph structure. It is equivalent to node2vec with p=1, q=1, and window size 1."
  },
  {
    "objectID": "m07-random-walks/random-walks-math.html",
    "href": "m07-random-walks/random-walks-math.html",
    "title": "Characteristics of Random Walks",
    "section": "",
    "text": "Let’s dive into the math behind random walks in a way that’s easy to understand.\nImagine you’re at node i at time t. You randomly move to a neighboring node j. The probability of this move, called the transition probability p_{ij}, is:\n\np_{ij} = \\frac{A_{ij}}{k_i},\n\nHere, A_{ij} is an element of the adjacency matrix, and k_i is the degree of node i. For a network with N nodes, we can represent all transition probabilities in a transition probability matrix P:\n\n\\mathbf{P} = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1N} \\\\\np_{21} & p_{22} & \\cdots & p_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{N1} & p_{N2} & \\cdots & p_{NN}\n\\end{pmatrix}\n\nThis matrix P encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps. For instance:\n\nAfter one step: P_{ij} = p_{ij}\nAfter two steps: \\left(\\mathbf{P}^{2}\\right)_{ij} = \\sum_{k} P_{ik} P_{kj}\nAfter T steps: \\left(\\mathbf{P}^{T}\\right)_{ij}\n\nLet's explore why $\\mathbf{P}^2$ represents the transition probabilities after two steps.\n\nFirst, recall that $\\mathbf{P}_{ij}$ is the probability of moving from node $i$ to node $j$ in one step. Now, consider a two-step walk from $i$ to $j$. We can express this as:\n\n$$(\\mathbf{P}^2)_{ij} = \\sum_k \\mathbf{P}_{ik} \\mathbf{P}_{kj}$$\n\nThis equation encapsulates a key idea: to go from $i$ to $j$ in two steps, we must pass through some intermediate node $k$. Let's break this down step by step:\n\n1. The probability of the first step ($i$ to $k$) is $\\mathbf{P}_{ik}$.\n2. The probability of the second step ($k$ to $j$) is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ → $k$ → $j$) is the product $\\mathbf{P}_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nLikewise, for three steps, we have:\n\n$$(\\mathbf{P}^3)_{ij} = \\sum_k \\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$$\n\nwhere:\n1. The probability of going from $i$ to $k$ in two steps is $\\left( \\mathbf{P}\\right)^2_{ik}$.\n2. The probability of going from $k$ to $j$ in one step is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ →...→$k$ → $j$) is the product $\\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nAnd we can extend this reasoning for any number of steps $t$.\n\nIn summary, for any number of steps $t$, $\\left( \\mathbf{P}^t \\right)_{ij}$ gives the probability of being at node $j$ after $t$ steps, starting from node $i$.\n\nAs T becomes very large, the probability distribution of being at each node, \\mathbf{x}(t), approaches a constant value:\n\n\\mathbf{x}(t+1) =\\mathbf{x}(t) \\mathbf{P}\n\nThis is an eigenvector equation. The solution, given by the Perron-Frobenius theorem, is called the stationary distribution:\n\n\\mathbf{x}(\\infty) = \\mathbb{\\pi}, \\; \\mathbf{\\pi} = [\\pi_1, \\ldots, \\pi_N]\n\nFor undirected networks, this stationary distribution always exists and is proportional to the degree of each node:\n\n\\pi_j = \\frac{k_j}{\\sum_{\\ell} k_\\ell} \\propto k_j\n\nThis means the probability of being at node j in the long run is proportional to the degree of node j. The normalization ensures that the sum of all probabilities is 1, i.e., \\sum_{j=1}^N \\pi_j = 1."
  },
  {
    "objectID": "m07-random-walks/random-walks-math.html#stationary-state",
    "href": "m07-random-walks/random-walks-math.html#stationary-state",
    "title": "Characteristics of Random Walks",
    "section": "",
    "text": "Let’s dive into the math behind random walks in a way that’s easy to understand.\nImagine you’re at node i at time t. You randomly move to a neighboring node j. The probability of this move, called the transition probability p_{ij}, is:\n\np_{ij} = \\frac{A_{ij}}{k_i},\n\nHere, A_{ij} is an element of the adjacency matrix, and k_i is the degree of node i. For a network with N nodes, we can represent all transition probabilities in a transition probability matrix P:\n\n\\mathbf{P} = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1N} \\\\\np_{21} & p_{22} & \\cdots & p_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{N1} & p_{N2} & \\cdots & p_{NN}\n\\end{pmatrix}\n\nThis matrix P encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps. For instance:\n\nAfter one step: P_{ij} = p_{ij}\nAfter two steps: \\left(\\mathbf{P}^{2}\\right)_{ij} = \\sum_{k} P_{ik} P_{kj}\nAfter T steps: \\left(\\mathbf{P}^{T}\\right)_{ij}\n\nLet's explore why $\\mathbf{P}^2$ represents the transition probabilities after two steps.\n\nFirst, recall that $\\mathbf{P}_{ij}$ is the probability of moving from node $i$ to node $j$ in one step. Now, consider a two-step walk from $i$ to $j$. We can express this as:\n\n$$(\\mathbf{P}^2)_{ij} = \\sum_k \\mathbf{P}_{ik} \\mathbf{P}_{kj}$$\n\nThis equation encapsulates a key idea: to go from $i$ to $j$ in two steps, we must pass through some intermediate node $k$. Let's break this down step by step:\n\n1. The probability of the first step ($i$ to $k$) is $\\mathbf{P}_{ik}$.\n2. The probability of the second step ($k$ to $j$) is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ → $k$ → $j$) is the product $\\mathbf{P}_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nLikewise, for three steps, we have:\n\n$$(\\mathbf{P}^3)_{ij} = \\sum_k \\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$$\n\nwhere:\n1. The probability of going from $i$ to $k$ in two steps is $\\left( \\mathbf{P}\\right)^2_{ik}$.\n2. The probability of going from $k$ to $j$ in one step is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ →...→$k$ → $j$) is the product $\\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nAnd we can extend this reasoning for any number of steps $t$.\n\nIn summary, for any number of steps $t$, $\\left( \\mathbf{P}^t \\right)_{ij}$ gives the probability of being at node $j$ after $t$ steps, starting from node $i$.\n\nAs T becomes very large, the probability distribution of being at each node, \\mathbf{x}(t), approaches a constant value:\n\n\\mathbf{x}(t+1) =\\mathbf{x}(t) \\mathbf{P}\n\nThis is an eigenvector equation. The solution, given by the Perron-Frobenius theorem, is called the stationary distribution:\n\n\\mathbf{x}(\\infty) = \\mathbb{\\pi}, \\; \\mathbf{\\pi} = [\\pi_1, \\ldots, \\pi_N]\n\nFor undirected networks, this stationary distribution always exists and is proportional to the degree of each node:\n\n\\pi_j = \\frac{k_j}{\\sum_{\\ell} k_\\ell} \\propto k_j\n\nThis means the probability of being at node j in the long run is proportional to the degree of node j. The normalization ensures that the sum of all probabilities is 1, i.e., \\sum_{j=1}^N \\pi_j = 1."
  },
  {
    "objectID": "m07-random-walks/random-walks-math.html#experiment",
    "href": "m07-random-walks/random-walks-math.html#experiment",
    "title": "Characteristics of Random Walks",
    "section": "2 Experiment",
    "text": "2 Experiment\nLet us demonstrate the above math by using a small network using Python. Let us consider a small network of 5 nodes, which looks like this:\n\nimport igraph as ig\nimport numpy as np\nedge_list = []\nfor i in range(5):\n    for j in range(i+1, 5):\n        edge_list.append((i, j))\n        edge_list.append((i+5, j+5))\nedge_list.append((0, 6))\n\ng = ig.Graph(edge_list)\nig.plot(g, vertex_size=20, vertex_label=np.arange(g.vcount()))\n\nThe transition probability matrix P is given by:\n\nimport scipy.sparse as sparse\n\nA = g.get_adjacency_sparse()\ndeg = np.array(A.sum(axis=1)).flatten()\nDinv = sparse.diags(1/deg)\nP = Dinv @ A\nP.toarray()\n\nLet us compute the stationary distribution by using the power method.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.zeros(g.vcount())\nx[1] = 1 # Start from node 1\nT = 100\nxt = []\nfor t in range(T):\n    x = x.reshape(1, -1) @ P\n    xt.append(x)\n\nxt = np.vstack(xt) # Stack the results vertically\n\nfig, ax = plt.subplots(figsize=(7,5))\npalette = sns.color_palette().as_hex()\nfor i in range(g.vcount()):\n    sns.lineplot(x=range(T), y=xt[:, i], label=f\"Node {i}\", ax=ax, color=palette[i])\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Probability\")\nax.set_title(\"Stationary distribution of a random walk\")\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\nWe see that the distributions of the walker converges, and there are three characteristic features in the convergence: 1. The distribution of the walker occilates with a decying amplitude and eventually converges. 2. Nodes of the same degree converge to the same stationary probability. 3. Nodes with higher degree converge to the higher stationary probability.\nTo validate the last two observation, let us compare the stationary distribution of a random walker with the expected stationary distribution, which is proportional to the degree of the nodes.\n\nimport pandas as pd\n\nn_edges = np.sum(deg) / 2\nexpected_stationary_dist = deg / (2 * n_edges)\n\npd.DataFrame({\n    \"Expected stationary distribution\": expected_stationary_dist,\n    \"Stationary distribution of a random walk\": xt[-1].flatten()\n}).style.format(\"{:.4f}\").set_caption(\"Comparison of Expected and Observed Stationary Distributions\").background_gradient(cmap='cividis', axis = None)"
  },
  {
    "objectID": "m07-random-walks/random-walks-math.html#time-to-reach-the-stationary-state",
    "href": "m07-random-walks/random-walks-math.html#time-to-reach-the-stationary-state",
    "title": "Characteristics of Random Walks",
    "section": "3 Time to reach the stationary state",
    "text": "3 Time to reach the stationary state\nLet’s explore how quickly a random walker reaches its stationary state. The convergence speed is influenced by two main factors: edge density and community structure. In sparse networks, the walker needs more steps to explore the entire network. Additionally, the walker tends to remain within its starting community for some time.\nThe mixing time, denoted as t_{\\text{mix}}, is defined as the minimum number of steps required for a random walk to get close to the stationary distribution, regardless of the starting point, with the maximum error less than \\epsilon:\nt_{\\text{mix}} = \\min\\{t : \\max_{{\\bf x}(0)} \\|{\\bf x}(t) - {\\bf \\pi}\\|_{1} \\leq \\epsilon\\}\nwhere \\|{\\bf x}(t) - {\\bf \\pi}\\|_{1} = 2\\max_{i} |x_i(t) - \\pi_i| represents the L1 distance between two probability distributions. The choice of \\epsilon is arbitrary.\nWe know that the distribution of a walker after t steps is given by:\n\n\\mathbf{x}(t) =  \\mathbf{x}(0) \\mathbf{P} ^{t}\n\nTo find this distribution, we need to compute \\mathbf{P}^t. However, we face a challenge: \\mathbf{P} is not diagonalizable.\nA diagonalizable matrix \\mathbf{S} can be written as \\mathbf{S} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1}, where \\mathbf{\\Lambda} is a diagonal matrix and \\mathbf{Q} is an orthogonal matrix. Visually, it looks like this:\n\nIt is useful because we can then compute the power of the matrix as follows:\n\n\\mathbf{S}^t = \\mathbf{Q} \\mathbf{\\Lambda}^t \\mathbf{Q}^{-1}\n\nAnd it is easy to find {\\bf Q} and {\\bf \\Lambda} by using eigenvalue decomposition if {\\bf S} is symmetric and consists only of real values. Namely, the eigenvectors form {\\cal Q} and the eigenvalues form the diagonal matrix {\\cal \\Lambda}.\nLet us demonstrate the above relation by calculating $\\mathbf{S}^2$.\n$$\n\\begin{align}\n\\mathbf{S}^2 &= \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1} \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1} \\\\\n&= \\mathbf{Q} \\mathbf{\\Lambda}^2 \\mathbf{Q}^{-1}.\n\\end{align}\n$$\n(Note that $\\mathbf{Q} \\mathbf{Q}^{-1} = {\\bf I}$.)\n\n![](../figs/diagonalizable-squared.jpg)\n\n\\mathbf{P} is also diagonalizable but not symmetric like \\mathbf{\\overline A} so that we cannot use the above relation directly. So we do a trick by rewriteing \\mathbf{P} as:\n\n\\mathbf{P} = \\mathbf{D}^{-1} \\mathbf{A} = \\mathbf{D}^{-\\frac{1}{2}} \\overline {\\bf A} \\mathbf{D}^{\\frac{1}{2}}\n\nwhere \\overline{\\bf A} = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} is the normalized adjacency matrix.\nThe advantage is that \\overline{\\bf A} is diagonalizable: \\overline{\\bf A} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^\\top. Using this, we can compute \\mathbf{P}^t:\n\n\\mathbf{P}^t = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q} \\mathbf{\\Lambda}^t \\mathbf{Q}^\\top \\mathbf{D}^{\\frac{1}{2}} = \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R ^\\top\n\nwhere \\mathbf{Q}_L = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q} and \\mathbf{Q}_R = \\mathbf{D}^{\\frac{1}{2}} \\mathbf{Q}.\nLet us demonstrate the above relation by calculating $\\mathbf{P}^2$.\n\n$$\n\\begin{align}\n\\mathbf{P}^2 &= \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} \\mathbf{D}^{\\frac{1}{2}} \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} \\mathbf{D}^{\\frac{1}{2}}\\\\\n&=  \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} ^2 \\mathbf{D}^{\\frac{1}{2}}\\\\\n&= \\mathbf{Q}_L \\mathbf{\\Lambda}^2 \\mathbf{Q}_R ^\\top\n\\end{align}\nThe probability distribution after t steps is then:\n\n\\mathbf{x}(t) = \\mathbf{x}(0) \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R ^\\top\n\nWe can rewrite this in a more intuitive form:\n\n\\begin{pmatrix}\nx_1(t) \\\\\nx_2(t) \\\\\n\\vdots \\\\\nx_N(t)\n\\end{pmatrix}\n=\n\\sum_{\\ell=1}^N\n\\left[\n\\lambda_\\ell^t\n\\begin{pmatrix}\nq^{(L)}_{\\ell 1} \\\\\nq^{(L)}_{\\ell 2} \\\\\n\\vdots \\\\\nq^{(L)}_{\\ell N}\n\\end{pmatrix}\n\\langle\\mathbf{q}^{(R)}_{\\ell},  \\mathbf{x}(0) \\rangle\n\\right]\n\nVisualize the above equation by using the following figure.\n\n![](../figs/diagonalizable-sum.jpg)\n\nThe term \\lambda_\\ell^t represents the contribution of each eigenvalue to the stationary distribution over time. As t increases, all terms decay exponentially except for the largest eigenvalue (\\lambda_1 = 1). This explains how the random walk converges to the stationary distribution:\n\n\\pi_i = \\lim_{t\\to\\infty} x_i(t) = \\begin{pmatrix} q^{(L)}_{1 1} \\\\ q^{(L)}_{1 2} \\\\ \\vdots \\\\ q^{(L)}_{1 N} \\end{pmatrix} \\langle\\mathbf{q}^{(R)}_{1},  \\mathbf{x}(0) \\rangle\n\nThe second largest eigenvalue primarily determines the convergence speed to the stationary distribution. A larger second eigenvalue leads to slower convergence. Thus, the mixing time is closely related to the second largest eigenvalue.\nLevin-Peres-Wilmer theorem states that the mixing time is bounded by the relaxation time as\n\nt_{\\text{mix}} &lt; \\tau \\log \\left( \\frac{1}{\\epsilon \\min_{i} \\pi_i} \\right), \\quad \\tau = \\frac{1}{1-\\lambda_2}\n\nwhere \\lambda_2 is the second largest eigenvalue of the normalized adjacency matrix. The mixing time is known to be bounded by the relaxation time as\nMore commonly, it is expressed using the second smallest eigenvalue \\mu of the normalized laplacian matrix as\n\nt_{\\text{mix}} \\leq \\frac{1}{\\mu}\n\nwhere \\mu = 1-\\lambda_2.\n\nCompute the mixing time\nLet us demonstrate the above math by using the network of two cliques.\n\n\nNormalized Adjacency Matrix\nFirst, let us construct the normalized adjacency matrix \\overline{\\bf A} of the network.\n\nDinv_sqrt = sparse.diags(1.0/np.sqrt(deg))\nA_norm = Dinv_sqrt @ A @ Dinv_sqrt\n\nNext, let us compute the eigenvalues and eigenvectors of the normalized adjacency matrix.\n\nevals, evecs = np.linalg.eigh(A_norm.toarray())\n\n`evals` and `evecs` are sorted in descending order of the eigenvalues. `evecs[:, 0]` is the eigenvector corresponding to the largest eigenvalue, which is always 1.\nThere is a similar function called `np.linalg.eig` which returns the eigenvalues and eigenvectors. It can be used for any matrices, while `np.linalg.eigh` is specifically for symmetric matrices. `np.linalg.eigh` is faster and more stable and therefore preferred if your matrix is symmetric. `np.linalg.eig` is more susceptible to numerical errors and therefore less stable.\nThe eigenvalues and eigenvectors are shown below.\n\npd.DataFrame({\n    \"Eigenvalue\": evals\n}).T.style.background_gradient(cmap='cividis', axis = 1).set_caption(\"Eigenvalues of the normalized adjacency matrix\")\n\n\npd.DataFrame({\n    \"Eigenvector %i\" % i: evecs[:, i]\n    for i in range(10)\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Eigenvectors of the normalized adjacency matrix\")\n\nNotice that the largest eigenvalue is 1, which is always true for a normalized adjacency matrix. The largest eigenvector (the leftmost one) is associated with the stationary distribution of the random walk.\nThe sign of the eigenvector is indeterminate, which means we can choose the sign of the eigenvector arbitrarily. In fact, `np.linalg.eigh` returns the eigenvector whose sign can vary for a different run.\nWe decompose \\overline{\\bf A} as\n\\overline {\\bf A} = {\\bf Q}{\\bf \\Lambda}{\\bf Q}^\\top\nwhere {\\bf Q} corresponds to eigvecs and {\\bf \\Lambda} corresponds to np.diag(evals) (since {\\bf \\Lambda} is a diagonal matrix). Let’s see if this is correct:\n\npd.DataFrame(A_norm.toarray()).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Normalized Adjacency Matrix\")\n\n\nA_norm_reconstructed = evecs @ np.diag(evals) @ evecs.T\npd.DataFrame(A_norm_reconstructed).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Reconstruction of the Normalized Adjacency Matrix\")\n\nNotice that the reconstruction is not perfect due to the numerical error, although overall the structure is correct.\n\n\nMulti-step Transition Probability\nLet us first conform whether we can compute the transition probability after t steps by using the eigenvalues and eigenvectors.\n\nt = 5\nx_0 = np.zeros(g.vcount())\nx_0[0] = 1\n\n# Compute x_t by using the eigenvalues and eigenvectors\nQ_L = np.diag(1.0/np.sqrt(deg)) @ evecs\nQ_R = np.diag(np.sqrt(deg)) @ evecs\nx_t = x_0 @ Q_L @ np.diag(evals**t) @ Q_R.T\n\n# Compute x_t by using the power iteration\nx_t_power = x_0.copy()\nfor i in range(t):\n    x_t_power = x_t_power @ P\n\npd.DataFrame({\n    \"Eigenvector\": x_t.flatten(),\n    \"Power iteration\": x_t_power.flatten()\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Comparison of Eigenvector and Power Iteration\")\n\n\n\nRelaxation Time and Mixing Time\nLet us measure the relaxation time of the random walk.\n\nevals, evecs = np.linalg.eigh(A_norm.toarray())\nlambda_2 = -np.sort(-evals)[1]\ntau = 1 / lambda_2\nprint(f\"The relaxation time of the random walk is {tau:.4f}.\")"
  },
  {
    "objectID": "m07-random-walks/appendix-unifying-centrality-and-communities.html",
    "href": "m07-random-walks/appendix-unifying-centrality-and-communities.html",
    "title": "Random walks unify centrality and communities",
    "section": "",
    "text": "Modularity can be intepreted as a random walk perspective. Modularity is given by\n\nQ = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)\n\nwhere m is the number of edges in the network, A_{ij} is the adjacency matrix, d_i is the degree of node i, c_i is the community of node i, and \\delta(c_i, c_j) is the Kronecker delta function (which is 1 if c_i = c_j and 0 otherwise).\nWe can rewrite the modularity using the language of random walks as follows.\n\n\\begin{aligned}\nQ &= \\sum_{ij} \\left(\\frac{A_{ij}}{2m}  - \\frac{d_i}{2m} \\frac{d_j}{2m} \\right) \\delta(c_i, c_j) \\\\\n&= \\sum_{ij} \\left(\\pi_i P_{ij}  - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)\n\\end{aligned}\n where \\pi_i is the stationary distribution of the random walk given by\n\n\\pi_i = \\frac{d_i}{2m}\n\nand P_{ij} is the transition probability between nodes i and j.\nLet's break down this derivation step by step:\n\n1. We start with the original modularity formula:\n\n   $$Q = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)$$\n\n2. First, we move the constant $1/(2m)$ to the inside of the parentheses:\n\n   $$Q = \\sum_{ij} \\left(\\frac{A_{ij}}{2m} - \\frac{d_i d_j}{2m^2} \\right) \\delta(c_i, c_j)$$\n\n3. Now, we recognize that $\\frac{A_{ij}}{2m}$ can be rewritten as:\n\n   $$\\frac{A_{ij}}{2m} = \\frac{d_i}{2m} \\cdot \\frac{A_{ij}}{d_i} = \\pi_i P_{ij}$$\n\n4. We also recognize that $\\frac{d_i}{2m}$ is the stationary distribution of the random walk, which we denote as $\\pi_i$:\n\n   $$\\frac{d_i}{2m} = \\pi_i$$\n\n5. Substituting these into our equation:\n\n   $$Q = \\sum_{ij} \\left(\\pi_i P_{ij} - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)$$\n\nThe expression suggests that:\n\nThe first term, \\pi_i P_{ij} \\delta(c_i, c_j), represents the probability that a walker is at node i and moves to node j within the same community by one step.\nThe second term, \\pi_i \\pi_j, represents the probability that a walker is at node i and moves to another node j within the same community after long steps.\n\nIn summary, modularity compares short-term and long-term random walk probabilities. High modularity indicates that a random walker is more likely to stay within the same community after one step than after many steps.\nBuilding on this perspective from random walks, Delvenne et al. {footcite}`delvenne2010stability` extends the modularity by comparing multi-step and long-step transition probabilities of a random walk. This approach, known as \"Markov stability\", shows that the number of steps acts as a \"resolution parameter\" that determines the scale of detectable communities."
  },
  {
    "objectID": "m07-random-walks/appendix-unifying-centrality-and-communities.html#modularity-interpretation-from-random-walk-perspective",
    "href": "m07-random-walks/appendix-unifying-centrality-and-communities.html#modularity-interpretation-from-random-walk-perspective",
    "title": "Random walks unify centrality and communities",
    "section": "",
    "text": "Modularity can be intepreted as a random walk perspective. Modularity is given by\n\nQ = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)\n\nwhere m is the number of edges in the network, A_{ij} is the adjacency matrix, d_i is the degree of node i, c_i is the community of node i, and \\delta(c_i, c_j) is the Kronecker delta function (which is 1 if c_i = c_j and 0 otherwise).\nWe can rewrite the modularity using the language of random walks as follows.\n\n\\begin{aligned}\nQ &= \\sum_{ij} \\left(\\frac{A_{ij}}{2m}  - \\frac{d_i}{2m} \\frac{d_j}{2m} \\right) \\delta(c_i, c_j) \\\\\n&= \\sum_{ij} \\left(\\pi_i P_{ij}  - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)\n\\end{aligned}\n where \\pi_i is the stationary distribution of the random walk given by\n\n\\pi_i = \\frac{d_i}{2m}\n\nand P_{ij} is the transition probability between nodes i and j.\nLet's break down this derivation step by step:\n\n1. We start with the original modularity formula:\n\n   $$Q = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)$$\n\n2. First, we move the constant $1/(2m)$ to the inside of the parentheses:\n\n   $$Q = \\sum_{ij} \\left(\\frac{A_{ij}}{2m} - \\frac{d_i d_j}{2m^2} \\right) \\delta(c_i, c_j)$$\n\n3. Now, we recognize that $\\frac{A_{ij}}{2m}$ can be rewritten as:\n\n   $$\\frac{A_{ij}}{2m} = \\frac{d_i}{2m} \\cdot \\frac{A_{ij}}{d_i} = \\pi_i P_{ij}$$\n\n4. We also recognize that $\\frac{d_i}{2m}$ is the stationary distribution of the random walk, which we denote as $\\pi_i$:\n\n   $$\\frac{d_i}{2m} = \\pi_i$$\n\n5. Substituting these into our equation:\n\n   $$Q = \\sum_{ij} \\left(\\pi_i P_{ij} - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)$$\n\nThe expression suggests that:\n\nThe first term, \\pi_i P_{ij} \\delta(c_i, c_j), represents the probability that a walker is at node i and moves to node j within the same community by one step.\nThe second term, \\pi_i \\pi_j, represents the probability that a walker is at node i and moves to another node j within the same community after long steps.\n\nIn summary, modularity compares short-term and long-term random walk probabilities. High modularity indicates that a random walker is more likely to stay within the same community after one step than after many steps.\nBuilding on this perspective from random walks, Delvenne et al. {footcite}`delvenne2010stability` extends the modularity by comparing multi-step and long-step transition probabilities of a random walk. This approach, known as \"Markov stability\", shows that the number of steps acts as a \"resolution parameter\" that determines the scale of detectable communities."
  },
  {
    "objectID": "m07-random-walks/appendix-unifying-centrality-and-communities.html#pagerank-interpretation-from-random-walk-perspective",
    "href": "m07-random-walks/appendix-unifying-centrality-and-communities.html#pagerank-interpretation-from-random-walk-perspective",
    "title": "Random walks unify centrality and communities",
    "section": "2 PageRank: Interpretation from random walk perspective",
    "text": "2 PageRank: Interpretation from random walk perspective\nPageRank can be interpreted from a random walk perspective:\n\nc_i = (1-\\beta) \\sum_j P_{ji} c_j + \\beta \\cdot \\frac{1}{N}\n\nWhere: - c_i is the PageRank of node i - P_{ji} is the transition probability from node j to node i - \\beta is the teleportation probability - N is the total number of nodes\nThis equation represents a random walk where: 1. With probability (1-\\beta), the walker follows a link to the next node. 2. With probability \\beta, the walker teleports to a random node in the network.\nThe PageRank c_i is the stationary distribution of this random walk, representing the long-term probability of finding the walker at node i.\nThis sounds odd at first glance. But it makes sense when you think about what PageRank was invented for, i.e., Web search. It characterizes a web surfer as a random walker that chooses the next page by randomly jumping to a random page with probability $\\beta$ or by following a link to a page with probability $1-\\beta$. The web page with the largest PageRank means that the page is most likely to be visited by this random web surfer."
  },
  {
    "objectID": "m07-random-walks/03-exercises.html",
    "href": "m07-random-walks/03-exercises.html",
    "title": "Exercises & Assignments",
    "section": "",
    "text": "We will implement and analyze random walks on real-world networks, exploring their applications for centrality measures and community detection.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Exercises & Assignments"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html",
    "href": "m07-random-walks/01-concepts.html",
    "title": "Random Walks Concepts",
    "section": "",
    "text": "Suppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network.\n\n\nRandom walks appear everywhere in daily life:\n\nNetflix browsing: You click on a movie, then another recommended movie, then another… Your viewing pattern follows a random walk through the recommendation network!\nWikipedia surfing: Starting from “Coffee”, you click links to “Brazil” → “Soccer” → “Mathematics” → “Physics”… Each click is a step in a random walk through knowledge.\nStock market movements: Daily price changes can be modeled as random walks, where each day’s price depends on the previous day plus some random fluctuation.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Random Walks Concepts"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#what-is-a-random-walk",
    "href": "m07-random-walks/01-concepts.html#what-is-a-random-walk",
    "title": "Random Walks Concepts",
    "section": "",
    "text": "Suppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network.\n\n\nRandom walks appear everywhere in daily life:\n\nNetflix browsing: You click on a movie, then another recommended movie, then another… Your viewing pattern follows a random walk through the recommendation network!\nWikipedia surfing: Starting from “Coffee”, you click links to “Brazil” → “Soccer” → “Mathematics” → “Physics”… Each click is a step in a random walk through knowledge.\nStock market movements: Daily price changes can be modeled as random walks, where each day’s price depends on the previous day plus some random fluctuation.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Random Walks Concepts"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#introduction-through-games-ladder-lottery",
    "href": "m07-random-walks/01-concepts.html#introduction-through-games-ladder-lottery",
    "title": "Random Walks Concepts",
    "section": "2 Introduction through Games: Ladder Lottery",
    "text": "2 Introduction through Games: Ladder Lottery\nTo make random walk concepts tangible, let’s start with a fun game that perfectly illustrates random walk principles:\n\n\n\n\n\n\nLadder Lottery\n\n\n\nLadder Lottery is a fun East Asian game, also known as “鬼腳圖” (Guijiaotu) in Chinese, “阿弥陀籤” (Amida-kuzi) in Japanese, “사다리타기” (Sadaritagi) in Korean, and “Ladder Lottery” in English. The game is played as follows: 1. A player is given a board with a set of vertical lines. 2. The player chooses a line and starts to move along the line 3. When hitting a horizontal line, the player must move along the horizontal line and then continue to move along the next vertical line. 4. The player wins if the player can hit a marked line at the bottom of the board. 5. You cannot see the horizontal lines in advance!\nPlay the Ladder Lottery Game! 🎮✨ and try to answer the following questions:\n\nIs there a strategy to maximize the probability of winning?\nHow does the probability of winning change as the number of horizontal lines increases?\n\n\n\n\nThe Ladder Lottery game is actually a perfect introduction to random walks! In this game, states are the vertical lines, transitions happen when you encounter horizontal connections, randomness comes from not knowing where the horizontal lines are placed, and long-term behavior determines your probability of winning. This simple game illustrates many key concepts we’ll explore in random walks on networks.\nA random walk in undirected networks follows this process: 1. Start at a node i 2. Randomly choose an edge to traverse to a neighbor node j 3. Repeat step 2 until you have taken T steps\n\n\nIn directed networks, a random walker can only move along the edge direction, and it can be that the random walker is stuck in a so-called “dead end” that does not have any outgoing edges.\n\nWhen studying random walks, we want to understand several key aspects: short-term behavior (where does the walker go in the first few steps?), long-term behavior (after many steps, where does the walker spend most of its time?), structural insights (what does the walker’s behavior tell us about the network?), and applications (how can we use random walks for centrality and community detection?).\n\n\n\n\n\n\nInteractive Exploration\n\n\n\nPlay with the Random Walk Simulator! 🎮✨ and try to answer the following questions:\n\nWhen the random walker makes many steps, where does it tend to visit most frequently?\nWhen the walker makes only a few steps, where does it tend to visit?\nDoes the behavior of the walker inform us about centrality of the nodes?\nDoes the behavior of the walker inform us about communities in the network?\n\n\n\n\nPen and Paper Exercises\nBefore diving into the mathematical details and coding, it’s important to work through some fundamental concepts by hand.\n\n✍️ Pen and paper exercises\n\nThese exercises will help you: - Understand the basic mechanics of random walks - Calculate transition probabilities manually - Explore simple examples of stationary distributions - Connect random walk concepts to network properties",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Random Walks Concepts"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#transition-probabilities",
    "href": "m07-random-walks/01-concepts.html#transition-probabilities",
    "title": "Random Walks Concepts",
    "section": "3 Transition Probabilities",
    "text": "3 Transition Probabilities\n\n\nLet’s see how this works with a more complex example. Consider a network with 10 nodes:\nLet us consider the following graph.\n\n\n\n\n\n\n\n\n\nThe transition matrix is given by:\n\n\n\n\n\n\n\n\n\nA random walk is characterized by the transition probabilities between nodes. The transition probability from node i to node j is:\n\nP_{ij} = \\frac{A_{ij}}{k_i}\n\nwhere A_{ij} is the adjacency matrix element and k_i is the degree of node i.\nWe can represent all transition probabilities in a transition probability matrix \\mathbf{P}:\n\n\\mathbf{P} = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1N} \\\\\np_{21} & p_{22} & \\cdots & p_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{N1} & p_{N2} & \\cdots & p_{NN}\n\\end{pmatrix}\n\nThis matrix \\mathbf{P} encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps:\n\nAfter one step: P_{ij} = p_{ij}\nAfter two steps: \\left(\\mathbf{P}^{2}\\right)_{ij} = \\sum_{k} P_{ik} P_{kj}\nAfter T steps: \\left(\\mathbf{P}^{T}\\right)_{ij}\n\nLet’s understand why \\mathbf{P}^2 represents the transition probabilities after two steps.\nFirst, recall that \\mathbf{P}_{ij} is the probability of moving from node i to node j in one step. Now, consider a two-step walk from i to j. We can express this as:\n(\\mathbf{P}^2)_{ij} = \\sum_k \\mathbf{P}_{ik} \\mathbf{P}_{kj}\nThis equation encapsulates a key idea: to go from i to j in two steps, we must pass through some intermediate node k. Let’s break this down step by step:\n\nThe probability of the first step (i to k) is \\mathbf{P}_{ik}.\nThe probability of the second step (k to j) is \\mathbf{P}_{kj}.\nThe probability of this specific path (i → k → j) is the product \\mathbf{P}_{ik} \\mathbf{P}_{kj}.\nWe sum over all possible intermediate nodes k to get the total probability.\n\nAnd we can extend this reasoning for any number of steps t. In summary, for any number of steps t, \\left( \\mathbf{P}^t \\right)_{ij} gives the probability of being at node j after t steps, starting from node i.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Random Walks Concepts"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#stationary-distribution",
    "href": "m07-random-walks/01-concepts.html#stationary-distribution",
    "title": "Random Walks Concepts",
    "section": "4 Stationary Distribution",
    "text": "4 Stationary Distribution\n\n\nLet’s compute \\mathbf{P}^2 for our larger network to see what happens after 2 steps:\n\n\n\n\n\n\n\n\n\nThis is after 10 steps.\n\n\n\n\n\n\n\n\n\nThis is after 1000 steps.\n\n\n\n\n\n\n\n\nFigure 1: Transition Matrix after 100 steps\n\n\n\n\n\nStationary distribution is the probability distribtion of the walker after infinite steps, representing the long-term behavior of the walker.\nAssuming that a stationary distribution exists (i.e., which is always true for undirected networks), the random walker at the stationary state must satisfy the following balance condition:\n\nx(t+1) = x(t) \\; \\text{for a large } t,\n where x(t) is the probability distribution of the walker at time t, represented as a column vector, where\n\nx(t) =\n\\begin{pmatrix}\nx_{i}(t) \\\\\nx_{j}(t) \\\\\n\\vdots \\\\\nx_{N}(t)\n\\end{pmatrix}\n\nwhere x_{i}(t) is the probability of being at node i at time t. The balance condition means that the system becomes time invariant, meaning that the probability of being at node i at time t is the same as the probability of being at node i at time t+1.\nWhat does x(t) look like in the stationary state? To understand this, let us represent x(t) using P and an initial distribution x(0), i.e.,\n\nx(t) = x^\\top(t-1) P = x^\\top(0) P^t.\n\nTo see how P^t looks like, see the figure on the right column. Notice that each column of P^t has the same values across all rows. Remind also that P_{ij} represents the transition probability from node i (row) to node j (column). This means that a random walker at time t, not matter where it was at time t-1, it will have the same probability of being at any node at time t!\nNow, why P^t has this peculiar property? This is because of the spectral property of matrix, P.\nFirst of all, we can rewrite the balance condition as the following eigenvalue equation: \n\\pi = \\pi P\n where \\pi=\\lim_{t\\to\\infty} x(t) is the stationary distribution. This means that the stationary distribution vector \\pi is parallel to the left eigenvector of P.\n\n\n\n\n\n\nNote\n\n\n\nNote that \\pi is parallel to but not necessarily equal to the left eigenvector of P, as \\pi is a probability whose sum is 1 while the left eigenvector has unit norm (i.e., the sum of the squared elements is 1).\n\n\nThe left-eigenvector associated with the stationary distribution \\pi is in fact associated with the largest eigenvalue of P, as per the Perron-Frobenius theorem. An intuition behind this is that the number of walkers in a graph remains invariant after a transition, which is evident from the fact \\sum_{j} P_{ij}=1 (if it’s greater than 1, the number of walkers increases and explodes to infinity). In language of spectra of matrices, this means that the eigenvalue is not rescaled by the transition matrix, which mathematically corresponds to having eigenvalue 1.\n\n\n\n\n\n\n\n\n\n\nFigure 2: Spectrum of Transition Matrix P\n\n\n\n\n\nThe other eigenvalues are less than one in magnitude and describes the short-term behavior of random walks, which we will discuss in the next section.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Random Walks Concepts"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#spectral-analysis-and-mixing-time",
    "href": "m07-random-walks/01-concepts.html#spectral-analysis-and-mixing-time",
    "title": "Random Walks Concepts",
    "section": "5 Spectral Analysis and Mixing Time",
    "text": "5 Spectral Analysis and Mixing Time\nNow, let’s turn our attention to the short-term dynamics of random walks. These are governed by the non-dominant (non-principal) eigenvectors of the transition probability matrix P. To analyze this behavior, we’ll need to use some concepts from linear algebra.\nThe short-term behavior of random walks is described as:\n\nx(t) = P^t  x(0)\n\nThus, it is determined by the initial distribution x(0) and the power of the transition probability matrix P^t. In long term, P^t approaches to that for the stationary distribution \\pi. Here we focus on the ehavior before the equilibrium is reached.\nTo understand the short-term behavior, we represent P as: \nP = \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\mathbf{A}} \\mathbf{D}^{\\frac{1}{2}}\n\nwhere \\overline{\\mathbf{A}} is a symmetric matrix and \\mathbf{D}^{-\\frac{1}{2}} is a diagonal matrix. These are defined respectively as follows.\n\nDiagonal degree matrix, \\mathbf{D}: we define a diagonal matrix whose diagonal elements are the degrees of the nodes, i.e., \n\\mathbf{D} = \\begin{pmatrix}\nd_1 & 0 & \\cdots & 0 \\\\\n0 & d_2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & d_N\n\\end{pmatrix}\n where d_i is the degree of node i.\nNormalized adjacency matrix, \\overline{\\mathbf{A}}: we define a normalized adjacency matrix whose elements are the normalized adjacency matrix, i.e., \n\\overline{\\mathbf{A}} = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}\n where \\mathbf{A} is the adjacency matrix. It is normalized in the sense that each entry is normalized by the squared root of the degree of the nodes.\n\nThe key property we will leverage is that the normalized adjacency matrix is diagonalizable, i.e., \n\\overline{\\mathbf{A}} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^T\n\nwhere \\mathbf{Q} is an orthogonal matrix and \\mathbf{\\Lambda} is a diagonal matrix. The transition matrix \\mathbf{P} can be written as: \n\\mathbf{P} = \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R^T\n\n\n\n\n\n\n\n\n\nFigure 3: A visual representation of diagonalizable matrix.\n\n\n\nSymmetric matrices are diagonalizable. And \\overline{\\mathbf{A}} is symmetric as far as the undirected network is considered.\nwhere \n\\mathbf{Q}_L = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q}, \\quad \\mathbf{Q}_R = \\mathbf{D}^{\\frac{1}{2}} \\mathbf{Q}.\n Importantly, \\mathbf{Q} is an orthogonal matrix, i.e., \\mathbf{Q} \\mathbf{Q}^T = \\mathbf{I}. Putting all together, we can compute \\mathbf{P}^t as:\n\n\\mathbf{P}^t = \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R^T\n\n\n\nThis could be understood by thinking of \\mathbf{P}^2, i.e.,\n\n\\begin{aligned}\n\\mathbf{P}^2 & = \\mathbf{Q}_L \\mathbf{\\Lambda} \\underbrace{\\mathbf{Q}_R^T \\mathbf{Q}_L}_{= \\mathbf{I}} \\mathbf{\\Lambda} \\mathbf{Q}_R^T \\\\\n& = \\mathbf{Q}_L \\mathbf{\\Lambda}^2 \\mathbf{Q}_R^T \\\\\n\\end{aligned}\n\n\n\n\n\n\n\nFigure 4: A visual representation of the short term behavior of random walks. We can see that x(t) can be edcomposed into the row of \\mathbf{Q}_R scaled by a dot-product of the initial distribution x(0) and the column of \\mathbf{Q}_L, along with the eigenvalues of the normalized adjacency matrix \\overline{\\mathbf{A}}. In this view, the short term distribution x(t) is more strongly influenced by the second largest eigenvalue \\lambda_2 followed by the other remaining eigenvalues.\n\n\n\nArmed with this result, let us understand the short-term behavior of random walks. A key property is the mixing time, which is the time it takes for the random walk to reach the stationary distribution. Formally, the mixing time t_{\\text{mix}} is defined as \nt_{\\text{mix}} = \\min\\{t : \\max_{\\mathbf{x}(0)} \\|\\mathbf{x}(t) - \\boldsymbol{\\pi}\\|_{1} \\leq \\epsilon\\}\n\nIt is not trivial to connect with this definition to the spectral properties of \\overline{\\mathbf{A}}. But, since the transition matrix \\mathbf{P} is determined by the eigenvalues and eigenvectors of the normalizsed adjacency matrix \\overline{\\mathbf{A}}, the mixing time is determined by the eigenvalues of \\overline{\\mathbf{A}}, in particular the second largest eigenvalue \\lambda_2, which dominates in \\mathbf{P}^t following the principal eigenvector \\pi. In fact, the mixing time is bounded by the second largest eigenvalue.\n\nt_{\\text{mix}} &lt; \\frac{1}{1-\\lambda_2} \\log \\left( \\frac{1}{\\epsilon \\min_{i} \\pi_i} \\right)\n\n\n\nAn alternative represention is to use the second smallest eigenvalue \\mu of the normalized Laplacian matrix:\n\nt_{\\text{mix}} \\leq \\frac{1}{\\mu}\n\nwhere \\mu = 1-\\lambda_2.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Random Walks Concepts"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#community-detection-through-random-walks",
    "href": "m07-random-walks/01-concepts.html#community-detection-through-random-walks",
    "title": "Random Walks Concepts",
    "section": "6 Community Detection through Random Walks",
    "text": "6 Community Detection through Random Walks\nRandom walks can reveal community structure in networks. Before reaching the steady state, walkers tend to remain within their starting community, then gradually diffuse to other communities. This temporal behavior provides insights into the network’s modular structure.\n\nRandom Walk Interpretation of Modularity\nModularity can be interpreted through random walks (Delvenne, Yaliraki, and Barahona 2010):\n\nQ = \\sum_{ij} \\left(\\pi_i P_{ij} - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)\n\nwhere: - \\pi_i = \\frac{d_i}{2m} is the stationary distribution of the random walk - P_{ij} is the transition probability between nodes i and j - \\delta(c_i, c_j) is 1 if nodes i and j are in the same community, 0 otherwise\nThe expression suggests that: 1. The first term, \\pi_i P_{ij} \\delta(c_i, c_j), represents the probability that a walker is at node i and moves to node j within the same community by one step. 2. The second term, \\pi_i \\pi_j, represents the probability that a walker is at node i and moves to another node j within the same community after long steps.\nHigh modularity indicates walkers are more likely to stay within communities in the short term than in the long term.\n\n\n(Delvenne, Yaliraki, and Barahona 2010) extends the modularity to the case of multi-step random walks, which can identify communities across different resolution scales.\n\n\nInfomap: Information-Theoretic Community Detection\nWhile modularity provides one approach to community detection through random walks, Infomap offers an information-theoretic perspective (Rosvall and Bergstrom 2008, 2009).\nInfomap asks: How can we most efficiently describe the path of a random walker through a network? The key insight is that if a network has strong community structure, a random walker will spend most of its time within communities, making short jumps between communities. This pattern can be compressed efficiently using a two-level code:\n\nModule code: A unique identifier for each community\nExit code: A special symbol indicating when the walker leaves a community\nNode code: Identifiers for nodes within each community\n\nBy compressing the trajectory of random walks, Infomap can find a community structure that minimizes the average bits needed to describe the random walk.\n\n\n\n\n\n\nFigure 5: Infomap finds community detection by compressing the trajectory of random walks. (a) shows a random walker’s trajectory through a network, while (d) demonstrates the hierarchical encoding scheme that minimizes description length by assigning short, reusable codewords to nodes within modules (colored regions) and special transition codes (pentagons/triangles) for movements between modules, with the optimal community structure being the partition that minimizes the average bits needed to describe the random walk",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Random Walks Concepts"
    ]
  },
  {
    "objectID": "m06-centrality/degree-distance-based-centrality.html",
    "href": "m06-centrality/degree-distance-based-centrality.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Have you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone’s talking about right now? These questions are all about finding out what’s important in a network of people, ideas, or things. In network science, we call this centrality.\nCentrality or importance is a question of how important a node is in a network. But the notion of importance is somewhat vague. In what sense we say a node is important? Answering this question needs a specific context, and there are many contexts in which the importance is defined.\n\n\n\nHere we will focus on several popular centrality measures. Let us denote by c_i the centrality of node i throughout this section. Here is a preview of the centrality measures we will cover in this section\n\n\n\n\n\n\n\n\nCentrality\nCategory\nDescription\n\n\n\n\nDegree Centrality\nDegree\nCounts the number of edges connected to a node.\n\n\nCloseness Centrality\nShortest Path\nMeasures how close a node is to all other nodes in the network.\n\n\nEccentricity Centrality\nShortest Path\nBased on the maximum shortest path distance from a node to any other node.\n\n\nHarmonic Centrality\nShortest Path\nAdjusts closeness centrality to work even in disconnected networks.\n\n\nBetweenness Centrality\nShortest Path\nMeasures the extent to which a node lies on paths between other nodes.\n\n\nEigenvector Centrality\nWalk\nMeasures a node’s influence based on the influence of its neighbors.\n\n\nHITS (Hub and Authority) Centrality\nWalk\nMeasures the importance of nodes as hubs and authorities in a network.\n\n\nKatz Centrality\nWalk\nConsiders the total number of walks between nodes, with a damping factor.\n\n\nPageRank\nWalk\nMeasures the importance of nodes based on the structure of incoming links.\n\n\n\n\n\nPerhaps the simplest form of cnetrality is degree centrality. It is just the count of the number of edges connected to a node (i.e., the number of neighbors, or degree in network science terminology). The most important node is thus the one with the highest degree.\n\nc_i = d_i = \\sum_{j} A_{ij}\n\nwhere A_{ij} is the adjacency matrix of the network, and d_i is the degree of node i.\n\n\n\n\nLet’s talk about an ancient Roman monument called the Milliarium Aureum, also known as the Golden Milestone. It was the starting point for measuring distances on all major roads in the Roman Empire. Emperor Augustus built it when Rome changed from a republic to an empire. The monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire. Perhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define centrality in networks.\n\n\n\nClosenes centrality is a measure of how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N - 1, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n\n\n### Harmonic centrality\n\n**Harmonic Centrality** is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can't reach others, making their distance infinite. This causes all centrality values to become zero, which isn't very helpful!\n\nTo fix this, Beauchamp {footcite:p}`beauchamp1965improved` came up with a clever solution called *harmonic centrality*. It works even when the network is disconnected.\n\n$$\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n$$\n\n### Eccentricity centrality\n\n**Eccentricity centrality** is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n\nThese centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.\n\nA central node should be close to all other nodes.\n\nCloseness centrality captures the notion of \"centrality\" in the network. Namely, a node is *central* if it is close to all other nodes.\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\nwhere $N$ is the number of nodes in the network. The numerator, $N$, is the normalization factor to make the centrality to have the maximum value of 1.\n\n\n### Eccentricity centrality\n\nEccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the *maximum* distance as opposed to the average distance like in the closeness centrality.\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n\n### Betweenness centrality\n\nAnother notion of centrality is *betweenness centrality*. It considers that a node is important if it lies on many shortest paths between other nodes.\n\n$$\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n$$\n\nwhere $\\sigma_{jk}$ is the number of shortest paths between nodes $j$ and $k$, and $\\sigma_{jk}(i)$ is the number of shortest paths between nodes $j$ and $k$ that pass through node $i$.\n\n\n\n\n\n:::{#quarto-navigation-envelope .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyLXRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXItdGl0bGU=\"}\n[Course Information]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMQ==\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvd2VsY29tZS5odG1sV2VsY29tZQ==\"}\n[About us]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvYWJvdXQuaHRtbEFib3V0LXVz\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvZGlzY29yZC5odG1sRGlzY29yZA==\"}\n[Using Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvbWluaWRvcmEtdXNhZ2UuaHRtbFVzaW5nLU1pbmlkb3Jh\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvc2V0dXAuaHRtbFNldHVw\"}\n[How to submit assignment]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvaG93LXRvLXN1Ym1pdC1hc3NpZ25tZW50Lmh0bWxIb3ctdG8tc3VibWl0LWFzc2lnbm1lbnQ=\"}\n[Introduction]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMg==\"}\n[Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9pbnRyby93aHktbmV0d29ya3MuaHRtbE5ldHdvcmtz\"}\n[M01: Euler Path]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMw==\"}\n[A Stroll, Seven Bridges, and a Mathematical Revolution]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMS1jb25jZXB0cy5odG1sQS1TdHJvbGwsLVNldmVuLUJyaWRnZXMsLWFuZC1hLU1hdGhlbWF0aWNhbC1SZXZvbHV0aW9u\"}\n[Coding Networks in Python]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMi1jb2RpbmcuaHRtbENvZGluZy1OZXR3b3Jrcy1pbi1QeXRob24=\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcw==\"}\n[Advanced: Sparse Matrices for Large-Scale Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wNC1hZHZhbmNlZC5odG1sQWR2YW5jZWQ6LVNwYXJzZS1NYXRyaWNlcy1mb3ItTGFyZ2UtU2NhbGUtTmV0d29ya3M=\"}\n[M02: Small World]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNA==\"}\n[Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDEtY29uY2VwdHMuaHRtbENvcmUtQ29uY2VwdHM=\"}\n[Efficient Network Representation and Computing Paths]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDItY29kaW5nLmh0bWxFZmZpY2llbnQtTmV0d29yay1SZXByZXNlbnRhdGlvbi1hbmQtQ29tcHV0aW5nLVBhdGhz\"}\n[Exercises and Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDMtZXhlcmNpc2VzLmh0bWxFeGVyY2lzZXMtYW5kLUFzc2lnbm1lbnRz\"}\n[Appendix - Brief Introduction to igraph]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDQtYXBwZW5kaXguaHRtbEFwcGVuZGl4LS0tQnJpZWYtSW50cm9kdWN0aW9uLXRvLWlncmFwaA==\"}\n[M03: Robustness]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNQ==\"}\n[Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMS1jb25jZXB0cy5odG1sQ29yZS1Db25jZXB0cw==\"}\n[Coding - Network Robustness Analysis]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMi1jb2RpbmcuaHRtbENvZGluZy0tLU5ldHdvcmstUm9idXN0bmVzcy1BbmFseXNpcw==\"}\n[Exercises and Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcy1hbmQtQXNzaWdubWVudHM=\"}\n[Exercises and Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wNC1hcHBlbmRpeC5odG1sRXhlcmNpc2VzLWFuZC1Bc3NpZ25tZW50cw==\"}\n[M04: Friendship Paradox]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNg==\"}\n[Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtbm9kZS1kZWdyZWUvMDEtY29uY2VwdHMuaHRtbENvcmUtQ29uY2VwdHM=\"}\n[Visualizing Degree Distributions in Python]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtbm9kZS1kZWdyZWUvMDItY29kaW5nLmh0bWxWaXN1YWxpemluZy1EZWdyZWUtRGlzdHJpYnV0aW9ucy1pbi1QeXRob24=\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtbm9kZS1kZWdyZWUvMDMtZXhlcmNpc2VzLmh0bWxFeGVyY2lzZXM=\"}\n[M05: Clustering]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNw==\"}\n[Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMS1jb25jZXB0cy5odG1sQ29yZS1Db25jZXB0cw==\"}\n[Clustering Algorithms and Implementation]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMi1jb2RpbmcuaHRtbENsdXN0ZXJpbmctQWxnb3JpdGhtcy1hbmQtSW1wbGVtZW50YXRpb24=\"}\n[Exercises and Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcy1hbmQtQXNzaWdubWVudHM=\"}\n[M06: Centrality]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOA==\"}\n[Centrality Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMS1jb25jZXB0cy5odG1sQ2VudHJhbGl0eS1Db25jZXB0cw==\"}\n[Coding - Centrality]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMi1jb2RpbmcuaHRtbENvZGluZy0tLUNlbnRyYWxpdHk=\"}\n[Exercises & Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcy0mLUFzc2lnbm1lbnRz\"}\n[M07: Random Walks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOQ==\"}\n[Random Walks Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAxLWNvbmNlcHRzLmh0bWxSYW5kb20tV2Fsa3MtQ29uY2VwdHM=\"}\n[Coding - Random Walks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAyLWNvZGluZy5odG1sQ29kaW5nLS0tUmFuZG9tLVdhbGtz\"}\n[Exercises & Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAzLWV4ZXJjaXNlcy5odG1sRXhlcmNpc2VzLSYtQXNzaWdubWVudHM=\"}\n[M08: Embedding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTA=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[M09: Graph Neural Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTE=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Home]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SG9tZQ==\"}\n[/index.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2luZGV4Lmh0bWw=\"}\n[Course]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q291cnNl\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2VsY29tZQ==\"}\n[/course/welcome.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS93ZWxjb21lLmh0bWw=\"}\n[About]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWJvdXQ=\"}\n[/course/about.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9hYm91dC5odG1s\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RGlzY29yZA==\"}\n[/course/discord.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9kaXNjb3JkLmh0bWw=\"}\n[Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6TWluaWRvcmE=\"}\n[/course/minidora-usage.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9taW5pZG9yYS11c2FnZS5odG1s\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6U2V0dXA=\"}\n[/course/setup.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9zZXR1cC5odG1s\"}\n[Intro]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SW50cm8=\"}\n[Why Networks?]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2h5IE5ldHdvcmtzPw==\"}\n[/intro/why-networks.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2ludHJvL3doeS1uZXR3b3Jrcy5odG1s\"}\n[Foundations]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Rm91bmRhdGlvbnM=\"}\n[─── M01: Euler Path ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMTogRXVsZXIgUGF0aCDilIDilIDilIA=\"}\n[Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29uY2VwdHM=\"}\n[/m01-euler_tour/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[Coding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29kaW5n\"}\n[/m01-euler_tour/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAyLWNvZGluZy5odG1s\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RXhlcmNpc2Vz\"}\n[/m01-euler_tour/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQ=\"}\n[/m01-euler_tour/04-advanced.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzA0LWFkdmFuY2VkLmh0bWw=\"}\n[─── M02: Small World ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMjogU21hbGwgV29ybGQg4pSA4pSA4pSA\"}\n[/m02-small-world/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMS1jb25jZXB0cy5odG1s\"}\n[/m02-small-world/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMi1jb2RpbmcuaHRtbA==\"}\n[/m02-small-world/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMy1leGVyY2lzZXMuaHRtbA==\"}\n[Appendix]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QXBwZW5kaXg=\"}\n[/m02-small-world/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wNC1hcHBlbmRpeC5odG1s\"}\n[─── M03: Robustness ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMzogUm9idXN0bmVzcyDilIDilIDilIA=\"}\n[/m03-robustness/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m03-robustness/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAyLWNvZGluZy5odG1s\"}\n[/m03-robustness/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[/m03-robustness/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzA0LWFwcGVuZGl4Lmh0bWw=\"}\n[Core Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29yZSBUb3BpY3M=\"}\n[─── M04: Friendship Paradox ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNDogRnJpZW5kc2hpcCBQYXJhZG94IOKUgOKUgOKUgA==\"}\n[/m04-node-degree/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1ub2RlLWRlZ3JlZS8wMS1jb25jZXB0cy5odG1s\"}\n[/m04-node-degree/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1ub2RlLWRlZ3JlZS8wMi1jb2RpbmcuaHRtbA==\"}\n[/m04-node-degree/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1ub2RlLWRlZ3JlZS8wMy1leGVyY2lzZXMuaHRtbA==\"}\n[─── M05: Clustering ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNTogQ2x1c3RlcmluZyDilIDilIDilIA=\"}\n[/m05-clustering/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m05-clustering/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAyLWNvZGluZy5odG1s\"}\n[/m05-clustering/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[─── M06: Centrality ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNjogQ2VudHJhbGl0eSDilIDilIDilIA=\"}\n[/m06-centrality/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m06-centrality/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAyLWNvZGluZy5odG1s\"}\n[/m06-centrality/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQgVG9waWNz\"}\n[─── M07: Random Walks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNzogUmFuZG9tIFdhbGtzIOKUgOKUgOKUgA==\"}\n[/m07-random-walks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m07-random-walks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDItY29kaW5nLmh0bWw=\"}\n[/m07-random-walks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[─── M08: Embedding ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wODogRW1iZWRkaW5nIOKUgOKUgOKUgA==\"}\n[/m08-embedding/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m08-embedding/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDItY29kaW5nLmh0bWw=\"}\n[/m08-embedding/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m08-embedding/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDQtYXBwZW5kaXguaHRtbA==\"}\n[─── M09: Graph Neural Networks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wOTogR3JhcGggTmV1cmFsIE5ldHdvcmtzIOKUgOKUgOKUgA==\"}\n[/m09-graph-neural-networks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m09-graph-neural-networks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDItY29kaW5nLmh0bWw=\"}\n[/m09-graph-neural-networks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m09-graph-neural-networks/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDQtYXBwZW5kaXguaHRtbA==\"}\n\n:::{.hidden .quarto-markdown-envelope-contents render-id=\"Zm9vdGVyLWxlZnQ=\"}\nCopyright 2024, Sadamori Kojaku\n:::\n\n:::\n\n\n\n:::{#quarto-meta-markdown .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGF0aXRsZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkdGl0bGU=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZHRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGFzaXRlbmFtZQ==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkZGVzYw==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZGRkZXNj\"}\n:::\n\n\n\n\n&lt;!-- --&gt;\n\n::: {.quarto-embedded-source-code}\n```````````````````{.markdown shortcodes=\"false\"}\n# What is centrality?\n\nHave you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone's talking about right now?\nThese questions are all about finding out what's important in a network of people, ideas, or things. In network science, we call this *centrality.*\n\nCentrality or *importance* is a question of how important a node is in a network.\nBut the notion of *importance* is somewhat vague.\nIn what sense we say a node is important?\nAnswering this question needs a specific *context*, and there are many contexts in which the *importance* is defined.\n\n![](../figs/centrality.jpg)\n\n## Different centrality measures\n\nHere we will focus on several popular centrality measures. Let us denote by $c_i$ the centrality of node $i$ throughout this section.\nHere is a preview of the centrality measures we will cover in this section\n\n| Centrality          | Category            | Description                                                                 |\n|-------------------------|---------------------|-----------------------------------------------------------------------------|\n| Degree Centrality       | Degree              | Counts the number of edges connected to a node.                             |\n| Closeness Centrality    | Shortest Path  | Measures how close a node is to all other nodes in the network.             |\n| Eccentricity Centrality | Shortest Path  | Based on the maximum shortest path distance from a node to any other node.  |\n| Harmonic Centrality     | Shortest Path  | Adjusts closeness centrality to work even in disconnected networks.         |\n| Betweenness Centrality  | Shortest Path  | Measures the extent to which a node lies on paths between other nodes.      |\n| Eigenvector Centrality  | Walk           | Measures a node's influence based on the influence of its neighbors.        |\n| HITS (Hub and Authority) Centrality | Walk  | Measures the importance of nodes as hubs and authorities in a network.      |\n| Katz Centrality         | Walk           | Considers the total number of walks between nodes, with a damping factor.   |\n| PageRank                | Walk           | Measures the importance of nodes based on the structure of incoming links.  |\n\n\n### Degree centrality\n\nPerhaps the simplest form of cnetrality is *degree centrality*. It is just the count of the number of edges connected to a node (i.e., the number of neighbors, or *degree* in network science terminology). The most important node is thus the one with the highest degree.\n\n$$\nc_i = d_i = \\sum_{j} A_{ij}\n$$\n\nwhere $A_{ij}$ is the adjacency matrix of the network, and $d_i$ is the degree of node $i$.\n\n### Centrality based on shortest path\n\n\n&lt;img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Milliarium_Aureum_op_het_Forum_Romanum_te_Rome_Columna_Miliaria_in_Foro_Romano_%28titel_op_object%29_Antieke_monumenten_%28serietitel%29_Antiquae_Urbis_Splendor_%28serietitel%29%2C_RP-P-2016-345-28-1.jpg/1546px-thumbnail.jpg?20191217151048\" alt=\"Roma Foro Romano Miliarium Aureum\" width=\"80%\" style=\"display: block; margin-left: auto; margin-right: auto;\"&gt;\n\n\nLet's talk about an ancient Roman monument called the *Milliarium Aureum*, also known as the *Golden Milestone*.\nIt was the starting point for measuring distances on all major roads in the Roman Empire.\nEmperor Augustus built it when Rome changed from a republic to an empire.\nThe monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire.\nPerhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define *centrality* in networks.\n\n### Closeness centrality\n**Closenes centrality** is a measure of how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\nwhere $N$ is the number of nodes in the network. The numerator, $N - 1$, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n&lt;img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Star_network_7.svg/1920px-Star_network_7.svg.png\" alt=\"Star graph S7\" width=\"50%\" style=\"display: block; margin-left: auto; margin-right: auto;\"&gt;\n\n\n\nHarmonic Centrality is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can’t reach others, making their distance infinite. This causes all centrality values to become zero, which isn’t very helpful!\nTo fix this, Beauchamp {footcite:p}beauchamp1965improved came up with a clever solution called harmonic centrality. It works even when the network is disconnected.\n\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n\n\n\n\nEccentricity centrality is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\nThese centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.\nA central node should be close to all other nodes.\nCloseness centrality captures the notion of “centrality” in the network. Namely, a node is central if it is close to all other nodes.\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N, is the normalization factor to make the centrality to have the maximum value of 1.\n\n\n\nEccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the maximum distance as opposed to the average distance like in the closeness centrality.\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\n\n\n\nAnother notion of centrality is betweenness centrality. It considers that a node is important if it lies on many shortest paths between other nodes.\n\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n\nwhere \\sigma_{jk} is the number of shortest paths between nodes j and k, and \\sigma_{jk}(i) is the number of shortest paths between nodes j and k that pass through node i.\n```````````````````"
  },
  {
    "objectID": "m06-centrality/degree-distance-based-centrality.html#different-centrality-measures",
    "href": "m06-centrality/degree-distance-based-centrality.html#different-centrality-measures",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Here we will focus on several popular centrality measures. Let us denote by c_i the centrality of node i throughout this section. Here is a preview of the centrality measures we will cover in this section\n\n\n\n\n\n\n\n\nCentrality\nCategory\nDescription\n\n\n\n\nDegree Centrality\nDegree\nCounts the number of edges connected to a node.\n\n\nCloseness Centrality\nShortest Path\nMeasures how close a node is to all other nodes in the network.\n\n\nEccentricity Centrality\nShortest Path\nBased on the maximum shortest path distance from a node to any other node.\n\n\nHarmonic Centrality\nShortest Path\nAdjusts closeness centrality to work even in disconnected networks.\n\n\nBetweenness Centrality\nShortest Path\nMeasures the extent to which a node lies on paths between other nodes.\n\n\nEigenvector Centrality\nWalk\nMeasures a node’s influence based on the influence of its neighbors.\n\n\nHITS (Hub and Authority) Centrality\nWalk\nMeasures the importance of nodes as hubs and authorities in a network.\n\n\nKatz Centrality\nWalk\nConsiders the total number of walks between nodes, with a damping factor.\n\n\nPageRank\nWalk\nMeasures the importance of nodes based on the structure of incoming links.\n\n\n\n\n\nPerhaps the simplest form of cnetrality is degree centrality. It is just the count of the number of edges connected to a node (i.e., the number of neighbors, or degree in network science terminology). The most important node is thus the one with the highest degree.\n\nc_i = d_i = \\sum_{j} A_{ij}\n\nwhere A_{ij} is the adjacency matrix of the network, and d_i is the degree of node i.\n\n\n\n\nLet’s talk about an ancient Roman monument called the Milliarium Aureum, also known as the Golden Milestone. It was the starting point for measuring distances on all major roads in the Roman Empire. Emperor Augustus built it when Rome changed from a republic to an empire. The monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire. Perhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define centrality in networks.\n\n\n\nClosenes centrality is a measure of how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N - 1, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n\n\n### Harmonic centrality\n\n**Harmonic Centrality** is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can't reach others, making their distance infinite. This causes all centrality values to become zero, which isn't very helpful!\n\nTo fix this, Beauchamp {footcite:p}`beauchamp1965improved` came up with a clever solution called *harmonic centrality*. It works even when the network is disconnected.\n\n$$\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n$$\n\n### Eccentricity centrality\n\n**Eccentricity centrality** is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n\nThese centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.\n\nA central node should be close to all other nodes.\n\nCloseness centrality captures the notion of \"centrality\" in the network. Namely, a node is *central* if it is close to all other nodes.\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\nwhere $N$ is the number of nodes in the network. The numerator, $N$, is the normalization factor to make the centrality to have the maximum value of 1.\n\n\n### Eccentricity centrality\n\nEccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the *maximum* distance as opposed to the average distance like in the closeness centrality.\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n\n### Betweenness centrality\n\nAnother notion of centrality is *betweenness centrality*. It considers that a node is important if it lies on many shortest paths between other nodes.\n\n$$\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n$$\n\nwhere $\\sigma_{jk}$ is the number of shortest paths between nodes $j$ and $k$, and $\\sigma_{jk}(i)$ is the number of shortest paths between nodes $j$ and $k$ that pass through node $i$.\n\n\n\n\n\n:::{#quarto-navigation-envelope .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyLXRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXItdGl0bGU=\"}\n[Course Information]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMQ==\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvd2VsY29tZS5odG1sV2VsY29tZQ==\"}\n[About us]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvYWJvdXQuaHRtbEFib3V0LXVz\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvZGlzY29yZC5odG1sRGlzY29yZA==\"}\n[Using Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvbWluaWRvcmEtdXNhZ2UuaHRtbFVzaW5nLU1pbmlkb3Jh\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvc2V0dXAuaHRtbFNldHVw\"}\n[How to submit assignment]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvaG93LXRvLXN1Ym1pdC1hc3NpZ25tZW50Lmh0bWxIb3ctdG8tc3VibWl0LWFzc2lnbm1lbnQ=\"}\n[Introduction]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMg==\"}\n[Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9pbnRyby93aHktbmV0d29ya3MuaHRtbE5ldHdvcmtz\"}\n[M01: Euler Path]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMw==\"}\n[A Stroll, Seven Bridges, and a Mathematical Revolution]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMS1jb25jZXB0cy5odG1sQS1TdHJvbGwsLVNldmVuLUJyaWRnZXMsLWFuZC1hLU1hdGhlbWF0aWNhbC1SZXZvbHV0aW9u\"}\n[Coding Networks in Python]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMi1jb2RpbmcuaHRtbENvZGluZy1OZXR3b3Jrcy1pbi1QeXRob24=\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcw==\"}\n[Advanced: Sparse Matrices for Large-Scale Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wNC1hZHZhbmNlZC5odG1sQWR2YW5jZWQ6LVNwYXJzZS1NYXRyaWNlcy1mb3ItTGFyZ2UtU2NhbGUtTmV0d29ya3M=\"}\n[M02: Small World]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNA==\"}\n[Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDEtY29uY2VwdHMuaHRtbENvcmUtQ29uY2VwdHM=\"}\n[Efficient Network Representation and Computing Paths]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDItY29kaW5nLmh0bWxFZmZpY2llbnQtTmV0d29yay1SZXByZXNlbnRhdGlvbi1hbmQtQ29tcHV0aW5nLVBhdGhz\"}\n[Exercises and Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDMtZXhlcmNpc2VzLmh0bWxFeGVyY2lzZXMtYW5kLUFzc2lnbm1lbnRz\"}\n[Appendix - Brief Introduction to igraph]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDQtYXBwZW5kaXguaHRtbEFwcGVuZGl4LS0tQnJpZWYtSW50cm9kdWN0aW9uLXRvLWlncmFwaA==\"}\n[M03: Robustness]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNQ==\"}\n[Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMS1jb25jZXB0cy5odG1sQ29yZS1Db25jZXB0cw==\"}\n[Coding - Network Robustness Analysis]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMi1jb2RpbmcuaHRtbENvZGluZy0tLU5ldHdvcmstUm9idXN0bmVzcy1BbmFseXNpcw==\"}\n[Exercises and Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcy1hbmQtQXNzaWdubWVudHM=\"}\n[Exercises and Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wNC1hcHBlbmRpeC5odG1sRXhlcmNpc2VzLWFuZC1Bc3NpZ25tZW50cw==\"}\n[M04: Friendship Paradox]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNg==\"}\n[Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtbm9kZS1kZWdyZWUvMDEtY29uY2VwdHMuaHRtbENvcmUtQ29uY2VwdHM=\"}\n[Visualizing Degree Distributions in Python]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtbm9kZS1kZWdyZWUvMDItY29kaW5nLmh0bWxWaXN1YWxpemluZy1EZWdyZWUtRGlzdHJpYnV0aW9ucy1pbi1QeXRob24=\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtbm9kZS1kZWdyZWUvMDMtZXhlcmNpc2VzLmh0bWxFeGVyY2lzZXM=\"}\n[M05: Clustering]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNw==\"}\n[Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMS1jb25jZXB0cy5odG1sQ29yZS1Db25jZXB0cw==\"}\n[Clustering Algorithms and Implementation]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMi1jb2RpbmcuaHRtbENsdXN0ZXJpbmctQWxnb3JpdGhtcy1hbmQtSW1wbGVtZW50YXRpb24=\"}\n[Exercises and Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcy1hbmQtQXNzaWdubWVudHM=\"}\n[M06: Centrality]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOA==\"}\n[Centrality Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMS1jb25jZXB0cy5odG1sQ2VudHJhbGl0eS1Db25jZXB0cw==\"}\n[Coding - Centrality]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMi1jb2RpbmcuaHRtbENvZGluZy0tLUNlbnRyYWxpdHk=\"}\n[Exercises & Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcy0mLUFzc2lnbm1lbnRz\"}\n[M07: Random Walks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOQ==\"}\n[Random Walks Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAxLWNvbmNlcHRzLmh0bWxSYW5kb20tV2Fsa3MtQ29uY2VwdHM=\"}\n[Coding - Random Walks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAyLWNvZGluZy5odG1sQ29kaW5nLS0tUmFuZG9tLVdhbGtz\"}\n[Exercises & Assignments]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAzLWV4ZXJjaXNlcy5odG1sRXhlcmNpc2VzLSYtQXNzaWdubWVudHM=\"}\n[M08: Embedding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTA=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[M09: Graph Neural Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTE=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Home]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SG9tZQ==\"}\n[/index.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2luZGV4Lmh0bWw=\"}\n[Course]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q291cnNl\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2VsY29tZQ==\"}\n[/course/welcome.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS93ZWxjb21lLmh0bWw=\"}\n[About]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWJvdXQ=\"}\n[/course/about.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9hYm91dC5odG1s\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RGlzY29yZA==\"}\n[/course/discord.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9kaXNjb3JkLmh0bWw=\"}\n[Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6TWluaWRvcmE=\"}\n[/course/minidora-usage.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9taW5pZG9yYS11c2FnZS5odG1s\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6U2V0dXA=\"}\n[/course/setup.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9zZXR1cC5odG1s\"}\n[Intro]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SW50cm8=\"}\n[Why Networks?]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2h5IE5ldHdvcmtzPw==\"}\n[/intro/why-networks.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2ludHJvL3doeS1uZXR3b3Jrcy5odG1s\"}\n[Foundations]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Rm91bmRhdGlvbnM=\"}\n[─── M01: Euler Path ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMTogRXVsZXIgUGF0aCDilIDilIDilIA=\"}\n[Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29uY2VwdHM=\"}\n[/m01-euler_tour/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[Coding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29kaW5n\"}\n[/m01-euler_tour/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAyLWNvZGluZy5odG1s\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RXhlcmNpc2Vz\"}\n[/m01-euler_tour/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQ=\"}\n[/m01-euler_tour/04-advanced.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzA0LWFkdmFuY2VkLmh0bWw=\"}\n[─── M02: Small World ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMjogU21hbGwgV29ybGQg4pSA4pSA4pSA\"}\n[/m02-small-world/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMS1jb25jZXB0cy5odG1s\"}\n[/m02-small-world/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMi1jb2RpbmcuaHRtbA==\"}\n[/m02-small-world/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMy1leGVyY2lzZXMuaHRtbA==\"}\n[Appendix]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QXBwZW5kaXg=\"}\n[/m02-small-world/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wNC1hcHBlbmRpeC5odG1s\"}\n[─── M03: Robustness ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMzogUm9idXN0bmVzcyDilIDilIDilIA=\"}\n[/m03-robustness/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m03-robustness/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAyLWNvZGluZy5odG1s\"}\n[/m03-robustness/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[/m03-robustness/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzA0LWFwcGVuZGl4Lmh0bWw=\"}\n[Core Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29yZSBUb3BpY3M=\"}\n[─── M04: Friendship Paradox ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNDogRnJpZW5kc2hpcCBQYXJhZG94IOKUgOKUgOKUgA==\"}\n[/m04-node-degree/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1ub2RlLWRlZ3JlZS8wMS1jb25jZXB0cy5odG1s\"}\n[/m04-node-degree/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1ub2RlLWRlZ3JlZS8wMi1jb2RpbmcuaHRtbA==\"}\n[/m04-node-degree/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1ub2RlLWRlZ3JlZS8wMy1leGVyY2lzZXMuaHRtbA==\"}\n[─── M05: Clustering ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNTogQ2x1c3RlcmluZyDilIDilIDilIA=\"}\n[/m05-clustering/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m05-clustering/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAyLWNvZGluZy5odG1s\"}\n[/m05-clustering/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[─── M06: Centrality ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNjogQ2VudHJhbGl0eSDilIDilIDilIA=\"}\n[/m06-centrality/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m06-centrality/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAyLWNvZGluZy5odG1s\"}\n[/m06-centrality/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQgVG9waWNz\"}\n[─── M07: Random Walks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNzogUmFuZG9tIFdhbGtzIOKUgOKUgOKUgA==\"}\n[/m07-random-walks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m07-random-walks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDItY29kaW5nLmh0bWw=\"}\n[/m07-random-walks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[─── M08: Embedding ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wODogRW1iZWRkaW5nIOKUgOKUgOKUgA==\"}\n[/m08-embedding/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m08-embedding/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDItY29kaW5nLmh0bWw=\"}\n[/m08-embedding/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m08-embedding/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDQtYXBwZW5kaXguaHRtbA==\"}\n[─── M09: Graph Neural Networks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wOTogR3JhcGggTmV1cmFsIE5ldHdvcmtzIOKUgOKUgOKUgA==\"}\n[/m09-graph-neural-networks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m09-graph-neural-networks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDItY29kaW5nLmh0bWw=\"}\n[/m09-graph-neural-networks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m09-graph-neural-networks/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDQtYXBwZW5kaXguaHRtbA==\"}\n\n:::{.hidden .quarto-markdown-envelope-contents render-id=\"Zm9vdGVyLWxlZnQ=\"}\nCopyright 2024, Sadamori Kojaku\n:::\n\n:::\n\n\n\n:::{#quarto-meta-markdown .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGF0aXRsZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkdGl0bGU=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZHRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGFzaXRlbmFtZQ==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkZGVzYw==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZGRkZXNj\"}\n:::\n\n\n\n\n&lt;!-- --&gt;\n\n::: {.quarto-embedded-source-code}\n```````````````````{.markdown shortcodes=\"false\"}\n# What is centrality?\n\nHave you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone's talking about right now?\nThese questions are all about finding out what's important in a network of people, ideas, or things. In network science, we call this *centrality.*\n\nCentrality or *importance* is a question of how important a node is in a network.\nBut the notion of *importance* is somewhat vague.\nIn what sense we say a node is important?\nAnswering this question needs a specific *context*, and there are many contexts in which the *importance* is defined.\n\n![](../figs/centrality.jpg)\n\n## Different centrality measures\n\nHere we will focus on several popular centrality measures. Let us denote by $c_i$ the centrality of node $i$ throughout this section.\nHere is a preview of the centrality measures we will cover in this section\n\n| Centrality          | Category            | Description                                                                 |\n|-------------------------|---------------------|-----------------------------------------------------------------------------|\n| Degree Centrality       | Degree              | Counts the number of edges connected to a node.                             |\n| Closeness Centrality    | Shortest Path  | Measures how close a node is to all other nodes in the network.             |\n| Eccentricity Centrality | Shortest Path  | Based on the maximum shortest path distance from a node to any other node.  |\n| Harmonic Centrality     | Shortest Path  | Adjusts closeness centrality to work even in disconnected networks.         |\n| Betweenness Centrality  | Shortest Path  | Measures the extent to which a node lies on paths between other nodes.      |\n| Eigenvector Centrality  | Walk           | Measures a node's influence based on the influence of its neighbors.        |\n| HITS (Hub and Authority) Centrality | Walk  | Measures the importance of nodes as hubs and authorities in a network.      |\n| Katz Centrality         | Walk           | Considers the total number of walks between nodes, with a damping factor.   |\n| PageRank                | Walk           | Measures the importance of nodes based on the structure of incoming links.  |\n\n\n### Degree centrality\n\nPerhaps the simplest form of cnetrality is *degree centrality*. It is just the count of the number of edges connected to a node (i.e., the number of neighbors, or *degree* in network science terminology). The most important node is thus the one with the highest degree.\n\n$$\nc_i = d_i = \\sum_{j} A_{ij}\n$$\n\nwhere $A_{ij}$ is the adjacency matrix of the network, and $d_i$ is the degree of node $i$.\n\n### Centrality based on shortest path\n\n\n&lt;img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Milliarium_Aureum_op_het_Forum_Romanum_te_Rome_Columna_Miliaria_in_Foro_Romano_%28titel_op_object%29_Antieke_monumenten_%28serietitel%29_Antiquae_Urbis_Splendor_%28serietitel%29%2C_RP-P-2016-345-28-1.jpg/1546px-thumbnail.jpg?20191217151048\" alt=\"Roma Foro Romano Miliarium Aureum\" width=\"80%\" style=\"display: block; margin-left: auto; margin-right: auto;\"&gt;\n\n\nLet's talk about an ancient Roman monument called the *Milliarium Aureum*, also known as the *Golden Milestone*.\nIt was the starting point for measuring distances on all major roads in the Roman Empire.\nEmperor Augustus built it when Rome changed from a republic to an empire.\nThe monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire.\nPerhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define *centrality* in networks.\n\n### Closeness centrality\n**Closenes centrality** is a measure of how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\nwhere $N$ is the number of nodes in the network. The numerator, $N - 1$, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n&lt;img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Star_network_7.svg/1920px-Star_network_7.svg.png\" alt=\"Star graph S7\" width=\"50%\" style=\"display: block; margin-left: auto; margin-right: auto;\"&gt;\n\n\n\nHarmonic Centrality is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can’t reach others, making their distance infinite. This causes all centrality values to become zero, which isn’t very helpful!\nTo fix this, Beauchamp {footcite:p}beauchamp1965improved came up with a clever solution called harmonic centrality. It works even when the network is disconnected.\n\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n\n\n\n\nEccentricity centrality is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\nThese centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.\nA central node should be close to all other nodes.\nCloseness centrality captures the notion of “centrality” in the network. Namely, a node is central if it is close to all other nodes.\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N, is the normalization factor to make the centrality to have the maximum value of 1.\n\n\n\nEccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the maximum distance as opposed to the average distance like in the closeness centrality.\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\n\n\n\nAnother notion of centrality is betweenness centrality. It considers that a node is important if it lies on many shortest paths between other nodes.\n\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n\nwhere \\sigma_{jk} is the number of shortest paths between nodes j and k, and \\sigma_{jk}(i) is the number of shortest paths between nodes j and k that pass through node i.\n```````````````````"
  },
  {
    "objectID": "m06-centrality/01-concepts.html",
    "href": "m06-centrality/01-concepts.html",
    "title": "Centrality Concepts",
    "section": "",
    "text": "Have you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone’s talking about right now? These questions are all about finding out what’s important in a network of people, ideas, or things. In network science, we call this centrality.\nCentrality or importance is a question of how important a node is in a network. But the notion of importance is somewhat vague. In what sense we say a node is important?\n\n\n\n\n\n\nExercise\n\n\n\nTry out the pen and paper exercise below to get a sense of centrality: School exercises",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Centrality Concepts"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#what-is-centrality",
    "href": "m06-centrality/01-concepts.html#what-is-centrality",
    "title": "Centrality Concepts",
    "section": "",
    "text": "Have you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone’s talking about right now? These questions are all about finding out what’s important in a network of people, ideas, or things. In network science, we call this centrality.\nCentrality or importance is a question of how important a node is in a network. But the notion of importance is somewhat vague. In what sense we say a node is important?\n\n\n\n\n\n\nExercise\n\n\n\nTry out the pen and paper exercise below to get a sense of centrality: School exercises",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Centrality Concepts"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#distance-based-centrality",
    "href": "m06-centrality/01-concepts.html#distance-based-centrality",
    "title": "Centrality Concepts",
    "section": "2 Distance-based centrality",
    "text": "2 Distance-based centrality\n\nLet’s talk about an ancient Roman monument called the Milliarium Aureum, also known as the Golden Milestone. It was the starting point for measuring distances on all major roads in the Roman Empire. Emperor Augustus built it when Rome changed from a republic to an empire. The monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire. Perhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define centrality in networks.\nThis family of centrality measures is based on shortest path distances between nodes. They consider a node important if it has short distances to other nodes or if it lies on many shortest paths.\n\nCloseness centrality\nCloseness centrality measures how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\n\n\n\n\n\n\n\n\nFigure 1: Closeness Centrality Visualization. Nodes with higher centrality (brighter colors) are closer to all other nodes on average.\n\n\n\n\n\nwhere N is the number of nodes in the network. The numerator, N - 1, is the normalization factor to make the centrality have a maximum value of 1.\n\n\nQuestion: What would be a graph where a node has the maximum closeness centrality of value 1?\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n\n\n\n\n\nHarmonic centrality\nThe closeness centrality falls short for disconnected networks. This is because the shortest distance between two nodes in different connected components is infinite, making the closeness centrality of all nodes in the disconnected components zero.\nA remedy is Harmonic centrality which adjusts closeness centrality (Beauchamp 1965) which is defined as\n\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n\n\n\n\n\n\n\n\n\nFigure 2: Harmonic Centrality Visualization. A variant of closeness that works well with disconnected components.\n\n\n\n\n\nThe distance between two nodes in different connected components has zero contribution to the harmonic centrality, making it a useful measure for disconnected networks.\n\n\nEccentricity centrality\nWhile the closeness and harmonic centralities focus on “average” distance, eccentricity centrality focuses on the farthest distance from a node to any other node. It is defined as\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\n\n\n\n\n\n\n\n\nFigure 3: Eccentricity Centrality Visualization. High-centrality nodes (brighter colors) have the smallest maximum distance to any other node.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen is eccentricity centrality useful?\n\n\n\nUnlike closeness or harmonic centrality, eccentricity centrality optimizes for the worst-case scenario, making it ideal when equity and maximum response times are critical. For example, placing emergency services or facilities to ensure no location is too far from help, designing robust communication or transportation networks that remain connected even if parts fail, and positioning distribution centers to guarantee reasonable delivery times to the most remote customers.\n\n\n\n\nBetweenness centrality\nBetweenness centrality considers that a node is important if it lies on many shortest paths between other nodes.\n\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n\n\n\n\n\n\n\n\n\nFigure 4: Betweenness Centrality Visualization. Brighter nodes lie on a larger number of shortest paths between other nodes.\n\n\n\n\n\nwhere \\sigma_{jk} is the number of shortest paths between nodes j and k, and \\sigma_{jk}(i) is the number of shortest paths between nodes j and k that pass through node i.",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Centrality Concepts"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#walk-based-centrality",
    "href": "m06-centrality/01-concepts.html#walk-based-centrality",
    "title": "Centrality Concepts",
    "section": "3 Walk-based centrality",
    "text": "3 Walk-based centrality\n“A man is known by the company he keeps” is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire. It suggests that a person’s character is reflected by the people this person is friends with. This idea can be applied to define the centrality of a node in a network.\nThis family of centrality measures considers that a node is important if it is connected to other important nodes, or if it receives many “walks” or “votes” from other nodes in the network. These measures often use recursive definitions and are computed using linear algebra techniques.\n\n\nAesop was an ancient Greek storyteller believed to have lived around the 6th century BCE. He is famous for his fables—short stories that use animals and everyday situations to teach moral lessons.\n\n\n\nThe Wolf and the Kid. Taken from Aesop’s Fables from Heritage History\n\n\n\nEigenvector centrality\nEigenvector centrality considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\n\\lambda c_i = \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i), when multiplied by a constant \\lambda, is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0). Using vector notation, we can rewrite the equation as\n\n\\lambda\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} =\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\lambda \\mathbf{c} = \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is the standard eigenvector equation! The solution \\mathbf{c} is an eigenvector of the adjacency matrix \\mathbf{A}, and \\lambda is its corresponding eigenvalue. But here’s the tricky part - a matrix can have multiple eigenvectors. So which one should we choose?\nLet’s think about what we want again. We want our centrality measure to be positive. It wouldn’t make much sense to have negative importance! So, we’re looking for an eigenvector where all the elements are positive. And a good news is that there’s a special eigenvector that fits the bill perfectly. The Perron-Frobenius theorem guarantees that the eigenvector associated with the largest eigenvalue always has all positive elements.\n\n\n\n\n\n\n\n\nFigure 5: Eigenvector Centrality Visualization. Brighter nodes are connected to other highly central nodes.\n\n\n\n\n\n\n\nPerron-Frobenius theorem: For a regular matrix \\mathbf{A} with and non-negative entries (A_{ij} \\geq 0), there exists a unique largest eigenvalue r &gt; 0 such that its corresponding eigenvector \\mathbf{v} has all positive entries: v_i &gt; 0 for all i.\nThus, the eigenvector centrality is the eigenvector of the adjacency matrix associated with the largest eigenvalue.\n\n\nHyperlink-Induced Topic Search (HITS) centrality\nHITS centrality extends eigenvector centrality to directed networks. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet’s put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbf{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n\n\n\n\nKatz centrality\nKatz centrality addresses a limitation of eigenvector centrality, which tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. The solution is to add a little bit of score to all nodes.\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\nThe equation can be solved by\n\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n\nwhere \\mathbf{1} is the vector of ones. By rewriting the equation, we get\n\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n\nBy taking the inverse of \\mathbf{I} - \\lambda \\mathbf{A}, we get\n$ = ( - )^{-1} $$\n\n\n\n\n\n\n\n\nFigure 6: Katz Centrality Visualization. A measure of influence that accounts for both direct and indirect connections.\n\n\n\n\n\n\n\nPageRank\nPageRank is the celebrated idea behind Google Search and can be seen as a cousin of Katz centrality.\n\nc_i = \\underbrace{(1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j}}_{\\text{Random walk from neighbors}} + \\underbrace{\\beta \\cdot \\frac{1}{N}}_{\\text{teleportation}}\n\n\n\n\n\n\n\n\n\nFigure 7: PageRank Centrality Visualization. Brighter nodes have a higher probability of being visited by a random walker.\n\n\n\n\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In the Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers.\n\n\nSee the following video for more details on PageRank:\n\n\n\n\nPersonalized PageRank\nPersonalized PageRank extends the standard PageRank algorithm by contextualizing the importance of nodes from a specific perspective in a network. To understand this, imagine you have a network of movies connected by similarity (sharing genres, actors, directors, etc.). Standard PageRank would rank movies based on their overall centrality in this similarity network. But suppose a student just watched “The Matrix” and wants to find similar movies. Personalized PageRank would start random walks from “The Matrix” and measure which movies are most reachable from it, effectively finding movies that are similar to “The Matrix” rather than just globally popular movies.\nPut it more formarmally, suppose a random walker starting from a node \\ell. The walker moves to the neighboring nodes just like in PageRank, but with a probability \\beta, it goes back to the starting node \\ell at every step.\nThus, \nc_i = \\underbrace{(1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j}}_{\\text{Random walk from neighbors}} + \\underbrace{\\beta \\cdot p_{\\ell}}_{\\text{Teleport to the starting node}}\n\nwhere p_{\\ell} is a one-hot vector that is 1 at the \\ell-th position and 0 elsewhere. The first term represents This equation can be solved numerically by taking the power iteration like we do for the PageRank. Alternatively, we can solve it by solving the linear system of equations.\n\n\nPersonalized PageRank can also be interpreted as the sum of probabilities of reaching each node from a focal set of nodes, where the probability decreases exponentially with distance. Let p_{\\ell i}^{(k)} be the probability of reaching node i from node \\ell in k steps. Then, the personalized PageRank is given by\n\nc_i = \\sum_{k=0}^{\\infty} \\beta (1-\\beta)^k p_{\\ell i}^{(k)}\n\nwhere ther term \\beta (1-\\beta)^k is the probability of reaching a node that is exactly k steps away. Think of it as a “weight” that decreases with distance. As i gets further away from the starting node \\ell. In other words, centrality of node i tends to be higher if it is closer to the starting node \\ell.\n\nPageRank and Personalized PageRank have been one of the most influential ideas in network science. There are many variants and extensions of these ideas. Here are some of my favorites:\n\n(Lambiotte and Rosvall 2012) proposes a teleportation method that corrects the bias coming from the degree of the starting node of PageRank.\n(Wu et al. 2017) proposes a second-order random walk-based proximity measure that considers the importance of a node in the context of a ranking problem.\n(Tong, Faloutsos, and Pan 2006) proposes a random walk with restart that considers the importance of a node in the context of a ranking problem.",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Centrality Concepts"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#degree-based-centrality",
    "href": "m06-centrality/01-concepts.html#degree-based-centrality",
    "title": "Centrality Concepts",
    "section": "4 Degree-based centrality",
    "text": "4 Degree-based centrality\nThe simplest approach to measuring centrality is to count the connections of each node. This gives us degree centrality, which considers a node important if it has many direct connections. Degree centrality is just the count of the number of edges connected to a node (i.e., the number of neighbors, or degree in network science terminology). The most important node is thus the one with the highest degree.\n\nc_i = d_i = \\sum_{j} A_{ij}\n\n\n\n\n\n\n\n\n\nFigure 8: Degree Centrality Visualization. The simplest measure: brighter nodes have more direct connections.\n\n\n\n\n\nwhere A_{ij} is the adjacency matrix of the network, and d_i is the degree of node i.\nDegree centrality is a no brainer measure of centrality. Interestingly, degree centralities are often strongly correlated with other centrality measures, such as the eigenvector centrality, pagerank, along with distance-based centralities (e.g., closeness centrality). Of course, degree centrality is a crude importance measure as it only focuses on the direct connections of a node and ignores who these connections are to.\nto.",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Centrality Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html",
    "href": "m05-clustering/02-coding.html",
    "title": "Clustering Algorithms and Implementation",
    "section": "",
    "text": "# If you are using Google Colab, uncomment the following line to install igraph\n#!sudo apt install libcairo2-dev pkg-config python3-dev\n#!pip install pycairo cairocffi\n#!pip install igraph\n\n\nLet us showcase how to use igraph to detect communities with modularity. We will use the Karate Club Network as an example.\n\nimport igraph\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10, 8))\ng = igraph.Graph.Famous(\"Zachary\")\nigraph.plot(g, target=ax, vertex_size=20)\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWhen it comes to maximizing modularity, there are a variety of algorithms to choose from. Two of the most popular ones are the Louvain and Leiden algorithms, both of which are implemented in igraph. The Louvain algorithm has been around for quite some time and is a classic choice, while the Leiden algorithm is a newer bee that often yields better accuracy. For our example, we’ll be using the Leiden algorithm, and I think you’ll find it really effective!\n\ncommunities = g.community_leiden(resolution=1, objective_function= \"modularity\")\n\nWhat is resolution? It is a parameter that helps us tackle the resolution limit of the modularity maximization algorithm {footcite}fortunato2007resolution! In simple terms, when we use the resolution parameter \\rho, the modularity formula can be rewritten as follow:\n\nQ(M) = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left(A_{ij} - \\rho \\frac{k_i k_j}{2m}\\right) \\delta(c_i, c_j)\n\nHere, the parameter \\rho plays a crucial role in balancing the positive and negative parts of the equation. The resolution limit comes into play because of the diminishing effect of the negative term as the number of edges m increases. The parameter \\rho can adjust this balance and allow us to circumvent the resolution limit.\nWhat is communities? This is a list of communities, where each community is represented by a list of nodes by their indices.\n\nprint(communities.membership)\n\n[0, 0, 0, 0, 1, 1, 1, 0, 2, 2, 1, 0, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2]\n\n\nLet us visualize the communities by coloring the nodes in the graph.\n\nimport seaborn as sns\ncommunity_membership = communities.membership\npalette = sns.color_palette().as_hex()\nfig, ax = plt.subplots(figsize=(10, 8))\nigraph.plot(g, target=ax, vertex_color=[palette[i] for i in community_membership])\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ncommunity_membership: This is a list of community membership for each node.\npalette: This is a list of colors to use for the communities.\nigraph.plot(g, vertex_color=[palette[i] for i in community_membership]): This plots the graph ‘g’ with nodes colored by their community.\n\n\n\n\nLet us turn the SBM as our community detection tool using graph-tool. This is a powerful library for network analysis, with a focus on the stochastic block model.\n#\n# Uncomment the following code if you are using Google Colab\n#\n#!wget https://downloads.skewed.de/skewed-keyring/skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n#!dpkg -i skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n#!echo \"deb [signed-by=/usr/share/keyrings/skewed-keyring.gpg] https://downloads.skewed.de/apt $(lsb_release -s -c) main\" &gt; /etc/apt/sources.list.d/skewed.list\n#!apt-get update\n#!apt-get install python3-graph-tool python3-matplotlib python3-cairo\n#!apt purge python3-cairo\n#!apt install libcairo2-dev pkg-config python3-dev\n#!pip install --force-reinstall pycairo\n#!pip install zstandard\nWe will identify the communities using the stochastic block model as follows. First, we will convert the graph object in igraph to that in graph-tool.\n\nimport graph_tool.all  as gt\nimport numpy as np\nimport igraph\n\n# igraph object\ng = igraph.Graph.Famous(\"Zachary\")\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Convert the graph object in igraph to that in graph-tool\nedges = g.get_edgelist()\nr, c = zip(*edges)\ng_gt = gt.Graph(directed=False)\ng_gt.add_edge_list(np.vstack([r, c]).T)\n\nThen, we will fit the stochastic block model to the graph.\n\n# Fit the stochastic block model\nstate = gt.minimize_blockmodel_dl(\n     g_gt,\n     state_args={\"deg_corr\": False, \"B_min\":2, \"B_max\":10},\n)\nb = state.get_blocks()\n\n\nB_min and B_max are the minimum and maximum number of communities to consider.\ndeg_corr is a boolean flag to switch to the degree-corrected SBM {footcite}karrer2011stochastic.\n\n\n\n\n\n\n\nNote\n\n\n\nHere’s a fun fact: the likelihood maximization on its own can’t figure out how many communities there should be. But graph-tool has a clever trick to circumvent this limitation. graph-tool actually fits multiple SBMs, each with a different number of communities. Then, it picks the most plausible one based on a model selection criterion.\n\n\nLet’s visualize the communities to see what we got.\n\n# Convert the block assignments to a list\ncommunity_membership = b.get_array()\n\n# The community labels may consist of non-consecutive integers, e.g., 10, 8, 1, 4, ...\n# So we reassign the community labels to be 0, 1, 2, ...\ncommunity_membership = np.unique(community_membership, return_inverse=True)[1]\ncommunity_membership\n\narray([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2])\n\n\n\n# Create a color palette\npalette = sns.color_palette().as_hex()\n# Plot the graph with nodes colored by their community\nfig, ax = plt.subplots(figsize=(10, 8))\nigraph.plot(\n    g,\n    target=ax,\n    vertex_color=[palette[i] for i in community_membership],\n)\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWhat we’re seeing here isn’t a failure at all. In fact, it’s the best partition according to our stochastic block model. The model has discovered something called a core-periphery structure (Borgatti and Everett 2000). Let me break that down:\n\nThink of a major international airport (the core) and smaller regional airports (the periphery).\nMajor international airports have many flights connecting to each other (densely connected).\nSmaller regional airports have fewer connections among themselves (sparsely connected).\nMany regional airports have flights to major hubs (periphery connected to the core).\n\nThat’s exactly what our model found in this network.\nIf we look at the adjacency matrix, we would see something that looks like an upside-down “L”. This shape is like a signature for core-periphery structures.\n\n# Convert igraph Graph to adjacency matrix\nA = np.array(g.get_adjacency().data)\n\n# Sort nodes based on their community (core first, then periphery)\nsorted_indices = np.argsort(community_membership)\nA_sorted = A[sorted_indices][:, sorted_indices]\n\n# Plot the sorted adjacency matrix\nplt.figure(figsize=(10, 8))\nplt.imshow(A_sorted, cmap='binary')\nplt.title(\"Sorted Adjacency Matrix: Core-Periphery Structure\")\nplt.xlabel(\"Node Index (sorted)\")\nplt.ylabel(\"Node Index (sorted)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTo account for",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Clustering Algorithms and Implementation"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html#modularity-maximization",
    "href": "m05-clustering/02-coding.html#modularity-maximization",
    "title": "Clustering Algorithms and Implementation",
    "section": "",
    "text": "Let us showcase how to use igraph to detect communities with modularity. We will use the Karate Club Network as an example.\n\nimport igraph\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10, 8))\ng = igraph.Graph.Famous(\"Zachary\")\nigraph.plot(g, target=ax, vertex_size=20)\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWhen it comes to maximizing modularity, there are a variety of algorithms to choose from. Two of the most popular ones are the Louvain and Leiden algorithms, both of which are implemented in igraph. The Louvain algorithm has been around for quite some time and is a classic choice, while the Leiden algorithm is a newer bee that often yields better accuracy. For our example, we’ll be using the Leiden algorithm, and I think you’ll find it really effective!\n\ncommunities = g.community_leiden(resolution=1, objective_function= \"modularity\")\n\nWhat is resolution? It is a parameter that helps us tackle the resolution limit of the modularity maximization algorithm {footcite}fortunato2007resolution! In simple terms, when we use the resolution parameter \\rho, the modularity formula can be rewritten as follow:\n\nQ(M) = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left(A_{ij} - \\rho \\frac{k_i k_j}{2m}\\right) \\delta(c_i, c_j)\n\nHere, the parameter \\rho plays a crucial role in balancing the positive and negative parts of the equation. The resolution limit comes into play because of the diminishing effect of the negative term as the number of edges m increases. The parameter \\rho can adjust this balance and allow us to circumvent the resolution limit.\nWhat is communities? This is a list of communities, where each community is represented by a list of nodes by their indices.\n\nprint(communities.membership)\n\n[0, 0, 0, 0, 1, 1, 1, 0, 2, 2, 1, 0, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2]\n\n\nLet us visualize the communities by coloring the nodes in the graph.\n\nimport seaborn as sns\ncommunity_membership = communities.membership\npalette = sns.color_palette().as_hex()\nfig, ax = plt.subplots(figsize=(10, 8))\nigraph.plot(g, target=ax, vertex_color=[palette[i] for i in community_membership])\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ncommunity_membership: This is a list of community membership for each node.\npalette: This is a list of colors to use for the communities.\nigraph.plot(g, vertex_color=[palette[i] for i in community_membership]): This plots the graph ‘g’ with nodes colored by their community.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Clustering Algorithms and Implementation"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html#stochstic-block-model",
    "href": "m05-clustering/02-coding.html#stochstic-block-model",
    "title": "Clustering Algorithms and Implementation",
    "section": "",
    "text": "Let us turn the SBM as our community detection tool using graph-tool. This is a powerful library for network analysis, with a focus on the stochastic block model.\n#\n# Uncomment the following code if you are using Google Colab\n#\n#!wget https://downloads.skewed.de/skewed-keyring/skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n#!dpkg -i skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n#!echo \"deb [signed-by=/usr/share/keyrings/skewed-keyring.gpg] https://downloads.skewed.de/apt $(lsb_release -s -c) main\" &gt; /etc/apt/sources.list.d/skewed.list\n#!apt-get update\n#!apt-get install python3-graph-tool python3-matplotlib python3-cairo\n#!apt purge python3-cairo\n#!apt install libcairo2-dev pkg-config python3-dev\n#!pip install --force-reinstall pycairo\n#!pip install zstandard\nWe will identify the communities using the stochastic block model as follows. First, we will convert the graph object in igraph to that in graph-tool.\n\nimport graph_tool.all  as gt\nimport numpy as np\nimport igraph\n\n# igraph object\ng = igraph.Graph.Famous(\"Zachary\")\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Convert the graph object in igraph to that in graph-tool\nedges = g.get_edgelist()\nr, c = zip(*edges)\ng_gt = gt.Graph(directed=False)\ng_gt.add_edge_list(np.vstack([r, c]).T)\n\nThen, we will fit the stochastic block model to the graph.\n\n# Fit the stochastic block model\nstate = gt.minimize_blockmodel_dl(\n     g_gt,\n     state_args={\"deg_corr\": False, \"B_min\":2, \"B_max\":10},\n)\nb = state.get_blocks()\n\n\nB_min and B_max are the minimum and maximum number of communities to consider.\ndeg_corr is a boolean flag to switch to the degree-corrected SBM {footcite}karrer2011stochastic.\n\n\n\n\n\n\n\nNote\n\n\n\nHere’s a fun fact: the likelihood maximization on its own can’t figure out how many communities there should be. But graph-tool has a clever trick to circumvent this limitation. graph-tool actually fits multiple SBMs, each with a different number of communities. Then, it picks the most plausible one based on a model selection criterion.\n\n\nLet’s visualize the communities to see what we got.\n\n# Convert the block assignments to a list\ncommunity_membership = b.get_array()\n\n# The community labels may consist of non-consecutive integers, e.g., 10, 8, 1, 4, ...\n# So we reassign the community labels to be 0, 1, 2, ...\ncommunity_membership = np.unique(community_membership, return_inverse=True)[1]\ncommunity_membership\n\narray([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2])\n\n\n\n# Create a color palette\npalette = sns.color_palette().as_hex()\n# Plot the graph with nodes colored by their community\nfig, ax = plt.subplots(figsize=(10, 8))\nigraph.plot(\n    g,\n    target=ax,\n    vertex_color=[palette[i] for i in community_membership],\n)\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWhat we’re seeing here isn’t a failure at all. In fact, it’s the best partition according to our stochastic block model. The model has discovered something called a core-periphery structure (Borgatti and Everett 2000). Let me break that down:\n\nThink of a major international airport (the core) and smaller regional airports (the periphery).\nMajor international airports have many flights connecting to each other (densely connected).\nSmaller regional airports have fewer connections among themselves (sparsely connected).\nMany regional airports have flights to major hubs (periphery connected to the core).\n\nThat’s exactly what our model found in this network.\nIf we look at the adjacency matrix, we would see something that looks like an upside-down “L”. This shape is like a signature for core-periphery structures.\n\n# Convert igraph Graph to adjacency matrix\nA = np.array(g.get_adjacency().data)\n\n# Sort nodes based on their community (core first, then periphery)\nsorted_indices = np.argsort(community_membership)\nA_sorted = A[sorted_indices][:, sorted_indices]\n\n# Plot the sorted adjacency matrix\nplt.figure(figsize=(10, 8))\nplt.imshow(A_sorted, cmap='binary')\nplt.title(\"Sorted Adjacency Matrix: Core-Periphery Structure\")\nplt.xlabel(\"Node Index (sorted)\")\nplt.ylabel(\"Node Index (sorted)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTo account for",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Clustering Algorithms and Implementation"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html",
    "href": "m04-node-degree/02-coding.html",
    "title": "Visualizing Degree Distributions in Python",
    "section": "",
    "text": "We’ll start by creating a scale-free network using the Barabási-Albert model and computing its degree distribution. This model generates networks with power-law degree distributions, making it ideal for demonstrating visualization techniques that work well with heavy-tailed distributions.\n\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a Barabási-Albert network with 10,000 nodes\ng = igraph.Graph.Barabasi(n=10000, m=1)\nA = g.get_adjacency()\n\nThe first step in analyzing any network is computing the degree sequence. In Python, we can extract degrees directly from the adjacency matrix by summing along rows (for undirected networks, row and column sums are identical). The flatten() method ensures we get a 1D array of degree values.\n\n# Compute degree for each node\ndeg = np.sum(A, axis=1).flatten()\n\n# Convert to probability distribution\np_deg = np.bincount(deg) / len(deg)",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#computing-degree-distributions-from-network-data",
    "href": "m04-node-degree/02-coding.html#computing-degree-distributions-from-network-data",
    "title": "Visualizing Degree Distributions in Python",
    "section": "",
    "text": "We’ll start by creating a scale-free network using the Barabási-Albert model and computing its degree distribution. This model generates networks with power-law degree distributions, making it ideal for demonstrating visualization techniques that work well with heavy-tailed distributions.\n\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a Barabási-Albert network with 10,000 nodes\ng = igraph.Graph.Barabasi(n=10000, m=1)\nA = g.get_adjacency()\n\nThe first step in analyzing any network is computing the degree sequence. In Python, we can extract degrees directly from the adjacency matrix by summing along rows (for undirected networks, row and column sums are identical). The flatten() method ensures we get a 1D array of degree values.\n\n# Compute degree for each node\ndeg = np.sum(A, axis=1).flatten()\n\n# Convert to probability distribution\np_deg = np.bincount(deg) / len(deg)",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#why-standard-histograms-fail-for-degree-distributions",
    "href": "m04-node-degree/02-coding.html#why-standard-histograms-fail-for-degree-distributions",
    "title": "Visualizing Degree Distributions in Python",
    "section": "2 Why standard histograms fail for degree distributions",
    "text": "2 Why standard histograms fail for degree distributions\nLet’s start with the obvious approach—a simple histogram. This immediately reveals why degree distribution visualization is challenging.\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\nax.set_title('Linear Scale: Most Information Hidden')\n\nText(0.5, 1.0, 'Linear Scale: Most Information Hidden')\n\n\n\n\n\n\n\n\n\nThis linear-scale plot shows the fundamental problem: most nodes cluster at low degrees, making the interesting high-degree tail invisible. Since power-law networks have heavy tails—a few nodes with very high degrees—we need visualization techniques that can handle this extreme heterogeneity.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#log-log-plots-revealing-the-power-law-structure",
    "href": "m04-node-degree/02-coding.html#log-log-plots-revealing-the-power-law-structure",
    "title": "Visualizing Degree Distributions in Python",
    "section": "3 Log-log plots: revealing the power-law structure",
    "text": "3 Log-log plots: revealing the power-law structure\nSwitching to logarithmic scales on both axes dramatically improves visibility across the entire degree range. This transformation is essential for identifying power-law behavior, which appears as straight lines in log-log space.\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_ylim(np.min(p_deg[p_deg&gt;0])*0.01, None)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\nax.set_title('Log-Log Scale: Structure Revealed')\n\nText(0.5, 1.0, 'Log-Log Scale: Structure Revealed')\n\n\n\n\n\n\n\n\n\nThe log-log plot reveals the power-law structure, but notice the noisy fluctuations at high degrees. This noise occurs because only a few nodes have very high degrees, leading to statistical fluctuations. While binning could smooth these fluctuations, it introduces arbitrary choices about bin sizes and loses information.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#the-ccdf-approach-smooth-curves-without-binning",
    "href": "m04-node-degree/02-coding.html#the-ccdf-approach-smooth-curves-without-binning",
    "title": "Visualizing Degree Distributions in Python",
    "section": "4 The CCDF approach: smooth curves without binning",
    "text": "4 The CCDF approach: smooth curves without binning\nThe complementary cumulative distribution function (CCDF) provides a superior visualization method. Instead of plotting the fraction of nodes with exactly degree k, CCDF plots the fraction with degree greater than k. This approach naturally smooths the data without requiring binning decisions.\n\n# Compute CCDF: fraction of nodes with degree &gt; k\nccdf_deg = 1 - np.cumsum(p_deg)[:-1]  # Exclude last element (always 0)\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\nax.set_title('CCDF: Smooth Power-Law Visualization')\n\nText(0.5, 1.0, 'CCDF: Smooth Power-Law Visualization')\n\n\n\n\n\n\n\n\n\nThe CCDF produces clean, interpretable curves even for noisy data. The slope directly relates to the power-law exponent: steeper slopes indicate more homogeneous degree distributions (fewer hubs), while flatter slopes suggest more heterogeneous distributions (more extreme hubs). This visualization technique has become the standard in network science for analyzing heavy-tailed distributions.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#implementing-the-friendship-paradox",
    "href": "m04-node-degree/02-coding.html#implementing-the-friendship-paradox",
    "title": "Visualizing Degree Distributions in Python",
    "section": "5 Implementing the friendship paradox",
    "text": "5 Implementing the friendship paradox\nNow let’s demonstrate the friendship paradox computationally. As covered in the concepts module, this phenomenon arises because high-degree nodes are more likely to be someone’s friend than low-degree nodes. We’ll implement this by sampling friends through edge-based sampling.\nTo capture this bias, we need to sample edges rather than nodes. When we sample an edge uniformly at random, we’re effectively sampling one endpoint of that edge—this gives us a “friend” from someone’s perspective. The key insight is that nodes with higher degrees appear as endpoints more frequently, creating the degree bias that drives the friendship paradox.\n\nfrom scipy import sparse\n\n# Extract all edges from the adjacency matrix\nsrc, trg, _ = sparse.find(A)\nprint(f\"Total number of edges: {len(src)}\")\nprint(f\"First few source nodes: {src[:10]}\")\nprint(f\"First few target nodes: {trg[:10]}\")\n\nTotal number of edges: 19998\nFirst few source nodes: [0 0 0 0 0 0 0 0 0 0]\nFirst few target nodes: [   1   24  242  555 1385 1885 2254 2521 2654 5133]\n\n\nThe sparse.find() function returns three arrays: source nodes, target nodes, and edge weights. Since we’re working with an unweighted network, we ignore the weights. Each edge appears twice in an undirected network (once as src→trg and once as trg→src), which is exactly what we want for sampling friends.\nNow we can compute the degree distribution of friends by taking the degrees of the source nodes from our edge list. This automatically implements the degree-biased sampling because high-degree nodes appear more frequently in the source node list.\n\n# Get degrees of \"friends\" (source nodes from edge sampling)\ndeg_friend = deg[src]\n\n# Compute degree distribution of friends\np_deg_friend = np.bincount(deg_friend) / len(deg_friend)\n\nprint(f\"Average degree in network: {np.mean(deg):.2f}\")\nprint(f\"Average degree of friends: {np.mean(deg_friend):.2f}\")\nprint(f\"Friendship paradox ratio: {np.mean(deg_friend) / np.mean(deg):.2f}\")\n\nAverage degree in network: 2.00\nAverage degree of friends: 4.87\nFriendship paradox ratio: 2.44",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#visualizing-the-degree-bias",
    "href": "m04-node-degree/02-coding.html#visualizing-the-degree-bias",
    "title": "Visualizing Degree Distributions in Python",
    "section": "6 Visualizing the degree bias",
    "text": "6 Visualizing the degree bias\nLet’s create a side-by-side comparison of both distributions using CCDF plots. This clearly shows how the friendship paradox manifests as a shift toward higher degrees in the friend distribution.\n\n# Compute CCDFs for both distributions\nccdf_deg = 1 - np.cumsum(p_deg)[:-1]\nccdf_deg_friend = 1 - np.cumsum(p_deg_friend)[:-1]\n\n# Create comparison plot\nfig, ax = plt.subplots(figsize=(10, 6))\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg,\n                  label='Regular nodes', linewidth=2, color='blue')\nax = sns.lineplot(x=np.arange(len(ccdf_deg_friend)), y=ccdf_deg_friend,\n                  label='Friends (degree-biased)', linewidth=2, color='red', ax=ax)\n\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\nax.set_title('Friendship Paradox: Friends Have Higher Degrees')\nax.legend(frameon=False)\nax.grid(True, alpha=0.3)\n\n\n\n\n\n\n\n\nThe plot clearly demonstrates the friendship paradox: the friend distribution (red line) lies below the node distribution (blue line), indicating that friends have systematically higher degrees. The flatter slope of the friend CCDF shows that the probability of encountering high-degree friends is much higher than encountering high-degree nodes when sampling uniformly.\nThis computational demonstration confirms the theoretical prediction that your friends will, on average, have more friends than you do. The magnitude of this effect depends on the heterogeneity of the degree distribution—the more heterogeneous the network, the stronger the friendship paradox becomes.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html",
    "href": "m03-robustness/03-exercises.html",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "✍️ Pen and Paper Exercise",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#pen-and-paper-exercise-from-mst-to-robust-grid-design",
    "href": "m03-robustness/03-exercises.html#pen-and-paper-exercise-from-mst-to-robust-grid-design",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "✍️ Pen and Paper Exercise",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#network-design-challenges",
    "href": "m03-robustness/03-exercises.html#network-design-challenges",
    "title": "Exercises and Assignments",
    "section": "2 Network Design Challenges",
    "text": "2 Network Design Challenges\n🚀 Interactive Demo",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#assignment",
    "href": "m03-robustness/03-exercises.html#assignment",
    "title": "Exercises and Assignments",
    "section": "3 Assignment",
    "text": "3 Assignment\n\nFor students enrolled in SSIE 641, you will receive a dedicated link to the assignment repository from the instructor.\nFor those who are not enrolled, fork this assignment repository at Github.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html",
    "href": "m03-robustness/01-concepts.html",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will explore network robustness through the lens of infrastructure design. Starting from the historical challenge of building cost-effective power grids, we will learn:\n\nHow minimum spanning trees provide optimal cost-efficiency for network connectivity\nWhy real-world networks have redundancies beyond minimum connectivity requirements\nHow networks respond to random failures versus targeted attacks\nQuantitative measures of network robustness and percolation theory\nDesign principles for balancing cost efficiency with resilience\n\nKeywords: minimum spanning tree, Kruskal’s algorithm, Prim’s algorithm, network redundancy, random failures, targeted attacks, connectivity loss, R-index, percolation, robustness paradox",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#what-to-learn-in-this-module",
    "href": "m03-robustness/01-concepts.html#what-to-learn-in-this-module",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will explore network robustness through the lens of infrastructure design. Starting from the historical challenge of building cost-effective power grids, we will learn:\n\nHow minimum spanning trees provide optimal cost-efficiency for network connectivity\nWhy real-world networks have redundancies beyond minimum connectivity requirements\nHow networks respond to random failures versus targeted attacks\nQuantitative measures of network robustness and percolation theory\nDesign principles for balancing cost efficiency with resilience\n\nKeywords: minimum spanning tree, Kruskal’s algorithm, Prim’s algorithm, network redundancy, random failures, targeted attacks, connectivity loss, R-index, percolation, robustness paradox",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#pen-and-paper-exercise-from-mst-to-robust-grid-design",
    "href": "m03-robustness/01-concepts.html#pen-and-paper-exercise-from-mst-to-robust-grid-design",
    "title": "Core Concepts",
    "section": "2 Pen-and-Paper Exercise: From MST to Robust Grid Design",
    "text": "2 Pen-and-Paper Exercise: From MST to Robust Grid Design\n\n✍️ Pen and Paper Exercise: Starting with a minimum spanning tree for cost efficiency, design a power grid network that maintains connectivity even when key components fail.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#network-design-challenges",
    "href": "m03-robustness/01-concepts.html#network-design-challenges",
    "title": "Core Concepts",
    "section": "3 Network Design Challenges",
    "text": "3 Network Design Challenges\n🚀 Interactive Demo",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#power-grid-design-challenge",
    "href": "m03-robustness/01-concepts.html#power-grid-design-challenge",
    "title": "Core Concepts",
    "section": "4 Power Grid Design Challenge",
    "text": "4 Power Grid Design Challenge\nIn the aftermath of World War I, the newly formed Czechoslovakia faced massive reconstruction challenges. Cities and towns across Moravia needed electricity, but the young nation had limited resources. Every resources spent on unnecessary infrastructure was a resource not available for hospitals, schools, or economic recovery. Engineers at the West Moravian Power Company faced a critical question: How do you connect every town and village to the electrical grid while using the minimum length of cable?\n\n\nOtakar Borůvka (1899-1995) was a Czech mathematician who is best known for his work on the minimum spanning tree problem.\n\nThe problem reached mathematician Otakar Borůvka through his friend at the power company. Borůvka’s 1926 solution gave us the first systematic approach to what we now call the minimum spanning tree problem: finding the cheapest way to connect all locations in a network.\n\nMinimum Spanning Tree\nA minimum spanning tree (MST) of a weighted network is a tree that:\n\nSpans all nodes (connects every location in the network)\nIs a tree (connected with no cycles - no redundant loops)\nHas minimum total weight among all possible spanning trees\n\nOtakar Borůvka delivered the first algorithm to solve this problem: Borůvka’s algorithm. But it is not the only algorithm to find the minimum spanning tree. In fact, there are several algorithms. We will cover two algorithms: Kruskal’s algorithm and Prim’s algorithm, which are easier to understand and implement.\n\n\nFinding the Minimum Spanning Tree\n\n\n\n\n\nKruskal’s Algorithm\nKruskal’s algorithm embodies a remarkably simple yet powerful intuition: always choose the cheapest available option, but never create wasteful loops. While sounds heuristic, this algorithm in fact leads to the global optimial solution!\nThe algorithm works by first sorting every possible connection from cheapest to most expensive like arranging all the cable segments by cost. Then, it examines each connection in order, asking a crucial question: “If I add this cable, will it create a redundant loop?” If the answer is no, the cable joins the growing network. If adding it would create a cycle—meaning the two locations are already connected through some other path—the algorithm skips it as wasteful. This process continues until every location is connected, guaranteeing both minimum cost and complete coverage.\n\n\nPrim’s Algorithm\nPrim’s algorithm takes a fundamentally different approach, embodying the intuition of organic growth from a single starting point. Picture an engineer beginning at the central power plant and asking: “What’s the cheapest way to connect one more location to our existing grid?” This local growth strategy builds the network incrementally, always expanding from what’s already been constructed.\nThe algorithm begins by selecting any location as its starting point, often the power plant in our analogy. From this initial seed, it repeatedly identifies the cheapest connection that would bring a new, unconnected location into the growing network. Unlike Kruskal’s global view, Prim’s algorithm maintains a clear distinction between locations already in the network and those still waiting to be connected. At each step, it finds the minimum-cost bridge between these two groups, gradually expanding the connected region until it encompasses every location.\nThis local expansion strategy mirrors how many real-world infrastructure projects actually develop. Engineers often start from existing facilities and expand outward, always seeking the most cost-effective way to serve additional areas. Prim’s algorithm formalizes this natural growth process.\n\n    \n    \n    \n    mo.vstack(%0A%20%20%20%20%5B%0A%20%20%20%20%20%20%20%20unique_weights%2C%0A%20%20%20%20%20%20%20%20time_step%2C%0A%20%20%20%20%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%20%20%20%20%22**Instructions**%3A%20Move%20the%20slider%20to%20see%20how%20each%20algorithm%20builds%20the%20MST%20step%20by%20step.%22%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%5D%0A)\n\n\n    \n    \n    \n    fig\n\n\n\n\n\n\n\nNote\n\n\n\nTwo algorithms find the same minimum spanning tree when all connection costs are different. If there are connections with the same cost, there are multiple minimum spanning trees of the same cost, and which tree to find depends on the algorithm. In particular, Prim’s algorithm finds different trees when starting from different locations.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#why-minimum-spanning-tree-is-not-enough",
    "href": "m03-robustness/01-concepts.html#why-minimum-spanning-tree-is-not-enough",
    "title": "Core Concepts",
    "section": "5 Why Minimum Spanning Tree is Not Enough",
    "text": "5 Why Minimum Spanning Tree is Not Enough\nMinimum spanning tree is an efficient way to connect all locations in a network with the minimum total cost. However, such a network is vulnerable to failures, e.g., the network can be disconnected when a single node fails, in particular those close to the center of the network. This is why our power grid has a lot of redundancies beyond the minimum spanning tree, for the sake of resilience against failures.\n\n\n\n\n\n\nFigure 1: This is the power grid of the United States.\n\n\n\n\nMeasuring Network Damage\nNot every failure is equal. Some failures are more damaging than others. For example, removing somee nodes in a grid network can be catastrophic, while removing other nodes can be more tolerable.\nWhile there can be many metrics to quantify network damage, we will focus on a purely topological metric: the fraction of nodes remaining in the largest connected component after removal.\n\n\\text{Connectivity} = \\frac{\\text{Size of largest component after removal}}{\\text{Original network size}}\n\n\n\n\n\n\n\nFigure 2\n\n\n\nThe robustness profile plots connectivity against the fraction of nodes removed, revealing how networks fragment. Crucially, the shape of this profile depends entirely on the order in which nodes are removed - random removal creates one pattern, while strategic targeting creates dramatically different patterns.\n\n\n\n\n\n\nFigure 3\n\n\n\nTo compare networks with a single metric, we use the R-index - the area under this curve:\n\nR = \\frac{1}{N} \\sum_{k=1}^{N-1} y_k\n\nThe robustness index is a measure of how robust a network is to under a sequential failure of nodes. The higher the R-index, the more robust the network is.\nNetworks can exhibit different robustness profiles under different attack strategies. One form of an attack is a random failure, where nodes are removed randomly. Another form of an attack is a targeted attack, where nodes are removed strategically.\nRandom failures are like earthquakes or equipment malfunctions; they strike unpredictably. In power grids, generators might fail due to technical problems. In computer networks, servers might crash randomly.\nEven if a network survives random failures beautifully, it might crumble under targeted attacks. Adversaries strategically choose which nodes to attack for maximum damage. The most intuitive strategy targets high-degree nodes (hubs) first, i.e., like targeting the busiest airports to disrupt air travel.\n\n\nThe asymmetry between random failures and targeted attacks is one of the most counterintuitive discoveries in network science. A network that seems robust can have hidden vulnerabilities that smart adversaries can exploit.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#theoretical-framework-for-network-robustness",
    "href": "m03-robustness/01-concepts.html#theoretical-framework-for-network-robustness",
    "title": "Core Concepts",
    "section": "6 Theoretical Framework for Network Robustness",
    "text": "6 Theoretical Framework for Network Robustness\nTo understand these patterns mathematically, we can view network attacks as the reverse process of percolation. Percolation theory studies phase transitions in connectivity by asking: as we randomly add nodes to a grid, when does a giant connected component emerge? Network robustness asks the opposite: as we remove nodes, when does the giant component disappear?\n\n\nPercolation theory originated in physics to understand how liquids flow through porous materials. The same mathematics explains how networks fragment under node removal - a beautiful example of how physics concepts illuminate network behavior.\n\n    \n    \n    \n    p_slider\n\n\n    \n    \n    \n    percolation_visualization()\n\n\n\nPercolation vs. Robustness: Two Sides of the Same Coin\nPercolation theory asks: “Starting from isolation, how many nodes must we connect to form a giant component?” - increasing connectivity from p = 0 to p = 1.\nRobustness analysis asks: “Starting from full connectivity, how many nodes must we remove to fragment the network?” - decreasing connectivity from p = 1 to p = 0.\nThese are mathematically equivalent processes, just viewed in opposite directions along the same connectivity parameter.\n\nThe Phase Transition\nImagine a grid where each square randomly becomes a “puddle” with probability p. As p increases, something dramatic happens - suddenly, a giant puddle spanning the entire grid appears! This phase transition occurs at a critical probability p_c. Crucially, the exact timing doesn’t matter; only the fraction of nodes present or removed determines connectivity.\n\n    \n    \n    \n    p_slider\n\n\n    \n    \n    \n    phase_transition_plot()\n\n\n\nThe Molloy-Reed Criterion\nFor networks with arbitrary degree distributions, the Molloy-Reed criterion determines whether a giant component exists - that is, whether the network contains a single large connected component that includes most of the nodes:\n\n\\kappa = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} &gt; 2\n\nwhere \\langle k \\rangle is the average degree and \\langle k^2 \\rangle is the average of squared degrees. The ratio \\kappa measures degree heterogeneity - networks with hubs have high \\kappa, while degree homogeneous networks have low \\kappa. When \\kappa &gt; 2, a giant component forms that dominates the network connectivity. See the Appendix for the proof of the Molloy-Reed criterion.\nThe Molloy-Reed criterion is a powerful tool to predict the existence of a giant component in a network and allows us to find the critical fraction of nodes that must be removed to break the network. This critial fraction depends on the strategy of the attack, along with the degree distribution. For simplicity, let us restrict ourselves into the random failures. For the random failure case, the critical fraction is given by:\n\nf_c = 1 - \\frac{1}{\\kappa - 1}\n\nThe value of \\kappa depends on the degree distribution, and below, we showcase two examples of degree distributions.\n\nDegree homogeneous network\nIn case of a degree homogeneous network like a random network considered in the exercise above, the critical fraction is given by:\n\nf_c = 1 - \\frac{1}{\\langle k \\rangle}\n\ngiven that \\langle k^2 \\rangle = \\langle k \\rangle^2 and thus \\kappa = \\langle k \\rangle. This suggests that the threshold is determined by the average degree \\langle k \\rangle. A large \\langle k \\rangle results in a larger f_c, meaning that the network is more robust against random failures.\n\n\nDegree heterogeneous network\nMost real-world networks are degree heterogeneous, i.e., the degree distribution P(k) \\sim k^{-\\gamma} follows a power law (called scale-free network). The power-law degree distribution has infinite second moment, i.e., \\langle k^2 \\rangle = \\infty and thus f_c = 1.0, which means that all nodes must be removed to break the network into disconnected components. This is the case where the number of nodes is infinite (i.e., so that a node has a very large degree for the degree distribution to be a valid power law). When restricting the maximum degree to be finite, the critical fraction is given by:\n\nf_c =\n\\begin{cases}\n1 - \\dfrac{1}{\\frac{\\gamma-2}{3-\\gamma} k_{\\text{min}} ^{\\gamma-2} k_{\\text{max}}^{3-\\gamma} -1} & \\text{if } 2 &lt; \\gamma &lt; 3 \\\\\n1 - \\dfrac{1}{\\frac{\\gamma-2}{\\gamma-3} k_{\\text{min}} - 1} & \\text{if } \\gamma &gt; 3 \\\\\n\\end{cases}\n\nwhere k_{\\text{min}} and k_{\\text{max}} are the minimum and maximum degree, respectively. The variable \\gamma is the exponent of the power law degree distribution, controlling the degree heterogeneity, where a lower \\gamma results in a more degree heterogeneous network.\n\nFor regime 2 &lt; \\gamma &lt; 3, the critical threshold f_c is determined by the extreme values of the degree distribution, k_{\\text{min}} and k_{\\text{max}}. And f_c \\rightarrow 1 when the maximum degree k_{\\text{max}} \\in [k_{\\text{min}}, N-1] increases. Notably, in this regime, the maximum degree k_{\\text{max}} increases as the network size N increases, and this makes f_c \\rightarrow 1.\nFor regime \\gamma &gt; 3, the critical threshold f_c is influenced by the minimum degree k_{\\text{min}}. In contrast to k_{\\text{max}}, k_{\\text{min}} remains constant as the network size N grows. Consequently, the network disintegrates when a finite fraction of its nodes are removed.\n\n\n    \n    \n    \n    chart_fc\n\n\n\n\nRobustness Under Attack\nWhile scale-free networks show remarkable robustness against random failures, they exhibit a fundamental vulnerability to targeted attacks that deliberately target high-degree nodes (hubs). This asymmetry reveals the “Achilles’ heel” property of complex networks, where the same structural features that provide robustness against random failures create critical vulnerabilities to strategic attacks.\nRather than removing nodes randomly, an adversary with knowledge of the network structure can systematically remove the highest-degree nodes first, followed by the next highest-degree nodes, and so on. Under this targeted hub removal strategy, scale-free networks fragment rapidly and dramatically. The critical threshold for attacks, f_c^{\\text{attack}}, is dramatically lower than for random failures. While random failures require f_c^{\\text{random}} \\approx 1 (nearly all nodes must be removed), targeted attacks need only f_c^{\\text{attack}} \\ll 1 (a small fraction of hubs) to fragment the network.\nTo understand how networks fragment under targeted attacks, we must consider two key effects that occur when the highest-degree nodes are systematically removed. First, the removal of hub nodes changes the maximum degree of the remaining network from k_{\\max} to a new lower value k'_{\\max}. Second, since these removed hubs had many connections, their elimination also removes many links from the network, effectively changing the degree distribution of the surviving nodes.\nThe mathematical analysis of this process relies on mapping the attack problem back to the random failure framework through careful accounting of these structural changes. When we remove an f fraction of the highest-degree nodes in a scale-free network, the new maximum degree becomes k'_{\\max} = k_{\\min} f^{1/(1-\\gamma)}, where the power-law exponent \\gamma determines how rapidly the degree sequence declines.\nFor scale-free networks with degree exponent \\gamma, the critical attack threshold f_c satisfies:\n\nf_c^{\\frac{2-\\gamma}{1-\\gamma}} = \\frac{2 + 2^{-\\gamma}}{3-\\gamma} k_{\\min} \\left(f_c^{\\frac{3-\\gamma}{1-\\gamma}} - 1\\right)\n\nThe fractional exponents (2-\\gamma)/(1-\\gamma) and (3-\\gamma)/(1-\\gamma) arise from the power-law degree distribution and determine how quickly the network fragments as hubs are removed. For networks with \\gamma &lt; 3 (highly heterogeneous degree distributions), these exponents are negative, leading to extremely small values of f_c, i.e., meaning just a tiny fraction of hub removal can destroy network connectivity.\nThis vulnerability has profound real-world implications across multiple domains. Power grids invest heavily in protecting major substations and transmission hubs because their failure could cascade throughout the system. Internet infrastructure includes hub redundancy and protection protocols to maintain connectivity when major routing nodes are compromised. Transportation networks maintain backup routes and alternative pathways when major airports or train stations fail. Even biological systems have evolved protective mechanisms for critical proteins that serve as hubs in cellular networks.\nThe robustness paradox demonstrates that no single network structure can be optimal against all types of failures. There’s always a fundamental trade-off between efficiency, which naturally favors hub-based architectures for optimal resource distribution, and security, which requires redundancy and distributed connectivity to prevent catastrophic failures from targeted attacks.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#design-principles-for-robust-networks",
    "href": "m03-robustness/01-concepts.html#design-principles-for-robust-networks",
    "title": "Core Concepts",
    "section": "7 Design Principles for Robust Networks",
    "text": "7 Design Principles for Robust Networks\nHow do we design networks that resist both random failures and targeted attacks? Key principles include:\n\nBalanced Degree Distribution: Avoid both extreme homogeneity and extreme hub concentration\nMultiple Redundant Pathways: Ensure removing any single node doesn’t isolate large portions\nStrategic Hub Protection: In hub-based networks, invest heavily in protecting critical nodes\nHierarchical Design: Combine local clusters with hub connections and redundant backbones\nAdaptive Responses: Design systems that can reconfigure when attacks are detected\n\nThese strategies reflect lessons learned from our historical power grid challenge: moving beyond the minimum spanning tree to create networks that balance efficiency with resilience.\n\n\n    \n    \n    \n    import%20marimo%20as%20mo%0Aimport%20matplotlib.pyplot%20as%20plt%0Aimport%20pandas%20as%20pd%0Aimport%20numpy%20as%20np%0Afrom%20scipy.ndimage%20import%20label%0Afrom%20matplotlib.colors%20import%20ListedColormap%0Afrom%20scipy.sparse%20import%20csr_matrix%0Afrom%20scipy.sparse.csgraph%20import%20connected_components%0A\n\n\n    \n    \n    \n    %23%20Control%20for%20edge%20weight%20uniqueness%0Aunique_weights%20%3D%20mo.ui.checkbox(%0A%20%20%20%20label%3D%22Use%20unique%20edge%20weights%20(when%20unchecked%2C%20some%20edges%20have%20same%20weight)%22%2C%0A%20%20%20%20value%3DTrue%2C%0A)%0A%0A%23%20Time%20step%20slider%20-%20fixed%20to%20accommodate%20MST%20(max%206%20edges%20for%207%20nodes)%0Atime_step%20%3D%20mo.ui.slider(%0A%20%20%20%20start%3D0%2C%0A%20%20%20%20stop%3D6%2C%20%20%23%20Fixed%20max%20for%20power%20grid%20(7%20nodes%20%3D%206%20MST%20edges)%0A%20%20%20%20step%3D1%2C%0A%20%20%20%20value%3D6%2C%20%20%23%20Start%20at%20final%20state%0A%20%20%20%20label%3D%22Algorithm%20Time%20Step%20(0%3Dstart%2C%206%3Dcomplete%20MST)%22%2C%0A)\n\n\n    \n    \n    \n    def%20create_power_grid_graph(use_unique_weights%3DTrue)%3A%0A%20%20%20%20%22%22%22Create%20power%20grid%20graph%20with%20nodes%20and%20edges%22%22%22%0A%0A%20%20%20%20%23%20Define%20nodes%20with%20positions%0A%20%20%20%20nodes%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%22A%22%3A%20(0%2C%201)%2C%0A%20%20%20%20%20%20%20%20%22B%22%3A%20(1%2C%202)%2C%0A%20%20%20%20%20%20%20%20%22C%22%3A%20(1%2C%200)%2C%0A%20%20%20%20%20%20%20%20%22D%22%3A%20(2%2C%202.5)%2C%0A%20%20%20%20%20%20%20%20%22E%22%3A%20(2%2C%201.5)%2C%0A%20%20%20%20%20%20%20%20%22F%22%3A%20(2%2C%200.5)%2C%0A%20%20%20%20%20%20%20%20%22G%22%3A%20(2%2C%20-0.5)%2C%0A%20%20%20%20%7D%0A%0A%20%20%20%20if%20use_unique_weights%3A%0A%20%20%20%20%20%20%20%20%23%20All%20weights%20are%20unique%0A%20%20%20%20%20%20%20%20edges%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22A%22%2C%20%22B%22%2C%208)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22A%22%2C%20%22C%22%2C%2012)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22B%22%2C%20%22D%22%2C%205)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22B%22%2C%20%22E%22%2C%207)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22C%22%2C%20%22F%22%2C%206)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22C%22%2C%20%22G%22%2C%204)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22D%22%2C%20%22E%22%2C%203)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22E%22%2C%20%22F%22%2C%209)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22F%22%2C%20%22G%22%2C%202)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22D%22%2C%20%22C%22%2C%2011)%2C%0A%20%20%20%20%20%20%20%20%5D%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%23%20Some%20weights%20are%20the%20same%20-%20multiple%20MSTs%20possible%0A%20%20%20%20%20%20%20%20edges%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22A%22%2C%20%22B%22%2C%208)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22A%22%2C%20%22C%22%2C%2012)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22B%22%2C%20%22D%22%2C%205)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22B%22%2C%20%22E%22%2C%207)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22C%22%2C%20%22F%22%2C%206)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22C%22%2C%20%22G%22%2C%204)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22D%22%2C%20%22E%22%2C%203)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22E%22%2C%20%22F%22%2C%2011)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22F%22%2C%20%22G%22%2C%202)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22D%22%2C%20%22C%22%2C%2011)%2C%0A%20%20%20%20%20%20%20%20%5D%0A%0A%20%20%20%20return%20nodes%2C%20edges%0A%0A%0A%23%20Create%20the%20graph%20based%20on%20current%20setting%0Anodes%2C%20edges%20%3D%20create_power_grid_graph(unique_weights.value)%0A%0Adef%20kruskal_algorithm(nodes_dict%2C%20edges_list)%3A%0A%20%20%20%20%22%22%22Kruskal's%20algorithm%20implementation%20without%20networkx%22%22%22%0A%0A%20%20%20%20%23%20Step%201%3A%20Sort%20edges%20by%20weight%20(global%20perspective)%0A%20%20%20%20sorted_edges%20%3D%20sorted(edges_list%2C%20key%3Dlambda%20x%3A%20x%5B2%5D)%0A%0A%20%20%20%20%23%20Initialize%20Union-Find%20data%20structure%0A%20%20%20%20parent%20%3D%20%7B%7D%0A%20%20%20%20rank%20%3D%20%7B%7D%0A%0A%20%20%20%20%23%20Initialize%20all%20nodes%20in%20Union-Find%0A%20%20%20%20for%20node%20in%20nodes_dict%3A%0A%20%20%20%20%20%20%20%20parent%5Bnode%5D%20%3D%20node%0A%20%20%20%20%20%20%20%20rank%5Bnode%5D%20%3D%200%0A%0A%20%20%20%20def%20find(x)%3A%0A%20%20%20%20%20%20%20%20if%20parent%5Bx%5D%20!%3D%20x%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20parent%5Bx%5D%20%3D%20find(parent%5Bx%5D)%0A%20%20%20%20%20%20%20%20return%20parent%5Bx%5D%0A%0A%20%20%20%20def%20union(x%2C%20y)%3A%0A%20%20%20%20%20%20%20%20px%2C%20py%20%3D%20find(x)%2C%20find(y)%0A%20%20%20%20%20%20%20%20if%20px%20%3D%3D%20py%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20False%0A%20%20%20%20%20%20%20%20if%20rank%5Bpx%5D%20%3C%20rank%5Bpy%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20px%2C%20py%20%3D%20py%2C%20px%0A%20%20%20%20%20%20%20%20parent%5Bpy%5D%20%3D%20px%0A%20%20%20%20%20%20%20%20if%20rank%5Bpx%5D%20%3D%3D%20rank%5Bpy%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20rank%5Bpx%5D%20%2B%3D%201%0A%20%20%20%20%20%20%20%20return%20True%0A%0A%20%20%20%20mst_edges%20%3D%20%5B%5D%0A%20%20%20%20steps%20%3D%20%5B%5D%0A%0A%20%20%20%20for%20u%2C%20v%2C%20weight%20in%20sorted_edges%3A%0A%20%20%20%20%20%20%20%20if%20union(u%2C%20v)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20mst_edges.append((u%2C%20v%2C%20weight))%0A%20%20%20%20%20%20%20%20%20%20%20%20steps.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22edge%22%3A%20(u%2C%20v)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22weight%22%3A%20weight%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22action%22%3A%20%22added%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22reason%22%3A%20f%22Connects%20%7Bu%7D%20and%20%7Bv%7D%20without%20creating%20cycle%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Continue%20until%20we%20have%20a%20spanning%20tree%20OR%20all%20edges%20are%20processed%0A%20%20%20%20%20%20%20%20if%20len(mst_edges)%20%3D%3D%20len(nodes_dict)%20-%201%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20break%0A%0A%20%20%20%20return%20mst_edges%2C%20steps%0A%0A%0Adef%20prim_algorithm(nodes_dict%2C%20edges_list%2C%20start_node%3D%22A%22)%3A%0A%20%20%20%20%22%22%22Prim's%20algorithm%20implementation%20without%20networkx%22%22%22%0A%0A%20%20%20%20%23%20Create%20adjacency%20list%0A%20%20%20%20adj%20%3D%20%7Bnode%3A%20%5B%5D%20for%20node%20in%20nodes_dict%7D%0A%20%20%20%20for%20u%2C%20v%2C%20weight%20in%20edges_list%3A%0A%20%20%20%20%20%20%20%20adj%5Bu%5D.append((v%2C%20weight))%0A%20%20%20%20%20%20%20%20adj%5Bv%5D.append((u%2C%20weight))%0A%0A%20%20%20%20visited%20%3D%20%7Bstart_node%7D%0A%20%20%20%20mst_edges%20%3D%20%5B%5D%0A%20%20%20%20steps%20%3D%20%5B%5D%0A%0A%20%20%20%20steps.append(%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22node%22%3A%20start_node%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22action%22%3A%20%22start%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22reason%22%3A%20f%22Starting%20from%20%7Bstart_node%7D%22%2C%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20)%0A%0A%20%20%20%20while%20len(visited)%20%3C%20len(nodes_dict)%3A%0A%20%20%20%20%20%20%20%20min_weight%20%3D%20float(%22inf%22)%0A%20%20%20%20%20%20%20%20min_edge%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20%23%20Find%20cheapest%20edge%20from%20visited%20to%20unvisited%20nodes%0A%20%20%20%20%20%20%20%20for%20node%20in%20visited%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20neighbor%2C%20weight%20in%20adj%5Bnode%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20neighbor%20not%20in%20visited%20and%20weight%20%3C%20min_weight%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20min_weight%20%3D%20weight%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20min_edge%20%3D%20(node%2C%20neighbor%2C%20weight)%0A%0A%20%20%20%20%20%20%20%20if%20min_edge%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20u%2C%20v%2C%20weight%20%3D%20min_edge%0A%20%20%20%20%20%20%20%20%20%20%20%20visited.add(v)%0A%20%20%20%20%20%20%20%20%20%20%20%20mst_edges.append((u%2C%20v%2C%20weight))%0A%20%20%20%20%20%20%20%20%20%20%20%20steps.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22edge%22%3A%20(u%2C%20v)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22weight%22%3A%20weight%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22action%22%3A%20%22added%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22reason%22%3A%20f%22Cheapest%20connection%20from%20visited%20set%20to%20%7Bv%7D%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20return%20mst_edges%2C%20steps%0A%0A%0A%23%20Run%20both%20algorithms%0Akruskal_mst%2C%20kruskal_steps%20%3D%20kruskal_algorithm(nodes%2C%20edges)%0Aprim_mst%2C%20prim_steps%20%3D%20prim_algorithm(nodes%2C%20edges)%0A%0A%23%20Calculate%20total%20weights%0Akruskal_weight%20%3D%20sum(w%20for%20_%2C%20_%2C%20w%20in%20kruskal_mst)%0Aprim_weight%20%3D%20sum(w%20for%20_%2C%20_%2C%20w%20in%20prim_mst)%0A%0A%23%20Display%20algorithm%20results%20with%20current%20step%20information%0Aweight_match%20%3D%20%22%E2%9C%85%20Same%22%20if%20kruskal_weight%20%3D%3D%20prim_weight%20else%20%22%E2%9D%8C%20Different%22%0A%0A%23%20Get%20current%20step%20information%0Acurrent_step%20%3D%20time_step.value%0Amax_steps%20%3D%20len(%5Bs%20for%20s%20in%20kruskal_steps%20if%20s%5B%22action%22%5D%20%3D%3D%20%22added%22%5D)\n\n\n    \n    \n    \n    def%20visualize_both_algorithms()%3A%0A%20%20%20%20%22%22%22Create%20side-by-side%20visualization%20of%20both%20algorithms%20with%20time%20step%20control%22%22%22%0A%0A%20%20%20%20fig%2C%20(ax1%2C%20ax2)%20%3D%20plt.subplots(1%2C%202%2C%20figsize%3D(16%2C%208))%0A%0A%20%20%20%20%23%20Get%20edges%20to%20show%20up%20to%20current%20time%20step%20for%20each%20algorithm%0A%20%20%20%20current_step%20%3D%20time_step.value%0A%0A%20%20%20%20%23%20For%20Kruskal%3A%20edges%20added%20in%20order%20they%20appear%20in%20steps%0A%20%20%20%20kruskal_edges_to_show%20%3D%20%5B%5D%0A%20%20%20%20for%20i%2C%20step%20in%20enumerate(kruskal_steps)%3A%0A%20%20%20%20%20%20%20%20if%20i%20%3E%3D%20current_step%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20if%20step%5B%22action%22%5D%20%3D%3D%20%22added%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20u%2C%20v%20%3D%20step%5B%22edge%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20weight%20%3D%20step%5B%22weight%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20kruskal_edges_to_show.append((u%2C%20v%2C%20weight))%0A%0A%20%20%20%20%23%20For%20Prim%3A%20edges%20added%20in%20order%20they%20appear%20in%20steps%0A%20%20%20%20prim_edges_to_show%20%3D%20%5B%5D%0A%20%20%20%20for%20i%2C%20step%20in%20enumerate(prim_steps%5B1%3A%5D%2C%201)%3A%20%20%23%20Skip%20the%20'start'%20step%0A%20%20%20%20%20%20%20%20if%20i%20%3E%20current_step%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20if%20step%5B%22action%22%5D%20%3D%3D%20%22added%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20u%2C%20v%20%3D%20step%5B%22edge%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20weight%20%3D%20step%5B%22weight%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20prim_edges_to_show.append((u%2C%20v%2C%20weight))%0A%0A%20%20%20%20algorithms%20%3D%20%5B%0A%20%20%20%20%20%20%20%20(ax1%2C%20%22Kruskal's%20Algorithm%22%2C%20kruskal_edges_to_show)%2C%0A%20%20%20%20%20%20%20%20(ax2%2C%20%22Prim's%20Algorithm%22%2C%20prim_edges_to_show)%2C%0A%20%20%20%20%5D%0A%0A%20%20%20%20for%20ax%2C%20title%2C%20edges_to_show%20in%20algorithms%3A%0A%20%20%20%20%20%20%20%20ax.clear()%0A%20%20%20%20%20%20%20%20ax.set_facecolor(%22white%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Draw%20all%20possible%20edges%20-%20dashed%20for%20unconnected%0A%20%20%20%20%20%20%20%20mst_edge_set%20%3D%20set((u%2C%20v)%20for%20u%2C%20v%2C%20_%20in%20edges_to_show)%20%7C%20set(%0A%20%20%20%20%20%20%20%20%20%20%20%20(v%2C%20u)%20for%20u%2C%20v%2C%20_%20in%20edges_to_show%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20for%20u%2C%20v%2C%20weight%20in%20edges%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20x1%2C%20y1%20%3D%20nodes%5Bu%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20x2%2C%20y2%20%3D%20nodes%5Bv%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20(u%2C%20v)%20in%20mst_edge_set%20or%20(v%2C%20u)%20in%20mst_edge_set%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20MST%20edge%20-%20solid%20black%20line%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ax.plot(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Bx1%2C%20x2%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5By1%2C%20y2%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22black%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20linewidth%3D3%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20solid_capstyle%3D%22round%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Non-MST%20edge%20-%20dashed%20grey%20line%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ax.plot(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Bx1%2C%20x2%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5By1%2C%20y2%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22grey%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20linewidth%3D2%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20linestyle%3D%22--%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20alpha%3D0.7%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Add%20edge%20weight%20labels%20with%20larger%20font%0A%20%20%20%20%20%20%20%20%20%20%20%20mid_x%2C%20mid_y%20%3D%20(x1%20%2B%20x2)%20%2F%202%2C%20(y1%20%2B%20y2)%20%2F%202%0A%20%20%20%20%20%20%20%20%20%20%20%20ax.text(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mid_x%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mid_y%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20str(weight)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontsize%3D20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20bbox%3Ddict(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20boxstyle%3D%22round%2Cpad%3D0.2%22%2C%20facecolor%3D%22white%22%2C%20alpha%3D0.9%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ha%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20va%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontweight%3D%22bold%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Draw%20nodes%20-%20color%20based%20on%20connection%20status%0A%20%20%20%20%20%20%20%20connected_nodes%20%3D%20set()%0A%20%20%20%20%20%20%20%20if%20%22Prim%22%20in%20title%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20Prim%2C%20start%20with%20node%20A%20always%20connected%0A%20%20%20%20%20%20%20%20%20%20%20%20connected_nodes.add(%22A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20u%2C%20v%2C%20_%20in%20edges_to_show%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_nodes.add(u)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_nodes.add(v)%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20Kruskal%2C%20find%20all%20nodes%20in%20connected%20components%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20edges_to_show%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Build%20Union-Find%20to%20determine%20connected%20components%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20parent%20%3D%20%7Bnode%3A%20node%20for%20node%20in%20nodes%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20find_root(x)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20parent%5Bx%5D%20!%3D%20x%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20parent%5Bx%5D%20%3D%20find_root(parent%5Bx%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20parent%5Bx%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20union_nodes(x%2C%20y)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20px%2C%20py%20%3D%20find_root(x)%2C%20find_root(y)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20px%20!%3D%20py%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20parent%5Bpy%5D%20%3D%20px%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Apply%20edges%20to%20build%20connected%20components%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20u%2C%20v%2C%20_%20in%20edges_to_show%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20union_nodes(u%2C%20v)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Find%20all%20nodes%20connected%20to%20any%20component%20that%20has%20edges%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_roots%20%3D%20set()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20u%2C%20v%2C%20_%20in%20edges_to_show%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_roots.add(find_root(u))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_roots.add(find_root(v))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20node%20in%20nodes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20find_root(node)%20in%20connected_roots%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_nodes.add(node)%0A%0A%20%20%20%20%20%20%20%20for%20node%2C%20(x%2C%20y)%20in%20nodes.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20color%20%3D%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%23f5cbcc%22%20if%20node%20in%20connected_nodes%20else%20%22%23d0e2f3%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20%20%23%20light%20red%20%3A%20light%20blue%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Draw%20larger%20circle%20with%20black%20border%0A%20%20%20%20%20%20%20%20%20%20%20%20circle%20%3D%20plt.Circle((x%2C%20y)%2C%200.15%2C%20color%3Dcolor%2C%20zorder%3D5)%0A%20%20%20%20%20%20%20%20%20%20%20%20ax.add_patch(circle)%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Add%20black%20border%0A%20%20%20%20%20%20%20%20%20%20%20%20border_circle%20%3D%20plt.Circle(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(x%2C%20y)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%200.15%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fill%3DFalse%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20edgecolor%3D%22black%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20linewidth%3D2%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zorder%3D6%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20ax.add_patch(border_circle)%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Larger%20text%0A%20%20%20%20%20%20%20%20%20%20%20%20ax.text(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20x%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20y%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20node%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ha%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20va%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontsize%3D20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontweight%3D%22bold%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zorder%3D7%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Clean%20title%0A%20%20%20%20%20%20%20%20ax.set_title(title%2C%20fontsize%3D22%2C%20fontweight%3D%22bold%22%2C%20pad%3D20)%0A%20%20%20%20%20%20%20%20ax.set_aspect(%22equal%22)%0A%20%20%20%20%20%20%20%20ax.axis(%22off%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Set%20axis%20limits%20with%20padding%0A%20%20%20%20%20%20%20%20x_coords%20%3D%20%5Bx%20for%20x%2C%20y%20in%20nodes.values()%5D%0A%20%20%20%20%20%20%20%20y_coords%20%3D%20%5By%20for%20x%2C%20y%20in%20nodes.values()%5D%0A%20%20%20%20%20%20%20%20ax.set_xlim(min(x_coords)%20-%200.3%2C%20max(x_coords)%20%2B%200.3)%0A%20%20%20%20%20%20%20%20ax.set_ylim(min(y_coords)%20-%200.3%2C%20max(y_coords)%20%2B%200.3)%0A%0A%20%20%20%20plt.tight_layout()%0A%20%20%20%20return%20fig%0A%0A%0A%23%20Create%20and%20display%20the%20visualization%0Afig%20%3D%20visualize_both_algorithms()\n\n\n\n    \n    \n    \n    %23%20Create%20a%20slider%20to%20control%20the%20puddle%20probability%0Ap_slider%20%3D%20mo.ui.slider(%0A%20%20%20%20start%3D0.0%2C%0A%20%20%20%20stop%3D1.0%2C%0A%20%20%20%20step%3D0.01%2C%0A%20%20%20%20value%3D0.5%2C%0A%20%20%20%20label%3D%22Puddle%20Probability%20(p)%22%0A)\n\n\n    \n    \n    \n    np.random.seed(42)%20%20%23%20For%20reproducible%20results%20during%20demo%0A%23%20Grid%20parameters%0Agrid_size%20%3D%2050%0AS%20%3D%20np.random.random((grid_size%2C%20grid_size))%0A%0Adef%20percolation_visualization()%3A%0A%0A%20%20%20%20%23%20Generate%20the%20percolation%20grid%20based%20on%20slider%20value%0A%20%20%20%20np.random.seed(42)%20%20%23%20For%20reproducible%20results%20during%20demo%0A%20%20%20%20grid%20%3D%20S%20%3C%20p_slider.value%0A%0A%20%20%20%20%23%20Find%20connected%20components%20(puddles%20that%20touch%20each%20other)%0A%20%20%20%20labeled_array%2C%20num_features%20%3D%20label(grid)%0A%0A%20%20%20%20%23%20Find%20the%20largest%20connected%20component%0A%20%20%20%20if%20num_features%20%3E%200%3A%0A%20%20%20%20%20%20%20%20sizes%20%3D%20%5B(labeled_array%20%3D%3D%20i).sum()%20for%20i%20in%20range(1%2C%20num_features%20%2B%201)%5D%0A%20%20%20%20%20%20%20%20largest_size%20%3D%20max(sizes)%0A%20%20%20%20%20%20%20%20largest_fraction%20%3D%20largest_size%20%2F%20(grid_size%20*%20grid_size)%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20largest_size%20%3D%200%0A%20%20%20%20%20%20%20%20largest_fraction%20%3D%200.0%0A%0A%20%20%20%20%23%20Create%20visualization%0A%20%20%20%20plt.figure(figsize%3D(8%2C%208))%0A%0A%20%20%20%20%23%20Create%20a%20display%20grid%20that%20shows%20largest%20component%20in%20red%0A%20%20%20%20display_grid%20%3D%20np.zeros_like(grid%2C%20dtype%3Dint)%0A%0A%20%20%20%20%23%20Find%20the%20largest%20component%0A%20%20%20%20if%20num_features%20%3E%200%3A%0A%20%20%20%20%20%20%20%20%23%20Find%20which%20label%20corresponds%20to%20the%20largest%20component%0A%20%20%20%20%20%20%20%20largest_label%20%3D%20np.argmax(sizes)%20%2B%201%20%20%23%20%2B1%20because%20labels%20start%20from%201%0A%0A%20%20%20%20%20%20%20%20%23%20Set%20display%20values%3A%200%3Dwhite%2C%201%3Dblue%20(small%20components)%2C%202%3Dred%20(largest%20component)%0A%20%20%20%20%20%20%20%20display_grid%5Bgrid%5D%20%3D%201%20%20%23%20All%20puddles%20start%20as%20blue%0A%20%20%20%20%20%20%20%20display_grid%5Blabeled_array%20%3D%3D%20largest_label%5D%20%3D%202%20%20%23%20Largest%20component%20in%20red%0A%0A%20%20%20%20%23%20Create%20custom%20colormap%3A%20white%20for%20empty%2C%20blue%20for%20small%20components%2C%20red%20for%20largest%0A%20%20%20%20colors%20%3D%20%5B'white'%2C%20'%234472C4'%2C%20'%23E74C3C'%5D%20%20%23%20white%2C%20blue%2C%20red%0A%20%20%20%20cmap%20%3D%20ListedColormap(colors)%0A%0A%20%20%20%20%23%20Plot%20the%20grid%0A%20%20%20%20ax%20%3D%20plt.imshow(display_grid%2C%20cmap%3Dcmap%2C%20interpolation%3D'nearest')%0A%0A%20%20%20%20%23%20Styling%0A%20%20%20%20plt.title(f'Percolation%20Grid%20(p%20%3D%20%7Bp_slider.value%3A.2f%7D)%5Cn'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'Largest%20Component%20(Red)%3A%20%7Blargest_size%7D%20squares%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'(%7Blargest_fraction%3A.1%25%7D%20of%20grid)'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontsize%3D14%2C%20pad%3D20)%0A%20%20%20%20plt.xlabel('Grid%20Position')%0A%20%20%20%20plt.ylabel('Grid%20Position')%0A%0A%20%20%20%20%23%20Add%20grid%20lines%20for%20clarity%0A%20%20%20%20plt.xticks(np.arange(-0.5%2C%20grid_size%2C%2010)%2C%20minor%3DTrue)%0A%20%20%20%20plt.yticks(np.arange(-0.5%2C%20grid_size%2C%2010)%2C%20minor%3DTrue)%0A%20%20%20%20plt.grid(which%3D'minor'%2C%20color%3D'gray'%2C%20linestyle%3D'-'%2C%20alpha%3D0.3)%0A%20%20%20%20plt.tick_params(which%3D'minor'%2C%20size%3D0)%0A%0A%20%20%20%20%23%20Add%20a%20legend%0A%20%20%20%20from%20matplotlib.patches%20import%20Patch%0A%20%20%20%20legend_elements%20%3D%20%5B%0A%20%20%20%20%20%20%20%20Patch(facecolor%3D'white'%2C%20edgecolor%3D'black'%2C%20label%3D'Empty')%2C%0A%20%20%20%20%20%20%20%20Patch(facecolor%3D'%234472C4'%2C%20label%3D'Small%20Components')%2C%0A%20%20%20%20%20%20%20%20Patch(facecolor%3D'%23E74C3C'%2C%20label%3D'Largest%20Component')%0A%20%20%20%20%5D%0A%20%20%20%20plt.legend(handles%3Dlegend_elements%2C%20loc%3D'upper%20right'%2C%20bbox_to_anchor%3D(1.15%2C%201))%0A%0A%20%20%20%20%23%20Return%20the%20plot%0A%20%20%20%20return%20ax\n\n\n    \n    \n    \n    %23%20Generate%20data%20for%20the%20phase%20transition%20plot%0Aprob_values%20%3D%20np.linspace(0%2C%201%2C%20100)%0Acomponent_fractions%20%3D%20%5B%5D%0A%0A%23grid_size_phase%20%3D%2050%20%20%23%20Use%20smaller%20grid%20for%20faster%20computation%0A%0A%23%20Calculate%20largest%20component%20size%20for%20different%20probabilities%0Anp.random.seed(42)%20%20%23%20Fixed%20seed%20for%20consistent%20results%0A%23S%20%3D%20np.random.random((grid_size_phase%2C%20grid_size_phase))%0Afor%20prob%20in%20prob_values%3A%0A%20%20%20%20%23%20Generate%20random%20grid%0A%20%20%20%20phase_grid%20%3D%20S%20%3C%20prob%0A%0A%20%20%20%20%23%20Find%20connected%20components%0A%20%20%20%20labeled_phase%2C%20num_phase%20%3D%20label(phase_grid)%0A%0A%20%20%20%20if%20num_phase%20%3E%200%3A%0A%20%20%20%20%20%20%20%20phase_sizes%20%3D%20%5B(labeled_phase%20%3D%3D%20i).sum()%20for%20i%20in%20range(1%2C%20num_phase%20%2B%201)%5D%0A%20%20%20%20%20%20%20%20largest_phase%20%3D%20max(phase_sizes)%20%2F%20(grid_size%20*%20grid_size)%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20largest_phase%20%3D%200.0%0A%0A%20%20%20%20component_fractions.append(largest_phase)\n\n\n    \n    \n    \n    def%20phase_transition_plot()%3A%0A%20%20%20%20%23%20Create%20the%20phase%20transition%20plot%0A%20%20%20%20plt.figure(figsize%3D(8%2C%206))%0A%0A%20%20%20%20%23%20Plot%20the%20phase%20transition%20curve%0A%20%20%20%20plt.plot(prob_values%2C%20component_fractions%2C%20'b-'%2C%20linewidth%3D2%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20label%3D'Largest%20Component%20Size')%0A%0A%20%20%20%20%23%20Highlight%20current%20probability%0A%20%20%20%20current_idx%20%3D%20int(p_slider.value%20*%2099)%20%20%23%20Convert%20to%20index%0A%20%20%20%20plt.plot(p_slider.value%2C%20component_fractions%5Bcurrent_idx%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20'ro'%2C%20markersize%3D10%2C%20label%3Df'Current%20p%20%3D%20%7Bp_slider.value%3A.2f%7D')%0A%0A%20%20%20%20%23%20Mark%20approximate%20critical%20point%20(for%202D%20lattice%2C%20pc%20%E2%89%88%200.593)%0A%20%20%20%20critical_p%20%3D%200.593%0A%20%20%20%20plt.axvline(x%3Dcritical_p%2C%20color%3D'gray'%2C%20linestyle%3D'--'%2C%20alpha%3D0.7%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20label%3Df'Critical%20point%20(p_c%20%E2%89%88%20%7Bcritical_p%7D)')%0A%0A%20%20%20%20%23%20Styling%0A%20%20%20%20plt.xlabel('Probability%20(p)'%2C%20fontsize%3D12)%0A%20%20%20%20plt.ylabel('Fraction%20of%20Grid%20in%20Largest%20Component'%2C%20fontsize%3D12)%0A%20%20%20%20plt.title('Percolation%20Phase%20Transition'%2C%20fontsize%3D14)%0A%20%20%20%20plt.grid(True%2C%20alpha%3D0.3)%0A%20%20%20%20plt.legend(frameon%3DFalse)%0A%20%20%20%20plt.xlim(0%2C%201)%0A%20%20%20%20plt.ylim(0%2C%201)%0A%0A%20%20%20%20%23%20Add%20phase%20labels%0A%20%20%20%20plt.text(0.2%2C%200.2%2C%20'Disconnected%5CnPhase'%2C%20fontsize%3D15%2C%20ha%3D'center'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20bbox%3Ddict(boxstyle%3D'round'%2C%20facecolor%3D'lightblue'%2C%20alpha%3D0.7))%0A%20%20%20%20plt.text(0.8%2C%200.2%2C%20'Connected%5CnPhase'%2C%20fontsize%3D15%2C%20ha%3D'center'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20bbox%3Ddict(boxstyle%3D'round'%2C%20facecolor%3D'%23f5cbcc'%2C%20alpha%3D0.7))%0A%0A%20%20%20%20return%20plt.gca()\n\n\n\n    \n    \n    \n    def%20compute_fc_powerlaw(gamma%2C%20k_min%2C%20k_max)%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20Compute%20the%20critical%20fraction%20f_c%20for%20a%20power-law%20degree%20distribution.%0A%0A%20%20%20%20Parameters%0A%20%20%20%20----------%0A%20%20%20%20gamma%20%3A%20float%0A%20%20%20%20%20%20%20%20Exponent%20of%20the%20power-law%20degree%20distribution.%0A%20%20%20%20k_min%20%3A%20float%0A%20%20%20%20%20%20%20%20Minimum%20degree%20in%20the%20network.%0A%20%20%20%20k_max%20%3A%20float%0A%20%20%20%20%20%20%20%20Maximum%20degree%20in%20the%20network.%0A%0A%20%20%20%20Returns%0A%20%20%20%20-------%0A%20%20%20%20f_c%20%3A%20float%0A%20%20%20%20%20%20%20%20Critical%20fraction%20of%20nodes%20that%20must%20be%20removed%20to%20break%20the%20network.%0A%20%20%20%20%22%22%22%0A%20%20%20%20if%20gamma%20%3E%203%3A%0A%20%20%20%20%20%20%20%20denom%20%3D%20(gamma%20-%202)%20%2F%20(gamma%20-%203)%20*%20k_min%20-%201%0A%20%20%20%20%20%20%20%20if%20denom%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%201.0%0A%20%20%20%20%20%20%20%20f_c%20%3D%201%20-%201%20%2F%20denom%0A%20%20%20%20elif%202%20%3C%20gamma%20%3C%203%3A%0A%20%20%20%20%20%20%20%20denom%20%3D%20(gamma%20-%202)%20%2F%20(3-gamma)%20*%20(k_min%20**%20(gamma%20-%202))%20*%20(k_max%20**%20(3%20-%20gamma))%20-%201%0A%20%20%20%20%20%20%20%20if%20denom%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%201.0%0A%20%20%20%20%20%20%20%20f_c%20%3D%201%20-%201%20%2F%20denom%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20raise%20ValueError(%22gamma%20must%20be%20%3E%202%20for%20a%20giant%20component%20to%20exist.%22)%0A%20%20%20%20return%20f_c\n\n\n    \n    \n    \n    import%20altair%20as%20alt%0A%0Akmax_values%20%3D%20np.arange(50%2C%201000%2C%2020)%0Agammas%20%3D%20%5B2.1%2C%202.5%2C%202.9%5D%0Agamma_labels%20%3D%20%7B2.1%3A%20%22gamma%20%3D%202.1%22%2C%202.5%3A%20%22gamma%20%3D%202.5%22%2C%202.9%3A%20%22gamma%20%3D%202.9%22%7D%0Acolors%20%3D%20%7B2.1%3A%20%22red%22%2C%202.5%3A%20%22blue%22%2C%202.9%3A%20%22orange%22%7D%0Alinestyles%20%3D%20%7B2.1%3A%20%22solid%22%2C%202.5%3A%20%22dashed%22%2C%202.9%3A%20%22dashed%22%7D%0A%0A%23%20Prepare%20data%20for%20Altair%0Adata%20%3D%20%5B%5D%0Afor%20gamma%20in%20gammas%3A%0A%20%20%20%20for%20kmax%20in%20kmax_values%3A%0A%20%20%20%20%20%20%20%20fc%20%3D%20compute_fc_powerlaw(gamma%2C%201%2C%20kmax)%0A%20%20%20%20%20%20%20%20data.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22Maximum%20degree%22%3A%20kmax%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22Critical%20fraction%22%3A%20fc%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22gamma%22%3A%20gamma_labels%5Bgamma%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22color%22%3A%20colors%5Bgamma%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22linestyle%22%3A%20linestyles%5Bgamma%5D%0A%20%20%20%20%20%20%20%20%7D)%0A%0Adf%20%3D%20pd.DataFrame(data)%0A%0A%23%20Altair%20plot%0A%0A%23%20Find%20the%20minimum%20y%20value%20(critical%20fraction)%20in%20the%20data%0Amin_fc%20%3D%20df%5B%22Critical%20fraction%22%5D.min()%0A%0Achart_fc%20%3D%20alt.Chart(df).mark_line().encode(%0A%20%20%20%20x%3Dalt.X(%0A%20%20%20%20%20%20%20%20%22Maximum%20degree%3AQ%22%2C%0A%20%20%20%20%20%20%20%20title%3D%22Maximum%20degree%22%2C%0A%20%20%20%20%20%20%20%20axis%3Dalt.Axis(titleFontSize%3D18%2C%20labelFontSize%3D14)%0A%20%20%20%20)%2C%0A%20%20%20%20y%3Dalt.Y(%0A%20%20%20%20%20%20%20%20%22Critical%20fraction%3AQ%22%2C%0A%20%20%20%20%20%20%20%20title%3D%22%24f_c%24%22%2C%0A%20%20%20%20%20%20%20%20scale%3Dalt.Scale(domain%3D%5Bmin_fc%2C%201.0%5D)%2C%0A%20%20%20%20%20%20%20%20axis%3Dalt.Axis(titleFontSize%3D18%2C%20labelFontSize%3D14)%0A%20%20%20%20)%2C%0A%20%20%20%20color%3Dalt.Color(%0A%20%20%20%20%20%20%20%20%22gamma%3AN%22%2C%0A%20%20%20%20%20%20%20%20scale%3Dalt.Scale(domain%3Dlist(gamma_labels.values())%2C%20range%3D%5Bcolors%5Bg%5D%20for%20g%20in%20gammas%5D)%2C%0A%20%20%20%20%20%20%20%20legend%3Dalt.Legend(title%3D%22gamma%22%2C%20titleFontSize%3D16%2C%20labelFontSize%3D14)%0A%20%20%20%20)%2C%0A%20%20%20%20strokeDash%3Dalt.StrokeDash(%0A%20%20%20%20%20%20%20%20%22gamma%3AN%22%2C%0A%20%20%20%20%20%20%20%20scale%3Dalt.Scale(domain%3Dlist(gamma_labels.values())%2C%20range%3D%5B%5B%5D%2C%20%5B5%2C5%5D%2C%20%5B5%2C5%5D%5D)%2C%0A%20%20%20%20%20%20%20%20legend%3DNone%0A%20%20%20%20)%0A).properties(%0A%20%20%20%20width%3D300%2C%0A%20%20%20%20height%3D300%2C%0A%20%20%20%20title%3Dalt.TitleParams(%0A%20%20%20%20%20%20%20%20text%3D%22Critical%20Fraction%20(k_min%20%3D%201)%22%2C%0A%20%20%20%20%20%20%20%20fontSize%3D20%0A%20%20%20%20)%0A)",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#references",
    "href": "m03-robustness/01-concepts.html#references",
    "title": "Core Concepts",
    "section": "8 References",
    "text": "8 References\n\nBorůvka, O. (1926). O jistém problému minimálním [About a certain minimal problem]. Práce Moravské Přírodovědecké Společnosti, 3, 37-58. [Original work on minimum spanning trees]\nMolloy, M., & Reed, B. (1995). A critical point for random graphs with a given degree sequence. Random Structures & Algorithms, 6(2-3), 161-180. [Molloy-Reed criterion]\nAlbert, R., Jeong, H., & Barabási, A. L. (2000). Error and attack tolerance of complex networks. Nature, 406(6794), 378-382. [Seminal paper on network robustness and the “Achilles’ heel” property]\nCohen, R., Erez, K., ben-Avraham, D., & Havlin, S. (2000). Resilience of the Internet to random breakdowns. Physical Review Letters, 85(21), 4626-4629. [Mathematical framework for random failures]\nCohen, R., Erez, K., ben-Avraham, D., & Havlin, S. (2001). Breakdown of the Internet under intentional attack. Physical Review Letters, 86(16), 3682-3685. [Mathematical analysis of targeted attacks]\nCallaway, D. S., Newman, M. E., Strogatz, S. H., & Watts, D. J. (2000). Network robustness and fragility: Percolation on random graphs. Physical Review Letters, 85(25), 5468-5471. [Percolation theory approach to network robustness]\nCohen, R., & Havlin, S. (2010). Complex Networks: Structure, Robustness and Function. Cambridge University Press. [Comprehensive treatment of network robustness theory]\nNewman, M. E. J. (2018). Networks. Oxford University Press. [Modern textbook covering network robustness and percolation]",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html",
    "href": "m02-small-world/04-appendix.html",
    "title": "Appendix - Brief Introduction to igraph",
    "section": "",
    "text": "The Erdős-Rényi random graph model is one of the fundamental models in network science, serving as our baseline for understanding what makes small-world networks special. There are two variants of this model: G(n,m) which creates n vertices with exactly m randomly chosen edges, and G(n,p) which creates n vertices where each possible edge exists with probability p. We focus on the G(n,p) model because it provides better analytical tractability for deriving mathematical properties.\n\n\n\n\n\n\nFigure 1: Erdős-Rényi random graph model.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Appendix - Brief Introduction to igraph"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html#erdős-rényi-random-graphs",
    "href": "m02-small-world/04-appendix.html#erdős-rényi-random-graphs",
    "title": "Appendix - Brief Introduction to igraph",
    "section": "",
    "text": "The Erdős-Rényi random graph model is one of the fundamental models in network science, serving as our baseline for understanding what makes small-world networks special. There are two variants of this model: G(n,m) which creates n vertices with exactly m randomly chosen edges, and G(n,p) which creates n vertices where each possible edge exists with probability p. We focus on the G(n,p) model because it provides better analytical tractability for deriving mathematical properties.\n\n\n\n\n\n\nFigure 1: Erdős-Rényi random graph model.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Appendix - Brief Introduction to igraph"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html#clustering-coefficient",
    "href": "m02-small-world/04-appendix.html#clustering-coefficient",
    "title": "Appendix - Brief Introduction to igraph",
    "section": "2 Clustering Coefficient",
    "text": "2 Clustering Coefficient\nThe clustering coefficient measures the probability that two neighbors of a node are also connected to each other. For Erdős-Rényi random graphs, we can derive the expected clustering coefficient analytically by exploiting the independence of edge formation.\nConsider a node i with degree k_i in an Erdős-Rényi graph G(n,p). The local clustering coefficient is defined as C_i = \\frac{2e_i}{k_i(k_i-1)}, where e_i is the number of edges between neighbors of node i. The key insight is that in the G(n,p) model, each possible edge exists with probability p independently of all other edges.\nFor a node with k neighbors, there are \\binom{k}{2} = \\frac{k(k-1)}{2} possible edges between its neighbors. Since each potential edge exists with probability p, the expected number of edges between neighbors is E[e_i | k_i = k] = \\frac{k(k-1)}{2} \\cdot p. Therefore, the expected local clustering coefficient for a node with degree k becomes:\nE[C_i | k_i = k] = \\frac{2 \\cdot \\frac{k(k-1)}{2} \\cdot p}{k(k-1)} = p\nThis result shows that the expected local clustering coefficient is simply p, independent of the node degree. Since this holds for all vertices regardless of their degree, the expected global clustering coefficient is also E[C] = p = \\frac{\\langle k \\rangle}{n-1}, where \\langle k \\rangle = p(n-1) is the expected degree.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Appendix - Brief Introduction to igraph"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html#average-path-length-derivation",
    "href": "m02-small-world/04-appendix.html#average-path-length-derivation",
    "title": "Appendix - Brief Introduction to igraph",
    "section": "3 Average Path Length Derivation",
    "text": "3 Average Path Length Derivation\nThe average path length in Erdős-Rényi graphs can be derived using a tree-expansion argument that reveals why these networks exhibit the small-world property of short distances.\nConsider an Erdős-Rényi model with average degree k = p(n-1). We can analyze the network structure by imagining a breadth-first expansion from any starting node, treating the resulting structure as a tree (this approximation works well because triangles and cycles are rare in sparse random graphs). From the root node, we can reach approximately 1 + k nodes in the first step. In the second step, each of these k nodes connects to roughly k new nodes (avoiding already-visited nodes), giving us 1 + k + k^2 total reachable nodes. Continuing this pattern, after h steps we can reach approximately 1 + k + k^2 + \\ldots + k^h \\approx k^h nodes.\nThe critical insight is that since Erdős-Rényi random graphs have few triangles and local clusters, most nodes in the network are reached only at the final step of this expansion process. When the expansion covers the entire network, we have k^h \\approx n. Solving for h: h \\approx \\log_{k}(n) = \\frac{\\log(n)}{\\log(k)} = \\frac{\\log(n)}{\\log(p(n-1))}.\nThis derivation reveals that the average shortest path length (diameter) of an Erdős-Rényi graph scales logarithmically with network size: \\langle d \\rangle \\approx \\frac{\\log(n)}{\\log(k)}. This logarithmic scaling demonstrates the “small-world” property inherent even in random graphs: even in large networks, the typical distance between nodes grows only logarithmically with network size, making the world surprisingly small despite its size.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Appendix - Brief Introduction to igraph"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html",
    "href": "m02-small-world/01-concepts.html",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will learn small-world experiments and conduct a small small-world experiment . We will learn:\n\nSmall-world experiment by Milgram\nDifferent concepts of distance: path, walks, circuits, cycles, connectedness\nHow to measure a distance between two nodes\nKeywords: small-world experiment, six degrees of separation, path, walks, circuits, cycles, connectedness, connected component, weakly connected component, strongly connected component.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#what-to-learn-in-this-module",
    "href": "m02-small-world/01-concepts.html#what-to-learn-in-this-module",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will learn small-world experiments and conduct a small small-world experiment . We will learn:\n\nSmall-world experiment by Milgram\nDifferent concepts of distance: path, walks, circuits, cycles, connectedness\nHow to measure a distance between two nodes\nKeywords: small-world experiment, six degrees of separation, path, walks, circuits, cycles, connectedness, connected component, weakly connected component, strongly connected component.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#small-world-experiment",
    "href": "m02-small-world/01-concepts.html#small-world-experiment",
    "title": "Core Concepts",
    "section": "2 Small-world experiment",
    "text": "2 Small-world experiment\n\n\nStanley Milgram (1933-1984) was an American social psychologist best known for his controversial obedience experiments at Yale University in the early 1960s. Beyond the obedience studies, Milgram conducted groundbreaking research on social networks, including the famous “small world” experiment that revealed the surprisingly short chains connecting any two people in society.\nHow far are two people in a social network? Milgram and his colleagues conducted a series of expriment to find out in the 1960s.\n\n\n\n\n\n\nFigure 1: Milgram’s small world experiment.\n\n\n\nThe experiment went as follows:\n\nMilgram first sent out packets to randomly selected people in Omaha, Nebraska, and Wichita, Kansas.\nThe recipient was asked to send the packet to the target person in Boston if they knew them. If not, they were to forward it to someone they knew on a first-name basis who might know the target.\nThe recipient continued to forward the packet to their acquaintances until it reached the target.\n\nThe results were surprising: out of the 160 letters sent, 64 successfully reached the target person by the chain of nearly six people, which was later called six degrees of separation. The results imply that, despite the fact that there were hundreds of millions of people in the United States, their social network was significantly compact, with two random people being connected to each other in only a few steps.\n\n\nThe term “Six degrees of separation” is commonly associated with Milgram’s experiment, but Milgram never used it. John Guare coined the term for his 1991 play and movie “Six Degrees of Separation.”\nThe results were later confirmed independently.\n\nYahoo research replicate the Milgram’s experiment by using emails. Started from more than 24,000 people, only 384 people reached the one of the 18 target person in 13 countries. Among the successful ones, the average length of the chain was about 4. When taken into account the broken chain, the average length was estimated between 5 and 7. (Goel, Muhamad, and Watts 2009)\nResearchers in Facebook and University of Milan analyzed the social network n Facebook, which consisted of 721 million active users and 69 billion friendships. The average length of the shortest chain was found to be 4.74. (Backstrom et al. 2012)",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#wikirace-experiencing-small-world-networks",
    "href": "m02-small-world/01-concepts.html#wikirace-experiencing-small-world-networks",
    "title": "Core Concepts",
    "section": "3 Wikirace: Experiencing Small-World Networks",
    "text": "3 Wikirace: Experiencing Small-World Networks\nLet us feel how small a large network can be by playing the Wikirace game.\n\n\n\nAt the end of the module, we will measure the average path length in a social network. Before jumping on, let us arm with some coding techniques to handle the network in the next two sections.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#why-is-small-world-networks-non-trivial",
    "href": "m02-small-world/01-concepts.html#why-is-small-world-networks-non-trivial",
    "title": "Core Concepts",
    "section": "4 Why is small-world networks non-trivial?",
    "text": "4 Why is small-world networks non-trivial?\n\n\n\n\nWhen we think about social networks, it’s natural to imagine that most people are friends with others who are nearby—friends of friends, classmates, colleagues, or neighbors. These are local connections, and they tend to form tightly-knit groups where everyone knows each other. In network terms, this means there are many triangles: if Alice is friends with Bob, and Bob is friends with Carol, then Alice is also likely to be friends with Carol.\nHowever, if a network only had these local, clustered connections, it would be difficult for information or influence to travel quickly across the entire network. You would have to go through many intermediaries to reach someone far away, resulting in a large diameter (the longest shortest path between any two nodes).\nWhat makes small-world networks non-trivial and surprising is that, despite having lots of local clustering (many triangles), they also have a few long-range connections—edges that link distant parts of the network. These “shortcuts” dramatically reduce the average distance between nodes. As a result, even in a huge network, you can reach almost anyone in just a few steps. This combination of high clustering and short path lengths is what defines the small-world property.\nIn summary:\n\nLocal connections create clustering (many triangles), but by themselves would make the network “large” in terms of path length.\nSmall-world networks have both high clustering and short average path lengths, thanks to a few edges that connect distant parts of the network.\nThis structure is non-trivial because it cannot be explained by local connections alone; the presence of long-range links is essential for the “small world” phenomenon.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#quantifying-small-world-properties",
    "href": "m02-small-world/01-concepts.html#quantifying-small-world-properties",
    "title": "Core Concepts",
    "section": "5 Quantifying Small-World Properties",
    "text": "5 Quantifying Small-World Properties\n\n\n\n\nLet us approach the small-world properties from mathematical angle. Two key characteristics of small-world networks are:\n\nShort average path length: You can reach distant parts of the network quickly.\nHigh clustering: Friends of friends are often friends.\n\n\nShort Average Path Length\n\n\nA path is a walk without repeated nodes. The shortest paths are the paths with the smallest number of edges.\nLet’s understand what average path length means. When we talk about how “far apart” two nodes are in a network, we mean the shortest number of edges you need to traverse to get from one node to the other. This is called the distance between nodes.\n\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nA\n\n\n\nB\n\nB\n\n\n\nA--B\n\n\n\n\nC\n\nC\n\n\n\nA--C\n\n\n\n\nB--C\n\n\n\n\nD\n\nD\n\n\n\nB--D\n\n\n\n\nC--D\n\n\n\n\n\n\n\nFigure 2: Simple network example for understanding shortest paths\n\n\n\n\n\nIn this simple network, let’s find the distance between nodes A and D:\n\nPath 1: A \\rightarrow B \\rightarrow D (2 edges)\nPath 2: A \\rightarrow C \\rightarrow D (2 edges)\nPath 3: A \\rightarrow C \\rightarrow B \\rightarrow D (3 edges)\n\nEven though there are multiple paths, the shortest path length (distance) from A to D is 2 edges.\nBuilding on this, let us calculate the average path length between two nodes. We have four nodes in the network, so there are 6 pairs of nodes. Let us enumerate them as follows:\n\n\n\n\n\n\n\n\nPair\nShortest Path\nLength\n\n\n\n\nA - B\nA \\rightarrow B\n1\n\n\nA - C\nA \\rightarrow C\n1\n\n\nA - D\nA \\rightarrow B \\rightarrow D or A \\rightarrow C \\rightarrow D\n2\n\n\nB - C\nB \\rightarrow C\n1\n\n\nB - D\nB \\rightarrow D\n1\n\n\nC - D\nC \\rightarrow D\n1\n\n\n\nThe average path length is simply the average of all these distances, which is 7 / 6 \\simeq 1.16.\n\n\nClustering Coefficient\nIn social networks, your friends tend to know each other. If you have a friend Alice, and Alice has friends Bob and Carol, local clustering asks: “Are Bob and Carol also friends with each other?” High local clustering means that your friends tend to know each other, creating dense local neighborhoods or cliques.\nThere are three ways to measure clustering: local clustering, average local clustering, and global clustering. The key difference is the focus of the measurement:\n\nLocal clustering focuses on the clustering of the neighbors of a specific node\nAverage local clustering focuses on the clustering of the neighbors of a node\nGlobal clustering focuses on the clustering of the entire network.\n\nLet us explain each of them one by one.\n\nLocal Clustering\nLocal clustering asks: given all your friends, how many of triangles you and your friends form, relative to the maximum possible number of triangles?\nThe local clustering coefficient C_i of a node i is defined as:\n\nC_i = \\dfrac{\\text{\\# of triangles involving } i \\text{ and its neighbors}}{\\text{\\# of edges possibly exist in the neighborhood of } i}\n\nOr alternatively, using the adjacency matrix A and the degree k_i of node i, \n\\begin{aligned}\nC_i = \\frac{\\sum_{j}\\sum_{\\ell} A_{ij}A_{j\\ell} A_{\\ell i} }{k_i(k_i-1)}\n\\end{aligned}\n\n\n\n\n\n\n\nNote: Derivation of the local clustering coefficient\n\n\n\n\n\nNumerator A_{ij}A_{j\\ell} A_{\\ell i} is a binary indicator of whether three nodes i, j, and \\ell form a triangle; A_{ij}A_{j\\ell} A_{\\ell i}=1 if a cycle i \\rightarrow j \\rightarrow \\ell \\rightarrow i exists, and 0 otherwise. By summing up all nodes, we have the number of triangles in the neighbors of i given by \\sum_{j}\\sum_{\\ell} A_{ij}A_{j\\ell} A_{\\ell i} / 2. Note that we divide the sum by 2 because the same triangle forms two cycles, i.g., i \\rightarrow j \\rightarrow \\ell \\rightarrow i and i \\rightarrow \\ell \\rightarrow j \\rightarrow i.\nThe number of possible triangles in the neighborhood of i is given by \\binom{k_i}{2} = k_i(k_i-1)/2.\nPutting them together:\n\nC_i = \\frac{\\sum_{j}\\sum_{\\ell} A_{ij}A_{j\\ell} A_{\\ell i} }{k_i(k_i-1)}\n\n\n\n\nFor example, let us compute the local clustering coefficient of node A in the following network. There are two triangles in the neighborhood of A. The number of possible triangles is 5 \\times 4 / 2 = 10. Thus, the local clustering coefficient of A is 2 / 10 = 0.2.\n\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nA\n\n\n\nB\n\nB\n\n\n\nA--B\n\n\n\n\nC\n\nC\n\n\n\nA--C\n\n\n\n\nD\n\nD\n\n\n\nA--D\n\n\n\n\nE\n\nE\n\n\n\nA--E\n\n\n\n\nF\n\nF\n\n\n\nA--F\n\n\n\n\nB--F\n\n\n\n\nC--E\n\n\n\n\n\n\n\nFigure 3: A network of friends\n\n\n\n\n\n\n\nAverage Local Clustering\nLocal clustering focuses on the clustering of a node’s neighborhood, while the global clustering focuses on the clustering of the entire network. One can adapt the local clustering for measuring the global clustering by taking the average of the local clustering coefficients of all nodes, i.e.,\n\n\\overline {C} = \\frac{1}{N} \\sum_{i=1}^N C_i\n\n\n\nGlobal Clustering\nGlobal clustering, also known as transitivity, measures the overall tendency for triangles to form throughout the entire network. It answers the question: “Across the whole network, how likely is it that two nodes connected to a common neighbor are also connected to each other?”\nThe global clustering coefficient C is defined as:\n\nC = \\frac{3 \\times \\text{number of triangles}}{\\text{number of connected triplets}}\n\nwhere a connected triplet is a set of three nodes connected by at least two edges, forming either a closed triplet (triangle) or an open triplet (wedge) shown below.\n\n\n\n\n\n\n\nG\n\n\n\nA1\n\nA1\n\n\n\nB1\n\nB1\n\n\n\nA1--B1\n\n\n\n\nC1\n\nC1\n\n\n\nB1--C1\n\n\n\n\nC1--A1\n\n\n\n\nA2\n\nA2\n\n\n\nB2\n\nB2\n\n\n\nA2--B2\n\n\n\n\nC2\n\nC2\n\n\n\nB2--C2\n\n\n\n\n\n Closed triplet (left) and open triplet (right) \n\n\n\nIn triplets, the order of the nodes matters. For example, (A_1, B_1, C_1) and (B_1, C_1, A_1) are two different triplets. A triangle pertains to three triplets, i.e., (A_1, B_1, C_1), (B_1, C_1, A_1), and (C_1, A_1, B_1). This is why we multiple three to the number of triangles in the numerator.\n\n\n\n\n\n\nKey difference between average local and global clustering\n\n\n\n\n\nIt is confusing to have two different global clustering measures, but the distinction becomes clearer if we think in terms of micro and macro perspectives:\n\nThe global clustering coefficient C (based on the total number of triangles and triplets in the network) is a micro-level measure. It looks at the prevalence of triangles relative to all possible connected triples in the entire network, essentially aggregating over all small, local patterns (triplets) to get a sense of how likely it is for any three connected nodes to form a closed triangle.\nThe average local clustering coefficient \\overline{C} is a macro-level measure. It first computes the clustering coefficient for each individual node (how clustered each node’s neighborhood is), and then averages these values across all nodes. This gives a sense of the overall tendency for nodes in the network to have tightly knit neighborhoods.\n\nSo the focal scope remains the same: the average local clustering focuses on a node’s neighborhood, while the global clustering focuses on the entire network.\n\n\n\n\n\n\nSmall-world coefficient\nNow let’s define a coefficient to measure the small-world property. Recall that a small-world network has both high clustering and short average path length. A naive approach is to take the ratio between the average local clustering coefficient and the average path length:\n\ns_{\\text{naive}} = \\frac{\\overline{C}}{\\overline{L}}\n\nwhere \\overline{C} is a clustering coefficient and \\overline{L} is the average path length. The original work by Watts and Strogatz used the average local clustering coefficient (Watts and Strogatz 1998) but one can use the global clustering coefficient as well, which leads to different results (Humphries and Gurney 2008).\nA high s_{\\text{naive}} value would seem to indicate a strong small-world property. However, this naive measure has a critical flaw: it can be high for trivial network structures. For example, a fully-connected network has \\overline{L} = 1 (minimum possible) and \\overline{C} = 1 (maximum possible), giving s_{\\text{naive}} = 1. This leads us to normalize against random networks with the same basic properties (Humphries and Gurney 2008).\nTo address this issue, Watts and Strogatz proposed normalizing by equivalent random networks. The small-world index (or small-world coefficient) is defined as:\n\n\\sigma = \\frac{\\overline{C}/\\overline{C}_{\\text{random}}}{\\overline{L}/\\overline{L}_{\\text{random}}} = \\frac{\\overline{C} \\cdot \\overline{L}_{\\text{random}}}{\\overline{L} \\cdot \\overline{C}_{\\text{random}}}\n\nwhere: \\overline{C}_{\\text{random}} and \\overline{L}_{\\text{random}} are the average clustering coefficient and the average path length of an equivalent random network. The “equivalent random network” typically refers to an Erdős–Rényi random graph, where edges are randomly connected with the same number of nodes and edges (or same average degree) as the original network (thus it represents a trivial random network of the same number of nodes and edges).\nA high \\sigma value greater than 1 indicates a strong small-world property. If \\sigma is close to 1, the network is not small-world but comparable to a random network in terms of the small-world property. If \\sigma is less than 1, the network is anti-small-world, i.e., it has a large average path length and low clustering compared to a random counterpart.\nSo how do we compute the reference value of \\overline{C}_{\\text{random}} and \\overline{L}_{\\text{random}}? We can compute them numerically by generating many random networks and computing the average of the clustering coefficient and the path length. For Erdős–Rényi random graph, it has been shown that the reference value of \\overline{C}_{\\text{random}} and \\overline{L}_{\\text{random}} follow on average (Humphries and Gurney 2008) (Newman, Strogatz, and Watts 2001): \n\\begin{aligned}\n\\overline{C}_{\\text{random}} & \\approx \\frac{\\langle k \\rangle}{n-1} \\\\\n\\overline{L}_{\\text{random}} &\\approx \\frac{\\ln n }{\\ln \\langle k \\rangle}\n\\end{aligned}\n\nwhere \\langle k \\rangle is the average degree of the network, and n is the number of nodes.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#watts-strogatz-model",
    "href": "m02-small-world/01-concepts.html#watts-strogatz-model",
    "title": "Core Concepts",
    "section": "6 Watts-Strogatz Model",
    "text": "6 Watts-Strogatz Model\n\n\n\n\n\n\nFigure 4: Watts-Strogatz model.\n\n\n\nWe have a way to measure the small-world property of a network, which reveals that the small-world property is surprisingly common in real-world networks. This leads to a question: what is the underlying mechanism? The Watts-Strogatz model provides a way to generate small-world networks, as we will see in the next section.\n\n\nHere is a nice blog post about the Watts-Strogatz model.\n\n\n“What I cannot create, I do not understand.” - Richard Feynman\n\nThis quote captures the essence of why models like Watts-Strogatz are crucial: by building networks that exhibit small-world properties, we gain deeper insight into how these properties emerge in real systems.\n\n\nWhat is the Watts-Strogatz Model?\nThe Watts-Strogatz model provides one explanation for the small-world phenomenon. The Watts-Strogatz model starts with a ring lattice and introduces randomness through edge rewiring:\nStep 1: Start with a Ring Lattice\n\nCreate a ring of N nodes\nConnect each node to its k nearest neighbors (k/2 on each side)\nThis gives high clustering but long average path length\n\nStep 2: Rewire Edges with Probability p\n\nFor each edge in the lattice:\n\nWith probability p: remove the edge and reconnect one endpoint to a randomly chosen node\nWith probability (1-p): keep the original edge\n\nAvoid self-loops and duplicate edges\n\nAt p = 0, the network is a regular ring lattice (high clustering, long paths); at p = 1, it becomes a random graph (low clustering, short paths). For 0 &lt; p &lt; 1, the network combines high clustering with short path lengths—the hallmark of the small-world property.\n\n\n\n\n\n\ninteractive exploration\n\n\n\nHere is the interactive visualization of the Watts-Strogatz model 😎: .\n\n\n\n\nWhy does the small-world property emerge?\nThe Watts-Strogatz model explains that the small-world property emerges from a small number of long-range connections that connect distant parts of the network, despite the nodes being connected to their local neighbors. While we have focused on social networks, the same explanation applies to different domains, such as biological networks (e.g., neurons are primarily connected locally but have some long-range connections that enable rapid information transmission), and technological networks (e.g., the Internet topology is regional but has some long-range connections that span continents).\n\n\nInteractive Exploration\n\n\nExplore the Watts-Strogatz model interactively by adjusting the rewiring probability and observing how network properties change:\nIn the next section, we will learn how to compute the shortest paths and connected components of a network using a library igraph.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#references",
    "href": "m02-small-world/01-concepts.html#references",
    "title": "Core Concepts",
    "section": "7 References",
    "text": "7 References\n\n\nBackstrom, Lars, Paolo Boldi, Marco Rosa, Johan Ugander, and Sebastiano Vigna. 2012. “Four Degrees of Separation.” In Proceedings of the 4th Annual ACM Web Science Conference, 33–42.\n\n\nGoel, Sharad, Roby Muhamad, and Duncan Watts. 2009. “Social Search in\" Small-World\" Experiments.” In Proceedings of the 18th International Conference on World Wide Web, 701–10.\n\n\nHumphries, Mark D., and Kevin Gurney. 2008. “Network ‘Small-World-Ness’: A Quantitative Method for Determining Canonical Network Equivalence.” Edited by Olaf Sporns. PLoS ONE 3 (4): e0002051. https://doi.org/10.1371/journal.pone.0002051.\n\n\nNewman, M. E. J., S. H. Strogatz, and D. J. Watts. 2001. “Random graphs with arbitrary degree distributions and their applications.” Physical Review E 64 (2). https://doi.org/10.1103/physreve.64.026118.\n\n\nWatts, Duncan J, and Steven H Strogatz. 1998. “Collective Dynamics of ‘Small-World’networks.” Nature 393 (6684): 440–42.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m01-euler_tour/03-exercises.html",
    "href": "m01-euler_tour/03-exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Open in molab\n\n\nExercise Notebook",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Exercises"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html",
    "href": "m01-euler_tour/01-concepts.html",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "",
    "text": "Our story begins not in a lab, but on the streets of an 18th-century Prussian city called Königsberg. It was a city of thinkers—most famously the philosopher Immanuel Kant—but the puzzle that would change mathematics belonged to everyone.\nThe city was built around two islands in the Pregel River, connected to the mainland and each other by seven distinct bridges. During their Sunday strolls, the citizens amused themselves with a challenge:\n\n\n\n\n\n\nThe Königsberg Bridge Problem\n\n\n\nIs it possible to design a walk through the city that crosses each of the seven bridges exactly once and return to the starting point?\n\n\nGo ahead, try it yourself on the map below. Tracing a path with your finger, you’ll soon discover the same frustrating problem the citizens did: you either get stuck, missing a bridge, or you have to cross one twice.\n\n\n\n\n\n\nFigure 1: A map of the seven bridges of Königsberg. Four landmasses are connected by seven bridges over the Pregel River.\n\n\n\nWhat makes this so difficult? No one could find a path, but more importantly, no one could prove it was impossible. The problem eventually reached the brilliant mathematician Leonhard Euler. His goal was not just to find an answer, but to understand the reason behind the answer.\n\n\n\n\n\n\nPause and Think Like a Mathematician\n\n\n\nBefore we reveal Euler’s solution, take a moment to be a mathematician yourself. This is how discovery happens. We strongly recommend working through this pen-and-paper worksheet to experience the discovery process.\nAs you work, ask yourself: - What information is essential? The length of the bridge? The size of the island? - What are the fundamental constraints of the problem? - How can you move from “I can’t find a path” to “A path cannot exist”?",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#why-was-this-puzzle-so-hard",
    "href": "m01-euler_tour/01-concepts.html#why-was-this-puzzle-so-hard",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "",
    "text": "Our story begins not in a lab, but on the streets of an 18th-century Prussian city called Königsberg. It was a city of thinkers—most famously the philosopher Immanuel Kant—but the puzzle that would change mathematics belonged to everyone.\nThe city was built around two islands in the Pregel River, connected to the mainland and each other by seven distinct bridges. During their Sunday strolls, the citizens amused themselves with a challenge:\n\n\n\n\n\n\nThe Königsberg Bridge Problem\n\n\n\nIs it possible to design a walk through the city that crosses each of the seven bridges exactly once and return to the starting point?\n\n\nGo ahead, try it yourself on the map below. Tracing a path with your finger, you’ll soon discover the same frustrating problem the citizens did: you either get stuck, missing a bridge, or you have to cross one twice.\n\n\n\n\n\n\nFigure 1: A map of the seven bridges of Königsberg. Four landmasses are connected by seven bridges over the Pregel River.\n\n\n\nWhat makes this so difficult? No one could find a path, but more importantly, no one could prove it was impossible. The problem eventually reached the brilliant mathematician Leonhard Euler. His goal was not just to find an answer, but to understand the reason behind the answer.\n\n\n\n\n\n\nPause and Think Like a Mathematician\n\n\n\nBefore we reveal Euler’s solution, take a moment to be a mathematician yourself. This is how discovery happens. We strongly recommend working through this pen-and-paper worksheet to experience the discovery process.\nAs you work, ask yourself: - What information is essential? The length of the bridge? The size of the island? - What are the fundamental constraints of the problem? - How can you move from “I can’t find a path” to “A path cannot exist”?",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#a-new-way-of-seeing-the-power-of-abstraction",
    "href": "m01-euler_tour/01-concepts.html#a-new-way-of-seeing-the-power-of-abstraction",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "2 A New Way of Seeing: The Power of Abstraction",
    "text": "2 A New Way of Seeing: The Power of Abstraction\nEuler’s genius was to realize that most of the information in the map was a distraction. He performed a radical act of simplification, an approach we now call abstraction.\nHe stripped the problem down to its skeleton: 1. He turned each of the four distinct landmasses into a simple dot (a node). 2. He turned each of the seven bridges into a simple line connecting the dots (an edge).\n\n\n\n\n\n\nFigure 2: Euler’s abstraction of the Königsberg bridge problem. The complex city map is reduced to a simple network of nodes and edges. Image from The Essential Guide to Graph Theory.\n\n\n\nThis wasn’t just a sketch; it was a new mathematical object. Euler had invented the graph (or network). He had created a new language to talk not about numbers or shapes, but about pure relationships and connectivity.\n\n\nLeonhard Euler (1707-1783)  One of history’s most prolific mathematicians. Despite losing his sight, he produced nearly half of his life’s work while completely blind.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#from-a-walk-to-a-proof-the-idea-of-degree",
    "href": "m01-euler_tour/01-concepts.html#from-a-walk-to-a-proof-the-idea-of-degree",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "3 From a Walk to a Proof: The Idea of Degree",
    "text": "3 From a Walk to a Proof: The Idea of Degree\nWith this new, simplified representation, Euler could stop thinking about walking and start thinking about rules. He focused on the nodes and asked a crucial question: how does a journey through a node work?\nImagine you are on a walk. Every time you arrive at a landmass, you cross one bridge. Every time you leave, you cross another. This means that for any landmass that is not the start or end of your journey, you must use bridges in pairs: one “in” and one “out.”\nThis leads to the key insight. Let’s count the number of bridges connected to each landmass. We’ll call this the degree of the node.\n\n\n\n\n\n\nKey Concept: Node Degree\n\n\n\nThe degree of a node is the number of edges connected to it. It is the most fundamental property of a node in a network.\n\n\n\nIf a node has an even degree (like 2, 4, or 6), you can always pass through it. For every “in” bridge, there is an “out” bridge.\nIf a node has an odd degree (like 1, 3, or 5), it must be special. The “in” and “out” bridges can’t all be paired up. One bridge will be left over. This means an odd-degree node must be the start or the end point of your walk.\n\nA walk can only have one start and one end. Therefore, to cross every bridge, there can be at most two nodes with an odd degree.\n\nThe Verdict\nLet’s apply this logic to the Königsberg graph:\n\nNorth Shore: Degree 3 (Odd)\nSouth Shore: Degree 3 (Odd)\nIsland A: Degree 5 (Odd)\nIsland B: Degree 3 (Odd)\n\nAll four landmasses have an odd degree! Since a walk can have at most two odd-degree nodes (one for the start, one for the end), the desired walk is mathematically impossible. Euler didn’t just fail to find a path; he proved, with logical certainty, that no such path could ever exist.\n\n\n\n\n\n\nEuler’s Conditions for a Walk\n\n\n\nA walk that crosses every edge in a graph exactly once (an Eulerian Path) is possible if and only if:\n\nThe graph is connected (you can get from any node to any other).\nAnd one of these is true:\n\nZero nodes have an odd degree. The walk must start and end at the same node (a closed loop, or Eulerian Circuit).\nExactly two nodes have an odd degree. The walk must start at one of the odd nodes and end at the other.\n\n\n\n\n\n\nA Tragic Epilogue\nThe story of the seven bridges has a sad, ironic twist. During World War II, the city of Königsberg was heavily bombed. Two of the seven bridges were destroyed, changing the layout of the city forever.\n\n\n\n\n\n\nFigure 3: After WWII bombing, only five bridges remained—finally making an Euler path possible.\n\n\n\nWith the two bridges gone, the network changed. Two of the landmasses now had an even degree, leaving just two with an odd degree. The impossible puzzle, which had fascinated people for over 200 years, was suddenly “solved” by the destruction of war.\nEuler’s solution was far more than fun trivia. It was the beginning of a new field of science. The idea of abstracting a system into nodes and edges is how we now understand our modern world. Every time you rely on a connected system, you are benefiting from the intellectual leap made by Euler over a puzzle about a Sunday stroll!",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#the-vocabulary-of-networks",
    "href": "m01-euler_tour/01-concepts.html#the-vocabulary-of-networks",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "4 The Vocabulary of Networks",
    "text": "4 The Vocabulary of Networks\nTo talk precisely about networks, we need to formalize the language Euler created. Here are the key terms.\n\nWalk, Trail, and Path\n\n\n\n\n\n\n\n\nTerm\nDefinition\nAnalogy: A Road Trip\n\n\n\n\nWalk\nA sequence of nodes where you can repeat both roads (edges) and cities (nodes).\nA casual drive where you can go down the same street multiple times.\n\n\nTrail\nA walk where you cannot repeat edges, but you can revisit nodes.\nA mail route. The carrier can’t cover the same street twice but may pass the same intersection.\n\n\nPath\nA walk where you cannot repeat nodes (or edges, by consequence).\nA trip visiting a sequence of cities, each one new.\n\n\n\n\n\nCycle and Circuit\nA journey that starts and ends at the same place is closed. This gives us two more terms:\n\n\n\n\n\n\n\n\nTerm\nDefinition\nAnalogy: A Round Trip\n\n\n\n\nCircuit\nA trail that starts and ends at the same node.\nA scenic drive from your hotel and back, never taking the same road twice.\n\n\nCycle\nA path that starts and ends at the same node.\nA perfect loop, like a lap on a racetrack.\n\n\n\nWith this vocabulary, we can be more precise about the Königsberg problem.\n\nAn Eulerian Trail/Path is a trail that uses every edge in the graph.\nAn Eulerian Circuit/Cycle is a circuit that uses every edge in the graph.\n\nThe citizens were looking for an Eulerian circuit. Euler proved that to have one, all nodes must have an even degree.\n\n\nNetwork Connectivity\nEuler’s theorem only applies if the graph is connected. If you can’t get from one part of the network to another, then a single walk can’t possibly cover all the edges.\n\nA graph is connected if there is a path between any two nodes.\nA disconnected graph is made of two or more separate “islands” of nodes, called connected components.\n\n\n\n\n\n\n\nFigure 4: A graph with three distinct connected components, highlighted in different colors.\n\n\n\n\nConnectivity in Directed Networks\nWhat if edges have a direction, like one-way streets? We call these directed graphs. This introduces two flavors of connectivity:\n\nWeakly Connected: The graph would be connected if you ignored the edge directions. You can get from A to B, but maybe not from B to A.\nStrongly Connected: There is a directed path from every node to every other node. No matter where you start, you can get anywhere else by following the arrows.\n\n\n\n\n\n\n\nFigure 5: A directed graph showing strongly and weakly connected components.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#references",
    "href": "m01-euler_tour/01-concepts.html#references",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "5 References",
    "text": "5 References",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to SSIE 641 Advanced Topics on Network Science",
    "section": "",
    "text": "``Don’t think! Feeeeeel’’ is a famous quote by Bruce Lee in the movie Enter the Dragon, and this is my guiding philosophy of learning.\nThis course is designed to help you feel the concepts and tools of network science through pen-and-paper exercises and hands-on coding."
  },
  {
    "objectID": "index.html#list-of-exercises-and-assignments",
    "href": "index.html#list-of-exercises-and-assignments",
    "title": "Welcome to SSIE 641 Advanced Topics on Network Science",
    "section": "1 List of Exercises and Assignments",
    "text": "1 List of Exercises and Assignments\n\n\n\nModule\nPen and Paper Exercise\nAssignment\nSlides\n\n\n\n\nM01: Euler Tour\nThe Koningsberg Bridge\n-\nSlides\n\n\nM02: Small World\nIt’s a small world!! 6 degrees of separation\nExercise\nSlides\n\n\nM03: Robustness\nBuild it, Break it, and Build it back!\nExercise\nSlides\n\n\nM04: Friendship Paradox\nData Visualization\nExercise\nSlides\n\n\nM05: Clustering\nPerfect vs. Almost Perfect\n-\nSlides\n\n\nM06: Centrality\nWho’s the Big Cheese in the University Clubs?\n-\nSlides\n\n\nM07: Random Walks\nRandom Walks on Networks\n-\nSlides\n\n\nM08: Embedding\nNetwork Embeddings\n-\nSlides\n\n\nM09: Graph Neural Networks\nGraph Neural Networks\n-\nSlides"
  },
  {
    "objectID": "course/minidora-usage.html#getting-started-with-minidora",
    "href": "course/minidora-usage.html#getting-started-with-minidora",
    "title": "Using Minidora",
    "section": "1 Getting Started with Minidora",
    "text": "1 Getting Started with Minidora\nMinidora is your personal AI tutor available 24/7 through Discord to help you master network science concepts. She’s designed to provide personalized learning support, answer questions about course materials, and guide you through challenging topics with patience and clarity. To interact with Minidora, simply use Discord slash commands or mention her directly in any channel or thread where she’s present.\nCheck out the instruction here on how to use Minidora: Minidora Usage. Minidora is available on Discord, and you can find the invitation link on the email sent in the first week of the semester. Or you can find the invitation link on the Brightspace.\n\n\n\n\n\n\nNote\n\n\n\nSome students could not find Minidora on Discord. The easiest way to get around this is:\n\nGo to the course discord server\nOpen “network science” channel.\nClick the Minidora icon and send a direct message\nType “/” and see if the available commands are shown.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/minidora-usage.html#asking-questions",
    "href": "course/minidora-usage.html#asking-questions",
    "title": "Using Minidora",
    "section": "2 Asking Questions",
    "text": "2 Asking Questions\nThe most straightforward way to get help is using the /ask command followed by your question. For example, suppose that you want to ask a subject (Euler tour) in module 1.\n\nType /ask then type space.\nType your question (e.g., What is an Euler tour?)\nType space\nYou will be prompted to specify the module id. The id consists of “m”. For example, if it is module 1, you should type m01. Type the module id.\nThen type enter.\n\nMinidora will then read the lecture content and provide an explanation.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/minidora-usage.html#natural-conversations-and-interactive-learning",
    "href": "course/minidora-usage.html#natural-conversations-and-interactive-learning",
    "title": "Using Minidora",
    "section": "3 Natural Conversations and Interactive Learning",
    "text": "3 Natural Conversations and Interactive Learning\nFor a more conversational experience, use the /chat command which allows you to interact with Minidora in a natural, free-flowing manner. You can say things like /chat I'm confused about small-world networks, can you explain them step by step? or /chat Can you help me debug this Python code for computing centrality? Minidora will engage in back-and-forth dialogue, ask clarifying questions, and adapt her explanations based on your responses.\nNote that /chat does not contextualize the Minidora to the course materials. That means that it does not read the lecture content and interact with the students with its build-in knowledge.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/minidora-usage.html#quizzes-and-assessment",
    "href": "course/minidora-usage.html#quizzes-and-assessment",
    "title": "Using Minidora",
    "section": "4 Quizzes and Assessment",
    "text": "4 Quizzes and Assessment\nTo test your understanding and reinforce learning, Minidora offers intelligent quiz features through the /quiz command. She can generate concept-based questions using /concept-quiz m01 multiple-choice for theoretical understanding, or coding challenges with /code-quiz m01 to practice implementation skills. Minidora tracks your progress and adapts quiz difficulty based on your performance, focusing on areas where you need more practice. You can also request quizzes on specific topics by adding subject keywords, such as /quiz m02 clustering algorithms.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/minidora-usage.html#tracking-your-progress",
    "href": "course/minidora-usage.html#tracking-your-progress",
    "title": "Using Minidora",
    "section": "5 Tracking Your Progress",
    "text": "5 Tracking Your Progress\nUse the /status command to monitor your learning journey and see detailed insights about your progress. Minidora provides different status views: /status summary gives you a quick overview of questions asked and concepts mastered, while /status concepts shows which topics you’ve learned and what to study next. The /status profile command reveals your personalized learning profile, including your preferred difficulty level, learning style, and areas where you excel or need additional support. This helps Minidora provide increasingly personalized assistance as you continue learning.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "assets/slides/intro/slide00.html#enginet",
    "href": "assets/slides/intro/slide00.html#enginet",
    "title": "Advanced Topics in Network Science",
    "section": "Enginet",
    "text": "Enginet"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#enginet-1",
    "href": "assets/slides/intro/slide00.html#enginet-1",
    "title": "Advanced Topics in Network Science",
    "section": "Enginet",
    "text": "Enginet"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#enginet-2",
    "href": "assets/slides/intro/slide00.html#enginet-2",
    "title": "Advanced Topics in Network Science",
    "section": "Enginet",
    "text": "Enginet"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#course-overview",
    "href": "assets/slides/intro/slide00.html#course-overview",
    "title": "Advanced Topics in Network Science",
    "section": "Course Overview",
    "text": "Course Overview\n\nInstructor: Sadamori Kojaku (幸若完壮)\nEmail: skojaku@binghamton.edu\nOffice Hours: Friday 10:00-14:00\nCourse Website: https://skojaku.github.io/adv-net-sci"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#lets-start-with-a-story",
    "href": "assets/slides/intro/slide00.html#lets-start-with-a-story",
    "title": "Advanced Topics in Network Science",
    "section": "Let’s start with a story… 🦠",
    "text": "Let’s start with a story… 🦠\n2009: H1N1 pandemic spreads globally\nDo you remember which countries were infected first and second? Why do you think these countries were affected first and second?\nThink about it for 30 seconds.\n\nYour predictions:\n\nGeographic distance matters?\nNearby countries first?\nThen spreading outward in circles?\n\nLet’s hear some thoughts…"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#answer",
    "href": "assets/slides/intro/slide00.html#answer",
    "title": "Advanced Topics in Network Science",
    "section": "Answer",
    "text": "Answer\n\nFirst: United States\nSecond: Spain"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#heres-what-actually-happened",
    "href": "assets/slides/intro/slide00.html#heres-what-actually-happened",
    "title": "Advanced Topics in Network Science",
    "section": "Here’s what actually happened…",
    "text": "Here’s what actually happened…\n\nQuestion: What do you notice? Does this match your prediction?"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#spot-the-networks",
    "href": "assets/slides/intro/slide00.html#spot-the-networks",
    "title": "Advanced Topics in Network Science",
    "section": "Spot the Networks! 👀",
    "text": "Spot the Networks! 👀\nLook around you right now…\nWhat networks do you interact with daily?\nTake 1 minute - list as many networks as you can"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#lets-share",
    "href": "assets/slides/intro/slide00.html#lets-share",
    "title": "Advanced Topics in Network Science",
    "section": "Let’s Share! 🗣️",
    "text": "Let’s Share! 🗣️\nWhat did you come up with?\nI’ll collect a few examples from the class…"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#here-are-some-you-might-have-missed",
    "href": "assets/slides/intro/slide00.html#here-are-some-you-might-have-missed",
    "title": "Advanced Topics in Network Science",
    "section": "Here Are Some You Might Have Missed:",
    "text": "Here Are Some You Might Have Missed:\n\n\nPlant-Pollinator Networks 🌼\n\n\n\n\n\n\nYour Brain Right Now! 🧠\n\n\n\n\n\nAs you’re listening, billions of neurons are connecting…"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#social-networks-obviously",
    "href": "assets/slides/intro/slide00.html#social-networks-obviously",
    "title": "Advanced Topics in Network Science",
    "section": "Social Networks (Obviously!) 📱",
    "text": "Social Networks (Obviously!) 📱\n\n\n\n\n\n\n\n\nHow do ideas spread through social networks?\nSame as diseases? Different?"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#how-did-you-get-to-class-today",
    "href": "assets/slides/intro/slide00.html#how-did-you-get-to-class-today",
    "title": "Advanced Topics in Network Science",
    "section": "How Did You Get to Class Today? 🚗",
    "text": "How Did You Get to Class Today? 🚗\n\nTransportation networks shape our daily choices!"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#wait---isnt-this-just-graph-theory",
    "href": "assets/slides/intro/slide00.html#wait---isnt-this-just-graph-theory",
    "title": "Advanced Topics in Network Science",
    "section": "Wait - Isn’t This Just Graph Theory? 🤔",
    "text": "Wait - Isn’t This Just Graph Theory? 🤔\n\n\nThese are typical topological patterns studied in Graph Theory.\nWhat do you notice about this pattern?"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#real-world-networks-look-like-this",
    "href": "assets/slides/intro/slide00.html#real-world-networks-look-like-this",
    "title": "Advanced Topics in Network Science",
    "section": "Real-World Networks Look Like This:",
    "text": "Real-World Networks Look Like This:\n\n\n\n\n\n\n\n\nWhat’s different here?\nWhy does this “messiness” matter?\nQuestion - what makes real networks “messy”?"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#philosophers-on-the-nature-of-reality",
    "href": "assets/slides/intro/slide00.html#philosophers-on-the-nature-of-reality",
    "title": "Advanced Topics in Network Science",
    "section": "Philosophers on the Nature of Reality",
    "text": "Philosophers on the Nature of Reality\n\nThales of Miletus (c. 624–546 BCE): Everything is water.\nPythagoras of Samos (c. 570–495 BCE): All is number.\nDemocritus of Abdera (c. 460–370 BCE): Everything is made of atoms.\nRené Descartes (1596–1650): Divide each problem into as many parts as possible.\nKey insight: Seek the fundamental building blocks—whether substance, number, atom, or principle—by breaking down complex systems into their simplest elements."
  },
  {
    "objectID": "assets/slides/intro/slide00.html#the-reductionist-approach",
    "href": "assets/slides/intro/slide00.html#the-reductionist-approach",
    "title": "Advanced Topics in Network Science",
    "section": "The Reductionist Approach 🧩",
    "text": "The Reductionist Approach 🧩\n\n\nBreak it down → Understand parts → Reassemble\nThis works well. Does it?"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#thought-experiment",
    "href": "assets/slides/intro/slide00.html#thought-experiment",
    "title": "Advanced Topics in Network Science",
    "section": "Thought Experiment 🤔",
    "text": "Thought Experiment 🤔\n\n\n\nImagine you’re an Alien scientist (like von Neumann!) studying humans…\nYou understand every single neuron in the human brain perfectly.\nCan we say we understand human consciousness? Why?"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#todays-highlight",
    "href": "assets/slides/intro/slide00.html#todays-highlight",
    "title": "Advanced Topics in Network Science",
    "section": "Today’s highlight",
    "text": "Today’s highlight\nWho is among the first to study the relationship of parts?\nLeonhard Euler (1707–1783)"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#course-objectives",
    "href": "assets/slides/intro/slide00.html#course-objectives",
    "title": "Advanced Topics in Network Science",
    "section": "Course Objectives",
    "text": "Course Objectives\n\n\nWe will:\n\n🔍 Analyze networks\n🧠 Learn key concepts\n🤖 Apply AI to networks\n\n\nAfter this course, you’ll be able to:\n\n📖 Understand network science papers\n🛠️ Do advanced network analysis\n📝 Design network research\n🔗 Connect Systems Science and networks"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#trap-1",
    "href": "assets/slides/intro/slide00.html#trap-1",
    "title": "Advanced Topics in Network Science",
    "section": "Trap #1",
    "text": "Trap #1\n\n\nPen & Paper Exercise\nAll modules start with an in-class pen & paper exercise.\n\nBring your pen to class\nYou solve it by yourself\nThen, discuss with your mates"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#trap-2",
    "href": "assets/slides/intro/slide00.html#trap-2",
    "title": "Advanced Topics in Network Science",
    "section": "Trap #2",
    "text": "Trap #2\n\n\nInteractive Visualization\nMost modules have an interactive game to play\n\nWining the game requires Network Science knowledge\nYou don’t have the knowledge initially but play the game\nYou will learn Network Science by learning how to win the game\n\n\nLink: Vaccination Game"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#trap-3",
    "href": "assets/slides/intro/slide00.html#trap-3",
    "title": "Advanced Topics in Network Science",
    "section": "Trap #3",
    "text": "Trap #3\nWeekly Quiz\nEvery class begins with a weekly quiz to review the previous week’s topics.\n\nWritten quiz\nOnly few questions\nGraded and reviewed during the class\nYou can resubmit the quiz (one time)\n(Enginet students will submit via Brightspace)"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#trap-4",
    "href": "assets/slides/intro/slide00.html#trap-4",
    "title": "Advanced Topics in Network Science",
    "section": "Trap #4",
    "text": "Trap #4\n\n\nAssignment\n\nMost modules have coding assignments\nDistributed via GitHub Classroom\nUnlimited attempts until deadline\nAutograded\n\n\n\n\nWe’ll cover assignment submission in class. Find the detailed instruction on the lecture note."
  },
  {
    "objectID": "assets/slides/intro/slide00.html#trap-5",
    "href": "assets/slides/intro/slide00.html#trap-5",
    "title": "Advanced Topics in Network Science",
    "section": "Trap #5",
    "text": "Trap #5\n\n\nLLM Dojo\n\nYou’ll create challenging questions for LLMs.\nYou’ll win if you can create one that stumps LLMs.\nEvery module has a LLM Dojo exercise\nCollected & Graded on GitHub\n\n\nYou’ll create a quiz & answer for LLMs.\n[[questions]]\nquestion = \"\"\"\n    When is the global clustering not a\n    good representation of the network?\n    \"\"\"\nanswer = \"\"\"\n    When the network is degree\n    heterogeneous. This is because\n    a single hub can create\n    substantially many triangles\n    in the network, not\n    representing the number of\n    triangles typical nodes\n    in the network form.\n    \"\"\""
  },
  {
    "objectID": "assets/slides/intro/slide00.html#trap-6",
    "href": "assets/slides/intro/slide00.html#trap-6",
    "title": "Advanced Topics in Network Science",
    "section": "Trap #6",
    "text": "Trap #6\nNetwork of the Week\n\nYou’ll pick a paper on network science of your interest\nYou’ll present the paper in the class\n\nroughly 10 minutes\n5 mins for Q&A\n\nThe instructor can help you find a paper"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#grading-items",
    "href": "assets/slides/intro/slide00.html#grading-items",
    "title": "Advanced Topics in Network Science",
    "section": "Grading items",
    "text": "Grading items\n\nQuiz (10%)\nNetwork of the Week Presentation (10%)\nAssignments (20%)\nExam (30%)\nProject (30%)\n\n\n✨ Bonus (30%)\n\n10% bonus for the best project (one team)\n10% for the excellent Network of the Week Presentation\n10% bonus for excellent question-answer assignment"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#exam",
    "href": "assets/slides/intro/slide00.html#exam",
    "title": "Advanced Topics in Network Science",
    "section": "Exam",
    "text": "Exam\n\nFinal exam on all topics\nDuring exam week (Dec 8-12)\nAll multiple choice questions\nTake home exam\nBrightspace will be used for submission"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#final-project",
    "href": "assets/slides/intro/slide00.html#final-project",
    "title": "Advanced Topics in Network Science",
    "section": "Final Project 🎓",
    "text": "Final Project 🎓\n\nIndividual project (30% of grade) 📊\nTimeline 📅\n\nProposal: Sept 30; Paper: Dec 5; Presentations: Dec 5\n\nRequirements 📋\n\nAbout Network Science\nDevelop a new method, new visualization, literature review, case study, etc."
  },
  {
    "objectID": "assets/slides/intro/slide00.html#example-project-01",
    "href": "assets/slides/intro/slide00.html#example-project-01",
    "title": "Advanced Topics in Network Science",
    "section": "Example Project 01",
    "text": "Example Project 01\nAnalysing the network of scientific topics"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#example-project-02",
    "href": "assets/slides/intro/slide00.html#example-project-02",
    "title": "Advanced Topics in Network Science",
    "section": "Example Project 02",
    "text": "Example Project 02\nCorrelation between the neural activities of the brain"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#example-project-03",
    "href": "assets/slides/intro/slide00.html#example-project-03",
    "title": "Advanced Topics in Network Science",
    "section": "Example Project 03",
    "text": "Example Project 03\nTesla Supercharger Network"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#ai-tutor",
    "href": "assets/slides/intro/slide00.html#ai-tutor",
    "title": "Advanced Topics in Network Science",
    "section": "AI Tutor 🤖",
    "text": "AI Tutor 🤖\n\n\n\nMinidora, an AI tutor for this course available 24/7 through Discord\n\n\nYou can chat, ask questions, and take quizzes with Minidora.\nSign up for the course on Discord to get access\nDemo: /ask What is an Euler tour?"
  },
  {
    "objectID": "assets/slides/intro/slide00.html#policy",
    "href": "assets/slides/intro/slide00.html#policy",
    "title": "Advanced Topics in Network Science",
    "section": "Policy",
    "text": "Policy\n\n📚 3-credit course: 6.5+ hours of work/week outside class\n🤖 AI tools allowed for learning, but cite if used in assignments\n💾 Back up all data and code (loss not an excuse for late work)\n♿ Accommodations available for students with disabilities\n🚫 Zero tolerance for academic dishonesty"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#quiz",
    "href": "assets/slides/m01/slide01-02.html#quiz",
    "title": "Advanced Topics in Network Science",
    "section": "Quiz",
    "text": "Quiz\n\nExplain in your own words what is the conditions for a graph to have an Euler path, and why?\nWhat is the minimum number of bridges required to make the Königsberg bridge puzzle have an Euler circuit? Explain your reasoning."
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#menue",
    "href": "assets/slides/m01/slide01-02.html#menue",
    "title": "Advanced Topics in Network Science",
    "section": "Menue",
    "text": "Menue\n\nConnected components\nRepresentation of networks\nCoding exercise: set up\nAssignment set up"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#connected-component",
    "href": "assets/slides/m01/slide01-02.html#connected-component",
    "title": "Advanced Topics in Network Science",
    "section": "Connected Component",
    "text": "Connected Component\nDefinition: A connected component is a maximal set of nodes where every node can reach every other node within that set.\n\nQuestion: Is a single node a connected component?"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#coding-networks-in-python",
    "href": "assets/slides/m01/slide01-02.html#coding-networks-in-python",
    "title": "Advanced Topics in Network Science",
    "section": "Coding Networks in Python 💻",
    "text": "Coding Networks in Python 💻\nGiven any network, how would you represent it in a computer?\n\n\nThree ways to represent the same network:\n\nEdge Table - List of connections\nAdjacency List - Each node’s neighbors\nAdjacency Matrix - Grid of 1s and 0s\n\n\n\n\n\n\n\n5 nodes, 6 edges"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#edge-table-the-direct-approach",
    "href": "assets/slides/m01/slide01-02.html#edge-table-the-direct-approach",
    "title": "Advanced Topics in Network Science",
    "section": "Edge Table: The Direct Approach 📋",
    "text": "Edge Table: The Direct Approach 📋\nSimply list every connection:\nedges = [\n    (0, 1),  # Node 0 connects to Node 1\n    (0, 2),  # Node 0 connects to Node 2\n    (1, 2),  # Node 1 connects to Node 2\n    (1, 3),  # Node 1 connects to Node 3\n    (2, 4),  # Node 2 connects to Node 4\n    (3, 4)   # Node 3 connects to Node 4\n]\n\nHow would you count the degree of node 1 from this list?\nHow would you find the neighbors of node 1?"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#adjacency-list-neighborhood-map",
    "href": "assets/slides/m01/slide01-02.html#adjacency-list-neighborhood-map",
    "title": "Advanced Topics in Network Science",
    "section": "Adjacency List: Neighborhood Map 🗺️",
    "text": "Adjacency List: Neighborhood Map 🗺️\nEach node knows its neighbors:\nneighbors = {\n    0: [1, 2],     # Node 0 connects to nodes 1,2\n    1: [0, 2, 3],  # Node 1 connects to nodes 0,2,3\n    2: [0, 1, 4],  # Node 2 connects to nodes 0,1,4\n    3: [1, 4],     # Node 3 connects to nodes 1,4\n    4: [2, 3]      # Node 4 connects to nodes 2,3\n}\n\nHow would you count the degree of node 1 from this list?\nHow would you find the neighbors of node 1?"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#adjacency-matrix-the-math-way",
    "href": "assets/slides/m01/slide01-02.html#adjacency-matrix-the-math-way",
    "title": "Advanced Topics in Network Science",
    "section": "Adjacency Matrix: The Math Way 📐",
    "text": "Adjacency Matrix: The Math Way 📐\nGrid where entry \\((i,j) = 1\\) if connected:\nimport numpy as np\n\nmatrix = np.array([\n    [0, 1, 1, 0, 0],  # Node 0: connects to 1,2\n    [1, 0, 1, 1, 0],  # Node 1: connects to 0,2,3\n    [1, 1, 0, 0, 1],  # Node 2: connects to 0,1,4\n    [0, 1, 0, 0, 1],  # Node 3: connects to 1,4\n    [0, 0, 1, 1, 0]   # Node 4: connects to 2,3\n])\n\nHow would you count the degree of node 1 from this matrix?\nHow would you find the neighbors of node 1?"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#implementing-eulers-theorem",
    "href": "assets/slides/m01/slide01-02.html#implementing-eulers-theorem",
    "title": "Advanced Topics in Network Science",
    "section": "Implementing Euler’s Theorem 🧮",
    "text": "Implementing Euler’s Theorem 🧮\ndef has_euler_path(adjacency_matrix):\n    # Calculate degrees\n    degrees = adjacency_matrix.sum(axis=1)\n\n    # Count odd degrees\n    odd_count = sum(1 for d in degrees if d % 2 == 1)\n\n    # Euler's condition\n    return odd_count == 0 or odd_count == 2\nDo you agree with this?"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#the-missing-piece-connectivity",
    "href": "assets/slides/m01/slide01-02.html#the-missing-piece-connectivity",
    "title": "Advanced Topics in Network Science",
    "section": "The Missing Piece: Connectivity ⚖️",
    "text": "The Missing Piece: Connectivity ⚖️\n\n\n\n\n\n\n\nRevisit\n\n\nAn Euler path exists if and only if:\n\nThe graph is connected ← We forgot this!\nExactly 0 or 2 nodes have odd degree"
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#representation-of-networks",
    "href": "assets/slides/m01/slide01-02.html#representation-of-networks",
    "title": "Advanced Topics in Network Science",
    "section": "Representation of Networks",
    "text": "Representation of Networks\n\n\nEdge Table\nedges = [\n    (0, 1),\n    (1, 2),\n    (2, 3)\n]\nBest for: Storage, I/O\n\nAdjacency List\nneighbors = {\n    0: [1],\n    1: [0, 2],\n    2: [1, 3]\n}\nBest for: Neighbor search\n\nAdjacency Matrix\nmatrix = np.array([\n    [0, 1, 0],\n    [1, 0, 1],\n    [0, 1, 0]\n])\nBest for: Math operations\n\nMy recommendation:\nUse edge table for saving the network data. Use (sparse) adjacency matrices for analysis."
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#coming-up-in-module-02",
    "href": "assets/slides/m01/slide01-02.html#coming-up-in-module-02",
    "title": "Advanced Topics in Network Science",
    "section": "Coming up in Module 02:",
    "text": "Coming up in Module 02:\nSmall world networks\n\n\n\n\nAlmost all 8 billion people on the planet are your friends of friends of friends of friends of friends of friends."
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#coding-exercise",
    "href": "assets/slides/m01/slide01-02.html#coding-exercise",
    "title": "Advanced Topics in Network Science",
    "section": "Coding Exercise",
    "text": "Coding Exercise\n\n\n\nRepresent the bridge network as either an edge table, an adjacency list, or an adjacency matrix in Python.\nWrite a function that takes the network data and returns the existence of an Euler path."
  },
  {
    "objectID": "assets/slides/m01/slide01-02.html#assignment-set-up",
    "href": "assets/slides/m01/slide01-02.html#assignment-set-up",
    "title": "Advanced Topics in Network Science",
    "section": "Assignment set up",
    "text": "Assignment set up\n\nhttps://classroom.github.com/a/Sdey2VNh.\nPreparations: Install Docker Desktop and GitHub Desktop\nA simple workflow using GitHub Web UI\nA recommended workflow using Docker and VS Code."
  },
  {
    "objectID": "course/setup.html",
    "href": "course/setup.html",
    "title": "Setup",
    "section": "",
    "text": "We’ll use Python to work with data throughout this course. Python is an excellent choice for network science for its rich ecosystem of libraries, readable and intuitive syntax, and well-documented documentation.\nWe strongly recommend using virtual environments to manage your Python packages. Virtual environments create isolated Python installations for each project, avoiding dependency hell and providing several key benefits:\n\n\nDon’t confuse Python virtual environments with virtual machines (VMs). Python virtual environments are lightweight isolation tools that only separate Python packages and dependencies within the same operating system. Virtual machines, on the other hand, create complete isolated operating systems.\n\nReproducibility: Your code will work consistently across different machines and over time\nFlexibility: You can use different versions of packages for different projects without conflicts\nPrevent project interference: Changes to one project won’t break another project’s dependencies\n\n\n\n\n\n\n\nFigure 1: Without virtual environments, you risk dependency hell where package conflicts make your projects unusable.\n\n\n\nWe recommend using mamba and uv. Mamba is a tool for quickly installing Python and other packages, and for creating isolated environments for your projects. uv is a fast Python package and project manager. While we won’t be running uv commands directly in this course, you’ll need uv to properly run Marimo notebooks, which provides a much better development experience. See here for installation instructions.\nFollow the following steps to install mamba, uv, along with the minimum Python packages required for this course.\n\nInstall mamba\nRun the following command to create a new environment with the minimum Python packages required for this course.\n\nmamba create -n advnetsci python==3.11 matplotlib scipy numpy pandas seaborn uv\n\nActivate the environment.\n\nmamba activate advnetsci\n\nPip install marimo.\n\npip install marimo\n\n\n\n\n\n\nIf you prefer tools other than uv, here are some alternatives:\n\nvenv: The standard library for creating virtual environments;\npyenv: Great for managing multiple Python versions;\nConda: Popular in data science, includes non-Python packages;\nMamba: Faster drop-in replacement for conda;\nMiniforge: Community-driven conda distribution with mamba included;",
    "crumbs": [
      "Home",
      "Course Information",
      "Setup"
    ]
  },
  {
    "objectID": "course/setup.html#python-and-virtual-environments",
    "href": "course/setup.html#python-and-virtual-environments",
    "title": "Setup",
    "section": "",
    "text": "We’ll use Python to work with data throughout this course. Python is an excellent choice for network science for its rich ecosystem of libraries, readable and intuitive syntax, and well-documented documentation.\nWe strongly recommend using virtual environments to manage your Python packages. Virtual environments create isolated Python installations for each project, avoiding dependency hell and providing several key benefits:\n\n\nDon’t confuse Python virtual environments with virtual machines (VMs). Python virtual environments are lightweight isolation tools that only separate Python packages and dependencies within the same operating system. Virtual machines, on the other hand, create complete isolated operating systems.\n\nReproducibility: Your code will work consistently across different machines and over time\nFlexibility: You can use different versions of packages for different projects without conflicts\nPrevent project interference: Changes to one project won’t break another project’s dependencies\n\n\n\n\n\n\n\nFigure 1: Without virtual environments, you risk dependency hell where package conflicts make your projects unusable.\n\n\n\nWe recommend using mamba and uv. Mamba is a tool for quickly installing Python and other packages, and for creating isolated environments for your projects. uv is a fast Python package and project manager. While we won’t be running uv commands directly in this course, you’ll need uv to properly run Marimo notebooks, which provides a much better development experience. See here for installation instructions.\nFollow the following steps to install mamba, uv, along with the minimum Python packages required for this course.\n\nInstall mamba\nRun the following command to create a new environment with the minimum Python packages required for this course.\n\nmamba create -n advnetsci python==3.11 matplotlib scipy numpy pandas seaborn uv\n\nActivate the environment.\n\nmamba activate advnetsci\n\nPip install marimo.\n\npip install marimo\n\n\n\n\n\n\nIf you prefer tools other than uv, here are some alternatives:\n\nvenv: The standard library for creating virtual environments;\npyenv: Great for managing multiple Python versions;\nConda: Popular in data science, includes non-Python packages;\nMamba: Faster drop-in replacement for conda;\nMiniforge: Community-driven conda distribution with mamba included;",
    "crumbs": [
      "Home",
      "Course Information",
      "Setup"
    ]
  },
  {
    "objectID": "course/setup.html#marimo-notebook",
    "href": "course/setup.html#marimo-notebook",
    "title": "Setup",
    "section": "2 Marimo Notebook",
    "text": "2 Marimo Notebook\nWe’ll use Marimo (GitHub) notebooks for assignments and interactive exercises throughout the course. Marimo is a reactive Python notebook that automatically updates when you change code, making it perfect for exploring network data and seeing results in real-time.\n\n\n\n\nMarimo integrates especially tightly with uv and provides a package sandbox feature that lets you inline dependencies directly in notebook files. This is the easiest way to get started - no prior uv knowledge required.\nCreating a sandboxed notebook:\nuvx marimo edit --sandbox my_notebook.py\nThis command installs marimo in a temporary environment, tracks your dependencies and stores them in the notebook file, and automatically downloads any existing dependencies.\nRunning sandboxed notebooks:\nuv run my_notebook.py\nBenefits: Dependencies are embedded in the notebook file itself, perfect reproducibility, and no need to manage separate dependency files.\n\nAlternative Installation\nIf you’re not using uv, you can install marimo with pip:\npip install marimo\n\n\nRunning Marimo\nTo start a new marimo notebook:\nmarimo edit\nTo open an existing marimo notebook:\nmarimo edit notebook.py",
    "crumbs": [
      "Home",
      "Course Information",
      "Setup"
    ]
  },
  {
    "objectID": "course/setup.html#github-and-github-copilot",
    "href": "course/setup.html#github-and-github-copilot",
    "title": "Setup",
    "section": "3 Github and GitHub Copilot",
    "text": "3 Github and GitHub Copilot\nWe’ll use GitHub for assignment collection and auto-grading in this course.\n\n\n\n\n\nMinimum Requirements\nAt the minimum level, you only need to:\n\nCreate a GitHub account at github.com\nKnow how to upload files to GitHub\n\nDetailed instructions on how to upload your assignments to GitHub will be provided separately - advanced Git features are not required for the course. See this assignment example to get familiar with the format.\n\n\nSubscribing to GitHub Copilot\nWe strongly encourage you to use GitHub Copilot, an AI-powered coding assistant that helps you write code faster and more efficiently. GitHub Copilot is an AI pair programmer that provides intelligent code suggestions, completions, and explanations directly in code editor, including VS Code and Marimo.\nStudents can get free access to GitHub Copilot Pro, which includes enhanced features and priority access. Visit the GitHub Copilot Pro free access page to get started.\nMarimo notebook supports GitHub Copilot out of the box. See the instruction to enable it. If you are using VS Code, you can also install the GitHub Copilot extension to get the same experience.\n\n\nFor Students Interested in Learning More\nUnderstanding Git and GitHub is useful for seamlessly working with assignments and will benefit your programming workflow. Additionally, Git and GitHub integrate nicely with AI tools for productivity improvement, making your development process more efficient.\n\n\nGit(Hub) and AI tools are like a pair of best friends. Git ensures that all edits are tracked and can be reverted. GitHub makes it easy for you to collaborate with (multiple) AI agents with you.\n\n\n\n\n\nGitHub Desktop (Recommended for Beginners)\nIf you want to learn more about version control, start with GitHub Desktop, a user-friendly graphical interface:\n\nGo to desktop.github.com\nDownload for your operating system\nInstall and sign in with your GitHub account\n\n\n\nUnderstanding Git and Version Control\nGit is a version control system that tracks changes in your code over time. Think of it as a sophisticated “save” system that:\n\nKeeps a complete history of all changes to your files\nLets you go back to any previous version\nAllows multiple people to work on the same project simultaneously\nHelps you manage different versions or “branches” of your work\n\nGitHub is a cloud-based platform that hosts Git repositories and adds collaboration features.\n\n\nLearning Resources\nEssential resources to understand Git concepts:\n\nInteractive Git Tutorial - Visual, hands-on learning\nGitHub Desktop Documentation - Official desktop app guide\nAtlassian Git Tutorials - Detailed tutorials with examples",
    "crumbs": [
      "Home",
      "Course Information",
      "Setup"
    ]
  },
  {
    "objectID": "intro/why-networks.html",
    "href": "intro/why-networks.html",
    "title": "Networks",
    "section": "",
    "text": "In 2009, the H1N1 influenza pandemic started in Mexico and spread around the world. Dirk Brockmann and Dirk Helbing tracked how the disease reached different countries and made a surprising discovery that would revolutionize how we understand spreading processes.\nThe most natural way to think about disease spread is through geographic distance. If you looked at a traditional world map, you might expect the disease to spread in expanding circles - first to nearby countries like Guatemala and the United States, then gradually to more distant places. But look at what the data actually shows:\n\n\n\n\n\n\nFigure 1: Geographic distance shows only weak correlation with disease arrival times for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\nDistance does explain the arrival time to some extent - there’s a rough trend where farther places tend to be infected later (C, D, E). But it doesn’t tell the whole story. At the same distances, some cities experienced early arrival while others experienced much later arrival. What explains this variation?\nThis mystery was solved by Dirk Brockmann and his colleagues, who realized that disease spread follows the hidden geometry of mobility networks - not geographic maps. Air travel connections, not physical distance, determined how quickly the pandemic reached different parts of the world.\n\n\n\n\n\n\nFigure 2: Effective distance (based on mobility networks) shows strong correlation with disease arrival times (R² = 0.973) for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\n\n\nSee (Brockmann and Helbing 2013) for more details.\nThe H1N1 example above reveals a fundamental truth: network structure determines how things spread. Geographic distance became irrelevant once we understood the underlying mobility network. This principle extends far beyond disease outbreaks.\nNetworks are everywhere. Look around you: plants depend on pollinators in ecological networks, predators and prey form intricate food webs, your brain operates through neural networks, and modern medicine maps drug interactions. At the molecular level, proteins interact in complex networks that sustain life. Socially, we’re connected through friendship networks, while globally, financial institutions form interconnected webs that can trigger worldwide crises. Every flight you take follows airport networks, every light switch connects to power grids, and every river flows through branching networks to the sea. Even the internet connecting you to this text and the knowledge graphs organizing human understanding - all are networks.\n\n\n\n\n\n\nPlant pollinator network\n\n\n\n\n\n\n\nFood web\n\n\n\n\n\n\n\nBrain network\n\n\n\n\n\n\n\n\n\nMedicine network\n\n\n\n\n\n\n\nProtein-protein interaction\n\n\n\n\n\n\n\nSocial network\n\n\n\n\n\n\n\n\n\nInternational financial network\n\n\n\n\n\n\n\nUS airport network\n\n\n\n\n\n\n\nPower grid network\n\n\n\n\n\n\n\n\n\nRiver network\n\n\n\n\n\n\n\nInternet network\n\n\n\n\n\n\n\nKnowledge graph",
    "crumbs": [
      "Home",
      "Introduction",
      "Networks"
    ]
  },
  {
    "objectID": "intro/why-networks.html#networks-are-everywhere-and-they-matter",
    "href": "intro/why-networks.html#networks-are-everywhere-and-they-matter",
    "title": "Networks",
    "section": "",
    "text": "In 2009, the H1N1 influenza pandemic started in Mexico and spread around the world. Dirk Brockmann and Dirk Helbing tracked how the disease reached different countries and made a surprising discovery that would revolutionize how we understand spreading processes.\nThe most natural way to think about disease spread is through geographic distance. If you looked at a traditional world map, you might expect the disease to spread in expanding circles - first to nearby countries like Guatemala and the United States, then gradually to more distant places. But look at what the data actually shows:\n\n\n\n\n\n\nFigure 1: Geographic distance shows only weak correlation with disease arrival times for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\nDistance does explain the arrival time to some extent - there’s a rough trend where farther places tend to be infected later (C, D, E). But it doesn’t tell the whole story. At the same distances, some cities experienced early arrival while others experienced much later arrival. What explains this variation?\nThis mystery was solved by Dirk Brockmann and his colleagues, who realized that disease spread follows the hidden geometry of mobility networks - not geographic maps. Air travel connections, not physical distance, determined how quickly the pandemic reached different parts of the world.\n\n\n\n\n\n\nFigure 2: Effective distance (based on mobility networks) shows strong correlation with disease arrival times (R² = 0.973) for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\n\n\nSee (Brockmann and Helbing 2013) for more details.\nThe H1N1 example above reveals a fundamental truth: network structure determines how things spread. Geographic distance became irrelevant once we understood the underlying mobility network. This principle extends far beyond disease outbreaks.\nNetworks are everywhere. Look around you: plants depend on pollinators in ecological networks, predators and prey form intricate food webs, your brain operates through neural networks, and modern medicine maps drug interactions. At the molecular level, proteins interact in complex networks that sustain life. Socially, we’re connected through friendship networks, while globally, financial institutions form interconnected webs that can trigger worldwide crises. Every flight you take follows airport networks, every light switch connects to power grids, and every river flows through branching networks to the sea. Even the internet connecting you to this text and the knowledge graphs organizing human understanding - all are networks.\n\n\n\n\n\n\nPlant pollinator network\n\n\n\n\n\n\n\nFood web\n\n\n\n\n\n\n\nBrain network\n\n\n\n\n\n\n\n\n\nMedicine network\n\n\n\n\n\n\n\nProtein-protein interaction\n\n\n\n\n\n\n\nSocial network\n\n\n\n\n\n\n\n\n\nInternational financial network\n\n\n\n\n\n\n\nUS airport network\n\n\n\n\n\n\n\nPower grid network\n\n\n\n\n\n\n\n\n\nRiver network\n\n\n\n\n\n\n\nInternet network\n\n\n\n\n\n\n\nKnowledge graph",
    "crumbs": [
      "Home",
      "Introduction",
      "Networks"
    ]
  },
  {
    "objectID": "intro/why-networks.html#how-to-represent-a-network",
    "href": "intro/why-networks.html#how-to-represent-a-network",
    "title": "Networks",
    "section": "2 How to represent a network",
    "text": "2 How to represent a network\nAlthough networks come from vastly different fields, we can represent them all using the same universal language 😉. Whether we’re studying brain connections, protein interactions, or social relationships, the mathematical representation remains identical. This abstraction is what makes network science so interdisciplinary.\nA network is simply a collection of nodes connected by edges. Despite this simplicity, it’s one of the most powerful abstractions we have for understanding complex systems.\nWe can represent any network in two equivalent ways. Schematically, we draw them as dots and lines - nodes connected by edges, as shown in this network diagram:\n\n\n\n\n\n\nSchematic network\n\n\n\n\n\n\n\nA network of penguins in the Kyoto Aquarium.\n\n\n\n\n\nWhile the schematic representation is useful, things can get complicated as soon as the network becomes large. Also, we want to represent data quantitatively to obtain a quantitative understanding of network properties and behaviors.\nTables are a natural way to represent networks. The idea is to list the pairs of nodes that are connected by an edge. For example:\n\n\n\nSource\nTarget\n\n\n\n\nNode1\nNode2\n\n\nNode1\nNode3\n\n\nNode2\nNode3\n\n\nNode2\nNode4\n\n\nNode3\nNode5\n\n\n\nThis is called an edge table. Each row represents a connection between two nodes. Once we write down networks in this tabular format, we can apply the same analytical tools regardless of the domain - whether it’s routers, people, neurons, or molecules.",
    "crumbs": [
      "Home",
      "Introduction",
      "Networks"
    ]
  },
  {
    "objectID": "intro/why-networks.html#are-we-done-with-networks",
    "href": "intro/why-networks.html#are-we-done-with-networks",
    "title": "Networks",
    "section": "3 Are we done with networks?",
    "text": "3 Are we done with networks?\nIf we can represent a network in a table—a familiar data format that can be analyzed by statistical methods, machine learning, and other tools—can we just use these tools to analyze networks? Why do we need to learn network science?\nLong story short, a network is not just a collection of nodes and edges. They work in tandem to create a complex system. And this view—that a system is not just a collection of parts—represents a critical shift in science.\nFor centuries, scientists believed in reductionism. If you could create modules that function like duck organs and assemble them together, the machine would eventually behave like a duck. Vaucanson’s 18th century Digesting Duck seemed to prove this approach worked remarkably well: break down complex systems into fundamental components, understand each part, then reassemble them to understand the whole.\n\n\n\n\n\nVaucanson’s Digesting Duck\n\n\nFind more details in Wikipedia\nHowever, scientists began to realize that not all systems can be decomposed into units that provide sufficient understanding of the system as a whole. Networks represent a fundamental challenge to reductionist thinking because their most important properties emerge from the interactions between components, not from the components themselves. You can understand every individual neuron in the brain, but this won’t tell you how consciousness emerges. You can analyze every person in a social movement, but this won’t predict how ideas spread through the population. You can study every computer on the internet, but this won’t explain how global information patterns form.\nThe difficulty lies not in the individual nodes or edges, but in how they combine to create system-level behaviors that are genuinely novel. Scale overwhelms intuition; while you can mentally track relationships between three people, the same intuition fails completely with three million. Small changes can have massive consequences; removing one connection might fragment an entire network, while removing another has no effect at all. This is why network science exists as a distinct field: the traditional reductionist toolkit simply isn’t sufficient for understanding interconnected systems where the connections themselves are the source of complexity!",
    "crumbs": [
      "Home",
      "Introduction",
      "Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html",
    "href": "m01-euler_tour/02-coding.html",
    "title": "Coding Networks in Python",
    "section": "",
    "text": "Now that you understand the conceptual foundation from Euler’s work, let’s explore how to represent and analyze networks computationally. Given a network of any size, our goal is to create a function that can tell us whether the network has an Euler path or not.\nWe’ll work through both general network representations and apply them specifically to the Königsberg bridge problem.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#network-representations-from-pictures-to-data-structures",
    "href": "m01-euler_tour/02-coding.html#network-representations-from-pictures-to-data-structures",
    "title": "Coding Networks in Python",
    "section": "1 Network Representations: From Pictures to Data Structures",
    "text": "1 Network Representations: From Pictures to Data Structures\nConsider this network with 5 nodes and 6 edges:\n\n\n\n\n\n\nFigure 1: A small graph of five nodes and six edges.\n\n\n\nHow do we represent this graph in a format that a computer can understand and manipulate? Just as Euler needed to abstract Königsberg’s bridges, we need data structures that capture the network’s essential connectivity while enabling efficient analysis.\n\n\nThe choice of representation can dramatically affect computational efficiency. For sparse networks (few edges), adjacency lists are memory-efficient. For dense networks or matrix operations, adjacency matrices are preferred.\nLet’s explore three fundamental approaches that form the backbone of all network algorithms.\n\nEdge Table: The Direct Approach\nThe edge table directly lists connections as pairs—the most intuitive way to store network data.\n\n\nEdge tables are also called “edge lists” and are the most common format for storing large-scale network data in files. Social media platforms like Twitter and Facebook store billions of connections this way.\n\n# Each row represents one edge (connection between two nodes)\nedges = [\n    (0, 1),  # Node 0 connects to Node 1\n    (0, 2),  # Node 0 connects to Node 2\n    (1, 2),  # Node 1 connects to Node 2\n    (1, 3),  # Node 1 connects to Node 3\n    (2, 4),  # Node 2 connects to Node 4\n    (3, 4)   # Node 3 connects to Node 4\n]\n\nprint(f\"Network has {len(edges)} edges\")\nprint(\"Edge list:\", edges)\n\nNetwork has 6 edges\nEdge list: [(0, 1), (0, 2), (1, 2), (1, 3), (2, 4), (3, 4)]\n\n\nThis mirrors how we’d naturally describe the network: “Node 0 connects to nodes 1 and 2, node 1 connects to nodes 0, 2, and 3…” It’s the digital equivalent of Euler’s original approach—simply listing which bridges connect which landmasses.\n\n\nAdjacency List: The Neighborhood Map\nThe adjacency list stores each node’s neighbors in a dictionary—like a social network where each person has a list of friends.\n\n\nMost graph algorithms prefer adjacency lists because they allow fast iteration over a node’s neighbors. This is crucial for algorithms like breadth-first search or computing clustering coefficients.\n\n# Define adjacency list directly as a dictionary\nneighbors = {\n    0: [1, 2],     # Node 0 connects to nodes 1 and 2\n    1: [0, 2, 3],  # Node 1 connects to nodes 0, 2, and 3\n    2: [0, 1, 4],  # Node 2 connects to nodes 0, 1, and 4\n    3: [1, 4],     # Node 3 connects to nodes 1 and 4\n    4: [2, 3]      # Node 4 connects to nodes 2 and 3\n}\n\nprint(\"Adjacency list representation:\")\nfor node, neighbor_list in neighbors.items():\n    print(f\"Node {node}: {neighbor_list}\")\n\nAdjacency list representation:\nNode 0: [1, 2]\nNode 1: [0, 2, 3]\nNode 2: [0, 1, 4]\nNode 3: [1, 4]\nNode 4: [2, 3]\n\n\n\n\nAdjacency Matrix\nThe adjacency matrix uses a grid where entry (i,j) = 1 if nodes are connected—the mathematician’s favorite representation.\n\n\nAdjacency matrices enable powerful mathematical operations. Matrix multiplication reveals paths of different lengths, and eigenvalue analysis can uncover community structure. Google’s PageRank algorithm fundamentally relies on matrix operations.\n\n# Define adjacency matrix directly\nimport numpy as np\n\nmatrix = np.array([\n    [0, 1, 1, 0, 0],  # Node 0 connects to nodes 1, 2\n    [1, 0, 1, 1, 0],  # Node 1 connects to nodes 0, 2, 3\n    [1, 1, 0, 0, 1],  # Node 2 connects to nodes 0, 1, 4\n    [0, 1, 0, 0, 1],  # Node 3 connects to nodes 1, 4\n    [0, 0, 1, 1, 0]   # Node 4 connects to nodes 2, 3\n])\n\nprint(\"Adjacency matrix:\")\nprint(matrix)\n\nAdjacency matrix:\n[[0 1 1 0 0]\n [1 0 1 1 0]\n [1 1 0 0 1]\n [0 1 0 0 1]\n [0 0 1 1 0]]\n\n\nNotice the symmetry: if node i connects to node j, then node j connects to node i (for undirected networks). This symmetry disappears in directed networks, where relationships can be one-way.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#node-degrees",
    "href": "m01-euler_tour/02-coding.html#node-degrees",
    "title": "Coding Networks in Python",
    "section": "2 Node Degrees",
    "text": "2 Node Degrees\nThe degree of a node is the number of edges connected to it. This simple concept was central to Euler’s proof—he realized that a valid bridge walk requires each landmass to have an even degree (except possibly the starting and ending points).\n\n\nIn Königsberg, all four landmasses had odd degree, making the bridge walk impossible. This insight—that global properties emerge from local structure—remains fundamental to network analysis today.\nHere’s how to compute degrees using each representation:\n\nFrom Edge Table\nCount how many times each node appears in the edge list.\n\n_degrees = [0] * 5\nfor node1, node2 in edges:\n    _degrees[node1] += 1\n    _degrees[node2] += 1\nprint(\"Degrees from edge list:\", _degrees)\n\nDegrees from edge list: [2, 3, 3, 2, 2]\n\n\n\n\nWe increment the degree counter for both nodes in each edge because every edge contributes to two nodes’ degrees. This is why the total degree always equals twice the number of edges.\n\n\nFrom Adjacency List\nCount the length of each node’s neighbor list—the most direct approach.\n\n_degrees = [len(neighbors[i]) for i in range(5)]\nprint(\"Degrees from adjacency list:\", _degrees)\n\nDegrees from adjacency list: [2, 3, 3, 2, 2]\n\n\n\n\nFrom Adjacency Matrix\nSum each row (or column) of the matrix—leveraging vectorized operations.\n\n_degrees = matrix.sum(axis=1)  # Sum rows\nprint(\"Degrees from adjacency matrix:\", _degrees)\n\nDegrees from adjacency matrix: [2 3 3 2 2]\n\n\n\n\nFor undirected networks, row sums equal column sums. For directed networks, row sums give out-degree (outgoing connections) while column sums give in-degree (incoming connections).",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#checking-for-trails-walks-and-paths",
    "href": "m01-euler_tour/02-coding.html#checking-for-trails-walks-and-paths",
    "title": "Coding Networks in Python",
    "section": "3 Checking for Trails, Walks, and Paths",
    "text": "3 Checking for Trails, Walks, and Paths\nNow that we understand how to represent networks and compute degrees, let’s implement functions to verify whether a sequence of nodes represents a valid walk, trail, path, or cycle. These verification algorithms are essential for network analysis and implementing graph traversal algorithms.\n\nVerifying a Walk\nA walk is the most permissive—we simply need to check that each consecutive pair of nodes is connected by an edge.\n\ndef is_walk(sequence, adjacency_matrix):\n    \"\"\"\n    Check if a sequence of nodes forms a valid walk.\n\n    Args:\n        sequence: List of node indices [v0, v1, v2, ...]\n        adjacency_matrix: 2D numpy array representing the graph\n\n    Returns:\n        bool: True if sequence is a valid walk, False otherwise\n    \"\"\"\n    if len(sequence) &lt; 2:\n        return True  # Single node or empty sequence is trivially a walk\n\n    # Use NumPy vectorized operations for efficient edge checking\n    sequence = np.array(sequence)\n    current_nodes = sequence[:-1]  # All nodes except the last\n    next_nodes = sequence[1:]      # All nodes except the first\n\n    # Simple but slower: for loop version (slower but more explicit)\n    # for i, j in zip(current_nodes, next_nodes):\n    #     if adjacency_matrix[i, j] == 0:\n    #         return False\n    # return True\n\n    # Check all edges at once using advanced indexing\n    edges_exist = adjacency_matrix[current_nodes, next_nodes]\n\n    # All edges must exist (all values must be 1)\n    return np.all(edges_exist == 1)\n\n\n# Test with our sample network\ntest_sequence = [0, 1, 2, 4, 3, 1]\nprint(f\"Sequence {test_sequence} is a valid walk: {is_walk(test_sequence, matrix)}\")\n\n# Test an invalid walk\ninvalid_sequence = [0, 3]  # No direct edge between 0 and 3\nprint(f\"Sequence {invalid_sequence} is a valid walk: {is_walk(invalid_sequence, matrix)}\")\n\nSequence [0, 1, 2, 4, 3, 1] is a valid walk: True\nSequence [0, 3] is a valid walk: False\n\n\n\n\n\n\n\n\nMind the loops!\n\n\n\nFor loops in Python is the notorious source of computational bottlenecks. Avoiding for loops significantly boosts the speed. In is_walk, we use one for loop but you can avoid it by using NumPy’s advanced indexing, i.e., adjacency_matrix[(current_nodes, next_nodes)]. The way to think about this is that (current_nodes, next_nodes) is a tuple of indices, acting as a multi-dimensional index. adjacency_matrix[(current_nodes, next_nodes)] is 1d array of length the same as current_nodes and next_nodes. If the value is 0, then the edge does not exist. We can then check if all the values are not zero.\n\n\n\n\nVerifying a Trail\nA trail requires all edges to be distinct, but nodes can repeat.\n\ndef is_trail(sequence, adjacency_matrix):\n    \"\"\"\n    Check if a sequence of nodes forms a valid trail.\n\n    Args:\n        sequence: List of node indices [v0, v1, v2, ...]\n        adjacency_matrix: 2D numpy array representing the graph\n\n    Returns:\n        bool: True if sequence is a valid trail, False otherwise\n    \"\"\"\n    if not is_walk(sequence, adjacency_matrix):\n        return False  # Must be a valid walk first\n\n    if len(sequence) &lt; 2:\n        return True\n\n    # Convert to numpy for efficient operations\n    sequence = np.array(sequence)\n    current_nodes = sequence[:-1]\n    next_nodes = sequence[1:]\n\n    # Use complex numbers to represent edges!\n    # For undirected graph: smaller_node + 1j * larger_node\n    # This ensures edge (1,2) and (2,1) both become 1+2j\n    edge_starts = np.minimum(current_nodes, next_nodes)  # Real part\n    edge_ends = np.maximum(current_nodes, next_nodes)    # Imaginary part\n    complex_edges = edge_starts + 1j * edge_ends\n\n    # Check uniqueness directly with NumPy\n    return len(complex_edges) == len(np.unique(complex_edges))\n\n    # Alternative: Original for loop version (slower but more explicit)\n    # used_edges = set()\n    # for i in range(len(sequence) - 1):\n    #     current_node = sequence[i]\n    #     next_node = sequence[i + 1]\n    #     # Create edge tuple (smaller index first for undirected graphs)\n    #     edge = (min(current_node, next_node), max(current_node, next_node))\n    #     if edge in used_edges:\n    #         return False  # Edge already used\n    #     used_edges.add(edge)\n    # return True\n\n# Test trail verification\ntrail_sequence = [0, 1, 3, 4, 2]\nprint(f\"Sequence {trail_sequence} is a valid trail: {is_trail(trail_sequence, matrix)}\")\n\n# Test invalid trail (reuses edge 1-2)\ninvalid_trail = [0, 1, 2, 1, 3]\nprint(f\"Sequence {invalid_trail} is a valid trail: {is_trail(invalid_trail, matrix)}\")\n\nSequence [0, 1, 3, 4, 2] is a valid trail: True\nSequence [0, 1, 2, 1, 3] is a valid trail: False\n\n\n\n\nnp.unique is a powerful function that can handle complex numbers natively.\n\n\n\n\n\n\nComplex Numbers for Edge Representation\n\n\n\nWe use complex numbers to represent edges! Each edge becomes smaller_node + 1j * larger_node. For example, edge (1,2) becomes 1+2j, and edge (2,1) also becomes 1+2j (normalized). Think of complex numbers as natural 2D coordinates for representing node pairs.\n\n\n\n\nVerifying a Path\nA path requires all nodes (except possibly start/end for cycles) to be distinct.\n\ndef is_path(sequence, adjacency_matrix):\n    \"\"\"\n    Check if a sequence of nodes forms a valid path.\n\n    Args:\n        sequence: List of node indices [v0, v1, v2, ...]\n        adjacency_matrix: 2D numpy array representing the graph\n        allow_cycle: If True, allows start node = end node (cycle)\n\n    Returns:\n        bool: True if sequence is a valid path, False otherwise\n    \"\"\"\n    if not is_walk(sequence, adjacency_matrix):\n        return False  # Must be a valid walk first\n\n    if len(sequence) &lt; 2:\n        return True\n\n    sequence = np.array(sequence)\n\n    return len(sequence) == len(np.unique(sequence))\n\n# Test path verification\npath_sequence = [0, 1, 3, 4]\nprint(f\"Sequence {path_sequence} is a valid path: {is_path(path_sequence, matrix)}\")\n\n# Test invalid path (repeats node 1)\ninvalid_path = [0, 1, 2, 1, 3]\nprint(f\"Sequence {invalid_path} is a valid path: {is_path(invalid_path, matrix)}\")\n\nSequence [0, 1, 3, 4] is a valid path: True\nSequence [0, 1, 2, 1, 3] is a valid path: False",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#connected-components",
    "href": "m01-euler_tour/02-coding.html#connected-components",
    "title": "Coding Networks in Python",
    "section": "4 Connected Components",
    "text": "4 Connected Components\nConnected components are the maximal sets of nodes where every pair is connected by some path. For Euler path analysis, this is crucial—an Euler path can only exist if the entire graph forms a single connected component (or if we’re only considering the component containing edges).\n\n\nIn Königsberg, all landmasses were connected by bridges, forming one component. If one landmass were isolated, no Euler path could traverse the entire city. This connectivity requirement is the first condition in Euler’s theorem.\n\nThe Algorithm: Depth-First Search\nA simple way to find connected components is to systematically explore from each unvisited node using depth-first search (DFS). This works because DFS can only reach nodes that are connected through some path.\nAlgorithm steps: 1. Mark all nodes as unvisited 2. For each unvisited node: - Start a new component - Use DFS to explore all reachable nodes - Add all reached nodes to this component 3. Return the list of components\n\ndef connected_components(adjacency_matrix):\n    \"\"\"\n    Find connected components in an undirected graph using adjacency matrix.\n\n    Args:\n        adjacency_matrix: 2D numpy array (square)\n\n    Returns:\n        List of lists, each sublist contains node indices in a component\n    \"\"\"\n    import numpy as np\n    n = adjacency_matrix.shape[0]\n    visited = np.zeros(n, dtype=bool)\n    components = []\n\n    def dfs(node, component):\n        \"\"\"Depth-first search to explore a component\"\"\"\n        # Mark the current node as visited and add it to current component\n        visited[node] = True\n        component.append(node)\n\n        # Find all neighbors of the current node using vectorized operation\n        neighbors = np.where(adjacency_matrix[node] &gt; 0)[0]\n\n        # Recursively visit unvisited neighbors\n        for neighbor in neighbors:\n            if not visited[neighbor]:\n                dfs(neighbor, component)\n\n    # Main algorithm: iterate through all nodes\n    for v in range(n):\n        if not visited[v]:  # Found a new component\n            component = []\n            dfs(v, component)  # Explore entire component\n            components.append(component)\n\n    return components\n\n# Test with our original connected graph\nprint(\"Testing with connected graph:\")\ncomponents = connected_components(matrix)\nprint(\"Connected components:\", components)\nprint(f\"Number of components: {len(components)}\")\n\n# Create a disconnected graph to demonstrate multiple components\ndisconnected_matrix = np.array([\n    [0, 1, 0, 0, 0],  # Component 1: nodes 0,1,2\n    [1, 0, 1, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 0, 0, 1],  # Component 2: nodes 3,4\n    [0, 0, 0, 1, 0]\n])\n\nprint(\"\\nTesting with disconnected graph:\")\ndisconnected_components = connected_components(disconnected_matrix)\nprint(\"Connected components:\", disconnected_components)\nprint(f\"Number of components: {len(disconnected_components)}\")\n\nTesting with connected graph:\nConnected components: [[0, np.int64(1), np.int64(2), np.int64(4), np.int64(3)]]\nNumber of components: 1\n\nTesting with disconnected graph:\nConnected components: [[0, np.int64(1), np.int64(2)], [3, np.int64(4)]]\nNumber of components: 2\n\n\n\n\nDFS naturally explores as “deep” as possible before backtracking. This makes it perfect for component finding because once we start exploring from a node, we want to find ALL nodes in its component before moving to the next component.\n\n\nImproved Euler Path Checker\nNow we can enhance our Euler path function to include the connectivity requirement:\n\ndef has_euler_path_complete(adjacency_matrix):\n    \"\"\"\n    Complete Euler path checker with connectivity verification.\n\n    Args:\n        adjacency_matrix: 2D numpy array representing the graph\n\n    Returns:\n        bool: True if graph has an Euler path, False otherwise\n    \"\"\"\n    # Check if graph is connected (ignoring isolated nodes)\n    components = connected_components(adjacency_matrix)\n\n    # Find nodes with at least one edge (degree &gt; 0)\n    degrees = adjacency_matrix.sum(axis=1)\n    non_isolated_nodes = np.where(degrees &gt; 0)[0]\n\n    if len(non_isolated_nodes) == 0:\n        return True  # Empty graph has Euler path trivially\n\n    # Check if all non-isolated nodes are in the same component\n    component_with_edges = None\n    for component in components:\n        if non_isolated_nodes[0] in component:\n            component_with_edges = set(component)\n            break\n\n    # All nodes with edges must be in the same component\n    if not all(node in component_with_edges for node in non_isolated_nodes):\n        return False  # Graph is disconnected\n\n    # Count nodes with odd degrees (among non-isolated nodes)\n    non_isolated_degrees = degrees[non_isolated_nodes]\n    odd_degree_count = np.sum(non_isolated_degrees % 2)\n\n    # Euler's theorem: exactly 0 or 2 nodes with odd degrees\n    return odd_degree_count == 0 or odd_degree_count == 2\n\n# Test with connected graph\nprint(\"Connected graph has Euler path:\", has_euler_path_complete(matrix))\n\n# Test with disconnected graph\nprint(\"Disconnected graph has Euler path:\", has_euler_path_complete(disconnected_matrix))\n\n# Test the classic Königsberg bridge problem (all odd degrees)\nkonigsberg = np.array([\n    [0, 1, 1, 1],  # Landmass 0 connects to all others (degree 3)\n    [1, 0, 1, 1],  # Landmass 1 connects to all others (degree 3)\n    [1, 1, 0, 1],  # Landmass 2 connects to all others (degree 3)\n    [1, 1, 1, 0]   # Landmass 3 connects to all others (degree 3)\n])\nprint(\"Königsberg bridges have Euler path:\", has_euler_path_complete(konigsberg))\n\nConnected graph has Euler path: True\nDisconnected graph has Euler path: False\nKönigsberg bridges have Euler path: False\n\n\n\n\n\n\n\n\nWhy Connectivity Matters\n\n\n\nEven if a graph has exactly 2 odd-degree nodes, an Euler path cannot exist if those nodes are in different connected components. You cannot traverse from one component to another without existing edges, making a single continuous path impossible.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#summary",
    "href": "m01-euler_tour/02-coding.html#summary",
    "title": "Coding Networks in Python",
    "section": "5 Summary",
    "text": "5 Summary\nYou now understand how to:\n\nRepresent networks using edge lists, adjacency lists, and adjacency matrices—each optimized for different computational tasks\nCompute node degrees efficiently using vectorized operations across all representations\nVerify walks, trails, paths, and cycles with robust algorithms that handle edge cases\nFind connected components using depth-first search to identify disconnected parts of networks\nApply Euler’s theorem completely by checking both degree conditions and connectivity requirements\n\n\n\n\n\n\n\nComputational Complexity\n\n\n\n\nDegree calculation: O(n²) for adjacency matrix, O(E) for edge list, O(1) for adjacency list\nWalk verification: O(k) where k is sequence length\nConnected components: O(n²) for adjacency matrix representation using DFS\nComplete Euler path check: O(n²) dominated by connectivity check\n\n\n\nThese fundamental algorithms form the building blocks for more sophisticated network analysis. Whether you’re analyzing social networks, transportation systems, or molecular structures, these core concepts of connectivity, traversal, and structural analysis remain essential.\nFrom Euler’s original insight about Königsberg’s bridges to modern network science, the mathematical principles you’ve implemented here continue to solve real-world problems—from GPS routing algorithms to understanding brain connectivity patterns.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/04-advanced.html",
    "href": "m01-euler_tour/04-advanced.html",
    "title": "Advanced: Sparse Matrices for Large-Scale Networks",
    "section": "",
    "text": "Modern networks have billions of nodes—far beyond Königsberg’s 4 landmasses. A dense adjacency matrix for Earth’s 8 billion people would require 512 exabytes of memory!\nReal networks are sparse: most node pairs aren’t connected. Edge lists save memory but are inefficient for common operations like finding neighbors or computing degrees.\n\n\nThink about the following operations:\n\nDegree: How many friends does a person have?\nNeighbors: Who are the friends of a person?\n\nThese operations are very common in network analysis. To do so, you need to go through all the edges in the network. This is not efficient, especially for large networks.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Advanced: Sparse Matrices for Large-Scale Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/04-advanced.html#the-scale-problem-from-königsberg-to-global-networks",
    "href": "m01-euler_tour/04-advanced.html#the-scale-problem-from-königsberg-to-global-networks",
    "title": "Advanced: Sparse Matrices for Large-Scale Networks",
    "section": "",
    "text": "Modern networks have billions of nodes—far beyond Königsberg’s 4 landmasses. A dense adjacency matrix for Earth’s 8 billion people would require 512 exabytes of memory!\nReal networks are sparse: most node pairs aren’t connected. Edge lists save memory but are inefficient for common operations like finding neighbors or computing degrees.\n\n\nThink about the following operations:\n\nDegree: How many friends does a person have?\nNeighbors: Who are the friends of a person?\n\nThese operations are very common in network analysis. To do so, you need to go through all the edges in the network. This is not efficient, especially for large networks.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Advanced: Sparse Matrices for Large-Scale Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/04-advanced.html#solution-sparse-matrices",
    "href": "m01-euler_tour/04-advanced.html#solution-sparse-matrices",
    "title": "Advanced: Sparse Matrices for Large-Scale Networks",
    "section": "2 Solution: Sparse Matrices",
    "text": "2 Solution: Sparse Matrices\nWe say a matrix is sparse if the matrix has only a handful of non-zero entries. This is indeed the case for most real-world networks. For such networks, we can use a special type of data type called Compressed Sparse Row (CSR) or Compressed Sparse Column (CSC) to represent the network. This is widely used in many network analysis tools and makes it possible to process large networks in practice.\nTo learn more, here is a very good blog post by Matt Eding about efficient network representations.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Advanced: Sparse Matrices for Large-Scale Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/04-advanced.html#scipys-compressed-sparse-row-csr-format",
    "href": "m01-euler_tour/04-advanced.html#scipys-compressed-sparse-row-csr-format",
    "title": "Advanced: Sparse Matrices for Large-Scale Networks",
    "section": "3 SciPy’s Compressed Sparse Row (CSR) Format",
    "text": "3 SciPy’s Compressed Sparse Row (CSR) Format\n\n\nHere is a short video explaining the CSR format. Good one to watch if you are visual learner.\n\n\n\n\n\n\n\n\nFigure 1: A sparse matrix is a matrix with only a handful of non-zero entries represented with a compressed sparse frmat.\n\n\n\nCSR stores only non-zero matrix entries using three arrays, making it the standard for large-scale network analysis.\n\nUnderstanding CSR Structure\nCSR format uses three arrays to represent a sparse matrix:\n\ndata: Contains all non-zero values\nindices: Column indices of each non-zero value\nindptr: Row pointers indicating where each row starts in the data array\n\n\n\nMemory efficiency: For a sparse matrix with m non-zero entries out of n^2 total entries, CSR uses O(m + n) memory instead of O(n^2). For social networks where m \\ll n^2, this is a massive saving!\n\nimport numpy as np\nfrom scipy import sparse\n\n# Create a small example network\n# Let's represent the same 5-node network from earlier\ndense_matrix = np.array([\n    [0, 1, 1, 0, 0],  # Node 0 connects to nodes 1, 2\n    [1, 0, 1, 1, 0],  # Node 1 connects to nodes 0, 2, 3\n    [1, 1, 0, 0, 1],  # Node 2 connects to nodes 0, 1, 4\n    [0, 1, 0, 0, 1],  # Node 3 connects to nodes 1, 4\n    [0, 0, 1, 1, 0]   # Node 4 connects to nodes 2, 3\n])\n\n# Convert to CSR format\ncsr_matrix = sparse.csr_matrix(dense_matrix)\n\nprint(\"Dense matrix shape:\", dense_matrix.shape)\nprint(\"CSR matrix shape:\", csr_matrix.shape)\nprint(\"Non-zero entries:\", csr_matrix.nnz)\nprint(\"Memory saved: {:.1f}%\".format((1 - csr_matrix.nnz / dense_matrix.size) * 100))\n\nDense matrix shape: (5, 5)\nCSR matrix shape: (5, 5)\nNon-zero entries: 12\nMemory saved: 52.0%\n\n\n\n\nInside the CSR Format\nLet’s examine the internal structure of our CSR matrix:\n\nprint(\"CSR internal arrays:\")\nprint(\"data (non-zero values):\", csr_matrix.data)\nprint(\"indices (column positions):\", csr_matrix.indices)\nprint(\"indptr (row pointers):\", csr_matrix.indptr)\n\n# Let's trace through how CSR works\nprint(\"\\nDecoding CSR structure:\")\nfor i in range(len(csr_matrix.indptr) - 1):\n    start = csr_matrix.indptr[i]\n    end = csr_matrix.indptr[i + 1]\n    row_data = csr_matrix.data[start:end]\n    row_indices = csr_matrix.indices[start:end]\n    print(f\"Row {i}: values {row_data} at columns {row_indices}\")\n\nCSR internal arrays:\ndata (non-zero values): [1 1 1 1 1 1 1 1 1 1 1 1]\nindices (column positions): [1 2 0 2 3 0 1 4 1 4 2 3]\nindptr (row pointers): [ 0  2  5  8 10 12]\n\nDecoding CSR structure:\nRow 0: values [1 1] at columns [1 2]\nRow 1: values [1 1 1] at columns [0 2 3]\nRow 2: values [1 1 1] at columns [0 1 4]\nRow 3: values [1 1] at columns [1 4]\nRow 4: values [1 1] at columns [2 3]\n\n\n\n\n\n\n\n\nHow CSR Works\n\n\n\nFor row i, the non-zero values are stored in data[indptr[i]:indptr[i+1]] with their column positions in indices[indptr[i]:indptr[i+1]].\nFor example, if indptr[0] = 0 and indptr[1] = 2, then row 0 has non-zero values data[0:2] at columns indices[0:2].\n\n\n\n\nCreating CSR Matrices from Edge Lists\nThe most common way to create network CSR matrices is from edge lists:\n\n# Define our network as an edge list\nedges = [\n    (0, 1), (0, 2),  # Node 0 connections\n    (1, 2), (1, 3),  # Node 1 connections\n    (2, 4),          # Node 2 connections\n    (3, 4)           # Node 3 connections\n]\n\n# Extract source and target nodes\nsources = [edge[0] for edge in edges]\ntargets = [edge[1] for edge in edges]\n\n# For undirected graphs, add reverse edges\nall_sources = sources + targets\nall_targets = targets + sources\n\n# Create data array (all ones for unweighted graph)\ndata_values = np.ones(len(all_sources))\n\n# Create CSR matrix directly from edge list\nn_nodes = 5\ncsr_from_edges = sparse.csr_matrix(\n    (data_values, (all_sources, all_targets)),\n    shape=(n_nodes, n_nodes)\n)\n\nprint(\"CSR from edge list:\")\nprint(csr_from_edges.toarray())\n\nCSR from edge list:\n[[0. 1. 1. 0. 0.]\n [1. 0. 1. 1. 0.]\n [1. 1. 0. 0. 1.]\n [0. 1. 0. 0. 1.]\n [0. 0. 1. 1. 0.]]\n\n\n\n\nEfficient Operations with CSR\nCSR format enables efficient network operations that would be slow with dense matrices:\n\n# Node degrees - sum each row\ndegrees = np.array(csr_matrix.sum(axis=1)).flatten()\nprint(\"Node degrees:\", degrees)\n\n# Find neighbors of node 1\nnode_1_neighbors = csr_matrix.indices[csr_matrix.indptr[1]:csr_matrix.indptr[2]]\nprint(\"Node 1 neighbors:\", node_1_neighbors)\n\n# Matrix multiplication for 2-hop paths\ntwo_hop_matrix = csr_matrix @ csr_matrix\nprint(\"Two-hop connections (shows paths of length 2):\")\nprint(two_hop_matrix.toarray())\n\nNode degrees: [2 3 3 2 2]\nNode 1 neighbors: [0 2 3]\nTwo-hop connections (shows paths of length 2):\n[[2 1 1 1 1]\n [1 3 1 0 2]\n [1 1 3 2 0]\n [1 0 2 2 0]\n [1 2 0 0 2]]\n\n\n\n\nMatrix multiplication: @ is the matrix multiplication operator in SciPy and NumPy. It is equivalent to np.dot.\n\n\nMemory Comparison: Dense vs CSR\nLet’s demonstrate the memory efficiency with a larger, sparser network:\n\n# Create a larger sparse network\nn = 1000\ndensity = 0.01  # Only 1% of edges exist\n\n# Generate random sparse matrix\nnp.random.seed(42)\nlarge_dense = sparse.random(n, n, density=density, format='csr')\n\nprint(f\"Network size: {n} × {n} = {n**2:,} potential edges\")\nprint(f\"Actual edges: {large_dense.nnz:,}\")\nprint(f\"Sparsity: {(1 - large_dense.nnz / (n*n)) * 100:.1f}% zeros\")\nprint(f\"CSR memory usage: ~{(large_dense.nnz * 2 + n) * 4 / 1024:.1f} KB\")\nprint(f\"Dense memory usage: ~{n*n * 4 / 1024:.1f} KB\")\nprint(f\"Memory savings: {((n*n * 4) - (large_dense.nnz * 2 + n) * 4) / (n*n * 4) * 100:.1f}%\")\n\nNetwork size: 1000 × 1000 = 1,000,000 potential edges\nActual edges: 10,000\nSparsity: 99.0% zeros\nCSR memory usage: ~82.0 KB\nDense memory usage: ~3906.2 KB\nMemory savings: 97.9%\n\n\n\n\nCSR for Network Analysis Algorithms\nCSR format integrates seamlessly with our previously defined functions:\n\ndef is_walk_sparse(sequence, csr_matrix):\n    \"\"\"\n    Check if a sequence forms a valid walk using sparse CSR matrix.\n    \"\"\"\n    if len(sequence) &lt; 2:\n        return True\n\n    sequence = np.array(sequence)\n    current_nodes = sequence[:-1]\n    next_nodes = sequence[1:]\n\n    # Use CSR matrix indexing - still works with advanced indexing!\n    edges_exist = csr_matrix[(current_nodes, next_nodes)]\n\n    # Convert sparse result to array and check\n    return np.all(edges_exist == 1)\n\n# Test with our CSR matrix\ntest_walk = [0, 1, 2, 4, 3, 1]\nprint(f\"Walk {test_walk} is valid: {is_walk_sparse(test_walk, csr_matrix)}\")\n\nWalk [0, 1, 2, 4, 3, 1] is valid: True\n\n\n\n\n\n\n\n\nBest Practices\n\n\n\nWhen to use CSR: - Sparse matrices - Row-based operations (computing degrees, finding neighbors) - Matrix-vector multiplication\nWhen to use dense matrices: - Small networks - Dense networks - Frequent random access to individual entries\n\n\n\n\nThere are several different sparse matrix formats such as COO, CSC, and LIL. If you are interested in learning more, you can check out this blog post by Matt Eding. The following video is also a good one to watch.\n\n\n\n\nAdvanced CSR Features\n\n# Submatrix extraction - get connections for subset of nodes\nsubset_nodes = [0, 1, 2]\nsubgraph = csr_matrix[subset_nodes][:, subset_nodes]\nprint(\"Subgraph for nodes [0, 1, 2]:\")\nprint(subgraph.toarray())\n\n# Efficient boolean operations\n# Find nodes with degree &gt; 2\nhigh_degree_nodes = np.where(degrees &gt; 2)[0]\nprint(\"High degree nodes (&gt; 2 connections):\", high_degree_nodes)\n\n# Matrix powers for path counting\npaths_3 = csr_matrix ** 3  # Counts 3-step paths\nprint(\"3-step path counts:\")\nprint(paths_3.toarray())\n\nSubgraph for nodes [0, 1, 2]:\n[[0 1 1]\n [1 0 1]\n [1 1 0]]\nHigh degree nodes (&gt; 2 connections): [1 2]\n3-step path counts:\n[[2 4 4 2 2]\n [4 2 6 5 1]\n [4 6 2 1 5]\n [2 5 1 0 4]\n [2 1 5 4 0]]\n\n\nThe CSR format transforms network analysis from impossible to practical for large-scale networks. By storing only the essential information (non-zero connections), we can analyze networks with millions of nodes and billions of edges on standard hardware—something that would require exabytes of memory with dense matrices!",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Advanced: Sparse Matrices for Large-Scale Networks"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html",
    "href": "m02-small-world/02-coding.html",
    "title": "Efficient Network Representation and Computing Paths",
    "section": "",
    "text": "The Python ecosystem offers several powerful libraries for network analysis, each with distinct strengths:\n\nnetworkx - a beginner-friendly library for network analysis\nigraph - a mature library with a wide range of algorithms\ngraph-tool - specialized for stochastic block models\nscipy - efficient tools for analyzing large networks\n\nThroughout this course, we’ll primarily use igraph, a mature and robust library originally developed for R and later ported to Python. While networkx is by far the most popular library, igraph offers several compelling advantages for serious network analysis: it provides more reliable algorithm implementations (avoiding persistent bugs found in some networkx functions like LFR benchmark and weighted degree assortativity), and its optimized C core delivers the performance needed for large-scale network computations.\n\n\nInstalling igraph\n# Using pip (with plotting support)\npip install igraph cairocffi\n\n# Using conda (recommended)\nconda install -c conda-forge igraph cairocffi\n\n# Alternative plotting backend\npip install igraph pycairo\n\n# For development version\npip install git+https://github.com/igraph/python-igraph.git\nNote: igraph requires compiled C libraries and plotting needs cairocffi or pycairo. Use conda for easier installation.\nFor advanced users comfortable with scipy, the csgraph submodule provides an excellent alternative that leverages one of Python’s most well-tested and optimized libraries. For example, csgraph.shortest_path and csgraph.connected_components offer high-performance implementations.\n\n\n\nLet us create a graph of 4 nodes and 4 edges. Our edge list is given by\n\nedge_list = [(0, 1), (1, 2), (0, 2), (0, 3)]\n\nigraph has an object Graph that stores a graph and provides methods to manipulate and analyze the graph. To create a graph from an edge list, we can use the add_edges method.\n\nimport igraph\n\ng = igraph.Graph() # Create an empty graph\ng.add_vertices(4) # Add 4 vertices\ng.add_edges(edge_list) # Add edges to the graph\n\n# Plot the graph\nigraph.plot(g, bbox=(150, 150), vertex_label=list(range(4)))\n\n\n\n\n\n\n\n\n\n\n\nLet’s compute the paths between nodes 2 and 3.\n\ng.get_all_simple_paths(2, to=3)\n\n[[2, 0, 3], [2, 1, 0, 3]]\n\n\nThis method enumerates all possible simple paths between two nodes. This is OK for small networks but quickly becomes impractical for larger networks, as the number of paths increases exponentially with the size of the network.\nOften, we are interested in the shortest path, which is the path with the smallest number of edges. The shortest path can be computed by using the get_shortest_paths method.\n\ng.get_shortest_paths(2, to=3)\n\n[[2, 0, 3]]\n\n\nNote that there can be multiple shortest paths between two nodes. If we are interested in the “length” instead of the path itself, there is a more efficient function distances.\n\ng.distances(2, 3)\n\n[[2]]\n\n\n\n\n\nIn the simple network above, we can see that for every pair of nodes, we can find a path connecting them. This is the definition of a connected graph. We can check this property for a given graph:\n\ncomponents = g.connected_components()\n\nThe components is a special object called VertexClustering in igraph. It has the following useful functions and attributes:\n\nprint(\"membership: \", components.membership)  # the IDs of the component each node belongs to.\nprint(\"sizes: \", list(components.sizes()))  # the number of nodes in each component.\nprint(\"giant: \", components.giant())  # a subgraph of the largest connected component.\n\nmembership:  [0, 0, 0, 0]\nsizes:  [4]\ngiant:  IGRAPH U--- 4 4 --\n+ edges:\n0--1 1--2 0--2 0--3\n\n\n\n\n\nNow, let us add two nodes that are not connected to the existing graph, and call connected_components again. 🔗➕\nCall get_shortest_paths between the two new nodes in different connected components. 🛣️🔍\nGet the largest connected component. 🌐🏆\n\n\n\n\n\nLet’s extend these ideas about paths and connected components to directed graphs.\n\nedge_list =[(0, 1), (1, 2), (2, 1), (2, 3), (2, 5), (3, 1), (3, 4), (3, 5), (4, 5), (5, 3)]\ng = igraph.Graph(directed=True)\ng.add_vertices(6)\ng.add_edges(edge_list)\nigraph.plot(g, bbox=(250, 250), vertex_label=list(range(6)))\n\n\n\n\n\n\n\n\nIn directed graphs, edges and paths can be one-way. For instance, in our graph, you can go from node 0 to node 3, but not from 3 to 0.\n\nprint(\"From 0 to 3\", g.get_all_simple_paths(0, to=3))\nprint(\"From 3 to 0\", g.get_all_simple_paths(3, to=0))\n\nFrom 0 to 3 [[0, 1, 2, 3], [0, 1, 2, 5, 3]]\nFrom 3 to 0 []\n\n\nThe shortest path from 4 to 1 must take a longer route due to edge directions.\n\ng.get_shortest_paths(4, 1)\n\n[[4, 5, 3, 1]]\n\n\nDirected networks have two kinds of connected components.\n\nStrongly connected components: Strongly connected means that there exists a direct path between every pair of nodes, i.e., that from any node to any other nodes while respecting the edge directionality.\nWeakly connected components: Weakly connected means that there exists a path between every pair of nodes when ignoring the edge directionality.\n\n\nprint(list(g.connected_components(mode=\"strong\")))\nprint(list(g.connected_components(mode=\"weak\")))\n\n[[0], [1, 2, 3, 4, 5]]\n[[0, 1, 2, 3, 4, 5]]",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Efficient Network Representation and Computing Paths"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#convenient-libraries-for-network-analysis",
    "href": "m02-small-world/02-coding.html#convenient-libraries-for-network-analysis",
    "title": "Efficient Network Representation and Computing Paths",
    "section": "",
    "text": "The Python ecosystem offers several powerful libraries for network analysis, each with distinct strengths:\n\nnetworkx - a beginner-friendly library for network analysis\nigraph - a mature library with a wide range of algorithms\ngraph-tool - specialized for stochastic block models\nscipy - efficient tools for analyzing large networks\n\nThroughout this course, we’ll primarily use igraph, a mature and robust library originally developed for R and later ported to Python. While networkx is by far the most popular library, igraph offers several compelling advantages for serious network analysis: it provides more reliable algorithm implementations (avoiding persistent bugs found in some networkx functions like LFR benchmark and weighted degree assortativity), and its optimized C core delivers the performance needed for large-scale network computations.\n\n\nInstalling igraph\n# Using pip (with plotting support)\npip install igraph cairocffi\n\n# Using conda (recommended)\nconda install -c conda-forge igraph cairocffi\n\n# Alternative plotting backend\npip install igraph pycairo\n\n# For development version\npip install git+https://github.com/igraph/python-igraph.git\nNote: igraph requires compiled C libraries and plotting needs cairocffi or pycairo. Use conda for easier installation.\nFor advanced users comfortable with scipy, the csgraph submodule provides an excellent alternative that leverages one of Python’s most well-tested and optimized libraries. For example, csgraph.shortest_path and csgraph.connected_components offer high-performance implementations.\n\n\n\nLet us create a graph of 4 nodes and 4 edges. Our edge list is given by\n\nedge_list = [(0, 1), (1, 2), (0, 2), (0, 3)]\n\nigraph has an object Graph that stores a graph and provides methods to manipulate and analyze the graph. To create a graph from an edge list, we can use the add_edges method.\n\nimport igraph\n\ng = igraph.Graph() # Create an empty graph\ng.add_vertices(4) # Add 4 vertices\ng.add_edges(edge_list) # Add edges to the graph\n\n# Plot the graph\nigraph.plot(g, bbox=(150, 150), vertex_label=list(range(4)))\n\n\n\n\n\n\n\n\n\n\n\nLet’s compute the paths between nodes 2 and 3.\n\ng.get_all_simple_paths(2, to=3)\n\n[[2, 0, 3], [2, 1, 0, 3]]\n\n\nThis method enumerates all possible simple paths between two nodes. This is OK for small networks but quickly becomes impractical for larger networks, as the number of paths increases exponentially with the size of the network.\nOften, we are interested in the shortest path, which is the path with the smallest number of edges. The shortest path can be computed by using the get_shortest_paths method.\n\ng.get_shortest_paths(2, to=3)\n\n[[2, 0, 3]]\n\n\nNote that there can be multiple shortest paths between two nodes. If we are interested in the “length” instead of the path itself, there is a more efficient function distances.\n\ng.distances(2, 3)\n\n[[2]]\n\n\n\n\n\nIn the simple network above, we can see that for every pair of nodes, we can find a path connecting them. This is the definition of a connected graph. We can check this property for a given graph:\n\ncomponents = g.connected_components()\n\nThe components is a special object called VertexClustering in igraph. It has the following useful functions and attributes:\n\nprint(\"membership: \", components.membership)  # the IDs of the component each node belongs to.\nprint(\"sizes: \", list(components.sizes()))  # the number of nodes in each component.\nprint(\"giant: \", components.giant())  # a subgraph of the largest connected component.\n\nmembership:  [0, 0, 0, 0]\nsizes:  [4]\ngiant:  IGRAPH U--- 4 4 --\n+ edges:\n0--1 1--2 0--2 0--3\n\n\n\n\n\nNow, let us add two nodes that are not connected to the existing graph, and call connected_components again. 🔗➕\nCall get_shortest_paths between the two new nodes in different connected components. 🛣️🔍\nGet the largest connected component. 🌐🏆\n\n\n\n\n\nLet’s extend these ideas about paths and connected components to directed graphs.\n\nedge_list =[(0, 1), (1, 2), (2, 1), (2, 3), (2, 5), (3, 1), (3, 4), (3, 5), (4, 5), (5, 3)]\ng = igraph.Graph(directed=True)\ng.add_vertices(6)\ng.add_edges(edge_list)\nigraph.plot(g, bbox=(250, 250), vertex_label=list(range(6)))\n\n\n\n\n\n\n\n\nIn directed graphs, edges and paths can be one-way. For instance, in our graph, you can go from node 0 to node 3, but not from 3 to 0.\n\nprint(\"From 0 to 3\", g.get_all_simple_paths(0, to=3))\nprint(\"From 3 to 0\", g.get_all_simple_paths(3, to=0))\n\nFrom 0 to 3 [[0, 1, 2, 3], [0, 1, 2, 5, 3]]\nFrom 3 to 0 []\n\n\nThe shortest path from 4 to 1 must take a longer route due to edge directions.\n\ng.get_shortest_paths(4, 1)\n\n[[4, 5, 3, 1]]\n\n\nDirected networks have two kinds of connected components.\n\nStrongly connected components: Strongly connected means that there exists a direct path between every pair of nodes, i.e., that from any node to any other nodes while respecting the edge directionality.\nWeakly connected components: Weakly connected means that there exists a path between every pair of nodes when ignoring the edge directionality.\n\n\nprint(list(g.connected_components(mode=\"strong\")))\nprint(list(g.connected_components(mode=\"weak\")))\n\n[[0], [1, 2, 3, 4, 5]]\n[[0, 1, 2, 3, 4, 5]]",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Efficient Network Representation and Computing Paths"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#clustering-coefficients",
    "href": "m02-small-world/02-coding.html#clustering-coefficients",
    "title": "Efficient Network Representation and Computing Paths",
    "section": "2 Clustering Coefficients",
    "text": "2 Clustering Coefficients\nNow let’s see how to compute the clustering coefficients you learned about using igraph.\nLet’s create a more interesting graph to demonstrate clustering:\n\n# Create a graph with some triangles\nedges = [(0, 1), (0, 2), (1, 2),  # Triangle: 0-1-2\n         (0, 3), (3, 4), (3, 5),  # Node 3 with two neighbors (4,5)\n         (4, 5),                  # Triangle: 3-4-5\n         (1, 6), (6, 7)]          # Linear extension\n\ng_cluster = igraph.Graph()\ng_cluster.add_vertices(8)\ng_cluster.add_edges(edges)\n\n# Plot the graph\nigraph.plot(g_cluster, bbox=(300, 200), vertex_label=list(range(8)))\n\n\n\n\n\n\n\n\n\nLocal Clustering Coefficient\nThe transitivity_local_undirected() function computes the local clustering coefficient for each node, returning a list of float values (one per node). It returns NaN for nodes with degree &lt; 2.\n\n# Local clustering coefficient for each node\nlocal_clustering = g_cluster.transitivity_local_undirected()\n\nprint(\"Local clustering coefficients:\")\nfor i, coeff in enumerate(local_clustering):\n    print(f\"Node {i}: {coeff:.3f}\")\n\nLocal clustering coefficients:\nNode 0: 0.333\nNode 1: 0.333\nNode 2: 1.000\nNode 3: 0.333\nNode 4: 1.000\nNode 5: 1.000\nNode 6: 0.000\nNode 7: nan\n\n\n\n\nUnderstanding the values: - 1.0 = All neighbors are connected (perfect local clustering) - 0.0 = No neighbors are connected - NaN = Node has degree &lt; 2 (clustering undefined)\nAnalyze how clustering values relate to actual neighborhood connectivity:\n\n# Analyze clustering for specific nodes\nfor node in range(g_cluster.vcount()):\n    neighbors = g_cluster.neighbors(node)\n    degree = len(neighbors)\n    clustering = local_clustering[node]\n\n    print(f\"Node {node}: degree={degree}, neighbors={neighbors}, clustering={clustering:.3f}\")\n\n    if degree &gt;= 2:\n        # Count actual triangles\n        possible_edges = degree * (degree - 1) // 2\n        actual_edges = 0\n        for i in range(len(neighbors)):\n            for j in range(i + 1, len(neighbors)):\n                if g_cluster.are_adjacent(neighbors[i], neighbors[j]):\n                    actual_edges += 1\n        print(f\"  -&gt; {actual_edges}/{possible_edges} neighbor pairs connected\")\n    print()\n\nNode 0: degree=3, neighbors=[1, 2, 3], clustering=0.333\n  -&gt; 1/3 neighbor pairs connected\n\nNode 1: degree=3, neighbors=[0, 2, 6], clustering=0.333\n  -&gt; 1/3 neighbor pairs connected\n\nNode 2: degree=2, neighbors=[0, 1], clustering=1.000\n  -&gt; 1/1 neighbor pairs connected\n\nNode 3: degree=3, neighbors=[0, 4, 5], clustering=0.333\n  -&gt; 1/3 neighbor pairs connected\n\nNode 4: degree=2, neighbors=[3, 5], clustering=1.000\n  -&gt; 1/1 neighbor pairs connected\n\nNode 5: degree=2, neighbors=[3, 4], clustering=1.000\n  -&gt; 1/1 neighbor pairs connected\n\nNode 6: degree=2, neighbors=[1, 7], clustering=0.000\n  -&gt; 0/1 neighbor pairs connected\n\nNode 7: degree=1, neighbors=[6], clustering=nan\n\n\n\n\n\nAverage Local Clustering\nThe transitivity_avglocal_undirected() function computes the average local clustering coefficient directly, returning a single float value. It automatically ignores NaN values from low-degree nodes.\n\n# Average local clustering (mean of local values)\navg_local_clustering = g_cluster.transitivity_avglocal_undirected()\nprint(f\"Average local clustering: {avg_local_clustering:.3f}\")\n\n# Verify by manual calculation\nimport numpy as np\nmanual_avg = np.nanmean(local_clustering)  # nanmean ignores NaN values\nprint(f\"Manual calculation: {manual_avg:.3f}\")\n\nAverage local clustering: 0.571\nManual calculation: 0.571\n\n\n\n\nGlobal Clustering Coefficient\nThe transitivity_undirected() function computes the global clustering coefficient (transitivity), returning a single float value.\n\n# Global clustering coefficient\nglobal_clustering = g_cluster.transitivity_undirected()\nprint(f\"Global clustering: {global_clustering:.3f}\")\n\n# Let's understand this calculation using supporting functions\n# list_triangles() returns all triangles in the graph\ntriangles_count = len(g_cluster.list_triangles())\nprint(f\"Number of triangles: {triangles_count}\")\nprint(f\"Triangles in graph: {g_cluster.list_triangles()}\")\n\n# Count connected triples (paths of length 2)\n# degree(node) returns the degree of a specific node\ntriples = 0\nfor node in range(g_cluster.vcount()):\n    degree = g_cluster.degree(node)\n    # Each node with degree d contributes d*(d-1)/2 triples\n    if degree &gt;= 2:\n        triples += degree * (degree - 1) // 2\n\nprint(f\"Connected triples: {triples}\")\nprint(f\"Global clustering = 3 * {triangles_count} / {triples} = {3 * triangles_count / triples:.3f}\")\n\nGlobal clustering: 0.462\nNumber of triangles: 2\nTriangles in graph: [(0, 1, 2), (3, 4, 5)]\nConnected triples: 13\nGlobal clustering = 3 * 2 / 13 = 0.462\n\n\n\n\nComparing Different Networks\nWe can use igraph’s built-in network generators: Graph.Full() creates complete graphs, Graph.Erdos_Renyi() creates random graphs, and Graph.Lattice() creates regular lattices.\n\n# Create different network types for comparison\nimport numpy as np\n\n# 1. Complete graph (everyone connected to everyone)\nn_complete = 6\ng_complete = igraph.Graph.Full(n_complete)\n\n# 2. Random graph (Erdős–Rényi)\nn_random = 20\np_random = 0.2\ng_random = igraph.Graph.Erdos_Renyi(n_random, p_random)\n\n# 3. Regular ring lattice (each node connected to k nearest neighbors)\nn_ring = 20\nk_ring = 4\ng_ring = igraph.Graph.Lattice(dim=[n_ring], circular=True, nei=k_ring//2)\n\nnetworks = {\n    \"Complete\": g_complete,\n    \"Random\": g_random,\n    \"Ring Lattice\": g_ring,\n    \"Our Example\": g_cluster\n}\n\nprint(\"Clustering Comparison:\")\nprint(\"-\" * 60)\nprint(f\"{'Network':&lt;15} {'Avg Local':&lt;12} {'Global':&lt;12} {'Nodes':&lt;8} {'Edges':&lt;8}\")\nprint(\"-\" * 60)\n\nfor name, graph in networks.items():\n    avg_local = graph.transitivity_avglocal_undirected()\n    global_clust = graph.transitivity_undirected()\n    nodes = graph.vcount()\n    edges = graph.ecount()\n\n    print(f\"{name:&lt;15} {avg_local:&lt;12.3f} {global_clust:&lt;12.3f} {nodes:&lt;8} {edges:&lt;8}\")\n\nClustering Comparison:\n------------------------------------------------------------\nNetwork         Avg Local    Global       Nodes    Edges   \n------------------------------------------------------------\nComplete        1.000        1.000        6        15      \nRandom          0.178        0.125        20       32      \nRing Lattice    0.500        0.500        20       40      \nOur Example     0.571        0.462        8        9       \n\n\n\n\nSmall-World Network Example\nThe Graph.Watts_Strogatz() function creates small-world networks using the Watts-Strogatz model. The average_path_length() function computes the mean shortest path length across all node pairs.\n\n# Create a small-world network (Watts-Strogatz model)\n# Start with ring lattice, then rewire some edges randomly\nn_ws = 30\nk_ws = 6\np_rewire = 0.1\n\ng_smallworld = igraph.Graph.Watts_Strogatz(dim=1, size=n_ws, nei=k_ws//2, p=p_rewire)\n\nprint(\"Small-World Network Analysis:\")\nprint(f\"Nodes: {g_smallworld.vcount()}, Edges: {g_smallworld.ecount()}\")\nprint(f\"Average local clustering: {g_smallworld.transitivity_avglocal_undirected():.3f}\")\nprint(f\"Global clustering: {g_smallworld.transitivity_undirected():.3f}\")\nprint(f\"Average path length: {g_smallworld.average_path_length():.3f}\")\n\n# Compare with random graph of same size and density\ng_random_compare = igraph.Graph.Erdos_Renyi(n_ws, g_smallworld.ecount() * 2 / (n_ws * (n_ws - 1)))\n\nprint(\"\\nCompared to random graph with same density:\")\nprint(f\"Random avg local clustering: {g_random_compare.transitivity_avglocal_undirected():.3f}\")\nprint(f\"Random global clustering: {g_random_compare.transitivity_undirected():.3f}\")\nprint(f\"Random average path length: {g_random_compare.average_path_length():.3f}\")\n\nSmall-World Network Analysis:\nNodes: 30, Edges: 90\nAverage local clustering: 0.361\nGlobal clustering: 0.319\nAverage path length: 2.149\n\nCompared to random graph with same density:\nRandom avg local clustering: 0.234\nRandom global clustering: 0.202\nRandom average path length: 2.048",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Efficient Network Representation and Computing Paths"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#exercise-02",
    "href": "m02-small-world/02-coding.html#exercise-02",
    "title": "Efficient Network Representation and Computing Paths",
    "section": "3 Exercise 02 🏋️‍♀️💪🧠",
    "text": "3 Exercise 02 🏋️‍♀️💪🧠\nLet’s compute the average path length of a network from pre-existing data and check if how long on average it takes to go from any node to any other node.\n\nSelect a network of your choice from Netzschleuder. For convenience, choose a network of nodes less than 5000.\nDownload the csv version of the data by clicking something like “3KiB” under csv column.\nUnzip the file and find “edges.csv”, open it with a text editor to familiarize yourself with the format.\nLoad the data using pandas.\nGet the source and target nodes from the data to create an edge list.\nConstruct a graph from the edge list, either using igraph or scipy.\nCompute the average path length\n\nHint: Finding all shortest paths is a qubic time operation with respect to the number of nodes, or simply put, it takes a long time to compute. So compute the “estimate” by sampling many pairs of nodes uniformly at random and computing the average path length.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Efficient Network Representation and Computing Paths"
    ]
  },
  {
    "objectID": "m02-small-world/appendix.html",
    "href": "m02-small-world/appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "CSR format is implemented in scipy. This consists of three arrays called indptr, indices, and data. For example,\n\nimport networkx as nx\nfrom scipy import sparse\n\nG = nx.karate_club_graph()\nA = sparse.csr_matrix(nx.adjacency_matrix(G))\n\nprint(\"A.indices:\", A.indices[:5])\nprint(\"A.indptr:\", A.indptr[:5])\nprint(\"A.data:\", A.data[:5])\n\nWe will walk you through what these arrays mean, how they are generated, and how we can leverage them for efficient computations.\n\n\nLet’s walk you through how to store an example adjacency matrix in Compressed Sparse Row (CSR) format. Our example adjacency matrix is as follows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n1\n\n\n2\n\n1\n\n1\n\n\n\n\n\n\n1\n\n\n3\n\n\n1\n\n1\n1\n1\n\n\n\n\n\n\n4\n\n\n\n1\n\n\n\n1\n\n\n\n\n\n5\n\n\n\n1\n\n\n\n\n\n\n\n\n\n6\n\n\n\n1\n\n\n\n\n1\n1\n\n\n\n7\n\n\n\n\n1\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n9\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n10\n1\n1\n1\n\n\n\n\n\n1\n1\n\n\n\n\n\nWe will first create adjacency list, which is a dictionary consisting of the row IDs and column IDs for the non-zero entries in the adjacency matrix.\n\n\n\\{\\text{Row ID}: (\\text{Column ID}, \\text{Value})\\}\n\n\nConcretely, in Python,\n\nadj_list = {\n  0:[(10,1)],\n  1:[(2,1), (10, 1)],\n  2:[(1,1), (3,1), (10, 1)],\n  3:[(2,1), (4,1), (5,1), (6,1)],\n  #...\n}\n\nCSR format is a concatenation of the keys and values of the adjacency list, respectively. The CSR format has a concatenated array of the values, one for column IDs and one for the values, called indices and data, respectively.\n\nimport numpy as np\n\nindices = np.array([vv[0] for k, v in adj_list.items() for vv in v])\nindices\n\n\ndata = np.array([vv[1] for k, v in adj_list.items() for vv in v])\ndata\n\nAdditionally, the CSR format has another array called indptr, which stores the Row IDs of the non-zero entries in the adjacency matrix. This indptr array has a value such that indptr[i] is the first index of indices that corresponds to the i-th row of the adjacency matrix. This can be generated by\n\nindptr = np.cumsum([0] + [len(adj_list[i]) for i in range(len(adj_list))])\nindptr\n\nwhere we added 0 at the beginning of the array to represent the first non-zero entry in the first row. The first row ends at index len(adj_list[0])-1, and the second row starts at index len(adj_list[0]) and ends at index len(adj_list[0])+len(adj_list[1])-1, and so on.\nNow we have three compressed vectors indptr, indices, and data, that together form the CSR format for the adjacency matrix.\n\n\n\nThe key advantage of the CSR representation is the memory efficiency. But you can leverage the CSR format for more efficient computations, if you know the semantics of indptr, indices, and data arrays.\nFor instance, one can compute the degree of a node by using\n\nnode = 1\ndegree = indptr[node+1] - indptr[node]\ndegree\n\nLet us break down the above code. - indptr[node] is the first index of the indices array that corresponds to the node-th row of the adjacency matrix. - indptr[node+1] is the first index of the indices array that corresponds to the (node+1)-th row of the adjacency matrix. - Thus, indptr[node+1] - indptr[node] is the number of non-zero entries in the node-th row of the adjacency matrix, which is the degree of the node-th node.\nUsing indices, it is easy to identify the neighbors of a given node by using\n\nneighbors = indices[indptr[node]:indptr[node+1]]\nneighbors\n\nwhere indices[indptr[node]:indptr[node+1]] is the corresponding column IDs of the non-zero entries in the node-th row of the adjacency matrix, which corresponds to the node IDs connected to the node-th node.\nThe edge weights to the neighbors can be obtained by using\n\nedge_weights = data[indptr[node]:indptr[node+1]]\nedge_weights"
  },
  {
    "objectID": "m02-small-world/appendix.html#compressed-sparse-row-csr-format",
    "href": "m02-small-world/appendix.html#compressed-sparse-row-csr-format",
    "title": "Appendix",
    "section": "",
    "text": "CSR format is implemented in scipy. This consists of three arrays called indptr, indices, and data. For example,\n\nimport networkx as nx\nfrom scipy import sparse\n\nG = nx.karate_club_graph()\nA = sparse.csr_matrix(nx.adjacency_matrix(G))\n\nprint(\"A.indices:\", A.indices[:5])\nprint(\"A.indptr:\", A.indptr[:5])\nprint(\"A.data:\", A.data[:5])\n\nWe will walk you through what these arrays mean, how they are generated, and how we can leverage them for efficient computations.\n\n\nLet’s walk you through how to store an example adjacency matrix in Compressed Sparse Row (CSR) format. Our example adjacency matrix is as follows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n1\n\n\n2\n\n1\n\n1\n\n\n\n\n\n\n1\n\n\n3\n\n\n1\n\n1\n1\n1\n\n\n\n\n\n\n4\n\n\n\n1\n\n\n\n1\n\n\n\n\n\n5\n\n\n\n1\n\n\n\n\n\n\n\n\n\n6\n\n\n\n1\n\n\n\n\n1\n1\n\n\n\n7\n\n\n\n\n1\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n9\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n10\n1\n1\n1\n\n\n\n\n\n1\n1\n\n\n\n\n\nWe will first create adjacency list, which is a dictionary consisting of the row IDs and column IDs for the non-zero entries in the adjacency matrix.\n\n\n\\{\\text{Row ID}: (\\text{Column ID}, \\text{Value})\\}\n\n\nConcretely, in Python,\n\nadj_list = {\n  0:[(10,1)],\n  1:[(2,1), (10, 1)],\n  2:[(1,1), (3,1), (10, 1)],\n  3:[(2,1), (4,1), (5,1), (6,1)],\n  #...\n}\n\nCSR format is a concatenation of the keys and values of the adjacency list, respectively. The CSR format has a concatenated array of the values, one for column IDs and one for the values, called indices and data, respectively.\n\nimport numpy as np\n\nindices = np.array([vv[0] for k, v in adj_list.items() for vv in v])\nindices\n\n\ndata = np.array([vv[1] for k, v in adj_list.items() for vv in v])\ndata\n\nAdditionally, the CSR format has another array called indptr, which stores the Row IDs of the non-zero entries in the adjacency matrix. This indptr array has a value such that indptr[i] is the first index of indices that corresponds to the i-th row of the adjacency matrix. This can be generated by\n\nindptr = np.cumsum([0] + [len(adj_list[i]) for i in range(len(adj_list))])\nindptr\n\nwhere we added 0 at the beginning of the array to represent the first non-zero entry in the first row. The first row ends at index len(adj_list[0])-1, and the second row starts at index len(adj_list[0]) and ends at index len(adj_list[0])+len(adj_list[1])-1, and so on.\nNow we have three compressed vectors indptr, indices, and data, that together form the CSR format for the adjacency matrix.\n\n\n\nThe key advantage of the CSR representation is the memory efficiency. But you can leverage the CSR format for more efficient computations, if you know the semantics of indptr, indices, and data arrays.\nFor instance, one can compute the degree of a node by using\n\nnode = 1\ndegree = indptr[node+1] - indptr[node]\ndegree\n\nLet us break down the above code. - indptr[node] is the first index of the indices array that corresponds to the node-th row of the adjacency matrix. - indptr[node+1] is the first index of the indices array that corresponds to the (node+1)-th row of the adjacency matrix. - Thus, indptr[node+1] - indptr[node] is the number of non-zero entries in the node-th row of the adjacency matrix, which is the degree of the node-th node.\nUsing indices, it is easy to identify the neighbors of a given node by using\n\nneighbors = indices[indptr[node]:indptr[node+1]]\nneighbors\n\nwhere indices[indptr[node]:indptr[node+1]] is the corresponding column IDs of the non-zero entries in the node-th row of the adjacency matrix, which corresponds to the node IDs connected to the node-th node.\nThe edge weights to the neighbors can be obtained by using\n\nedge_weights = data[indptr[node]:indptr[node+1]]\nedge_weights"
  },
  {
    "objectID": "m03-robustness/02-coding.html",
    "href": "m03-robustness/02-coding.html",
    "title": "Coding - Network Robustness Analysis",
    "section": "",
    "text": "Network robustness analysis focuses on understanding how networks behave when nodes or edges are removed, whether through random failures or targeted attacks. The Python ecosystem provides powerful tools for analyzing these phenomena:\n\nigraph - comprehensive network analysis with robust algorithms for connectivity analysis\nscipy.sparse.csgraph - efficient connected component algorithms for large networks\nnetworkx - alternative approach with different robustness metrics\n\nThroughout this analysis, we’ll use igraph for its reliable implementations and performance advantages when working with connectivity measures and component analysis.\n\n\nInstalling igraph\n# Using pip (with plotting support)\npip install igraph cairocffi\n\n# Using conda (recommended)\nconda install -c conda-forge igraph cairocffi\n\n# Alternative plotting backend\npip install igraph pycairo\nNote: igraph requires compiled C libraries and plotting needs cairocffi or pycairo. Use conda for easier installation.\nFor advanced users comfortable with scipy, the csgraph submodule provides an excellent alternative that leverages one of Python’s most well-tested and optimized libraries. For example, csgraph.shortest_path and csgraph.connected_components offer high-performance implementations.\n\n\nLet’s start by creating a network using the famous Zachary’s karate club, which provides an excellent testbed for robustness analysis:\n\nimport igraph\n\n# Create the famous Zachary's karate club network\ng = igraph.Graph.Famous('Zachary')\n\n# Visualize the network\nigraph.plot(g, bbox=(300, 200), vertex_size=20, vertex_label=list(range(g.vcount())))\n\n\n\n\n\n\n\n\n\n\nAbout Zachary’s Karate Club\nZachary’s karate club is a famous network of 34 members of a karate club documenting friendships between members. The network is undirected and originally unweighted, making it an excellent testbed for robustness analysis.\n\n\n\nBefore analyzing robustness, let’s understand how to measure network connectivity. In network analysis, we often need to identify connected components:\n\ncomponents = g.connected_components()\nprint(\"Number of components:\", len(components))\nprint(\"Component sizes:\", list(components.sizes()))\nprint(\"Largest component size:\", components.giant().vcount())\n\nNumber of components: 1\nComponent sizes: [34]\nLargest component size: 34\n\n\nThe connectivity of a network is typically measured as the fraction of nodes in the largest connected component:\n\nimport numpy as np\n\ndef network_connectivity(graph, original_size=None):\n    \"\"\"Calculate network connectivity as fraction of nodes in largest component\"\"\"\n    if original_size is None:\n        original_size = graph.vcount()\n\n    if graph.vcount() == 0:\n        return 0.0\n\n    components = graph.connected_components()\n    return max(components.sizes()) / original_size\n\n# Test the function\nconnectivity = network_connectivity(g)\nprint(f\"Current connectivity: {connectivity:.3f}\")\n\nCurrent connectivity: 1.000",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#key-robustness-concepts-in-igraph",
    "href": "m03-robustness/02-coding.html#key-robustness-concepts-in-igraph",
    "title": "Coding - Network Robustness Analysis",
    "section": "",
    "text": "Network robustness analysis focuses on understanding how networks behave when nodes or edges are removed, whether through random failures or targeted attacks. The Python ecosystem provides powerful tools for analyzing these phenomena:\n\nigraph - comprehensive network analysis with robust algorithms for connectivity analysis\nscipy.sparse.csgraph - efficient connected component algorithms for large networks\nnetworkx - alternative approach with different robustness metrics\n\nThroughout this analysis, we’ll use igraph for its reliable implementations and performance advantages when working with connectivity measures and component analysis.\n\n\nInstalling igraph\n# Using pip (with plotting support)\npip install igraph cairocffi\n\n# Using conda (recommended)\nconda install -c conda-forge igraph cairocffi\n\n# Alternative plotting backend\npip install igraph pycairo\nNote: igraph requires compiled C libraries and plotting needs cairocffi or pycairo. Use conda for easier installation.\nFor advanced users comfortable with scipy, the csgraph submodule provides an excellent alternative that leverages one of Python’s most well-tested and optimized libraries. For example, csgraph.shortest_path and csgraph.connected_components offer high-performance implementations.\n\n\nLet’s start by creating a network using the famous Zachary’s karate club, which provides an excellent testbed for robustness analysis:\n\nimport igraph\n\n# Create the famous Zachary's karate club network\ng = igraph.Graph.Famous('Zachary')\n\n# Visualize the network\nigraph.plot(g, bbox=(300, 200), vertex_size=20, vertex_label=list(range(g.vcount())))\n\n\n\n\n\n\n\n\n\n\nAbout Zachary’s Karate Club\nZachary’s karate club is a famous network of 34 members of a karate club documenting friendships between members. The network is undirected and originally unweighted, making it an excellent testbed for robustness analysis.\n\n\n\nBefore analyzing robustness, let’s understand how to measure network connectivity. In network analysis, we often need to identify connected components:\n\ncomponents = g.connected_components()\nprint(\"Number of components:\", len(components))\nprint(\"Component sizes:\", list(components.sizes()))\nprint(\"Largest component size:\", components.giant().vcount())\n\nNumber of components: 1\nComponent sizes: [34]\nLargest component size: 34\n\n\nThe connectivity of a network is typically measured as the fraction of nodes in the largest connected component:\n\nimport numpy as np\n\ndef network_connectivity(graph, original_size=None):\n    \"\"\"Calculate network connectivity as fraction of nodes in largest component\"\"\"\n    if original_size is None:\n        original_size = graph.vcount()\n\n    if graph.vcount() == 0:\n        return 0.0\n\n    components = graph.connected_components()\n    return max(components.sizes()) / original_size\n\n# Test the function\nconnectivity = network_connectivity(g)\nprint(f\"Current connectivity: {connectivity:.3f}\")\n\nCurrent connectivity: 1.000",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#network-robustness-analysis",
    "href": "m03-robustness/02-coding.html#network-robustness-analysis",
    "title": "Coding - Network Robustness Analysis",
    "section": "2 Network Robustness Analysis",
    "text": "2 Network Robustness Analysis\nNow let’s explore how networks behave when nodes fail or are attacked systematically.\n  \n\n# If you are using Google Colab, uncomment the following line to install igraph\n# !sudo apt install libcairo2-dev pkg-config python3-dev\n# !pip install pycairo cairocffi\n# !pip install igraph\n\n\nRandom Attack Simulation\nRandom attacks simulate random failures where nodes are removed with equal probability. Let’s implement a systematic approach:\n\nimport pandas as pd\n\ndef simulate_random_attack(graph):\n    \"\"\"Simulate random node removal and measure connectivity\"\"\"\n    g_test = graph.copy()\n    original_size = g_test.vcount()\n    results = []\n\n    for i in range(original_size - 1):  # Remove all but one node\n        # Randomly select and remove a node\n        node_idx = np.random.choice(g_test.vs.indices)\n        g_test.delete_vertices(node_idx)\n\n        # Measure connectivity\n        connectivity = network_connectivity(g_test, original_size)\n\n        # Store results\n        results.append({\n            \"connectivity\": connectivity,\n            \"frac_nodes_removed\": (i + 1) / original_size,\n        })\n\n    return pd.DataFrame(results)\n\n# Run the simulation\ndf_random = simulate_random_attack(g)\n\nLet’s visualize the robustness profile:\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style='white', font_scale=1.2)\nsns.set_style('ticks')\n\nfig, ax = plt.subplots(figsize=(6, 5))\nax.plot(df_random[\"frac_nodes_removed\"],\n        df_random[\"connectivity\"],\n        'o-', linewidth=2, markersize=4, label=\"Random attack\")\nax.set_xlabel(\"Proportion of nodes removed\")\nax.set_ylabel(\"Connectivity\")\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nsns.despine()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTargeted Attack Simulation\nTargeted attacks remove nodes based on specific criteria, such as degree centrality. High-degree nodes (hubs) often play crucial roles in network connectivity:\n\ndef simulate_targeted_attack(graph, criterion=\"degree\"):\n    \"\"\"Simulate targeted node removal based on specified criterion\"\"\"\n    g_test = graph.copy()\n    original_size = g_test.vcount()\n    results = []\n\n    for i in range(original_size - 1):\n        # Remove node with highest degree\n        if criterion == \"degree\":\n            degrees = g_test.degree()\n            node_idx = g_test.vs.indices[np.argmax(degrees)]\n\n        g_test.delete_vertices(node_idx)\n\n        # Measure connectivity\n        connectivity = network_connectivity(g_test, original_size)\n\n        # Store results\n        results.append({\n            \"connectivity\": connectivity,\n            \"frac_nodes_removed\": (i + 1) / original_size,\n        })\n\n    return pd.DataFrame(results)\n\n# Run targeted attack simulation\ndf_targeted = simulate_targeted_attack(g)\n\nNow let’s compare both attack strategies:\n\nfig, ax = plt.subplots(figsize=(7, 5))\n\nax.plot(df_random[\"frac_nodes_removed\"],\n        df_random[\"connectivity\"],\n        'o-', linewidth=2, markersize=4, label=\"Random attack\", alpha=0.8)\n\nax.plot(df_targeted[\"frac_nodes_removed\"],\n        df_targeted[\"connectivity\"],\n        's-', linewidth=2, markersize=4, label=\"Targeted attack\", alpha=0.8)\n\nax.set_xlabel(\"Proportion of nodes removed\")\nax.set_ylabel(\"Connectivity\")\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nax.legend(frameon=False)\nsns.despine()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe comparison reveals a key insight: while networks are often robust against random failures, they can be vulnerable to targeted attacks on high-degree nodes.\n\nExercise 01 🏋️‍♀️💪🧠\n\nExamine the degree distribution of the Zachary network and identify the nodes with highest degrees. 📊🔍\nCreate a visualization showing which nodes are removed first in the targeted attack. 🎯📈\nTry implementing a targeted attack based on betweenness centrality instead of degree. How does it compare? 🌐⚡",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#minimum-spanning-tree-analysis",
    "href": "m03-robustness/02-coding.html#minimum-spanning-tree-analysis",
    "title": "Coding - Network Robustness Analysis",
    "section": "3 Minimum Spanning Tree Analysis",
    "text": "3 Minimum Spanning Tree Analysis\nUnderstanding network structure through minimum spanning trees can provide insights into network robustness. Let’s explore this concept:\n\nimport random\n\n# Create a weighted version of our network for MST analysis\ng_weighted = g.copy()\ng_weighted.es[\"weight\"] = [random.randint(1, 10) for _ in g_weighted.es]\n\n# Visualize weighted network\nigraph.plot(g_weighted, bbox=(300, 200),\n           edge_width=[w/3 for w in g_weighted.es[\"weight\"]],\n           vertex_label=list(range(g_weighted.vcount())))\n\n\n\n\n\n\n\n\n\nComputing the Minimum Spanning Tree\nThe minimum spanning tree represents the most efficient way to connect all nodes:\n\n# Find minimum spanning tree\nmst = g_weighted.spanning_tree(weights=g_weighted.es[\"weight\"])\n\n# Visualize the MST\nigraph.plot(mst, bbox=(300, 200),\n           edge_width=[w/3 for w in mst.es[\"weight\"]],\n           vertex_label=list(range(mst.vcount())))\n\n\n\n\n\n\n\n\nThe MST identifies the most critical connections for maintaining network connectivity, which relates directly to robustness analysis.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#percolation-theory",
    "href": "m03-robustness/02-coding.html#percolation-theory",
    "title": "Coding - Network Robustness Analysis",
    "section": "4 Percolation Theory",
    "text": "4 Percolation Theory\nNetwork robustness can be viewed as the inverse process of percolation. In percolation theory, we study how connectivity emerges as we randomly add nodes to a network.\n\ndef percolation_simulation(lattice_size=100, p_values=None):\n    \"\"\"Simulate percolation on a 2D lattice\"\"\"\n    if p_values is None:\n        p_values = np.linspace(0, 1, 20)\n\n    # Create 2D lattice\n    g_lattice = igraph.Graph.Lattice([lattice_size, lattice_size],\n                                    nei=1, directed=False,\n                                    mutual=False, circular=False)\n\n    results = []\n    for p in p_values:\n        # Randomly keep nodes with probability p\n        keep_nodes = np.where(np.random.rand(g_lattice.vcount()) &lt; p)[0]\n\n        if len(keep_nodes) &gt; 0:\n            g_sub = g_lattice.subgraph(keep_nodes)\n            largest_size = network_connectivity(g_sub, g_lattice.vcount())\n        else:\n            largest_size = 0\n\n        results.append({\"p\": p, \"largest_component_fraction\": largest_size})\n\n    return pd.DataFrame(results)\n\n# Run percolation simulation\ndf_percolation = percolation_simulation(lattice_size=50)\n\n\nfig, ax = plt.subplots(figsize=(6, 5))\n\nax.plot(df_percolation[\"p\"],\n        df_percolation[\"largest_component_fraction\"],\n        'o-', linewidth=2, markersize=4)\n\n# Mark theoretical critical point for 2D lattice\ncritical_p = 0.593  # Theoretical value for 2D square lattice\nax.axvline(x=critical_p, color='red', linestyle='--', alpha=0.7,\n           label=f'Critical point (p_c ≈ {critical_p})')\n\nax.set_xlabel(\"Probability (p)\")\nax.set_ylabel(\"Fractional largest component size\")\nax.set_title(\"Percolation on 2D Lattice\")\nax.legend(frameon=False)\nsns.despine()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPhase Transition\nThe sharp transition around p_c demonstrates a phase transition - a sudden change from a disconnected to connected state as we cross the critical threshold.\n\nWant to see this in action? 🌟 Check out this interactive simulation.\nPlay around with it and watch how the puddles grow and connect. 🌊\n\n[Bernoulli Percolation Simulation 🌐](https://visualize-it.github.io/bernoulli_percolation/simulation.html) 🔗",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#exercise-02",
    "href": "m03-robustness/02-coding.html#exercise-02",
    "title": "Coding - Network Robustness Analysis",
    "section": "5 Exercise 02 🏋️‍♀️",
    "text": "5 Exercise 02 🏋️‍♀️\nLet’s explore robustness in real-world networks by analyzing data from Netzschleuder.\n\nSelect a network with fewer than 5000 nodes from Netzschleuder\nDownload the CSV version and load it using pandas\nCreate the network using igraph\nCompare random vs. targeted attack robustness profiles\nCalculate theoretical predictions using the Molloy-Reed criterion\n\nHint: For large networks, consider sampling node pairs to estimate average path length rather than computing all pairwise distances.\n\n# Your implementation here",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#real-world-case-study-airport-network",
    "href": "m03-robustness/02-coding.html#real-world-case-study-airport-network",
    "title": "Coding - Network Robustness Analysis",
    "section": "6 Real-World Case Study: Airport Network",
    "text": "6 Real-World Case Study: Airport Network\nLet’s analyze a more complex real-world network to see robustness principles in action:\n\n# Load airport network data\ndf_airports = pd.read_csv(\"https://raw.githubusercontent.com/skojaku/core-periphery-detection/master/data/edge-table-airport.csv\")\n\n# Process edge data\nedges = df_airports[[\"source\", \"target\"]].to_numpy()\nedges = np.unique(edges.reshape(-1), return_inverse=True)[1]\nedges = edges.reshape(-1, 2)\n\n# Create network\ng_airports = igraph.Graph()\ng_airports.add_vertices(np.max(edges) + 1)\ng_airports.add_edges([tuple(edge) for edge in edges])\n\nprint(f\"Airport network: {g_airports.vcount()} nodes, {g_airports.ecount()} edges\")\n\nAirport network: 2905 nodes, 30442 edges\n\n\n\nTheoretical Prediction using Molloy-Reed Criterion\nThe Molloy-Reed criterion provides a theoretical framework for predicting network robustness:\n\n# Calculate degree statistics\ndegrees = np.array(g_airports.degree())\nk_mean = np.mean(degrees)\nk_squared_mean = np.mean(degrees**2)\n\n# Molloy-Reed criterion: kappa_0 &gt; 2 for giant component\nkappa_0 = k_squared_mean / k_mean\nprint(f\"κ₀ = &lt;k²&gt;/&lt;k&gt; = {kappa_0:.3f}\")\n\n# Critical fraction for network breakdown\nf_c = 1 - 1 / (kappa_0 - 1)\nprint(f\"Predicted critical fraction f_c = {f_c:.3f}\")\n\nκ₀ = &lt;k²&gt;/&lt;k&gt; = 110.937\nPredicted critical fraction f_c = 0.991\n\n\nThe high f_c value indicates the airport network is extremely robust to random failures, maintaining connectivity until almost all nodes are removed.\n\n# Simulate and visualize (using subset for efficiency)\nn_samples = min(500, g_airports.vcount() - 1)  # Sample for computational efficiency\nsample_indices = np.linspace(0, g_airports.vcount() - 2, n_samples, dtype=int)\n\ndf_airport_robustness = simulate_random_attack(g_airports)\ndf_airport_sample = df_airport_robustness.iloc[sample_indices]\n\nfig, ax = plt.subplots(figsize=(6, 5))\nax.plot(df_airport_sample[\"frac_nodes_removed\"],\n        df_airport_sample[\"connectivity\"],\n        'o-', linewidth=2, markersize=3, alpha=0.8)\n\n# Add theoretical prediction\nax.axvline(x=f_c, color='red', linestyle='--', alpha=0.7,\n           label=f'Theoretical f_c = {f_c:.3f}')\n\n# Add diagonal reference line\nax.plot([0, 1], [1, 0], 'gray', linestyle=':', alpha=0.5, label='Linear decline')\n\nax.set_xlabel(\"Proportion of nodes removed\")\nax.set_ylabel(\"Connectivity\")\nax.set_title(\"Airport Network Robustness\")\nax.legend(frameon=False)\nsns.despine()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nKey Design Principles for Robust Networks\nBased on percolation theory and empirical analysis, robust networks share several characteristics:\n\nDegree heterogeneity: Networks with diverse degree distributions (high κ₀) maintain connectivity better\nDistributed hubs: Resilience improves when connectivity doesn’t depend on single critical nodes\nRedundant pathways: Multiple paths between node pairs provide backup routes when primary connections fail\n\nUnderstanding these principles helps in designing resilient infrastructure networks, from transportation systems to communication networks.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m04-node-degree/01-concepts.html",
    "href": "m04-node-degree/01-concepts.html",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "",
    "text": "What you’ll learn in this module\n\n\n\nThis module introduces a single, powerful idea — the node’s degree — and shows how that simple number reveals a network’s structure and behavior.\nYou’ll learn:\n\nWhat degree and degree distribution mean and how to read them.\nHow to visualize degree distributions so underlying patterns become clear.\nThe counterintuitive Friendship Paradox and the notion of degree bias.\nPractical consequences for network robustness, spreading processes, and targeted interventions.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#node-degree",
    "href": "m04-node-degree/01-concepts.html#node-degree",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "1 Node degree",
    "text": "1 Node degree\nLet’s talk about node degree. A node’s degree is the number of edges touching it. Here we focus on why that simple count matters.\nAt the level of an individual node, degree measures visibility and influence: high-degree nodes see and can spread information (or infection) quickly; low-degree nodes have limited reach. At the level of a network, the collection of degrees reveals how centralized or evenly distributed connectivity is — and that shape drives many collective behaviors.\n\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nA (3)\n\n\n\nB\n\nB (1)\n\n\n\nA--B\n\n\n\n\nC\n\nC (1)\n\n\n\nA--C\n\n\n\n\nD\n\nD (1)\n\n\n\nA--D\n\n\n\n\n\n\n\nFigure 1: A small example graph — node degrees are shown as labels\n\n\n\n\n\nThe tiny graph above makes the point visually: node A has degree 3 (it connects to three nodes) while B, C, and D each have degree 1. That asymmetry — a mix of hubs and leaves — is common in real networks and underlies many of the phenomena we study.\n\nDegree distribution\nShift your attention from single nodes to the whole network by asking: how common is each degree? The degree distribution answers that question — it lists the fraction of nodes with degree 1, degree 2, degree 3, and so on. Reading this distribution quickly tells you whether connectivity is evenly spread or concentrated in a few nodes.\nWhy does that summary matter in practice? Because the distribution shapes how networks behave. We have already seen this in the previous modules:\n\nRobustness vs. fragility — Networks with heavy-tailed degree distributions tolerate random node loss (most removals hit low-degree nodes) but are fragile to targeted hub removal, which can fragment the network.\nSmall-world effects — If a few hubs dominate the degree distribution, they act as shortcuts that dramatically reduce distances between nodes.\n\nWe will add an additional interesting example, called the Friendship Paradox, in the next section.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#the-friendship-paradox",
    "href": "m04-node-degree/01-concepts.html#the-friendship-paradox",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "2 The Friendship Paradox",
    "text": "2 The Friendship Paradox\nThe Friendship Paradox (Scott Feld, 1991) states that your friends have more friends than you do on average. This is not an insult — it is a statistical consequence of how connections are counted in most social networks. This counterintuitive phenomenon emerges from the mathematical properties of networks and has profound implications for how we understand social structures, information flow, and even public health interventions.\n\n\n\n\nAt its core, the Friendship Paradox reveals a fundamental asymmetry in social networks: high-degree nodes (popular individuals) are more likely to be counted as friends by others, while low-degree nodes are less likely to be referenced. This creates a sampling bias where the average degree of your friends tends to be higher than your own degree, and indeed higher than the average degree of the entire network.\n\n\n\n\n\n\n\n\nG\n\n\n\nAlex\n\nAlex\n(1)\n\n\n\nBob\n\nBob\n(3)\n\n\n\nAlex--Bob\n\n\n\n\nCarol\n\nCarol\n(1)\n\n\n\nCarol--Bob\n\n\n\n\nDavid\n\nDavid\n(1)\n\n\n\nDavid--Bob\n\n\n\n\n\n\n\nFigure 2: Friendship paradox example — node labels show degrees\n\n\n\n\n\nThe network diagram above illustrates the Friendship Paradox with a simple four-node network. The average degree in this network is (1+3+1+1)/4 = 1.5, but when we look at the average degree of each person’s friends, we get a different story.\nLet us list all the friendship ties in adjacency list format, along with the degree of each node in parentheses:\n\nBob: Alex (1), Carol (1), David (1)\nAlex: Bob (3)\nCarol: Bob (3)\nDavid: Bob (3)\n\nNow, let’s compute the average degree of a friend.\n\n\\frac{\\overbrace{1 + 1 + 1}^{\\text{Bob's friends}} + \\overbrace{3 + 3 + 3}^{\\text{The friends of Alex, Carol, and David}}}{\\underbrace{6}_{\\text{\\# of friends}}} = 2\n\nwhich confirms the friendship paradox, i.e., a someone’s friend tends to have more friends than that someone.\nWhy this produces the paradox? Notice that high-degree nodes like Bob are referenced multiple times when computing the average degree of a friend. This is because Bob are a friend of many friends! On the other hand, low-degree nodes are referenced less often. This bias towards high-degree nodes is what makes the friendship paradox a paradox.\nBeyond a fun trivia, the friendship paradox has practical implications. In social networks, most people will find that their friends have more friends than they do, not because they’re unpopular, but because of this statistical bias. The same principle applies to many other networks: in scientific collaboration networks, your coauthors tend to have more collaborators than you do; in the internet, the websites you link to tend to have more incoming links than your website.\n\n\n\n\n\n\nTry it yourself\n\n\n\n\nChallenge: Can you build a network where your friends always have more friends than you? Test ideas with this interactive Friendship Paradox Game 🎮.\n\n\n\n\nThe friendship paradox in public health\nThis observation has profound practical consequences, especially in public health and epidemiology. To slow an epidemic you can use the friendship paradox to find better targets, called acquaintance immunization (Cohen, Havlin, and ben-Avraham 2003), which goes as follows:\n\nPick a random sample of individuals.\nAsk each to nominate one friend.\nVaccinate the nominated friends (who tend to be better connected).\n\nThis works because when people nominate a friend, they’re more likely to name someone with many social connections. By targeting these nominated friends, public health officials can reach the most connected individuals in a network without needing to map the entire social structure.\n\n\nThe acquaintance immunization does not require the knowledge of the entire network structure, which makes it a practical and effective way to slow an epidemic.\n\n\n\n\n\n\nPut the idea to the test\n\n\n\nChallenge: Can you control an outbreak by vaccinating people chosen via the friendship paradox? Try to outperform random vaccination in this Vaccination Game 🎮.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#visualizing-degree-distributions",
    "href": "m04-node-degree/01-concepts.html#visualizing-degree-distributions",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "3 Visualizing degree distributions",
    "text": "3 Visualizing degree distributions\nThe very first step to understand degree distribution is to visualize it. But visualizing degree distribution is not as simple as it seems. Take for example, the following histogram of a degree distribution.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 3: A histogram of a scale-free degree distribution on a linear scale. It’s nearly impossible to see the structure of the tail.\n\n\n\n\n\nThis is a plot you would often see for a real-world network. Most nodes have a very small degree, so they are all crammed into the first few bins on the left. The long tail of high-degree nodes—which hold most edges in the network—is invisible because there are very few of them. This is a fat-tailed distribution, which is a common characteristics of real-world networks.\nTo solve this, we can plot the same histogram but with both axes on a logarithmic scale. This is called a log–log plot.\n\n\n\n\n\n\n\n\nFigure 4: The same degree histogram on a log-log scale. The structure becomes much clearer, revealing a roughly linear relationship.\n\n\n\n\n\nA log–log plot (Figure 4) makes both low- and high-degree nodes visible, revealing heavy-tailed patterns. If the tail is roughly linear, it suggests a power-law degree distribution: the probability a node has degree k falls off as k^{-\\gamma}. The slope of the line shows how quickly high-degree nodes become rare. A steeper slope (higher \\gamma) means fewer hubs; a shallower slope means more. Interestingly, many real-world networks exhibit power-law(-like) degree distributions, whether they are biological, technical, or social. This universality of power-law degree distributions is one of the foundational insights of Network Science.\n\n\nBarabási and Albert (1999) (Barabási and Albert 1999) reported the universality of power-law degree distribution in real-world networks. They proposed a mechanism of the emergence of power-law degree distribution, called preferential attachment, which is a subject of a separate module.\nWhether power-law degree distribution is a good model for real-world networks is a topic of debate (Artico et al. 2020) (Holme 2019) (Voitalov et al. 2019) (Broido and Clauset 2019). A straight line on a log-log plot is not a unique signature of power-law degree distribution. One can construct it by a mixture of poisson distributions, or some other distributions. Testing whether a network is a power-law or not requires statistical assessment going beyond the visual inspection.\nThe log-log plot above shows probability density function (PDF) of the degree distribution. It is defined as the fraction of nodes with degree exactly k.\n\np(k) = \\frac{\\text{number of nodes with degree } k}{N}\n\nwhere N is the total number of nodes in the network.\nThe PDF is useful but often noisy, especially in the tail where there are few observations. A better, more stable choice is the complementary cumulative distribution function (CCDF), which is useful for plotting heavy-tailed distributions.\n\n\nFor a visual comparison of CCDF and PDF, see Figure 3 in (Newman 2005)\n\n\\text{CCDF}(k) = P(k' &gt; k) = \\sum_{k'=k+1}^\\infty p(k')\n\nCCDF represents the fraction of nodes with degree greater than k, or equivalently, the fraction of nodes that survive the degree cutoff k. It is also known as the survival function of the degree distribution.\n\n\n\n\n\n\n\n\nFigure 5: The CCDF of the degree distribution on a log-log scale.\n\n\n\n\n\nA nice feature of the CCDF compared to the PDF is that it does not require any binning of the data. When calculating the PDF, we need to bin the data into a finite number of bins, which is subject to the choice of bin size. CCDF does not require any binning of the data.\n\n\nThere is a related function called the cumulative distribution function (CDF), which is the fraction of nodes with degree less than or equal to k, i.e., 1 - \\text{CCDF}(k).\nFor degree-heterogenous networks, the CCDF is preferred over the CDF because the CDF does not show the tail of the distribution clearly.\n\n\n\n\n\n\n\n\nFigure 6: The CDF of the degree distribution on a log-log scale.\n\n\n\n\n\n\nInterpreting the CCDF for Power-Law Distributions\nFor networks whose degree distribution follows a power law, the CCDF offers a direct path to estimating the power-law exponent, \\gamma. Let’s walk through the derivation to see how.\nA continuous power-law distribution is defined by the probability density function (PDF): \np(k) = Ck^{-\\gamma}\n where C is a normalization constant ensuring the total probability is 1.\nThe CCDF, which we denote as P(k), is the probability that a node’s degree k' is greater than some value k. We calculate this by integrating the PDF from k to infinity: \nP(k) = \\int_{k}^{\\infty} p(k') dk' = \\int_{k}^{\\infty} Ck'^{-\\gamma} dk'\n Performing the integration gives us: \nP(k) = C \\left[ \\frac{k'^{-\\gamma+1}}{-\\gamma+1} \\right]_{k}^{\\infty}\n Assuming \\gamma &gt; 1, which is typical for real-world networks, the term k'^{-\\gamma+1} approaches zero as k' approaches infinity. The expression simplifies to: \nP(k) = -C \\left( \\frac{k^{-\\gamma+1}}{-\\gamma+1} \\right) = \\frac{C}{\\gamma-1} k^{-(\\gamma-1)}\n This result shows that the CCDF itself follows a power law, P(k) \\propto k^{-(\\gamma-1)}.\nTo see what this means for a log-log plot, we take the logarithm of both sides: \n\\log P(k) = \\log\\left(\\frac{C}{\\gamma-1}\\right) - (\\gamma-1)\\log(k)\n This equation is in the form of a straight line, y = b + mx, where:\n\ny = \\log P(k)\nx = \\log(k)\nThe y-intercept b = \\log\\left(\\frac{C}{\\gamma-1}\\right)\nThe slope m = -(\\gamma-1) = 1-\\gamma\n\n\n\n\n\n\n\nKey Relationship\n\n\n\nFor a power-law distribution, the slope of the CCDF on a log-log plot is 1 - \\gamma.\nThis is a crucial point for accurately estimating the scaling exponent from empirical data. For example, if you measure the slope of the CCDF plot to be -1.3, the estimated power-law exponent \\gamma is 2.3, not 1.3 (since -1.3 = 1 - 2.3).",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html",
    "href": "m05-clustering/01-concepts.html",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will learn community detection, one of the most widely-used yet controversial techniques in network analysis. We will learn:\n\nWhat is community structure in networks?\nHow to operationalize community structure?\nHow to find communities in networks?\nLimitations of community detection\nKeywords: community detection, assortativity, modularity, resolution limit, rugged landscape, random graph, label switching algorithm, Louvain algorithm, stochastic block model, the configuration model.\n\n\n\n✍️ Pen and Paper Exercise 🚢",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#what-to-learn-in-this-module",
    "href": "m05-clustering/01-concepts.html#what-to-learn-in-this-module",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will learn community detection, one of the most widely-used yet controversial techniques in network analysis. We will learn:\n\nWhat is community structure in networks?\nHow to operationalize community structure?\nHow to find communities in networks?\nLimitations of community detection\nKeywords: community detection, assortativity, modularity, resolution limit, rugged landscape, random graph, label switching algorithm, Louvain algorithm, stochastic block model, the configuration model.\n\n\n\n✍️ Pen and Paper Exercise 🚢",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#what-is-community-structure",
    "href": "m05-clustering/01-concepts.html#what-is-community-structure",
    "title": "Core Concepts",
    "section": "2 What is community structure?",
    "text": "2 What is community structure?\nBirds of a feather flock together, and so do many other things. For instance, we have a group of friends with similar interests who hang out together frequently but may not interact as much with other groups.\n\n\n\nBirds of a feather\n\n\nIn networks, communities are groups of nodes that share similar connection patterns. These communities do not always mean densely-connected nodes. Sometimes, a community can be nodes that are not connected to each other, but connect similarly to other groups. For instance, in a user-movie rating network, a community might be users with similar movie tastes, even if they don’t directly connect to each other.\n\n\n\nCommunity structure in a social network\n\n\nCommunities reflect underlying mechanisms of network formation and underpin the dynamics of information propagation. Examples include:\n\nHomophily: The tendency of similar nodes to form connections.\nFunctional groups: Nodes that collaborate for specific purposes.\nHierarchical structure: Smaller communities existing within larger ones.\nInformation flow: The patterns of information, influence, or disease propagation through the network.\n\nThis is why network scientists are sooo obsessed with community structure in networks. See (Fortunato 2010), (Fortunato and Hric 2016), (Peixoto 2019) for comprehensive reviews on network communities.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#pattern-matching-approach",
    "href": "m05-clustering/01-concepts.html#pattern-matching-approach",
    "title": "Core Concepts",
    "section": "3 Pattern matching approach",
    "text": "3 Pattern matching approach\nCommunity detection is an abstract unsupervised problem. It is abstract because there is no clear-cut definition or ground truth to compare against. The concept of a community in a network is subjective and highly context-dependent.\nA classical approach to community detection is based on pattern matching. Namely, we first explicitly define a community by a specific connectivity pattern of its members. Then, we search for these communities in the network.\n\n\n\n\n\n\nFigure 1: Cliques of different sizes. Taken from https://pythonhosted.org/trustedanalytics/python_api/graphs/graph-/kclique_percolation.html\n\n\n\nPerhaps, the strictest definition of a community is a clique: a group of nodes all connected to each other. Examples include triangles (3-node cliques) and fully-connected squares (4-node cliques). However, cliques are often too rigid for real-world networks. In social networks, for instance, large groups of friends rarely have every member connected to every other, yet we want to accept such “in-perfect” social circles as communities. This leads to the idea of relaxed versions of cliques, called pseudo-cliques.\nPseudo-cliques are defined by relaxing at least one of the following three dimensions of strictness, i.e., degree, density, and distance. We will walk through each of them in details as follows.\n\nDegree relaxation\nDegree relaxation acknowledges that real-world groups rarely have perfect connectivity among all members. The k-plex (Seidman and Foster 1978) is a classic example: it allows each node in a group to miss connections to up to k other members, making it possible to model social circles where not everyone knows everyone else.\nA similar relaxation is the k-core (Seidman 1983), which requires each node to have at least k connections within the group, capturing the idea of a “core” of well-connected individuals. These approaches reflect the reality that cohesive groups can exist even when some connections are missing, and they help distinguish between core and peripheral members in a network.\n\n\n\n\n\n\n\n\n\n\nG\n\n\ncluster_not_dense\n3-plex, 1-core\n\n\ncluster_dense\n 2-plex, 2-core\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\ne\n\ne\n\n\n\na--e\n\n\n\n\nc\n\nc\n\n\n\nb--c\n\n\n\n\nb--e\n\n\n\n\nd\n\nd\n\n\n\nc--d\n\n\n\n\nc--e\n\n\n\n\nd--e\n\n\n\n\nf\n\nf\n\n\n\ng\n\ng\n\n\n\nf--g\n\n\n\n\nh\n\nh\n\n\n\ng--h\n\n\n\n\ni\n\ni\n\n\n\nj\n\nj\n\n\n\ni--j\n\n\n\n\nj--f\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Comparison of the k-plex and k-core in different graphs.\n\n\n\n\n\nDensity relaxation\nDensity relaxation shifts the focus from individual connections to the overall cohesiveness of the group. Instead of requiring every possible connection, a \\rho-dense subgraph (Goldberg 1984) enforces that the group contains at least a fraction \\rho of all possible internal edges. This approach is useful for identifying communities that are highly, but not perfectly, interconnected—such as a friend group where most, but not all, pairs know each other.\n\n\n\n\n\n\n\n\n\n\nG\n\n\ncluster_dense\n0.7-dense, 2-plex, 2-core\n\n\ncluster_not_dense\n0.7-dense, 3-plex, 1-core\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\ne\n\ne\n\n\n\na--e\n\n\n\n\nc\n\nc\n\n\n\nb--c\n\n\n\n\nb--e\n\n\n\n\nd\n\nd\n\n\n\nc--d\n\n\n\n\nc--e\n\n\n\n\nd--e\n\n\n\n\nf\n\nf\n\n\n\ng\n\ng\n\n\n\nf--g\n\n\n\n\nh\n\nh\n\n\n\nf--h\n\n\n\n\ng--h\n\n\n\n\ni\n\ni\n\n\n\nj\n\nj\n\n\n\ni--j\n\n\n\n\nj--f\n\n\n\n\nj--g\n\n\n\n\nj--h\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: The two subgraphs are equally dense, but the left one is 2-plex and 2-core, while the right one is 3-plex and 1-core.\n\n\n\n\n\nDistance relaxation\nDistance relaxation allows for the inclusion of nodes that are not directly connected but are still close in terms of network steps. The n-clique (Luce 1950) is a group where every pair of nodes is within n steps of each other, so members can be connected through mutual friends. However, this can sometimes include connections that pass through nodes outside the group, which led to refinements such as the n-clan and n-club (Mokken et al. 1979), where all paths between members must remain within the group itself. These definitions help capture the idea of communities that are tightly knit not just by direct ties, but also by short, internal paths.\n\n\n\n\n\n\n\n\n\n\nG\n\n\ncluster_clique\n\n\ncluster_clan\n\n3-clan, 2-clique\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\nc\n\nc\n\n\n\nd\n\nd\n\n\n\nc--d\n\n\n\n\nd--a\n\n\n\n\ne\n\ne\n\n\n\ne--a\n\n\n\n\ne--d\n\n\n\n\nf\n\nf\n\n\n\nf--b\n\n\n\n\nf--c\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: In both n-clique and n-clan, two nodes are connected at most n steps apart. But for the n-clique, they can be connected through other nodes outside the group. n-clan is more strict in a sense that it requires all paths between two nodes to be within the group.\n\n\n\n\n\nHybrid approaches\nHybrid approaches combine these dimensions to capture even more nuanced community structures. The k-truss (Saito, Yamada, and Kazama 2008; Cohen 2009; Wang et al. 2010) requires that every edge in the group participates in at least k-2 triangles, emphasizing the importance of triadic relationships for group stability. The \\rho-dense core (Koujaku et al. 2016) balances high internal density with sparse external connections, identifying groups that are not only cohesive inside but also well-separated from the rest of the network. These hybrid definitions reflect the complex and overlapping nature of real-world communities, where both internal cohesion and clear boundaries matter.\n\n\n\n\n\n\nFigure 5: Illustation of different pseudo cliques. Taken from {footcite}koujaku2016dense.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#graph-cut-approach",
    "href": "m05-clustering/01-concepts.html#graph-cut-approach",
    "title": "Core Concepts",
    "section": "4 Graph cut approach",
    "text": "4 Graph cut approach\nAnother approach from computer science is to treat a community detection problem as an optimization problem. An early example is the graph cut problem, which asks to find the minimum number of edges to cut the graph into two disconnected components.\nSpecifically, let us consider cutting the network into two communities. Let V_1 and V_2 be the set of nodes in the two communities. Then, the cut is the number of edges between the two communities, which is given by\n\n\\begin{align}\n\\text{Cut}(V_1, V_2) = \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\\end{align}\n\nNow, the community detection problem is translated into an optimization problem, with the goal of finding a cut V_1, V_2 that minimizes \\text{Cut}(V_1, V_2).\n\n\n\n\n\n\nExercise\n\n\n\nThe description of this problem is not complete 😈.\nCan you identify what is missing in the description of the graph cut problem? Without this, the best cut is trivial. “Graph Cut Problem 🎮”\n\n\n\n\n\n\n\n\nClick to reveal the answer!\n\n\n\n\n\nThe missing element is a constraint: each community must contain at least one node. Without this, the trivial solution of placing all nodes in a single community would always yield a cut of zero.\n\n\n\n\nBalanced cut\nGraph cut often provide unbalanced communities, e.g., a community consisting of a single node, and another consisting of all other nodes. For example, if the network has a node with degree one (e.g., one edge), an optimal cut will be to place this node in its own community, resulting in a cut of one.\n\nRatio cut\nRatio cut addresses this issue by introducing a normalization factor to balance the cut. Suppose we cut the network into two communities V_1 and V_2, then the ratio cut is defined as\n\n\\begin{align}\n\\text{Ratio cut}(V_1, V_2) = \\frac{1}{|V_1| \\cdot |V_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\\end{align}\n\nThe normalization factor 1/(|V_1| |V_2|) balances the community sizes. It’s smallest when communities are equal (|V_1| = |V_2|) and largest when one community has only one node (|V_1| = 1 or |V_2| = 1).\n\n\nNormalized cut\nNormalized cut (Shi and Malik 2000) balances communities based on edge count, unlike Ratio cut which uses node count. It is defined as\n\n\\text{Normalized cut}(V_1, V_2) = \\frac{1}{|E_1| \\cdot |E_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|E_1| and |E_2| are the number of edges in the communities V_1 and V_2, respectively.\n\n\n\nCut into more than two communities\nRatio cut and Normalized cut can be extended to cut into more than two communities. Specifically, we can extend them to cut into k communities, i.e., V_1, V_2, \\dots, V_k by defining\n\n\\begin{align}\n\\text{Ratio cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|V_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right) \\\\\n\\text{Normalized cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|E_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right)\n\\end{align}\n\n\n\nFor both ratio and normalized cut, finding the best cut is a NP-hard problem. Yet, there are some heuristics to find a good cut. Interested students are encouraged to refer to Ulrike von Luxburg “A Tutorial on Spectral Clustering” for more details.\nA key limitation of Ratio cut and Normalized cut is that they require us to choose the number of communities in advance, which is often unknown in real networks. This leads to the most celebrated yet controversial community detection method, i.e, modularity maximization, which we will cover in the next section.\n\n\n\n\n\n\nExercise\n\n\n\nAnother key limitation of Ratio cut and Normalized cut is that they tend to favor communities of similar size, even though real communities can vary a lot (Palla et al. 2005; Clauset, Newman, and Moore 2004). This problem also exists in the modularity maximization method.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#modularity-measuring-assortativity-against-null-models",
    "href": "m05-clustering/01-concepts.html#modularity-measuring-assortativity-against-null-models",
    "title": "Core Concepts",
    "section": "5 Modularity: measuring assortativity against null models",
    "text": "5 Modularity: measuring assortativity against null models\n\nKey idea\nModularity is by far the most widely used method for community detection. Modularity can be derived in many ways, but we will follow the one derived from assortativity.\nAssortativity is a measure of the tendency of nodes to connect with nodes of the same attribute. The attribute, in our case, is the community that the node belongs to, and we say that a network is assortative if nodes of the same community are more likely to connect with each other than nodes of different communities.\nLet’s think about assortativity by using color balls and strings! 🎨🧵\n\n\n\n\n\n\nFigure 6: Illustration of how modularity measures assortativity relative to a null model.\n\n\n\nImagine we’re playing a game as follows:\n\nPicture each connection in our network as two colored balls joined by a piece of string. 🔴🟢–🔵🟡\nThe color of each ball shows which community it belongs to.\nNow, let’s toss all these ball-and-string pairs into a big bag.\nWe’ll keep pulling out strings with replacement and checking if the balls on each end match colors.\n\nThe more color matches we find, the more assortative our network is. But, there’s a catch! What if we got lots of matches just by luck? For example, if all our balls were the same color, we’d always get a match. But that doesn’t tell us much about our communities. So, to be extra clever, we compare our results to a “random” version (null model):\n\nWe snip all the strings and mix up all the balls.\nThen we draw pairs of balls at random with replacement and see how often the colors match.\n\n\n\nBy comparing our original network to this mixed-up version, we can see if our communities are really sticking together more than we’d expect by chance. For example, if all nodes belong to the same community, we would always get a match for the random version as well, which informs us that a high likelihood of matches is not surprising.\nBuilding on this, the modularity is defined as\n\n\\dfrac{\\text{\\# of matches} - \\text{Average \\# of random matches}}{\\text{Maximum possible \\# of matches}}\n\nThis comparison against the random version is the heart of modularity. Unlike graph cut methods that aim to maximize assortativity directly, modularity measures assortativity relative to a null model.\n\n\nModularity formula\nLet’s dive into the modularity formula! To put modularity into math terms, we need a few ingredients:\n\nm: The total number of strings (edges) in our bag\nn: The total number of balls (nodes) we have\nA_{ij}: This tells us if ball i and ball j are connected by a string\n\\delta(c_i,c_j): This is our color-checker. It gives us a 1 if balls i and j are the same color (same community), and 0 if they’re different.\n\nNow, the probability of pulling out a string out of m string and finding matching colors on both ends is:\n\n\\frac{1}{m} \\sum_{i=1}^n \\sum_{j=i+1}^n A_{ij} \\delta(c_i,c_j) = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j)\n\nWe set A_{ii} = 0 by assuming our network doesn’t have any “selfie strings” (where a ball is connected to itself). Also, we changed our edge counting a bit. Instead of counting each string once (which gave us m), we’re now counting each string twice (once from each end). That’s why we use 2m on the right-hand side of the equation.\nNow, imagine we’ve cut all the strings, and we’re going to draw two balls at random with replacement. Here’s how our new bag looks:\n\nWe have 2m balls in total (1 string has 2 balls, and thus m strings have 2m balls in total).\nA node with k edges correspond to the k of 2m balls in the bag.\nThe color of each ball in our bag matches the color (or community) of its node in the network.\n\nNow, what’s the chance of pulling out two balls of the same color?\n\n\\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\nwhere k_i is the degree (i.e., the number of edges) of node i, and C is the total number of communities (i.e., colors).\nHere’s what it means in simple terms:\n\nWe look at each color (c) one by one (the outer sum).\nFor each color, we figure out how many balls of that color are in our bag (\\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i)).\nWe divide by 2m to get the probability of drawing a ball of that color.\nWe then calculate the chance of grabbing that color twice in a row (\\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2).\nFinally, we add up these chances for all C colors.\n\nPutting altogether, the modularity is defined by\n\n\\begin{align}\nQ &=\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\\end{align}\n\nBy rearranging the terms, we get the standard expression for modularity:\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)\n\nSee the Appendix for the derivations.\n\n\nModularity Demo\nLet’s learn how the modularity works by playing with a community detection game!\n\n\n\n\n\n\nExercise 1\n\n\n\nFind communities by maximizing the modularity. Modularity maximization (two communities) 🎮\n\n\nOne of the good things about modularity is that it can figure out how many communities there should be all by itself! 🕵️‍♀️ Let’s have some fun with this idea. We’re going to play the same game again, but this time, we’ll start with a different number of communities. See how the modularity score changes as we move things around.\n\n\n\n\n\n\nExercise 2\n\n\n\nFind communities by maximizing the modularity. Modularity maximization (four communities) 🎮\n\n\nNow, let’s take our modularity maximization for a real-world example! 🥋 We’re going to use the famous karate club network. This network represents friendships between members of a university karate club. It’s a classic in the world of network science, and it’s perfect for seeing how modularity works in practice.\n\n\n\n\n\n\nExercise 3\n\n\n\nFind communities by maximizing the modularity. Modularity maximization (four communities) 🎮\n\n\n\n\nLimitation of Modularity\nLike many other community detection methods, modularity is not a silver bullet. Thanks to extensive research, we know many limitations of modularity. Let’s take a look at a few of them.\n\n\nResolution limit\nThe modularity finds two cliques connected by a single edge as two separate communities. But what if we add another community to this network? Our intuition tells us that, because communities are local structure, the two cliques should remain separated by the modularity. But is this the case?\n\n\n\n\n\n\nExercise 4\n\n\n\nFind communities by maximizing the modularity. Modularity maximization (four communities) 🎮\n\n\n\n\n\n\n\n\nClick here to see the solution\n\n\n\n\n\nThe best modularity score actually comes from merging our two cliques into one big community. This behavior is what we call the Resolution limit (Fortunato and Barthelemy 2007). Modularity can’t quite make out communities that are smaller than a certain size!\nThink of it like this: modularity is trying to see the big picture, but it misses the little details. In network terms, the number of edges m_c in a community c has to be bigger than a certain size. This size is related to the total number of edges m in the whole network. We write this mathematically as {\\cal O}(m).\n\n\n\n\n\nSpurious communities\nWhat if the network does not have any communities at all? Does the modularity find no communities? To find out, let’s run the modularity on a random network, where each pair of nodes is connected randomly with the same probability.\n\n\n\n\n\n\nExercise 5\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) 🎮\n\n\n\n\n\n\nClick here to see the solution\n\n\n\n\n\nSurprise, surprise! 😮 Modularity finds communities even in our random network, and with a very high score too! It’s like finding shapes in clouds - sometimes our brains (or algorithms) see patterns where there aren’t any.\nThe wild thing is that the modularity score for this random network is even higher than what we saw for our network with two clear cliques!\nThis teaches us two important lessons: 1. We can’t compare modularity scores between different networks. It’s like comparing apples and oranges! 🍎🍊 2. A high modularity score doesn’t always mean we’ve found communities.\nInterested readers can read more about this in this tweet by Tiago Peixoto and the discussion here.\n\n\nModularity maximization is not a reliable method to find communities in networks. Here's a simple example showing why:1. Generate an Erdős-Rényi random graph with N nodes and average degree &lt;k&gt;.2. Find the maximum modularity partition. pic.twitter.com/MTt5DdFXSX\n\n— Tiago Peixoto ((tiagopeixoto?)) December 2, 2021\n\n\n\n\n\n\n\nThe simple answer is no. Modularity is still a powerful tool for finding communities in networks. Like any other method, it has its limitations. And knowing these limitations is crucial for using it effectively. There is “free lunch” in community detection (Peel, Larremore, and Clauset 2017). When these implicit assumptions are met, modularity is in fact a very powerful method for community detection. For example, it is in fact an “optimal” method for a certain class of networks (Nadakuditi and Newman 2012).",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#stochastic-block-model",
    "href": "m05-clustering/01-concepts.html#stochastic-block-model",
    "title": "Core Concepts",
    "section": "6 Stochastic Block Model",
    "text": "6 Stochastic Block Model\nLet’s talk about two ways to look at communities in networks. In modularity maximization, we are given a network and asked to find the best way to group its parts into communities. Let’s flip that idea on its head! 🙃 Instead of starting with a network and looking for communities, we start with the communities and ask, “What kind of network would we get if the nodes form these communities?”. This is the idea of the Stochastic Block Model (SBM).\n\nModel\nIn stochastic block model, we describe a network using probabilities given a community structure. Specifically, let us consider two nodes i and j who belong to community c_i and c_j. Then, the probability of an edge between i and j is given by their community membership.\n\nP(A_{ij}=1|c_i, c_j) = p_{c_i,c_j}\n\nwhere p_{c_i,c_j} is the probability of an edge between nodes in community c_i and c_j, respectively. Importantly, the probability p_{c_i,c_j} is specified by the community membership of the nodes, c_i and c_j. As a result, when plotting the adjacency matrix of one realization of SBM, we observe “blocks” of different edge densities, which is why we say that SBM is a “block model”.\n\n\n\n\n\n\n\n\nFigure 7: Adjacency Matrix of Stochastic Block Model\n\n\n\n\n\n\n\nCharacterizing network structures with the SBM\nStochastic Block Model is a flexible model that can be used to describe a wide range of network structures.\nLet’s start with communities where nodes within a community are more likely to be connected to each other than nodes in different communities. We can describe this using SBM by:\n\nP_{c,c'} = \\begin{cases}\n    p_{\\text{in}} & \\text{if } c = c' \\\\\n    p_{\\text{out}} & \\text{if } c \\neq c'\n\\end{cases}\n\n\np_{\\text{in}} is the chance of a connection between nodes in the same community\np_{\\text{out}} is the chance of a connection between nodes in different communities\n\nUsually, we set p_{\\text{in}} &gt; p_{\\text{out}}, because nodes in the same community tend to be more connected.\nBut, there’s more SBM can do:\n\nDisassortative communities: What if we flip things around and set p_{\\text{in}} &lt; p_{\\text{out}}? Now we have communities where nodes prefer to connect with nodes from other communities. This is not in line with the communities we have focused on so far. Yet, it is still a valid model of community structure, and SBM allows for this generalization of community structure easily.\nRandom networks: If we make p_{\\text{in}} = p_{\\text{out}}, we get a completely random network where every node has an equal chance of connecting to any other node. This is what we call an Erdős-Rényi network.\n\nIn sum, SBM has been used as a playground for network scientists. We can use it to create many interesting network structures and study how they behave.\n\n\nDetecting communities with SBM\nIf we know how a network is generated given a community membership, then we can ask ourselves the following question: what is the most likely community membership that generates the observed network? This is exactly a maximum likelihood problem.\nWe can describe the probability of seeing a particular network, given a community structure as follows:\n\nP(\\left\\{A_{ij}\\right\\}_{ij}) = \\prod_{i&lt;j} P(A_{ij}=1|c_i, c_j)^{A_{ij}} (1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}.\n\nLet’s break this down into simpler terms:\n\nFirst, \\left\\{A_{ij}\\right\\}_{ij} is just saying “all the connections in our network”. Think of it as a big table showing who’s connected to whom.\nWe use \\prod_{i &lt; j} instead of \\prod_{i,j} because we’re dealing with an undirected network. This means if Alice is friends with Bob, Bob is also friends with Alice. We only need to count this friendship once, not twice.\nThe last part, P(A_{ij}=1|c_i, c_j)^A_{ij}(1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}} is a shorthand way of saying “what’s the chance of this connection existing or not existing?” If the connection exists (A_{ij}=1), we use the first part. If it doesn’t (A_{ij}=0), we use the second part. It’s a two-in-one formula.\n\nWe can take the logarithm of both sides of our equation. This turns our big product (multiplication) into a simpler sum (addition).\n\n\\begin{aligned}\n{\\cal L}=&\\log P(\\left\\{A_{ij}\\right\\}_{ij}) \\\\\n=& \\sum_{i&lt;j} A_{ij} \\log P(A_{ij}=1|c_i, c_j) \\\\\n&+ (1-A_{ij}) \\log (1-P(A_{ij}=1|c_i, c_j)).\n\\end{aligned}\n\nWe call this the likelihood function. It tells us how likely we are to see this network given our community guess. We can play around with different community assignments and edge probabilities to see which one gives us the highest likelihood.\nOur likelihood function has a special shape - it is a concave function with respect to p_{c,c'}. This means that the likelihood function is a hill with only one peak when we look at it in terms of edge probability p_{c,c'}.\n\n\n\n\n\n\n\n\nFigure 8: Schematic of Likelihood Function (Concave)\n\n\n\n\n\nSo, what does this mean for us? The top of this hill (our maximum value) is flat, and there’s only one flat spot on the whole hill. So if we can find a spot where the hill isn’t sloping at all (that’s what we mean by “zero gradient”), we’ve found the very top of the hill.;\nIn math terms, we take the derivative of our likelihood function with respect to p_{c,c'} and set it to zero, i.e., \\partial {\\cal L}  / \\partial p_{cc'} = 0. Here is what we get:\n\n\\begin{aligned}\n\\frac{\\partial {\\cal L}}{\\partial p_{c,c'}} &= 0 \\\\\n\\Rightarrow & \\sum_{i&lt;j} \\left[A_{ij} \\frac{1}{p_{c_i,c_j}} \\delta(c_i,c)\\delta(c_j,c') -(1-A_{ij}) \\frac{1}{1-p_{c_i,c_j}}\\delta(c_i,c')\\delta(c_j,c') \\right] = 0 \\\\\n\\Rightarrow &\n\\frac{m_{cc'}}{p_{c_i,c_j}} - \\frac{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') }{1-p_{c_i,c_j}} = 0 & \\text{if } c \\neq  c' \\\\\n\\Rightarrow & p_{c,c'} = \\frac{m_{cc'}}{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c')}\n\\end{aligned}\n\nLet’s break down these equations:\n\nm_{cc'} is the number of edges between nodes in community c and those in community c'.\nThe derivative \\partial \\log p_{cc} / \\partial p_{cc} is just 1/p_{cc}.\n\nThe denominator \\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') is the total number of pairs of nodes that belong to communities c and c'. It is given by\n\n\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') =\n\\begin{cases}\nn_cn_{c'} & \\text{if } c \\neq c' \\\\\n\\frac{n_c (n_c - 1)}{2} & \\text{if } c = c'\n\\end{cases}\n\nWhy do we have two different equations for p_{c,c'}? It’s because we are counting each pair of nodes only by once. It is easy to verify when looking at the adjacency matrix:\n\n\n\n\n\n\n\n\nFigure 9: Adjacency Matrix of Stochastic Block Model\n\n\n\n\n\nThe upper triangle of the adjacency matrix represents i &lt; j over which we take the sum. When c=c' (the diagonal block), we count only the upper half of the block, resulting in \\frac{n_c (n_c - 1)}{2}. When c \\neq c' (different communities), we count all connections between them, resulting in n_cn_{c'}.\nWe have now obtaind the likelihood function based only on the community assignment. Maximizing {\\cal L} with respect to the community assignment gives us the most likely community assignment for the network.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m05-clustering/03-exercises.html",
    "href": "m05-clustering/03-exercises.html",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "For students enrolled in SSIE 641, you will receive a dedicated link to the assignment repository from the instructor.\nFor those who are not enrolled, fork this assignment repository at Github.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m05-clustering/03-exercises.html#assignment",
    "href": "m05-clustering/03-exercises.html#assignment",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "For students enrolled in SSIE 641, you will receive a dedicated link to the assignment repository from the instructor.\nFor those who are not enrolled, fork this assignment repository at Github.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m06-centrality/02-coding.html",
    "href": "m06-centrality/02-coding.html",
    "title": "Coding - Centrality",
    "section": "",
    "text": "Let’s compute the centrality of the network using Python igraph.\n\n# Uncomment if you use Colab\n#!pip install igraph\n\n\nimport igraph\n\nnames = [\n    \"Sarah\",\n    \"Mike\",\n    \"Emma\",\n    \"Alex\",\n    \"Olivia\",\n    \"James\",\n    \"Sophia\",\n    \"Ethan\",\n    \"Ava\",\n    \"Noah\",\n    \"Lily\",\n    \"Lucas\",\n    \"Henry\",\n]\nedge_list = [\n    (0, 1),\n    (0, 2),\n    (1, 2),\n    (2, 3),\n    (3, 4),\n    (3, 5),\n    (3, 6),\n    (4, 5),\n    (6, 7),\n    (6, 8),\n    (6, 9),\n    (7, 8),\n    (7, 9),\n    (8, 9),\n    (9, 10),\n    (9, 11),\n    (9, 12),\n]\ng = igraph.Graph()\ng.add_vertices(13)\ng.vs[\"name\"] = names\ng.add_edges(edge_list)\nigraph.plot(g, vertex_label=g.vs[\"name\"])\n\n\n\n\n\n\n\n\nigraph offers a wide range of centrality measures as methods of the igraph.Graph class.\n\nDegree centrality: igraph.Graph.degree()\nCloseness centrality: igraph.Graph.closeness()\nBetweenness centrality: igraph.Graph.betweenness()\nHarmonic centrality: igraph.Graph.harmonic_centrality()\nEccentricity: igraph.Graph.eccentricity()\nEigenvector centrality: igraph.Graph.eigenvector_centrality()\nPageRank centrality: igraph.Graph.personalized_pagerank()\n\nFor example, the closeness centrality is computed by\n\ng.closeness()\n\n[0.3,\n 0.3,\n 0.4,\n 0.5217391304347826,\n 0.36363636363636365,\n 0.36363636363636365,\n 0.5454545454545454,\n 0.42857142857142855,\n 0.42857142857142855,\n 0.48,\n 0.3333333333333333,\n 0.3333333333333333,\n 0.3333333333333333]\n\n\n\n\nLet’s compute the Katz centrality without using igraph. Let us first define the adjacency matrix of the graph\n\nA = g.get_adjacency_sparse()\n\nwhich is the scipy CSR sparse matrix. The Katz centrality is given by\n\n\\mathbf{c} = \\beta \\mathbf{1} + \\alpha \\mathbf{A} \\mathbf{c}\n\nSo, how do we solve this? We can use a linear solver but here we will use a simple method:\n\nInitialize \\mathbf{c} with a random vector.\nCompute the right hand side of the equation and update \\mathbf{c}.\nRepeat the process until \\mathbf{c} converges.\n\nLet’s implement this.\n\nimport numpy as np\n\nalpha, beta = 0.1, 0.05 # Hyperparameters\nn_nodes = g.vcount() # number of nodes\nc = np.random.rand(n_nodes, 1) # column random vector\n\nfor _ in range(100):\n    c_next = beta * np.ones((n_nodes, 1)) + alpha * A * c\n    if np.linalg.norm(c_next - c) &lt; 1e-6:\n        break\n    c = c_next\nprint(c)\n\n[[0.06338729]\n [0.06338729]\n [0.07048542]\n [0.07807918]\n [0.06423107]\n [0.06423107]\n [0.08184309]\n [0.07474495]\n [0.07474495]\n [0.09085937]\n [0.05908602]\n [0.05908602]\n [0.05908602]]\n\n\n\nDoes the centrality converge?\nChange the hyperparameter and see how the result changes 😉 If the centrality diverges, think about why it diverges.\n\nHint: Katz centrality can be analytically computed by\n\n\\mathbf{c} = \\beta \\left(\\mathbf{I} -  \\alpha \\mathbf{A} \\right)^{-1} \\mathbf{1}\n\n\n\n\nCompute the PageRank centrality of this graph\n\n# Your code here\n\n\n\n\n\n\n\n\nimport pandas as pd\n\nroot = \"https://raw.githubusercontent.com/skojaku/adv-net-sci/main/data/roman-roads\"\nnode_table = pd.read_csv(f\"{root}/node_table.csv\")\nedge_table = pd.read_csv(f\"{root}/edge_table.csv\")\n\nThe node table:\n\nnode_table.head(3)\n\n\n\n\n\n\n\n\nnode_id\nlon\nlat\n\n\n\n\n0\n0\n12.506\n41.875\n\n\n1\n1\n12.470\n41.904\n\n\n2\n2\n12.471\n41.881\n\n\n\n\n\n\n\nThe edge table:\n\nedge_table.head(3)\n\n\n\n\n\n\n\n\nsrc\ntrg\n\n\n\n\n0\n1785\n358\n\n\n1\n1785\n1771\n\n\n2\n1771\n350\n\n\n\n\n\n\n\nLet’s construct a network from the node and edge tables.\n\nimport igraph\n\ng = igraph.Graph() # create an empty graph\ng.add_vertices(node_table[\"node_id\"].values) # add nodes\ng.add_edges(list(zip(edge_table[\"src\"].values, edge_table[\"trg\"].values))) # add edges\n\nwhich looks like this:\n\ncoord = list(zip(node_table[\"lon\"].values, -node_table[\"lat\"].values))\nigraph.plot(g, layout = coord, vertex_size = 5)\n\n\n\n\n\n\n\n\n\n\n\n\nCompute the following centrality measures:\n\nDegree centrality 🔢\nEigenvector centrality\nPageRank centrality\nKatz centrality\nBetweenness centrality\nCloseness centrality\n\nPlot the centrality measures on the map and see in which centrality Rome is the most important node. 🗺️🏛️ (as beautiful as possible!!)",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Coding - Centrality"
    ]
  },
  {
    "objectID": "m06-centrality/02-coding.html#network-of-university-students",
    "href": "m06-centrality/02-coding.html#network-of-university-students",
    "title": "Coding - Centrality",
    "section": "",
    "text": "Let’s compute the centrality of the network using Python igraph.\n\n# Uncomment if you use Colab\n#!pip install igraph\n\n\nimport igraph\n\nnames = [\n    \"Sarah\",\n    \"Mike\",\n    \"Emma\",\n    \"Alex\",\n    \"Olivia\",\n    \"James\",\n    \"Sophia\",\n    \"Ethan\",\n    \"Ava\",\n    \"Noah\",\n    \"Lily\",\n    \"Lucas\",\n    \"Henry\",\n]\nedge_list = [\n    (0, 1),\n    (0, 2),\n    (1, 2),\n    (2, 3),\n    (3, 4),\n    (3, 5),\n    (3, 6),\n    (4, 5),\n    (6, 7),\n    (6, 8),\n    (6, 9),\n    (7, 8),\n    (7, 9),\n    (8, 9),\n    (9, 10),\n    (9, 11),\n    (9, 12),\n]\ng = igraph.Graph()\ng.add_vertices(13)\ng.vs[\"name\"] = names\ng.add_edges(edge_list)\nigraph.plot(g, vertex_label=g.vs[\"name\"])\n\n\n\n\n\n\n\n\nigraph offers a wide range of centrality measures as methods of the igraph.Graph class.\n\nDegree centrality: igraph.Graph.degree()\nCloseness centrality: igraph.Graph.closeness()\nBetweenness centrality: igraph.Graph.betweenness()\nHarmonic centrality: igraph.Graph.harmonic_centrality()\nEccentricity: igraph.Graph.eccentricity()\nEigenvector centrality: igraph.Graph.eigenvector_centrality()\nPageRank centrality: igraph.Graph.personalized_pagerank()\n\nFor example, the closeness centrality is computed by\n\ng.closeness()\n\n[0.3,\n 0.3,\n 0.4,\n 0.5217391304347826,\n 0.36363636363636365,\n 0.36363636363636365,\n 0.5454545454545454,\n 0.42857142857142855,\n 0.42857142857142855,\n 0.48,\n 0.3333333333333333,\n 0.3333333333333333,\n 0.3333333333333333]\n\n\n\n\nLet’s compute the Katz centrality without using igraph. Let us first define the adjacency matrix of the graph\n\nA = g.get_adjacency_sparse()\n\nwhich is the scipy CSR sparse matrix. The Katz centrality is given by\n\n\\mathbf{c} = \\beta \\mathbf{1} + \\alpha \\mathbf{A} \\mathbf{c}\n\nSo, how do we solve this? We can use a linear solver but here we will use a simple method:\n\nInitialize \\mathbf{c} with a random vector.\nCompute the right hand side of the equation and update \\mathbf{c}.\nRepeat the process until \\mathbf{c} converges.\n\nLet’s implement this.\n\nimport numpy as np\n\nalpha, beta = 0.1, 0.05 # Hyperparameters\nn_nodes = g.vcount() # number of nodes\nc = np.random.rand(n_nodes, 1) # column random vector\n\nfor _ in range(100):\n    c_next = beta * np.ones((n_nodes, 1)) + alpha * A * c\n    if np.linalg.norm(c_next - c) &lt; 1e-6:\n        break\n    c = c_next\nprint(c)\n\n[[0.06338729]\n [0.06338729]\n [0.07048542]\n [0.07807918]\n [0.06423107]\n [0.06423107]\n [0.08184309]\n [0.07474495]\n [0.07474495]\n [0.09085937]\n [0.05908602]\n [0.05908602]\n [0.05908602]]\n\n\n\nDoes the centrality converge?\nChange the hyperparameter and see how the result changes 😉 If the centrality diverges, think about why it diverges.\n\nHint: Katz centrality can be analytically computed by\n\n\\mathbf{c} = \\beta \\left(\\mathbf{I} -  \\alpha \\mathbf{A} \\right)^{-1} \\mathbf{1}\n\n\n\n\nCompute the PageRank centrality of this graph\n\n# Your code here",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Coding - Centrality"
    ]
  },
  {
    "objectID": "m06-centrality/02-coding.html#network-of-ancient-roman-roads",
    "href": "m06-centrality/02-coding.html#network-of-ancient-roman-roads",
    "title": "Coding - Centrality",
    "section": "",
    "text": "import pandas as pd\n\nroot = \"https://raw.githubusercontent.com/skojaku/adv-net-sci/main/data/roman-roads\"\nnode_table = pd.read_csv(f\"{root}/node_table.csv\")\nedge_table = pd.read_csv(f\"{root}/edge_table.csv\")\n\nThe node table:\n\nnode_table.head(3)\n\n\n\n\n\n\n\n\nnode_id\nlon\nlat\n\n\n\n\n0\n0\n12.506\n41.875\n\n\n1\n1\n12.470\n41.904\n\n\n2\n2\n12.471\n41.881\n\n\n\n\n\n\n\nThe edge table:\n\nedge_table.head(3)\n\n\n\n\n\n\n\n\nsrc\ntrg\n\n\n\n\n0\n1785\n358\n\n\n1\n1785\n1771\n\n\n2\n1771\n350\n\n\n\n\n\n\n\nLet’s construct a network from the node and edge tables.\n\nimport igraph\n\ng = igraph.Graph() # create an empty graph\ng.add_vertices(node_table[\"node_id\"].values) # add nodes\ng.add_edges(list(zip(edge_table[\"src\"].values, edge_table[\"trg\"].values))) # add edges\n\nwhich looks like this:\n\ncoord = list(zip(node_table[\"lon\"].values, -node_table[\"lat\"].values))\nigraph.plot(g, layout = coord, vertex_size = 5)\n\n\n\n\n\n\n\n\n\n\n\n\nCompute the following centrality measures:\n\nDegree centrality 🔢\nEigenvector centrality\nPageRank centrality\nKatz centrality\nBetweenness centrality\nCloseness centrality\n\nPlot the centrality measures on the map and see in which centrality Rome is the most important node. 🗺️🏛️ (as beautiful as possible!!)",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Coding - Centrality"
    ]
  },
  {
    "objectID": "m06-centrality/eigencentrality.html",
    "href": "m06-centrality/eigencentrality.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "“A man is known by the company he keeps” is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire. It suggests that a person’s character is reflected by the people this person is friends with. This idea can be applied to define the centrality of a node in a network.\n\n\nOne considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here’s the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet’s think about it for a moment. We want our centrality measure to be positive. It wouldn’t make much sense to have negative importance! So, we’re looking for an eigenvector where all the elements are positive. And a good news is that there’s a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associted with the largest eigenvalue always has all positive elements.\nThis centrality is called Eigenvector centrality.\n\n\n\nEigenvector centrality has several problems. One is that it does not handle directed networks very well. A natural extension of eigenvector centrality to directed networks is the HITS centrality. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet’s put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbb{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree $d_j$ of the authority, namely\n\n$$\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n$$\n\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting $x_i = d_i$.\n:::\n\n## Katz centrality\n\nEigenvector centrality tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. A solution is to add a little bit of score to all nodes.\n\n$$\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n$$\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nDerive the solution of the Katz centrality.\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe equation can be solved by\n\n$$\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n$$\n\nwhere $\\mathbf{1}$ is the vector of ones. By rewriting the equation, we get\n\n$$\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n$$\n\nBy taking the inverse of $\\mathbf{I} - \\lambda \\mathbf{A}$, we get\n\n$$\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n$$\n\n\nYou’ve probably heard PageRank, a celebrated idea behind Google Search. It is like a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers."
  },
  {
    "objectID": "m06-centrality/eigencentrality.html#eigenvector-centrality",
    "href": "m06-centrality/eigencentrality.html#eigenvector-centrality",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "One considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here’s the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet’s think about it for a moment. We want our centrality measure to be positive. It wouldn’t make much sense to have negative importance! So, we’re looking for an eigenvector where all the elements are positive. And a good news is that there’s a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associted with the largest eigenvalue always has all positive elements.\nThis centrality is called Eigenvector centrality."
  },
  {
    "objectID": "m06-centrality/eigencentrality.html#hyperlink-induced-topic-search-hits-centrality",
    "href": "m06-centrality/eigencentrality.html#hyperlink-induced-topic-search-hits-centrality",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Eigenvector centrality has several problems. One is that it does not handle directed networks very well. A natural extension of eigenvector centrality to directed networks is the HITS centrality. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet’s put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbb{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree $d_j$ of the authority, namely\n\n$$\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n$$\n\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting $x_i = d_i$.\n:::\n\n## Katz centrality\n\nEigenvector centrality tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. A solution is to add a little bit of score to all nodes.\n\n$$\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n$$\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nDerive the solution of the Katz centrality.\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe equation can be solved by\n\n$$\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n$$\n\nwhere $\\mathbf{1}$ is the vector of ones. By rewriting the equation, we get\n\n$$\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n$$\n\nBy taking the inverse of $\\mathbf{I} - \\lambda \\mathbf{A}$, we get\n\n$$\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n$$\n\n\nYou’ve probably heard PageRank, a celebrated idea behind Google Search. It is like a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers."
  },
  {
    "objectID": "m06-centrality/eigencentrality.html#pagerank",
    "href": "m06-centrality/eigencentrality.html#pagerank",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "You’ve probably heard PageRank, a celebrated idea behind Google Search. It is like a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers."
  },
  {
    "objectID": "m07-random-walks/02-coding.html",
    "href": "m07-random-walks/02-coding.html",
    "title": "Coding - Random Walks",
    "section": "",
    "text": "In the previous section, we learned the theoretical foundations of random walks. Now we’ll implement these concepts in Python and explore their practical applications for network analysis.\nRecall that a random walk is a process where we: 1. Start at a node i 2. Randomly choose an edge to traverse to a neighbor node j 3. Repeat until we’ve taken T steps\nLet’s see how this simple process can reveal deep insights about network structure.\n\n\n\n\n\nWe’ll start by implementing random walks on a simple graph of five nodes.\n\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n\n\n\n\n\n\n\n\n\n\n\nA random walk is characterized by the transition probabilities between nodes:\nP_{ij} = \\frac{A_{ij}}{k_i}\nLet’s compute and visualize the transition probability matrix \\mathbf{P}:\n\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] &gt; 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i-&gt;ij\", A, 1 / k)\n\n\nprint(\"Transition probability matrix:\\n\", P)\n\nTransition probability matrix:\n [[0.         0.33333333 0.33333333 0.33333333 0.        ]\n [0.5        0.         0.         0.5        0.        ]\n [0.33333333 0.         0.         0.33333333 0.33333333]\n [0.25       0.25       0.25       0.         0.25      ]\n [0.         0.         0.5        0.5        0.        ]]\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n\n\n\n\n\n\n\n\nEach row and column of \\mathbf{P} corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\n\n\n\nNow let’s simulate a random walk step by step. We represent the position of the walker using a vector \\mathbf{x} with five elements, where we mark the current node with 1 and others as 0:\n\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n\nInitial position of the walker:\n [1 0 0 0 0]\n\n\nThis vector representation lets us compute transition probabilities to other nodes:\n\\mathbf{x} \\mathbf{P}\n\nprobs = x @ P\nprint(\"Transition probabilities from current position:\\n\", probs)\n\nTransition probabilities from current position:\n [0.         0.33333333 0.33333333 0.33333333 0.        ]\n\n\nWe can then draw the next node based on these probabilities:\n\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position after one step:\\n\", x)\n\nPosition after one step:\n [0 1 0 0 0]\n\n\n\n\n\nWrite the following function to simulate the random walk for a given number of steps and return the x for each step:\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n    n_nodes = A.shape[0]\n\n    # Initialize position\n    x = np.zeros(n_nodes)\n    x[0] = 1  # Start at node 0\n\n    positions = [x.copy()]\n\n    for step in range(n_steps):\n        probs = x @ P\n        next_node = ... # fill in the missing code\n        x[:] = 0\n        x[next_node] = 1\n        positions.append(x.copy())\n\n    return np.array(positions)\n\n# Test the function\nwalk_positions = random_walk(A, 10)\nprint(\"Walker positions over 10 steps:\")\nprint(walk_positions)\n\n\n\n\n\n\nWhat is the expected position of the walker after multiple steps? For the first step from initial position \\mathbf{x}(0):\n\\mathbb{E}[\\mathbf{x}(1)] = \\mathbf{x}(0) \\mathbf{P}\n\nx_0 = np.array([1, 0, 0, 0, 0])\nx_1 = x_0 @ P\nprint(\"Expected position after one step:\\n\", x_1)\n\nExpected position after one step:\n [0.         0.33333333 0.33333333 0.33333333 0.        ]\n\n\nFor the second step:\n\\mathbb{E}[\\mathbf{x}(2)] = \\mathbf{x}(0) \\mathbf{P}^2\n\nx_2 = x_1 @ P\nprint(\"Expected position after two steps:\\n\", x_2)\n\nExpected position after two steps:\n [0.36111111 0.08333333 0.08333333 0.27777778 0.19444444]\n\n\nIn general, the expected position at time t is:\n\\mathbb{E}[\\mathbf{x}(t)] = \\mathbf{x}(0) \\mathbf{P}^t\n\n\n\nWrite a function to compute the expected position of the walker at time t:\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The expected position at time t.\n    \"\"\"\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n\n    # Compute P^t\n    P_t = ... # fill in the missing code\n\n    return x_0 @ P_t\n\n# Test the function\nx_0 = np.array([1, 0, 0, 0, 0])\nfor t in [1, 2, 5, 10]:\n    x_t = expected_position(A, x_0, t)\n    print(f\"Expected position at time {t}: {x_t}\")\n\n\n\nPlot each element of \\mathbf{x}(t) as a function of t for t=0,1,2,\\ldots, 100. Try different initial positions and compare the results!\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_convergence(A, x_0, max_t=100):\n    \"\"\"Plot the convergence to stationary distribution.\"\"\"\n\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n    n_nodes = A.shape[0]\n\n    # Compute expected positions over time\n    positions = []\n    x_t = x_0.copy()\n    positions.append(x_t.copy())\n\n    for t in range(max_t):\n        x_t = x_t @ P\n        positions.append(x_t.copy())\n\n    positions = np.array(positions)\n\n    # Plot\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    for i in range(n_nodes):\n        ax.plot(range(max_t + 1), positions[:, i], label=f\"Node {i}\", linewidth=2)\n\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Probability\")\n    ax.set_title(\"Random Walk Convergence to Stationary Distribution\")\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    plt.show()\n\n# Test with different starting positions\nstarting_positions = [\n    [1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 0, 0, 1]\n]\n\nfor i, x_0 in enumerate(starting_positions):\n    print(f\"\\nStarting from node {np.argmax(x_0)}:\")\n    plot_convergence(A, np.array(x_0))\n\n\nStarting from node 0:\n\n\n\n\n\n\n\n\n\n\nStarting from node 1:\n\n\n\n\n\n\n\n\n\n\nStarting from node 4:\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s demonstrate random walks on a more complex network structure.\n\nimport igraph as ig\nimport numpy as np\n\n# Create a network with two communities\nedge_list = []\nfor i in range(5):\n    for j in range(i+1, 5):\n        edge_list.append((i, j))\n        edge_list.append((i+5, j+5))\nedge_list.append((0, 6))\n\ng = ig.Graph(edge_list)\nig.plot(g, vertex_size=20, vertex_label=np.arange(g.vcount()))\n\n\n\n\n\n\n\n\n\n\nThe transition probability matrix \\mathbf{P} is:\n\nimport scipy.sparse as sparse\n\nA = g.get_adjacency_sparse()\ndeg = np.array(A.sum(axis=1)).flatten()\nDinv = sparse.diags(1/deg)\nP = Dinv @ A\n\nLet’s compute the stationary distribution using the power method:\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.zeros(g.vcount())\nx[1] = 1 # Start from node 1\nT = 100\nxt = []\nfor t in range(T):\n    x = x.reshape(1, -1) @ P\n    xt.append(x)\n\nxt = np.vstack(xt) # Stack the results vertically\n\nfig, ax = plt.subplots(figsize=(10, 6))\npalette = sns.color_palette().as_hex()\nfor i in range(g.vcount()):\n    sns.lineplot(x=range(T), y=xt[:, i], label=f\"Node {i}\", ax=ax, color=palette[i % len(palette)])\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Probability\")\nax.set_title(\"Stationary distribution of a random walk\")\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWe observe three key features: 1. The distribution oscillates with decaying amplitude before converging 2. Nodes of the same degree converge to the same stationary probability 3. Nodes with higher degree have higher stationary probability\nLet’s verify this by comparing with the theoretical stationary distribution:\n\nimport pandas as pd\n\nn_edges = np.sum(deg) / 2\nexpected_stationary_dist = deg / (2 * n_edges)\n\npd.DataFrame({\n    \"Expected stationary distribution\": expected_stationary_dist,\n    \"Observed stationary distribution\": xt[-1].flatten()\n}).style.format(\"{:.4f}\").set_caption(\"Comparison of Expected and Observed Stationary Distributions\").background_gradient(cmap='cividis', axis=None)\n\n\n\n\n\n\nTable 1: Comparison of Expected and Observed Stationary Distributions\n\n\n\n\n\n \nExpected stationary distribution\nObserved stationary distribution\n\n\n\n\n0\n0.1190\n0.1191\n\n\n1\n0.0952\n0.0953\n\n\n2\n0.0952\n0.0953\n\n\n3\n0.0952\n0.0953\n\n\n4\n0.0952\n0.0953\n\n\n5\n0.0952\n0.0952\n\n\n6\n0.1190\n0.1190\n\n\n7\n0.0952\n0.0952\n\n\n8\n0.0952\n0.0952\n\n\n9\n0.0952\n0.0952\n\n\n\n\n\n\n\n\n\n\n\n\nRandom walks can capture community structure. Let’s explore this with a ring of cliques:\n\nimport networkx as nx\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nn_cliques = 3\nn_nodes_per_clique = 5\n\nG = nx.ring_of_cliques(n_cliques, n_nodes_per_clique)\ng = igraph.Graph().Adjacency(nx.to_numpy_array(G).tolist()).as_undirected()\nmembership = np.repeat(np.arange(n_cliques), n_nodes_per_clique)\n\ncolor_map = [sns.color_palette()[i] for i in membership]\nigraph.plot(g, vertex_size=20, vertex_color=color_map)\n\n\n\n\n\n\n\n\n\n\nLet’s compute the expected position over time and visualize how the walker explores communities:\n\nfrom scipy import sparse\n\n# Get the adjacency matrix and degree\nA = g.get_adjacency_sparse()\nk = np.array(g.degree())\n\n# Compute the transition matrix efficiently using scipy.sparse\nP = sparse.diags(1 / k) @ A\n\n\n# Compute the expected position from node 2 over 300 steps\nx_t = np.zeros(g.vcount())\nx_t[2] = 1\nx_list = [x_t]\nfor t in range(300):\n    x_t = x_t @ P\n    x_list.append(x_t)\nx_list = np.array(x_list)\n\n\n# Plot the network at different time steps\ncmap = sns.color_palette(\"viridis\", as_cmap=True)\n\nsns.set_style('white')\nsns.set(font_scale=1.2)\nsns.set_style('ticks')\n\nfig, axes = plt.subplots(figsize=(15,10), ncols = 3, nrows = 2)\n\nt_list = [0, 1, 3, 5, 10, 299]\nfor i, t in enumerate(t_list):\n    igraph.plot(g, vertex_size=20, vertex_color=[cmap(x_list[t][j] / np.max(x_list[t])) for j in range(g.vcount())], target = axes[i//3][i%3])\n    axes[i//3][i%3].set_title(f\"$t$ = {t}\", fontsize = 25)\n\n\n\n\n\n\n\n\nThe color intensity represents the probability of the walker being at each node. Notice how: - Initially, the walker is concentrated at the starting node - It gradually diffuses within its community - Only later does it spread to other communities - Eventually, it reaches the stationary distribution\nThis temporal behavior reveals the community structure!\n\n\n\n\n\n\nLet’s demonstrate the spectral analysis of random walks:\n\n# Using the two-clique network from before\nA_norm = g.get_adjacency_sparse()\ndeg = np.array(A_norm.sum(axis=1)).flatten()\n\n# Normalized adjacency matrix\nDinv_sqrt = sparse.diags(1.0/np.sqrt(deg))\nA_norm = Dinv_sqrt @ A_norm @ Dinv_sqrt\n\n\n# Compute eigenvalues and eigenvectors\nevals, evecs = np.linalg.eigh(A_norm.toarray())\n\n\n# Display eigenvalues\npd.DataFrame({\n    \"Eigenvalue\": evals\n}).T.style.background_gradient(cmap='cividis', axis = 1).set_caption(\"Eigenvalues of the normalized adjacency matrix\")\n\n\n\n\n\n\nTable 2: Eigenvalues of the normalized adjacency matrix\n\n\n\n\n\n \n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n\nEigenvalue\n-0.400000\n-0.362289\n-0.362289\n-0.250000\n-0.250000\n-0.250000\n-0.250000\n-0.250000\n-0.250000\n-0.100000\n-0.030903\n-0.030903\n0.893192\n0.893192\n1.000000\n\n\n\n\n\n\n\n\nThe largest eigenvalue is always 1 for a normalized adjacency matrix. The associated eigenvector gives the stationary distribution.\n\n\n\n\nlambda_2 = -np.sort(-evals)[1]  # Second largest eigenvalue\ntau = 1 / (1 - lambda_2)  # Relaxation time\nprint(f\"The second largest eigenvalue is {lambda_2:.4f}\")\nprint(f\"The relaxation time of the random walk is {tau:.4f}\")\n\nThe second largest eigenvalue is 0.8932\nThe relaxation time of the random walk is 9.3626\n\n\n\n\n\nLet’s verify we can compute multi-step transitions using eigenvalues:\n\nt = 5\nx_0 = np.zeros(g.vcount())\nx_0[0] = 1\n\n# Method 1: Using eigenvalues and eigenvectors\nQ_L = np.diag(1.0/np.sqrt(deg)) @ evecs\nQ_R = np.diag(np.sqrt(deg)) @ evecs\nx_t_spectral = x_0 @ Q_L @ np.diag(evals**t) @ Q_R.T\n\n# Method 2: Using power iteration\nP_matrix = sparse.diags(1/deg) @ g.get_adjacency_sparse()\nx_t_power = x_0.copy()\nfor i in range(t):\n    x_t_power = x_t_power @ P_matrix\n\npd.DataFrame({\n    \"Spectral method\": x_t_spectral.flatten(),\n    \"Power iteration\": x_t_power.flatten()\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Comparison of Spectral and Power Iteration Methods\")\n\n\n\n\n\n\nTable 3: Comparison of Spectral and Power Iteration Methods\n\n\n\n\n\n \nSpectral method\nPower iteration\n\n\n\n\n0\n0.138150\n0.138150\n\n\n1\n0.138670\n0.138670\n\n\n2\n0.126020\n0.126020\n\n\n3\n0.126020\n0.126020\n\n\n4\n0.126020\n0.126020\n\n\n5\n0.042000\n0.042000\n\n\n6\n0.026300\n0.026300\n\n\n7\n0.018400\n0.018400\n\n\n8\n0.018400\n0.018400\n\n\n9\n0.018400\n0.018400\n\n\n10\n0.042000\n0.042000\n\n\n11\n0.067420\n0.067420\n\n\n12\n0.037400\n0.037400\n\n\n13\n0.037400\n0.037400\n\n\n14\n0.037400\n0.037400\n\n\n\n\n\n\n\n\n\n\n\n\nRandom walks converge to stationary distributions proportional to node degrees\nCommunity structure is revealed through short-term vs. long-term behavior\nSpectral properties control convergence speed and mixing times\nImplementation requires careful attention to matrix operations and numerical stability\nApplications span centrality measures, community detection, and network characterization\n\nThis foundation prepares you to apply random walks to real-world network analysis problems and understand their connections to other network science techniques.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Coding - Random Walks"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#introduction-from-theory-to-practice",
    "href": "m07-random-walks/02-coding.html#introduction-from-theory-to-practice",
    "title": "Coding - Random Walks",
    "section": "",
    "text": "In the previous section, we learned the theoretical foundations of random walks. Now we’ll implement these concepts in Python and explore their practical applications for network analysis.\nRecall that a random walk is a process where we: 1. Start at a node i 2. Randomly choose an edge to traverse to a neighbor node j 3. Repeat until we’ve taken T steps\nLet’s see how this simple process can reveal deep insights about network structure.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Coding - Random Walks"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#implementing-random-walks-in-python",
    "href": "m07-random-walks/02-coding.html#implementing-random-walks-in-python",
    "title": "Coding - Random Walks",
    "section": "",
    "text": "We’ll start by implementing random walks on a simple graph of five nodes.\n\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n\n\n\n\n\n\n\n\n\n\n\nA random walk is characterized by the transition probabilities between nodes:\nP_{ij} = \\frac{A_{ij}}{k_i}\nLet’s compute and visualize the transition probability matrix \\mathbf{P}:\n\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] &gt; 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i-&gt;ij\", A, 1 / k)\n\n\nprint(\"Transition probability matrix:\\n\", P)\n\nTransition probability matrix:\n [[0.         0.33333333 0.33333333 0.33333333 0.        ]\n [0.5        0.         0.         0.5        0.        ]\n [0.33333333 0.         0.         0.33333333 0.33333333]\n [0.25       0.25       0.25       0.         0.25      ]\n [0.         0.         0.5        0.5        0.        ]]\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n\n\n\n\n\n\n\n\nEach row and column of \\mathbf{P} corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\n\n\n\nNow let’s simulate a random walk step by step. We represent the position of the walker using a vector \\mathbf{x} with five elements, where we mark the current node with 1 and others as 0:\n\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n\nInitial position of the walker:\n [1 0 0 0 0]\n\n\nThis vector representation lets us compute transition probabilities to other nodes:\n\\mathbf{x} \\mathbf{P}\n\nprobs = x @ P\nprint(\"Transition probabilities from current position:\\n\", probs)\n\nTransition probabilities from current position:\n [0.         0.33333333 0.33333333 0.33333333 0.        ]\n\n\nWe can then draw the next node based on these probabilities:\n\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position after one step:\\n\", x)\n\nPosition after one step:\n [0 1 0 0 0]\n\n\n\n\n\nWrite the following function to simulate the random walk for a given number of steps and return the x for each step:\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n    n_nodes = A.shape[0]\n\n    # Initialize position\n    x = np.zeros(n_nodes)\n    x[0] = 1  # Start at node 0\n\n    positions = [x.copy()]\n\n    for step in range(n_steps):\n        probs = x @ P\n        next_node = ... # fill in the missing code\n        x[:] = 0\n        x[next_node] = 1\n        positions.append(x.copy())\n\n    return np.array(positions)\n\n# Test the function\nwalk_positions = random_walk(A, 10)\nprint(\"Walker positions over 10 steps:\")\nprint(walk_positions)",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Coding - Random Walks"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#expected-behavior-of-random-walks",
    "href": "m07-random-walks/02-coding.html#expected-behavior-of-random-walks",
    "title": "Coding - Random Walks",
    "section": "",
    "text": "What is the expected position of the walker after multiple steps? For the first step from initial position \\mathbf{x}(0):\n\\mathbb{E}[\\mathbf{x}(1)] = \\mathbf{x}(0) \\mathbf{P}\n\nx_0 = np.array([1, 0, 0, 0, 0])\nx_1 = x_0 @ P\nprint(\"Expected position after one step:\\n\", x_1)\n\nExpected position after one step:\n [0.         0.33333333 0.33333333 0.33333333 0.        ]\n\n\nFor the second step:\n\\mathbb{E}[\\mathbf{x}(2)] = \\mathbf{x}(0) \\mathbf{P}^2\n\nx_2 = x_1 @ P\nprint(\"Expected position after two steps:\\n\", x_2)\n\nExpected position after two steps:\n [0.36111111 0.08333333 0.08333333 0.27777778 0.19444444]\n\n\nIn general, the expected position at time t is:\n\\mathbb{E}[\\mathbf{x}(t)] = \\mathbf{x}(0) \\mathbf{P}^t\n\n\n\nWrite a function to compute the expected position of the walker at time t:\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The expected position at time t.\n    \"\"\"\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n\n    # Compute P^t\n    P_t = ... # fill in the missing code\n\n    return x_0 @ P_t\n\n# Test the function\nx_0 = np.array([1, 0, 0, 0, 0])\nfor t in [1, 2, 5, 10]:\n    x_t = expected_position(A, x_0, t)\n    print(f\"Expected position at time {t}: {x_t}\")\n\n\n\nPlot each element of \\mathbf{x}(t) as a function of t for t=0,1,2,\\ldots, 100. Try different initial positions and compare the results!\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_convergence(A, x_0, max_t=100):\n    \"\"\"Plot the convergence to stationary distribution.\"\"\"\n\n    k = np.sum(A, axis=1)\n    P = A / k[:, np.newaxis]\n    n_nodes = A.shape[0]\n\n    # Compute expected positions over time\n    positions = []\n    x_t = x_0.copy()\n    positions.append(x_t.copy())\n\n    for t in range(max_t):\n        x_t = x_t @ P\n        positions.append(x_t.copy())\n\n    positions = np.array(positions)\n\n    # Plot\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    for i in range(n_nodes):\n        ax.plot(range(max_t + 1), positions[:, i], label=f\"Node {i}\", linewidth=2)\n\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Probability\")\n    ax.set_title(\"Random Walk Convergence to Stationary Distribution\")\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    plt.show()\n\n# Test with different starting positions\nstarting_positions = [\n    [1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 0, 0, 1]\n]\n\nfor i, x_0 in enumerate(starting_positions):\n    print(f\"\\nStarting from node {np.argmax(x_0)}:\")\n    plot_convergence(A, np.array(x_0))\n\n\nStarting from node 0:\n\n\n\n\n\n\n\n\n\n\nStarting from node 1:\n\n\n\n\n\n\n\n\n\n\nStarting from node 4:",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Coding - Random Walks"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#practical-demonstration-with-real-networks",
    "href": "m07-random-walks/02-coding.html#practical-demonstration-with-real-networks",
    "title": "Coding - Random Walks",
    "section": "",
    "text": "Let’s demonstrate random walks on a more complex network structure.\n\nimport igraph as ig\nimport numpy as np\n\n# Create a network with two communities\nedge_list = []\nfor i in range(5):\n    for j in range(i+1, 5):\n        edge_list.append((i, j))\n        edge_list.append((i+5, j+5))\nedge_list.append((0, 6))\n\ng = ig.Graph(edge_list)\nig.plot(g, vertex_size=20, vertex_label=np.arange(g.vcount()))\n\n\n\n\n\n\n\n\n\n\nThe transition probability matrix \\mathbf{P} is:\n\nimport scipy.sparse as sparse\n\nA = g.get_adjacency_sparse()\ndeg = np.array(A.sum(axis=1)).flatten()\nDinv = sparse.diags(1/deg)\nP = Dinv @ A\n\nLet’s compute the stationary distribution using the power method:\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.zeros(g.vcount())\nx[1] = 1 # Start from node 1\nT = 100\nxt = []\nfor t in range(T):\n    x = x.reshape(1, -1) @ P\n    xt.append(x)\n\nxt = np.vstack(xt) # Stack the results vertically\n\nfig, ax = plt.subplots(figsize=(10, 6))\npalette = sns.color_palette().as_hex()\nfor i in range(g.vcount()):\n    sns.lineplot(x=range(T), y=xt[:, i], label=f\"Node {i}\", ax=ax, color=palette[i % len(palette)])\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Probability\")\nax.set_title(\"Stationary distribution of a random walk\")\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWe observe three key features: 1. The distribution oscillates with decaying amplitude before converging 2. Nodes of the same degree converge to the same stationary probability 3. Nodes with higher degree have higher stationary probability\nLet’s verify this by comparing with the theoretical stationary distribution:\n\nimport pandas as pd\n\nn_edges = np.sum(deg) / 2\nexpected_stationary_dist = deg / (2 * n_edges)\n\npd.DataFrame({\n    \"Expected stationary distribution\": expected_stationary_dist,\n    \"Observed stationary distribution\": xt[-1].flatten()\n}).style.format(\"{:.4f}\").set_caption(\"Comparison of Expected and Observed Stationary Distributions\").background_gradient(cmap='cividis', axis=None)\n\n\n\n\n\n\nTable 1: Comparison of Expected and Observed Stationary Distributions\n\n\n\n\n\n \nExpected stationary distribution\nObserved stationary distribution\n\n\n\n\n0\n0.1190\n0.1191\n\n\n1\n0.0952\n0.0953\n\n\n2\n0.0952\n0.0953\n\n\n3\n0.0952\n0.0953\n\n\n4\n0.0952\n0.0953\n\n\n5\n0.0952\n0.0952\n\n\n6\n0.1190\n0.1190\n\n\n7\n0.0952\n0.0952\n\n\n8\n0.0952\n0.0952\n\n\n9\n0.0952\n0.0952",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Coding - Random Walks"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#community-structure-detection",
    "href": "m07-random-walks/02-coding.html#community-structure-detection",
    "title": "Coding - Random Walks",
    "section": "",
    "text": "Random walks can capture community structure. Let’s explore this with a ring of cliques:\n\nimport networkx as nx\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nn_cliques = 3\nn_nodes_per_clique = 5\n\nG = nx.ring_of_cliques(n_cliques, n_nodes_per_clique)\ng = igraph.Graph().Adjacency(nx.to_numpy_array(G).tolist()).as_undirected()\nmembership = np.repeat(np.arange(n_cliques), n_nodes_per_clique)\n\ncolor_map = [sns.color_palette()[i] for i in membership]\nigraph.plot(g, vertex_size=20, vertex_color=color_map)\n\n\n\n\n\n\n\n\n\n\nLet’s compute the expected position over time and visualize how the walker explores communities:\n\nfrom scipy import sparse\n\n# Get the adjacency matrix and degree\nA = g.get_adjacency_sparse()\nk = np.array(g.degree())\n\n# Compute the transition matrix efficiently using scipy.sparse\nP = sparse.diags(1 / k) @ A\n\n\n# Compute the expected position from node 2 over 300 steps\nx_t = np.zeros(g.vcount())\nx_t[2] = 1\nx_list = [x_t]\nfor t in range(300):\n    x_t = x_t @ P\n    x_list.append(x_t)\nx_list = np.array(x_list)\n\n\n# Plot the network at different time steps\ncmap = sns.color_palette(\"viridis\", as_cmap=True)\n\nsns.set_style('white')\nsns.set(font_scale=1.2)\nsns.set_style('ticks')\n\nfig, axes = plt.subplots(figsize=(15,10), ncols = 3, nrows = 2)\n\nt_list = [0, 1, 3, 5, 10, 299]\nfor i, t in enumerate(t_list):\n    igraph.plot(g, vertex_size=20, vertex_color=[cmap(x_list[t][j] / np.max(x_list[t])) for j in range(g.vcount())], target = axes[i//3][i%3])\n    axes[i//3][i%3].set_title(f\"$t$ = {t}\", fontsize = 25)\n\n\n\n\n\n\n\n\nThe color intensity represents the probability of the walker being at each node. Notice how: - Initially, the walker is concentrated at the starting node - It gradually diffuses within its community - Only later does it spread to other communities - Eventually, it reaches the stationary distribution\nThis temporal behavior reveals the community structure!",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Coding - Random Walks"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#mixing-time-and-spectral-analysis",
    "href": "m07-random-walks/02-coding.html#mixing-time-and-spectral-analysis",
    "title": "Coding - Random Walks",
    "section": "",
    "text": "Let’s demonstrate the spectral analysis of random walks:\n\n# Using the two-clique network from before\nA_norm = g.get_adjacency_sparse()\ndeg = np.array(A_norm.sum(axis=1)).flatten()\n\n# Normalized adjacency matrix\nDinv_sqrt = sparse.diags(1.0/np.sqrt(deg))\nA_norm = Dinv_sqrt @ A_norm @ Dinv_sqrt\n\n\n# Compute eigenvalues and eigenvectors\nevals, evecs = np.linalg.eigh(A_norm.toarray())\n\n\n# Display eigenvalues\npd.DataFrame({\n    \"Eigenvalue\": evals\n}).T.style.background_gradient(cmap='cividis', axis = 1).set_caption(\"Eigenvalues of the normalized adjacency matrix\")\n\n\n\n\n\n\nTable 2: Eigenvalues of the normalized adjacency matrix\n\n\n\n\n\n \n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n\nEigenvalue\n-0.400000\n-0.362289\n-0.362289\n-0.250000\n-0.250000\n-0.250000\n-0.250000\n-0.250000\n-0.250000\n-0.100000\n-0.030903\n-0.030903\n0.893192\n0.893192\n1.000000\n\n\n\n\n\n\n\n\nThe largest eigenvalue is always 1 for a normalized adjacency matrix. The associated eigenvector gives the stationary distribution.\n\n\n\n\nlambda_2 = -np.sort(-evals)[1]  # Second largest eigenvalue\ntau = 1 / (1 - lambda_2)  # Relaxation time\nprint(f\"The second largest eigenvalue is {lambda_2:.4f}\")\nprint(f\"The relaxation time of the random walk is {tau:.4f}\")\n\nThe second largest eigenvalue is 0.8932\nThe relaxation time of the random walk is 9.3626\n\n\n\n\n\nLet’s verify we can compute multi-step transitions using eigenvalues:\n\nt = 5\nx_0 = np.zeros(g.vcount())\nx_0[0] = 1\n\n# Method 1: Using eigenvalues and eigenvectors\nQ_L = np.diag(1.0/np.sqrt(deg)) @ evecs\nQ_R = np.diag(np.sqrt(deg)) @ evecs\nx_t_spectral = x_0 @ Q_L @ np.diag(evals**t) @ Q_R.T\n\n# Method 2: Using power iteration\nP_matrix = sparse.diags(1/deg) @ g.get_adjacency_sparse()\nx_t_power = x_0.copy()\nfor i in range(t):\n    x_t_power = x_t_power @ P_matrix\n\npd.DataFrame({\n    \"Spectral method\": x_t_spectral.flatten(),\n    \"Power iteration\": x_t_power.flatten()\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Comparison of Spectral and Power Iteration Methods\")\n\n\n\n\n\n\nTable 3: Comparison of Spectral and Power Iteration Methods\n\n\n\n\n\n \nSpectral method\nPower iteration\n\n\n\n\n0\n0.138150\n0.138150\n\n\n1\n0.138670\n0.138670\n\n\n2\n0.126020\n0.126020\n\n\n3\n0.126020\n0.126020\n\n\n4\n0.126020\n0.126020\n\n\n5\n0.042000\n0.042000\n\n\n6\n0.026300\n0.026300\n\n\n7\n0.018400\n0.018400\n\n\n8\n0.018400\n0.018400\n\n\n9\n0.018400\n0.018400\n\n\n10\n0.042000\n0.042000\n\n\n11\n0.067420\n0.067420\n\n\n12\n0.037400\n0.037400\n\n\n13\n0.037400\n0.037400\n\n\n14\n0.037400\n0.037400\n\n\n\n\n\n\n\n\n\n\n\n\nRandom walks converge to stationary distributions proportional to node degrees\nCommunity structure is revealed through short-term vs. long-term behavior\nSpectral properties control convergence speed and mixing times\nImplementation requires careful attention to matrix operations and numerical stability\nApplications span centrality measures, community detection, and network characterization\n\nThis foundation prepares you to apply random walks to real-world network analysis problems and understand their connections to other network science techniques.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Coding - Random Walks"
    ]
  },
  {
    "objectID": "m07-random-walks/amida-kuji.html",
    "href": "m07-random-walks/amida-kuji.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Ladder Lottery\n\n\n\n\n\n\nLadder Lottery\n\n\n\n:class: tip\nLadder Lottery is a fun East Asian game, also known as “鬼腳圖” (Guijiaotu) in Chinese, “阿弥陀籤” (Amida-kuzi) in Japanese, “사다리타기” (Sadaritagi) in Korean, and “Ladder Lottery” in English. The game is played as follows: 1. A player is given a board with a set of vertical lines. 2. The player chooses a line and starts to move along the line 3. When hitting a horizontal line, the player must move along the horizontal line and then continue to move along the next vertical line. 4. The player wins if the player can hit a marked line at the bottom of the board. 5. You cannot see the horizontal lines in advance!\nPlay the {{ ‘Ladder Lottery Game! 🎮✨’.replace(‘BASE_URL’, base_url) }} and try to answer the following questions:\n\nIs tehre a strategy to maximize the probability of winning?\nHow does the probability of winning change as the number of horizontal lines increases?"
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html",
    "href": "m07-random-walks/random-walks-code.html",
    "title": "Random Walks in Python",
    "section": "",
    "text": "We will simulate random walks on a simple graph of five nodes as follows.\n\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n\nA random walk is characterized by the transition probabilities between nodes.\n\nP_{ij} = \\frac{A_{ij}}{k_i}\n\nLet us first compute the transition probabilities and store them in a matrix, \\mathbf{P}.\n\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] &gt; 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i-&gt;ij\", A, 1 / k)\n\n\nprint(\"Transition probability matrix:\\n\", P)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n\nEach row and column of \\mathbf{P} corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\nNow, let us simulate a random walk on this graph. We represent a position of the walker by a vector, \\mathbf{x}, with five elements, each of which represents a node. We mark the node that the walker is currently at by 1 and others as 0.\n\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n\nThis vector representation is convenient to get the probabilities of transitions to other nodes from the current node:\n\n\\mathbf{x} \\mathbf{P}\n\nwhich is translated into the following code:\n\nprobs = x @ P\nprint(\"Position of the walker after one step:\\n\", probs)\n\nWe can then draw the next node based on the probabilities\n\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position of the walker after one step:\\n\", x)\n\nBy repeating this process, we can simulate the random walk.\n\n\nWrite the following function to simulate the random walk for a given number of steps and return the x for each step.\n\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x (np.ndarray): The initial position of the walker.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass"
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html#simulating-random-walks",
    "href": "m07-random-walks/random-walks-code.html#simulating-random-walks",
    "title": "Random Walks in Python",
    "section": "",
    "text": "We will simulate random walks on a simple graph of five nodes as follows.\n\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n\nA random walk is characterized by the transition probabilities between nodes.\n\nP_{ij} = \\frac{A_{ij}}{k_i}\n\nLet us first compute the transition probabilities and store them in a matrix, \\mathbf{P}.\n\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] &gt; 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i-&gt;ij\", A, 1 / k)\n\n\nprint(\"Transition probability matrix:\\n\", P)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n\nEach row and column of \\mathbf{P} corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\nNow, let us simulate a random walk on this graph. We represent a position of the walker by a vector, \\mathbf{x}, with five elements, each of which represents a node. We mark the node that the walker is currently at by 1 and others as 0.\n\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n\nThis vector representation is convenient to get the probabilities of transitions to other nodes from the current node:\n\n\\mathbf{x} \\mathbf{P}\n\nwhich is translated into the following code:\n\nprobs = x @ P\nprint(\"Position of the walker after one step:\\n\", probs)\n\nWe can then draw the next node based on the probabilities\n\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position of the walker after one step:\\n\", x)\n\nBy repeating this process, we can simulate the random walk.\n\n\nWrite the following function to simulate the random walk for a given number of steps and return the x for each step.\n\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x (np.ndarray): The initial position of the walker.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass"
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html#expected-behavior-of-random-walks",
    "href": "m07-random-walks/random-walks-code.html#expected-behavior-of-random-walks",
    "title": "Random Walks in Python",
    "section": "2 Expected behavior of random walks",
    "text": "2 Expected behavior of random walks\nWhat is the expected position of the walker after multiple steps? It is easy to compute the expected position of the walker after one step from initial position x(0):\n\n\\mathbb{E}[x(1)] = x(0) P\n\nwhere x(t) is the probability distribution of the walker at time t. In Python, the expected position of the walker at time t=1 is given by\n\nx_0 = np.array([1, 0, 0, 0, 0])\nx_1 = x_0 @ P\nprint(\"Expected position of the walker after one step:\\n\", x_1)\n\nFor the second step, the expected position of the walker is given by\n\n\\mathbb{E}[x(2)] = \\mathbb{E}[x(1) P] = \\mathbb{E}[x(0) P] P = x(0) P^2\n\nIn other words,\n\nx_2 = x_1 @ P\nprint(\"Expected position of the walker after two steps:\\n\", x_2)\n\nFollowing the same argument, the expected position of the walker at time t is given by\n\n\\mathbb{E}[x(t)] = x(0) P^t\n\n\nExercise 02\nWrite a function to compute the expected position of the walker at time t using the above formula:\n\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n    \"\"\"\n    # Your code here\n    pass\n\n\n\nExercise 03\nPlot each element of x(t) as a function of t for t=0,1,2,\\ldots, 1000. Try different initial positions and compare the results!\nSteps: 1. Define the initial position of the walker. 2. Compute the expected position of the walker at time t using the function you wrote above. 3. Draw a line for each element of x(t), totalling 5 lines. 4. Create multiple such plots for different initial positions and compare them."
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html#community-structure",
    "href": "m07-random-walks/random-walks-code.html#community-structure",
    "title": "Random Walks in Python",
    "section": "3 Community structure",
    "text": "3 Community structure\nRandom walks can capture community structure of a network. To see this, let us consider a network of a ring of cliques.\n\nimport networkx as nx\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nn_cliques = 3\nn_nodes_per_clique = 5\n\nG = nx.ring_of_cliques(n_cliques, n_nodes_per_clique)\ng = igraph.Graph().Adjacency(nx.to_numpy_array(G).tolist()).as_undirected()\nmembership = np.repeat(np.arange(n_cliques), n_nodes_per_clique)\n\ncolor_map = [sns.color_palette()[i] for i in membership]\nigraph.plot(g, vertex_size=20, vertex_color=color_map)\n\nLet us compute the expected position of the walker after 1 to 10 steps.\nCompute the transition matrix:\n\n:tags: [hide-cell]\nfrom scipy import sparse\n\n# Get the adjacency matrix and degree\nA = g.get_adjacency_sparse()\nk = np.array(g.degree())\n\n# This is an efficient way to compute the transition matrix\n# using scipy.sparse\nP = sparse.diags(1 / k) @ A\n\nCompute the expected position of the walker after 1 to 300 steps:\n\n:tags: [hide-cell]\n\nx_t = np.zeros(g.vcount())\nx_t[2] = 1\nx_list = [x_t]\nfor t in range(300):\n    x_t = x_t @ P\n    x_list.append(x_t)\nx_list = np.array(x_list)\n\nPlot the expected position of the walker at each step:\n\n:tags: [hide-input]\n\ncmap = sns.color_palette(\"viridis\", as_cmap=True)\n\nsns.set_style('white')\nsns.set(font_scale=1.2)\nsns.set_style('ticks')\n\nfig, axes = plt.subplots(figsize=(15,10), ncols = 3, nrows = 2)\n\nt_list = [0, 1, 3, 5, 10, 299]\nfor i, t in enumerate(t_list):\n    igraph.plot(g, vertex_size=20, vertex_color=[cmap(x_list[t][j] / np.max(x_list[t])) for j in range(g.vcount())], target = axes[i//3][i%3])\n    axes[i//3][i%3].set_title(f\"$t$ = {t}\", fontsize = 25)\n\nwhere the color of each node represents the probability of the walker being at that node.\nAn important observation is that the walker spends more time in the clique that it started from and then diffuse to others. Thus, the position of the walker before reaching the steady state tells us the community structure of the network."
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html#exercise-04",
    "href": "m07-random-walks/random-walks-code.html#exercise-04",
    "title": "Random Walks in Python",
    "section": "4 Exercise 04",
    "text": "4 Exercise 04\n\nGenerate a network of 100 nodes with 4 communities using a stochastic block model, with inter-community edge probability 0.05 and intra-community edge probability 0.2. Then, compute the expected position of the walker starting from node zero after x steps. Plot the results for x = 0, 5, 10, 1000.\nIncrease the inter-community edge probability to 0.15 and repeat the simulation. Compare the results with the previous simulation."
  },
  {
    "objectID": "m08-embedding/02-coding.html",
    "href": "m08-embedding/02-coding.html",
    "title": "Embedding Methods: Implementation and Practice",
    "section": "",
    "text": "In this section, we implement the embedding methods discussed in the concepts section.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#spectral-embedding",
    "href": "m08-embedding/02-coding.html#spectral-embedding",
    "title": "Embedding Methods: Implementation and Practice",
    "section": "1 Spectral Embedding",
    "text": "1 Spectral Embedding\n\nExample: Spectral Embedding with Adjacency Matrix\nLet us demonstrate spectral embedding with a simple example using the karate club network.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a small example network\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).toarray()\nlabels = np.unique([d[1]['club'] for d in G.nodes(data=True)], return_inverse=True)[1]\ncmap = sns.color_palette()\nnx.draw(G, with_labels=False, node_color=[cmap[i] for i in labels])\n\n\n:tags: [hide-input]\n\n# Compute the spectral decomposition\neigvals, eigvecs = np.linalg.eig(A)\n\n# Find the top d eigenvectors\nd = 2\nsorted_indices = np.argsort(eigvals)[::-1][:d]\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n# Plot the results\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Spectral Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nInterestingly, the first eigenvector corresponds to the eigencentrality of the network, representing the centrality of the nodes. The second eigenvector captures the community structure of the network, clearly separating the two communities in the network.\n\n\nExample: Modularity Embedding\nWe can use the modularity matrix to generate a low-dimensional embedding of the network.\n\n:tags: [hide-input]\n\ndeg = np.sum(A, axis=1)\nm = np.sum(deg) / 2\nQ = A - np.outer(deg, deg) / (2 * m)\nQ/= 2*m\n\neigvals, eigvecs = np.linalg.eig(Q)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(-eigvals)[:d]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Modularity Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\n\n\nExample: Laplacian Eigenmap\nLet us first compute the Laplacian matrix and its eigenvectors.\n\n:tags: [hide-input]\n\nD = np.diag(np.sum(A, axis=1))\nL = D - A\n\neigvals, eigvecs = np.linalg.eig(L)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(eigvals)[1:d+1]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nThe eigenvectors corresponding to the d smallest eigenvalues are:\n\n:tags: [hide-input]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Laplacian Eigenmap')\nax.set_xlabel('Eigenvector 2')\nax.set_ylabel('Eigenvector 3')\nplt.show()",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#neural-embedding-with-word2vec",
    "href": "m08-embedding/02-coding.html#neural-embedding-with-word2vec",
    "title": "Embedding Methods: Implementation and Practice",
    "section": "2 Neural Embedding with word2vec",
    "text": "2 Neural Embedding with word2vec\n\nExample: word2vec with Text\nTo showcase the effectiveness of word2vec, let’s walk through an example using the gensim library.\n\nimport gensim\nimport gensim.downloader\nfrom gensim.models import Word2Vec\n\n# Load pre-trained word2vec model from Google News\nmodel = gensim.downloader.load('word2vec-google-news-300')\n\nOur first example is to find the words most similar to king.\n\n# Example usage\nword = \"king\"\nsimilar_words = model.most_similar(word)\nprint(f\"Words most similar to '{word}':\")\nfor similar_word, similarity in similar_words:\n    print(f\"{similar_word}: {similarity:.4f}\")\n\nA cool (yet controversial) application of word embeddings is analogy solving. Let us consider the following puzzle:\n\nman is to woman as king is to ___ ?\n\nWe can use word embeddings to solve this puzzle.\n\n# We solve the puzzle by\n#\n#  vec(king) - vec(man) + vec(woman)\n#\n# To solve this, we use the model.most_similar function, with positive words being \"king\" and \"woman\" (additive), and negative words being \"man\" (subtractive).\n#\nmodel.most_similar(positive=['woman', \"king\"], negative=['man'], topn=5)\n\nThe last example is to visualize the word embeddings.\n\n:tags: [hide-input]\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ncountries = ['Germany', 'France', 'Italy', 'Spain', 'Portugal', 'Greece']\ncapital_words = ['Berlin', 'Paris', 'Rome', 'Madrid', 'Lisbon', 'Athens']\n\n# Get the word embeddings for the countries and capitals\ncountry_embeddings = np.array([model[country] for country in countries])\ncapital_embeddings = np.array([model[capital] for capital in capital_words])\n\n# Compute the PCA\npca = PCA(n_components=2)\nembeddings = np.vstack([country_embeddings, capital_embeddings])\nembeddings_pca = pca.fit_transform(embeddings)\n\n# Create a DataFrame for seaborn\ndf = pd.DataFrame(embeddings_pca, columns=['PC1', 'PC2'])\ndf['Label'] = countries + capital_words\ndf['Type'] = ['Country'] * len(countries) + ['Capital'] * len(capital_words)\n\n# Plot the data\nplt.figure(figsize=(12, 10))\n\n# Create a scatter plot with seaborn\nscatter_plot = sns.scatterplot(data=df, x='PC1', y='PC2', hue='Type', style='Type', s=200, palette='deep', markers=['o', 's'])\n\n# Annotate the points\nfor i in range(len(df)):\n    plt.text(df['PC1'][i], df['PC2'][i] + 0.08, df['Label'][i], fontsize=12, ha='center', va='bottom',\n             bbox=dict(facecolor='white', edgecolor='none', alpha=0.8))\n\n# Draw arrows between countries and capitals\nfor i in range(len(countries)):\n    plt.arrow(df['PC1'][i], df['PC2'][i], df['PC1'][i + len(countries)] - df['PC1'][i], df['PC2'][i + len(countries)] - df['PC2'][i],\n              color='gray', alpha=0.6, linewidth=1.5, head_width=0.02, head_length=0.03)\n\nplt.legend(title='Type', title_fontsize='13', fontsize='11')\nplt.title('PCA of Country and Capital Word Embeddings', fontsize=16)\nplt.xlabel('Principal Component 1', fontsize=14)\nplt.ylabel('Principal Component 2', fontsize=14)\nax = plt.gca()\nax.set_axis_off()\n\nWe can see that word2vec places the words representing countries close to each other and so do the words representing their capitals. The country-capital relationship is also roughly preserved, e.g., Germany-Berlin vector is roughly parallel to France-Paris vector.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#graph-embedding-with-word2vec",
    "href": "m08-embedding/02-coding.html#graph-embedding-with-word2vec",
    "title": "Embedding Methods: Implementation and Practice",
    "section": "3 Graph Embedding with word2vec",
    "text": "3 Graph Embedding with word2vec\n\nExercise 01: Implement DeepWalk\nIn this exercise, we implement DeepWalk step by step.\n\nStep 1: Data preparation\nWe will use the karate club network as an example.\nLoad the data\n\n:tags: [hide-input]\n\nimport igraph\nimport networkx as nx\nimport numpy as np\nimport seaborn as sns\n\ng = igraph.Graph.Famous(\"Zachary\")\nA = g.get_adjacency_sparse()\n\n# Add the community labels to the nodes for visualization\ng.vs[\"label\"] = np.unique([d[1]['club'] for d in nx.karate_club_graph().nodes(data=True)], return_inverse=True)[1]\n\npalette = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[palette[label] for label in g.vs[\"label\"]], bbox=(300, 300))\n\n\n\nStep 2: Generate random walks\nNext, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network. Let us first implement a function to sample random walks from a given network.\n\ndef random_walk(net, start_node, walk_length):\n    # Initialize the walk with the starting node\n    walk = [start_node]\n\n    # Continue the walk until the desired length is reached\n    while len(walk) &lt; walk_length:\n        # Get the current node (the last node in the walk)\n        cur = walk[-1]\n\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n\n        # If the current node has neighbors, randomly choose one and add it to the walk\n        if len(cur_nbrs) &gt; 0:\n            walk.append(np.random.choice(cur_nbrs))\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    # Return the generated walk\n    return walk\n\nGenerate 10 random walks of length 50 starting from each node.\n\nn_nodes = g.vcount()\nn_walkers_per_node = 10\nwalk_length = 50\nwalks = []\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(random_walk(A, i, walk_length))\n\n\n\nStep 3: Train the word2vec model\nThen, we feed the random walks to the word2vec model.\n\nfrom gensim.models import Word2Vec\n\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\nHere,\n\nvector_size is the dimension of the embedding vectors.\nwindow indicates the maximum distance between a word and its context words. For example, in the random walk [0, 1, 2, 3, 4, 5, 6, 7], the context words of node 2 are [0, 1, 3, 4, 5] when window=3.\nmin_count is the minimum number of times a word must appear in the training data to be included in the vocabulary.\nsg=1 indicates that we are using the skip-gram model.\nhs=1 indicates that we are using hierarchical softmax.\n\nNow, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the wv attribute. The embedding of node i is given by model.wv[i].\n\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\nembedding is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.\nPrint the first 3 nodes\n\n:tags: [hide-input]\n\nembedding[:3]\n\nLet’s visualize the node embeddings using UMAP.\n\n:tags: [hide-input]\nimport umap\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource, HoverTool\n\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nshow(p)\n\n\n\nStep 4: Clustering\nOne of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as K-means and Gaussian mixture model. Let’s see what we can get from the node embeddings.\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Determine the optimal number of clusters using the silhouette score\ndef Kmeans_with_silhouette(embedding, n_clusters_range=(2, 10)):\n    silhouette_scores = []\n\n    # Iterate over a range of cluster numbers from 2 to 9\n    for n_clusters in range(*n_clusters_range):\n        # Create a KMeans object with the current number of clusters\n        kmeans = KMeans(n_clusters=n_clusters)\n\n        # Fit the KMeans model to the embedding data\n        kmeans.fit(embedding)\n\n        # Calculate the silhouette score for the current clustering\n        score = silhouette_score(embedding, kmeans.labels_)\n\n        # Append the number of clusters and its corresponding silhouette score to the list\n        silhouette_scores.append((n_clusters, score))\n\n    # Find the number of clusters that has the highest silhouette score\n    optimal_n_clusters = max(silhouette_scores, key=lambda x: x[1])[0]\n\n    # Create a KMeans object with the optimal number of clusters\n    kmeans = KMeans(n_clusters=optimal_n_clusters)\n\n    # Fit the KMeans model to the embedding data with the optimal number of clusters\n    kmeans.fit(embedding)\n\n    # Return the labels (cluster assignments) for each data point\n    return kmeans.labels_\n\n\nimport seaborn as sns\nlabels = Kmeans_with_silhouette(embedding)\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500))\n\n\n\n\nExercise 02: Implement node2vec\nLet’s implement the biased random walk for node2vec\n\ndef node2vec_random_walk(net, start_node, walk_length, p, q):\n    \"\"\"\n    Sample a random walk starting from start_node.\n    \"\"\"\n    # Initialize the walk with the start_node\n    walk = [start_node]\n\n    # Continue the walk until it reaches the desired length\n    while len(walk) &lt; walk_length:\n        # Get the current node in the walk\n        cur = walk[-1]\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n        # Check if the current node has any neighbors\n        if len(cur_nbrs) &gt; 0:\n            # If the walk has just started, randomly choose the next node from the neighbors\n            if len(walk) == 1:\n                walk.append(np.random.choice(cur_nbrs))\n            else:\n                # Get the previous node in the walk\n                prev = walk[-2]\n                # Use the alias sampling method to choose the next node based on the bias parameters p and q\n                next_node = alias_sample(net, cur_nbrs, prev, p, q)\n                # Append the chosen next node to the walk\n                walk.append(next_node)\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    return walk\n\ndef alias_sample(net, neighbors, prev, p, q):\n    \"\"\"\n    Helper function to sample the next node in the walk.\n    \"\"\"\n    # Implement the logic to sample the next node based on the bias parameters p and q\n    # You can use the formula provided in the instructions to calculate the probabilities\n    # and then sample the next node accordingly.\n    # Initialize an empty list to store the unnormalized probabilities for each neighbor\n    unnormalized_probs = []\n\n    # Iterate over each neighbor of the current node\n    for neighbor in neighbors:\n        # If the neighbor is the same as the previous node in the walk\n        if neighbor == prev:\n            # Append the probability 1/p to the unnormalized probabilities list\n            unnormalized_probs.append(1 / p)\n        # If the neighbor is connected to the previous node in the walk\n        elif neighbor in net[prev].indices:\n            # Append the probability 1 to the unnormalized probabilities list\n            unnormalized_probs.append(1)\n        # If the neighbor is not connected to the previous node in the walk\n        else:\n            # Append the probability 1/q to the unnormalized probabilities list\n            unnormalized_probs.append(1 / q)\n\n    # Calculate the normalization constant by summing all unnormalized probabilities\n    norm_const = sum(unnormalized_probs)\n\n    # Normalize the probabilities by dividing each unnormalized probability by the normalization constant\n    normalized_probs = [float(prob) / norm_const for prob in unnormalized_probs]\n\n    # Randomly choose the next node from the neighbors based on the normalized probabilities\n    next_node = np.random.choice(neighbors, size=1, p=normalized_probs)[0]\n\n    # Return the chosen next node\n    return next_node\n\nNow, let’s set up the word2vec model for node2vec.\n\nwalks = []\np = 1\nq = 0.1\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(node2vec_random_walk(A, i, walk_length, p, q))\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\nNow, we extract the node embeddings from the word2vec model.\n\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\nLet’s visualize the node embeddings from node2vec.\n\n:tags: [hide-input]\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]],\n    name = [str(i) for i in range(n_nodes)]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nhover = HoverTool()\nhover.tooltips = [\n    (\"Name\", \"@name\"),\n    (\"Community\", \"@community\")\n]\np.add_tools(hover)\n\nshow(p)\n\nThe results for clustering are as follows:\n\nimport seaborn as sns\n\nlabels = Kmeans_with_silhouette(embedding)\n\n\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500), vertex_label=[\"%d\" %  d for d in  np.arange(n_nodes)])",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/spectral-embedding.html",
    "href": "m08-embedding/spectral-embedding.html",
    "title": "Spectral Embedding",
    "section": "",
    "text": "Networks are a high-dimensional discrete data that can be difficult to analyze with traditional machine learning methods that assume continuous and smooth data. Spectral embedding is a technique to embed networks into low-dimensional spaces.\nLet us approach the spectral embedding from the perspective of network compression. Suppose we have an adjacency matrix \\mathbf{A} of a network. The adjacency matrix is a high-dimensional data, i.e., a matrix has size N \\times N for a network of N nodes. We want to compress it into a lower-dimensional matrix \\mathbf{U} of size N \\times d for a user-defined small integer d &lt; N. A good \\mathbf{U} should preserve the network structure and thus can reconstruct the original data \\mathbf{A} as closely as possible. This leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nwhere:\n\n\\mathbf{U}\\mathbf{U}^\\top is the outer product of \\mathbf{U} and represents the reconstructed network.\n\\|\\cdot\\|_F is the Frobenius norm, which is the sum of the squares of the elements in the matrix.\nJ(\\mathbf{U}) is the loss function that measures the difference between the original network \\mathbf{A} and the reconstructed network \\mathbf{U}\\mathbf{U}^\\top.\n\nBy minimizing the Frobenius norm with respect to \\mathbf{U}, we obtain the best low-dimensional embedding of the network.\n\n\nLet us first understand the solution intuitively. Consider the spectral decomposition of \\mathbf{A}:\n\n\\mathbf{A} = \\sum_{i=1}^N \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top\n\nwhere \\lambda_i are weights and \\mathbf{u}_i are column vectors. Each term \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top is a rank-one matrix that captures a part of the network’s structure. The larger the weight \\lambda_i, the more important that term is in describing the network.\nTo compress the network, we can select the d terms with the largest weights \\lambda_i. By combining the corresponding \\mathbf{u}_i vectors into a matrix \\mathbf{U}, we obtain a good low-dimensional embedding of the network.\n\nFor a formal proof, please refer to the Appendix section.\n\n\n\nLet us demonstrate the results with a simple example as follows.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a small example network\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).toarray()\nlabels = np.unique([d[1]['club'] for d in G.nodes(data=True)], return_inverse=True)[1]\ncmap = sns.color_palette()\nnx.draw(G, with_labels=False, node_color=[cmap[i] for i in labels])\n\n\n:tags: [hide-input]\n\n# Compute the spectral decomposition\neigvals, eigvecs = np.linalg.eig(A)\n\n# Find the top d eigenvectors\nd = 2\nsorted_indices = np.argsort(eigvals)[::-1][:d]\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n# Plot the results\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Spectral Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nInterestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes. The second eigenvector captures the community structure of the network, clearly separating the two communities in the network."
  },
  {
    "objectID": "m08-embedding/spectral-embedding.html#network-compression",
    "href": "m08-embedding/spectral-embedding.html#network-compression",
    "title": "Spectral Embedding",
    "section": "",
    "text": "Networks are a high-dimensional discrete data that can be difficult to analyze with traditional machine learning methods that assume continuous and smooth data. Spectral embedding is a technique to embed networks into low-dimensional spaces.\nLet us approach the spectral embedding from the perspective of network compression. Suppose we have an adjacency matrix \\mathbf{A} of a network. The adjacency matrix is a high-dimensional data, i.e., a matrix has size N \\times N for a network of N nodes. We want to compress it into a lower-dimensional matrix \\mathbf{U} of size N \\times d for a user-defined small integer d &lt; N. A good \\mathbf{U} should preserve the network structure and thus can reconstruct the original data \\mathbf{A} as closely as possible. This leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nwhere:\n\n\\mathbf{U}\\mathbf{U}^\\top is the outer product of \\mathbf{U} and represents the reconstructed network.\n\\|\\cdot\\|_F is the Frobenius norm, which is the sum of the squares of the elements in the matrix.\nJ(\\mathbf{U}) is the loss function that measures the difference between the original network \\mathbf{A} and the reconstructed network \\mathbf{U}\\mathbf{U}^\\top.\n\nBy minimizing the Frobenius norm with respect to \\mathbf{U}, we obtain the best low-dimensional embedding of the network.\n\n\nLet us first understand the solution intuitively. Consider the spectral decomposition of \\mathbf{A}:\n\n\\mathbf{A} = \\sum_{i=1}^N \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top\n\nwhere \\lambda_i are weights and \\mathbf{u}_i are column vectors. Each term \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top is a rank-one matrix that captures a part of the network’s structure. The larger the weight \\lambda_i, the more important that term is in describing the network.\nTo compress the network, we can select the d terms with the largest weights \\lambda_i. By combining the corresponding \\mathbf{u}_i vectors into a matrix \\mathbf{U}, we obtain a good low-dimensional embedding of the network.\n\nFor a formal proof, please refer to the Appendix section.\n\n\n\nLet us demonstrate the results with a simple example as follows.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a small example network\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).toarray()\nlabels = np.unique([d[1]['club'] for d in G.nodes(data=True)], return_inverse=True)[1]\ncmap = sns.color_palette()\nnx.draw(G, with_labels=False, node_color=[cmap[i] for i in labels])\n\n\n:tags: [hide-input]\n\n# Compute the spectral decomposition\neigvals, eigvecs = np.linalg.eig(A)\n\n# Find the top d eigenvectors\nd = 2\nsorted_indices = np.argsort(eigvals)[::-1][:d]\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n# Plot the results\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Spectral Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nInterestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes. The second eigenvector captures the community structure of the network, clearly separating the two communities in the network."
  },
  {
    "objectID": "m08-embedding/spectral-embedding.html#modularity-embedding",
    "href": "m08-embedding/spectral-embedding.html#modularity-embedding",
    "title": "Spectral Embedding",
    "section": "2 Modularity embedding",
    "text": "2 Modularity embedding\nIn a similar vein, we can use the modularity matrix to generate a low-dimensional embedding of the network. Namely, let us define the modularity matrix \\mathbf{Q} as follows:\n\nQ_{ij} = \\frac{1}{2m}A_{ij} - \\frac{k_i k_j}{4m^2}\n\nwhere k_i is the degree of node i, and m is the number of edges in the network.\nWe then compute the eigenvectors of \\mathbf{Q} and use them to embed the network into a low-dimensional space just as we did for the adjacency matrix.\n\n:tags: [hide-input]\n\ndeg = np.sum(A, axis=1)\nm = np.sum(deg) / 2\nQ = A - np.outer(deg, deg) / (2 * m)\nQ/= 2*m\n\neigvals, eigvecs = np.linalg.eig(Q)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(-eigvals)[:d]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Modularity Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nThe modularity embedding can be used to bipartition the network into two communities using a simple algorithm: group nodes with the same sign of the second eigenvector {footcite}`newman2006modularity`."
  },
  {
    "objectID": "m08-embedding/spectral-embedding.html#laplacian-eigenmap",
    "href": "m08-embedding/spectral-embedding.html#laplacian-eigenmap",
    "title": "Spectral Embedding",
    "section": "3 Laplacian Eigenmap",
    "text": "3 Laplacian Eigenmap\nLaplacian Eigenmap {footcite}belkin2003laplacian is another approach to compress a network into a low-dimensional space. The fundamental idea behind this method is to position connected nodes close to each other in the low-dimensional space. This approach leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J_{LE}(\\mathbf{U}),\\quad J_{LE}(\\mathbf{U}) = \\frac{1}{2}\\sum_{i,j} A_{ij} \\| u_i - u_j \\|^2\n\nIn this equation, \\| u_i - u_j \\|^2 represents the squared distance between nodes i and j in the low-dimensional space. The goal is to minimize this distance for connected nodes (where A_{ij} = 1). The factor \\frac{1}{2} is included for mathematical convenience in later calculations.\nTo solve this optimization problem, we rewrite J_{LE}(\\mathbf{U}) as follows:\n\n\\begin{aligned}\nJ_{LE}(\\mathbf{U}) &= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\| u_i - u_j \\|^2 \\\\\n&= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\left( \\| u_i \\|^2 - 2 u_i^\\top u_j + \\| u_j \\|^2 \\right) \\\\\n&= \\sum_{i}\\sum_{j} A_{ij} \\| u_i \\|^2 - \\sum_{i}\\sum_{j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i} k_i \\| u_i \\|^2 - \\sum_{i,j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i,j} L_{ij} u_i^\\top u_j\n\\end{aligned}\n\nwhere\n\nL_{ij} = \\begin{cases}\nk_i & \\text{if } i = j \\\\\n-A_{ij} & \\text{if } i \\neq j\n\\end{cases}\n\nLet us go through the derivation step by step.\n\nIn the first step (i.e., the second line), we expand the squared norm using the vector identity \\|a-b\\|^2 = \\|a\\|^2 - 2a^\\top b + \\|b\\|^2.\nIn the second step (i.e., the third line), we distribute the sum and the factor \\frac{1}{2}. The middle term gets a factor of 1 because it appears twice in the expansion (once for i,j and once for j,i), canceling out the \\frac{1}{2}. Note that the term A_{ij} is symmetric, i.e., A_{ij} = A_{ji}.\nIn the third step (i.e., the fourth line), we recognize that \\sum_j A_{ij} is the degree of node i, which we denote as k_i.\nFinally, we combine the terms by using the Laplacian matrix \\mathbf{L}.\n\nThe minimization problem can be rewritten as:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nwhere\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\mathbf{u}_1 ^\\top \\\\\n\\mathbf{u}_2 ^\\top \\\\\n\\vdots \\\\\n\\mathbf{u}_N ^\\top \\\\\n\\end{bmatrix}\n\nSee the Appendix section for the detailed derivation.\nBy taking the derivative of J_{LE}(\\mathbf{U}) with respect to \\mathbf{U} and set it to zero, we obtain the following equation:\n\n\\frac{\\partial J_{LE}}{\\partial \\mathbf{U}} = 0 \\implies \\mathbf{L} \\mathbf{U} = \\lambda \\mathbf{U}\n\nThe solution is the d eigenvectors associated with the d smallest eigenvalues of \\mathbf{L}.\nIt is important to note that the eigenvector corresponding to the smallest eigenvalue (which is always zero for connected graphs) is trivial - it’s the all-one vector. Therefore, in practice, we typically compute the d+1 smallest eigenvectors and discard the one corresponding to the zero eigenvalue.\n\nAn example for the Laplacian Eigenmap\nLet us first compute the Laplacian matrix and its eigenvectors.\n\n:tags: [hide-input]\n\nD = np.diag(np.sum(A, axis=1))\nL = D - A\n\neigvals, eigvecs = np.linalg.eig(L)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(eigvals)[1:d+1]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nThe eigenvectors corresponding to the d smallest eigenvalues are:\n\n:tags: [hide-input]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Laplacian Eigenmap')\nax.set_xlabel('Eigenvector 2')\nax.set_ylabel('Eigenvector 3')\nplt.show()"
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html",
    "href": "m09-graph-neural-networks/02-coding.html",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "",
    "text": "Graph Neural Networks are a type of neural network for graph data. node2vec and deepwalk stem from the idea of language modeling. In this module, we will focus on another branch of graph neural networks that stem from image processing.\n\n\nEdge detection is a classical problem in image processing. The goal is to identify the boundaries of objects in an image.\n\nTo approach the problem, let us first remind that an image is a matrix of pixels. Each pixel has RGB values, each of which represents the intensity of red, green, and blue color. To simplify the problem, we focus on grayscale images, in which each pixel has only one value representing the brightness. In this case, an image can be represented as a 2D matrix, where each element in the matrix represents the brightness of a pixel.\n\n\n\n\nHuman eyes are very sensitive to brightness changes. An edge in an image appears when there is a significant brightness change between adjacent pixels. To be more concrete, let’s consider a small example consisting of 6x6 pixels, with a vertical line from the top to the bottom, where the brightness is higher than the neighboring pixels. This is an edge we want to detect.\n\nX = \\begin{bmatrix}\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10\n\\end{bmatrix}\n\nLet’s zoom on the pixel at (3, 3) and its surrounding pixels.\n\nZ = \\begin{bmatrix}\n10 & 80 & 10 \\\\\n\\textcolor{blue}{10} & \\textcolor{red}{80} & \\textcolor{purple}{10} \\\\\n10 & 80 & 10\n\\end{bmatrix}\n\nwhere the central pixel is highlighted in red. Since we are interested in the edge which is a sudden change in brightness along the horizontal direction, we take a derivative at the central pixel by\n\n\\nabla Z_{22} = \\textcolor{blue}{Z_{2,1}} - \\textcolor{purple}{Z_{2,3}}\n\nFollowing the same process, we can compute the derivative at all pixels, which gives us the (horizontal) derivative of the image.\n\n\\begin{bmatrix}\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & -\n\\end{bmatrix}\n\nThe symbol - indicates that the derivative is not defined because one of the neighboring pixels is out of the image boundary. We observe that the derivative is high at the edge and low elsewhere. This is a simple but effective way to detect edges in an image.\nWe can consider a derivative operator along the vertical direction that computes the difference between the vertical neighboring pixels.\n\n\\nabla Z_{22} = Z_{1,2} - Z_{3,2}\n\nAnd, when applied to the entire image, the result is\n\n\\begin{bmatrix}\n- & - & - & - & -  & - \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n- & - & - & - & - & -\n\\end{bmatrix}\n\nThe all entries are zero, meaning that there is no edge in the vertical direction.\nWe can combine the horizontal and vertical derivatives to get the gradient of the image. For example,\n\n\\nabla Z_{22} = Z_{12} - Z_{32} + Z_{21} - Z_{23}\n\nWhen applied to the entire image, the result is the same as the horizontal derivative.\n\n\n\nWe observe that there is a repeated pattern in the derivative computation: we are taking addition and subtraction of neighbiring pixels. This motivates us to generalize the operation to a more general form.\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j}\n\nwhere K is a 3 \\times 3 matrix, and w=h=3 represent the width and height of the kernel.\n\nK_{\\text{horizontal}} = \\begin{bmatrix}\n0 & 0 & 0 \\\\\n-1 & 0 & 1 \\\\\n0 & 0 & 0\n\\end{bmatrix},\\quad\nK_{\\text{vertical}} = \\begin{bmatrix}\n0 & -1 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{bmatrix}\n\nThe operation of K on the image is called convolution, and K is called the kernel or filter. More generally, the convolution of a kernel K and an image X is defined as\n\nY_{ij} = \\sum_{p}\\sum_{q} K_{pq} X_{i+p-\\frac{h+1}{2}, j+q-\\frac{w+1}{2}}\n\nwhere h and w are the height and width of the kernel, respectively.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#preliminaries-image-processing",
    "href": "m09-graph-neural-networks/02-coding.html#preliminaries-image-processing",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "",
    "text": "Graph Neural Networks are a type of neural network for graph data. node2vec and deepwalk stem from the idea of language modeling. In this module, we will focus on another branch of graph neural networks that stem from image processing.\n\n\nEdge detection is a classical problem in image processing. The goal is to identify the boundaries of objects in an image.\n\nTo approach the problem, let us first remind that an image is a matrix of pixels. Each pixel has RGB values, each of which represents the intensity of red, green, and blue color. To simplify the problem, we focus on grayscale images, in which each pixel has only one value representing the brightness. In this case, an image can be represented as a 2D matrix, where each element in the matrix represents the brightness of a pixel.\n\n\n\n\nHuman eyes are very sensitive to brightness changes. An edge in an image appears when there is a significant brightness change between adjacent pixels. To be more concrete, let’s consider a small example consisting of 6x6 pixels, with a vertical line from the top to the bottom, where the brightness is higher than the neighboring pixels. This is an edge we want to detect.\n\nX = \\begin{bmatrix}\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10\n\\end{bmatrix}\n\nLet’s zoom on the pixel at (3, 3) and its surrounding pixels.\n\nZ = \\begin{bmatrix}\n10 & 80 & 10 \\\\\n\\textcolor{blue}{10} & \\textcolor{red}{80} & \\textcolor{purple}{10} \\\\\n10 & 80 & 10\n\\end{bmatrix}\n\nwhere the central pixel is highlighted in red. Since we are interested in the edge which is a sudden change in brightness along the horizontal direction, we take a derivative at the central pixel by\n\n\\nabla Z_{22} = \\textcolor{blue}{Z_{2,1}} - \\textcolor{purple}{Z_{2,3}}\n\nFollowing the same process, we can compute the derivative at all pixels, which gives us the (horizontal) derivative of the image.\n\n\\begin{bmatrix}\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & -\n\\end{bmatrix}\n\nThe symbol - indicates that the derivative is not defined because one of the neighboring pixels is out of the image boundary. We observe that the derivative is high at the edge and low elsewhere. This is a simple but effective way to detect edges in an image.\nWe can consider a derivative operator along the vertical direction that computes the difference between the vertical neighboring pixels.\n\n\\nabla Z_{22} = Z_{1,2} - Z_{3,2}\n\nAnd, when applied to the entire image, the result is\n\n\\begin{bmatrix}\n- & - & - & - & -  & - \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n- & - & - & - & - & -\n\\end{bmatrix}\n\nThe all entries are zero, meaning that there is no edge in the vertical direction.\nWe can combine the horizontal and vertical derivatives to get the gradient of the image. For example,\n\n\\nabla Z_{22} = Z_{12} - Z_{32} + Z_{21} - Z_{23}\n\nWhen applied to the entire image, the result is the same as the horizontal derivative.\n\n\n\nWe observe that there is a repeated pattern in the derivative computation: we are taking addition and subtraction of neighbiring pixels. This motivates us to generalize the operation to a more general form.\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j}\n\nwhere K is a 3 \\times 3 matrix, and w=h=3 represent the width and height of the kernel.\n\nK_{\\text{horizontal}} = \\begin{bmatrix}\n0 & 0 & 0 \\\\\n-1 & 0 & 1 \\\\\n0 & 0 & 0\n\\end{bmatrix},\\quad\nK_{\\text{vertical}} = \\begin{bmatrix}\n0 & -1 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{bmatrix}\n\nThe operation of K on the image is called convolution, and K is called the kernel or filter. More generally, the convolution of a kernel K and an image X is defined as\n\nY_{ij} = \\sum_{p}\\sum_{q} K_{pq} X_{i+p-\\frac{h+1}{2}, j+q-\\frac{w+1}{2}}\n\nwhere h and w are the height and width of the kernel, respectively.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#from-image-to-graph",
    "href": "m09-graph-neural-networks/02-coding.html#from-image-to-graph",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "2 From Image to Graph",
    "text": "2 From Image to Graph\n\nAnalogy between image and graph data\nWe can think of a convolution of an image from the perspective of networks. In the convolution of an image, a pixel is convolved with its neighbors. We can regard each pixel as a node, and each node is connected to its neighboring nodes (pixels) that are involved in the convolution.\n\nBuilding on this analogy, we can extend the idea of convolution to general graph data. Each node has a pixel value(s) (e.g., feature vector), which is convolved with the values of its neighbors in the graph. This is the key idea of graph convolutional networks. But, there is a key difference: while the number of neighbors for an image is homogeneous, the number of neighbors for a node in a graph can be heterogeneous. Each pixel has the same number of neighbors (except for the boundary pixels), but nodes in a graph can have very different numbers of neighbors. This makes it non-trivial to define the “kernel” for graph convolution.\n\n\nSpectral filter on graphs\nJust like we can define a convolution on images in the frequency domain, we can also define a ‘’frequency domain’’ for graphs.\nConsider a network of N nodes, where each node has a feature variable {\\mathbf x}_i \\in \\mathbb{R}. We are interested in:\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2,\n\nwhere A_{ij} is the adjacency matrix of the graph. The quantity J represents the total variation of x between connected nodes; a small J means that connected nodes have similar x (low variation; low frequency), while a large J means that connected nodes have very different x (high variation; high frequency).\nWe can rewrite J as\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 = {\\bf x}^\\top {\\bf L} {\\bf x},\n\nwhere {\\bf L} is the Laplacian matrix of the graph given by\n\nL_{ij} = \\begin{cases}\n-1 & \\text{if } i \\text{ and } j \\text{ are connected} \\\\\nk_i & \\text{if } i = j \\\\\n0 & \\text{otherwise}\n\\end{cases}.\n\nand {\\bf x} = [x_1,x_2,\\ldots, x_N]^\\top is a column vector of feature variables.\n\n\n\n\n\n\nDetailed derivation\n\n\n\n:tag: note :class: dropdown\nThe above derivation shows that the total variation of x between connected nodes is proportional to {\\bf x}^\\top {\\bf L} {\\bf x}.\n\n\\begin{aligned}\nJ &= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 \\\\\n&= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\underbrace{A_{ij}\\left( x_i^2 +x_j^2\\right)}_{\\text{symmetric}} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2\\underbrace{\\sum_{j=1}^N A_{ij}}_{\\text{degree of node } i, k_i} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2 k_i - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\underbrace{[x_1,x_2,\\ldots, x_N]}_{{\\bf x}} \\underbrace{\\begin{bmatrix} k_1 & 0 & \\cdots & 0 \\\\ 0 & k_2 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & k_N \\end{bmatrix}}_{{\\bf D}} \\underbrace{\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N \\end{bmatrix}}_{{\\bf x}} - 2\\underbrace{\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}}_{{\\bf x}^\\top {\\mathbf A} {\\bf x}} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf D} {\\bf x} - {\\bf x}^\\top {\\mathbf A} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf L} {\\bf x},\n\\end{aligned}\n\n\n\nLet us showcase the analogy between the Fourier transform and the Laplacian matrix. In the Fourier transform, a signal is decomposed into sinusoidal basis functions. Similarly, for a graph, we can decompose the variation J into eigenvector bases.\n\nJ = \\sum_{i=1}^N \\lambda_i  {\\bf x}^\\top {\\mathbf u}_i {\\mathbf u}_i^\\top {\\bf x} = \\sum_{i=1}^N \\lambda_i  ||{\\bf x}^\\top {\\mathbf u}_i||^2.\n\nwhere {\\mathbf u}_i is the eigenvector corresponding to the eigenvalue \\lambda_i. - The term ({\\bf x}^\\top {\\mathbf u}_i) is a dot-product between the feature vector {\\bf x} and the eigenvector {\\mathbf u}_i, which measures how much {\\bf x} coheres with eigenvector {\\mathbf u}_i, similar to how Fourier coefficients measure coherency with sinusoids. - Each ||{\\bf x}^\\top {\\mathbf u}_i||^2 is the ‘’strength’’ of {\\bf x} with respect to the eigenvector {\\mathbf u}_i, and the total variation J is a weighted sum of these strengths.\nSome eigenvectors correspond to low-frequency components, while others correspond to high-frequency components. For example, the total variation J for an eigenvector {\\mathbf u}_i is given by\n\nJ = \\frac{1}{2} \\sum_{j}\\sum_{\\ell} A_{j\\ell}(u_{ij} - u_{i\\ell})^2 = {\\mathbf u}_i^\\top {\\mathbf L} {\\mathbf u}_i = \\lambda_i.\n\nThis equation provides key insight into the meaning of eigenvalues:\n\nFor an eigenvector {\\mathbf u}_i, its eigenvalue \\lambda_i measures the total variation for {\\mathbf u}_i.\nLarge eigenvalues mean large differences between neighbors (high frequency), while small eigenvalues mean small differences (low frequency).\n\nThus, if {\\bf x} aligns well with {\\mathbf u}_i with a large \\lambda_i, then {\\bf x} has a strong high-frequency component; if {\\bf x} aligns well with {\\mathbf u}_i with a small \\lambda_i, then {\\bf x} has strong low-frequency component.\n\n\nSpectral Filtering\nEigenvalues \\lambda_i can be thought of as a filter that controls which frequency components pass through. Instead of using the filter associated with the Laplacian matrix, we can design a filter h(\\lambda_i) to control which frequency components pass through. This leads to the idea of spectral filtering. Two common filters are:\n\nLow-pass Filter: h_{\\text{low}}(\\lambda) = \\frac{1}{1 + \\alpha\\lambda}\n\nPreserves low frequencies (small λ)\nSuppresses high frequencies (large λ)\nResults in smoother signals\n\nHigh-pass Filter: h_{\\text{high}}(\\lambda) = \\frac{\\alpha\\lambda}{1 + \\alpha\\lambda}\n\nPreserves high frequencies\nSuppresses low frequencies\nEmphasizes differences between neighbors\n\n\n\n:tags: [remove-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context(\"talk\")\n\nalpha = 1\nlambdas = np.linspace(0, 10, 100)\nh_low = 1 / (1 + alpha * lambdas)\nh_high = (alpha * lambdas) / (1 + alpha * lambdas)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\nsns.lineplot(x=lambdas, y=h_low, label=\"Low-pass filter\", ax=axes[0])\naxes[0].legend(frameon=False).remove()\nsns.lineplot(x=lambdas, y=h_high, label=\"High-pass filter\", ax=axes[1])\naxes[1].legend(frameon=False).remove()\naxes[0].set_title(\"Low-pass filter\")\naxes[1].set_title(\"High-pass filter\")\nfig.text(0.5, 0.01, \"Eigenvalue $\\lambda$\", ha=\"center\")\naxes[0].set_ylabel(\"Filter response $h(\\lambda)$\")\nsns.despine()\nplt.tight_layout()\n\n\n\nExample\nLet us showcase the idea of spectral filtering with a simple example with the karate club network.\n\n:tags: [remove-input]\nimport igraph as ig\nimport numpy as np\nfrom scipy import sparse\nimport matplotlib as mpl\n\nG = ig.Graph.Famous(\"Zachary\")\nA = G.get_adjacency_sparse()\n\nWe will first compute the laplacian matrix and its eigendecomposition.\n\n# Compute Laplacian matrix\ndeg = np.array(A.sum(axis=1)).reshape(-1)\nD = sparse.diags(deg)\nL = D - A\n\n# Compute eigendecomposition\nevals, evecs = np.linalg.eigh(L.toarray())\n\n# Sort eigenvalues and eigenvectors\norder = np.argsort(evals)\nevals = evals[order]\nevecs = evecs[:, order]\n\nNow, let’s create a low-pass and high-pass filter.\n\nalpha = 2\nL_low = evecs @ np.diag(1 / (1 + alpha * evals)) @ evecs.T\nL_high = evecs @ np.diag(alpha * evals / (1 + alpha * evals)) @ evecs.T\n\nprint(\"Size of low-pass filter:\", L_low.shape)\nprint(\"Size of high-pass filter:\", L_high.shape)\n\nNotice that the high-pass filter and low-pass filter are matrices of the same size as the adjacency matrix A, which defines a ‘convolution’ on the graph as follows:\n\n{\\bf x}' = {\\bf L}_{\\text{low}} {\\bf x} \\quad \\text{or} \\quad {\\bf x}' = {\\bf L}_{\\text{high}} {\\bf x}.\n\nwhere {\\bf L}_{\\text{low}} and {\\bf L}_{\\text{high}} are the low-pass and high-pass filters, respectively, and {\\bf x}' is the convolved feature vector.\nNow, let’s see how these filters work. Our first example is a random feature vector.\n\n# Random feature vector\nx = np.random.randn(A.shape[0], 1)\n\n# Convolve with low-pass filter\nx_low = L_low @ x\n\n# Convolve with high-pass filter\nx_high = L_high @ x\n\nLet us visualize the results.\n\n:tags: [hide-input]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\nnorm = mpl.colors.Normalize(vmin=-0.3, vmax=0.3)\n\n# Original\nvalues = x.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\n# Low-pass filter applied\nvalues = L_low @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\n# High-pass filter applied\nvalues = L_high @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\nWe observe that the low-pass filter results in smoother {\\bf x} between connected nodes (i.e., neighboring nodes have similar {\\bf x}). The original {\\bf x} and {\\bf x}'_{\\text{low}} are very similar because random variables are high-frequency components. In contrast, when we apply the high-pass filter, {\\bf x}'_{\\text{high}} is similar to {\\bf x} because the high-frequency components are not filtered.\nLet’s now use an eigenvector as our feature vector {\\bf x}.\n\n:tags: [hide-input]\neigen_centrality = np.array(G.eigenvector_centrality()).reshape(-1, 1)\nlow_pass_eigen = L_low @ eigen_centrality\nhigh_pass_eigen = L_high @ eigen_centrality\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\n\nnorm = mpl.colors.Normalize(vmin=-0, vmax=0.3)\nvalues = eigen_centrality.reshape(-1)# high_pass_random.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\nvalues = low_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\nvalues = high_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\nThe high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#graph-convolutional-networks",
    "href": "m09-graph-neural-networks/02-coding.html#graph-convolutional-networks",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "3 Graph Convolutional Networks",
    "text": "3 Graph Convolutional Networks\nWe have seen that spectral filters give us a principled way to think about “convolution” on irregular graph structures, and controlling the frequency components brings out different aspects of the data. We now go one step further: instead of designing filters by hand, we can learn them from data for specific tasks.\n\nSpectral Graph Convolutional Networks\nA simplest form of learnable spectral filter is given by\n\n{\\bf L}_{\\text{learn}} = \\sum_{k=1}^K \\theta_k {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\nwhere {\\mathbf u}_k are the eigenvectors and \\theta_k are the learnable parameters. The variable K is the number of eigenvectors used (i.e., the rank of the filter). The weight \\theta_k is learned to maximize the performance of the task at hand.\nBuilding on this idea, {footcite}bruna2014spectral added a nonlinearity to the filter and proposed a spectral convolutional neural network (GCN) by\n\n{\\bf x}^{(\\ell+1)} = h\\left( L_{\\text{learn}} {\\bf x}^{(\\ell)}\\right),\n\nwhere h is an activation function, and {\\bf x}^{(\\ell)} is the feature vector of the \\ell-th convolution. They further extend this idea to convolve on multidimensional feature vectors, {\\bf X} \\in \\mathbb{R}^{N \\times f_{\\text{in}}} to produce new feature vectors of different dimensionality, {\\bf X}' \\in \\mathbb{R}^{N \\times f_{\\text{out}}}.\n\n\\begin{aligned}\n{\\bf X}^{(\\ell+1)}_i &= h\\left( \\sum_j L_{\\text{learn}}^{(i,j)} {\\bf X}^{(\\ell)}_j\\right),\\quad \\text{where} \\quad L^{(i,j)}_{\\text{learn}} = \\sum_{k=1}^K \\theta_{k, (i,j)} {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\\end{aligned}\n\nNotice that the learnable filter L_{\\text{learn}}^{(i,j)} is defined for each pair of input i and output j dimensions.\nMany GCNs simple when it comes to implementation despite the complicated formula. And this is one of my ways to learn GNNs. Check out the [Appendix for the Python implementation](appendix.md).\n\n\n\nFrom Spectral to Spatial\nSpectral GCNs are mathematically elegant but have two main limitations: 1. Computational Limitation: Computing the spectra of the Laplacian is expensive {\\cal O}(N^3) and prohibitive for large graphs 2. Spatial Locality: The learned filters are not spatially localized. A node can be influenced by all other nodes in the graph.\nThese two limitations motivate the development of spatial GCNs.\n\n\nChebNet\nChebNet {footcite}defferrard2016convolutional is one of the earliest spatial GCNs that bridges the gap between spectral and spatial domains. The key idea is to leverage Chebyshev polynomials to approximate {\\bf L}_{\\text{learn}} by\n\n{\\bf L}_{\\text{learn}} \\approx \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}), \\quad \\text{where} \\quad \\tilde{{\\bf L}} = \\frac{2}{\\lambda_{\\text{max}}}{\\bf L} - {\\bf I},\n\nwhere \\tilde{{\\bf L}} is the scaled and normalized Laplacian matrix in order to have eigenvalues in the range of [-1,1]. The Chebyshev polynomials T_k(\\tilde{{\\bf L}}) transforms the eigenvalues \\tilde{{\\bf L}} to the following recursively:\n\n\\begin{aligned}\nT_0(\\tilde{{\\bf L}}) &= {\\bf I} \\\\\nT_1(\\tilde{{\\bf L}}) &= \\tilde{{\\bf L}} \\\\\nT_k(\\tilde{{\\bf L}}) &= 2\\tilde{{\\bf L}} T_{k-1}(\\tilde{{\\bf L}}) - T_{k-2}(\\tilde{{\\bf L}})\n\\end{aligned}\n\nWe then replace {\\bf L}_{\\text{learn}} in the original spectral GCN with the Chebyshev polynomial approximation:\n\n{\\bf x}^{(\\ell+1)} = h\\left( \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}){\\bf x}^{(\\ell)}\\right),\n\nwhere: - T_k(\\tilde{{\\bf L}}) applies the k-th Chebyshev polynomial to the scaled Laplacian matrix - \\theta_k are the learnable parameters - K is the order of the polynomial (typically small, e.g., K=3)\n\n\nGraph Convolutional Networks by Kipf and Welling\nWhile ChebNet offers a principled way to approximate spectral convolutions, Kipf and Welling (2017) {footcite}kipf2017semi proposed an even simpler and highly effective variant called Graph Convolutional Networks (GCN).\n\nFirst-order Approximation\nThe key departure is to use the first-order approximation of the Chebyshev polynomials.\n\ng_{\\theta'} * x \\approx \\theta'_0x + \\theta'_1(L - I_N)x = \\theta'_0x - \\theta'_1D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}x\n\nThis is crude approximation but it leads to a much simpler form, leaving only two learnable parameters, instead of K parameters in the original ChebNet.\nAdditionally, they further simplify the formula by using the same \\theta for both remaining parameters (i.e., \\theta_0 = \\theta and \\theta_1 = -\\theta). The result is the following convolutional filter:\n\ng_{\\theta} * x \\approx \\theta(I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}})x\n\nWhile this is a very simple filter, one can stack multiple layers of convolutions to perform high-order graph convolutions.\n\n\nDeep GCNs can suffer from over-smoothing\nGCN models can be deep, and when they are too deep, they start suffering from an ill-posed problem called gradient vanishing/exploding, where the gradients of the loss function becomes too small or too large to update the model parameters. It is a common problem in deep learning.\nTo facilitate the training of deep GCNs, the authors introduce a very simple trick called renormalization. The idea is to add self-connections to the graph:\n\n\\tilde{A} = A + I_N, \\quad \\text{and} \\quad \\tilde{D}_{ii} = \\sum_j \\tilde{A}_{ij}\n\nAnd use \\tilde{A} and \\tilde{D} to form the convolutional filter.\nAltogether, this leads to the following layer-wise propagation rule:\nX^{(\\ell+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}X^{(\\ell)}W^{(\\ell)})\nwhere: - X^{(\\ell)} is the matrix of node features at layer \\ell - W^{(\\ell)} is the layer’s trainable weight matrix - \\sigma is a nonlinear activation function (e.g., ReLU)\nThese simplifications offer several advantages: - Efficiency: Linear complexity in number of edges - Localization: Each layer only aggregates information from immediate neighbors - Depth: Fewer parameters allow building deeper models - Performance: Despite (or perhaps due to) its simplicity, it often outperforms more complex models\n\n\n\n\n\n\nExercise\n\n\n\n:class: note\nLet’s implement a simple GCN model for node classification. Coding Exercise",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#popular-graph-neural-networks",
    "href": "m09-graph-neural-networks/02-coding.html#popular-graph-neural-networks",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "4 Popular Graph Neural Networks",
    "text": "4 Popular Graph Neural Networks\nIn this section, we will introduce three popular GNNs: GraphSAGE, Graph Attention Networks (GAT), and Graph Isomorphism Network (GIN).\n\nGraphSAGE: Sample and Aggregate\nGraphSAGE {footcite}hamilton2017graphsage introduced a different GCN that can be generalized to unseen nodes (they called it “inductive”). While previous approaches like ChebNet and GCN operate on the entire graph, GraphSAGE proposes an inductive framework that generates embeddings by sampling and aggregating features from a node’s neighborhood.\n\n\n\nKey Ideas\nGraphSAGE involves two key ideas: (1) sampling and (2) aggregation.\n\nNeighborhood Sampling\nThe key idea is the neighborhood sampling. Instead of using all neighbors, GraphSAGE samples a fixed-size set of neighbors for each node. This controls memory complexity, a key limitation of the previous GNNs.\nAnother key advantage of neighborhood sampling is that it enables GraphSAGE to handle dynamic, growing networks. Consider a citation network where new papers (nodes) are continuously added. Traditional GCNs would need to recompute filters for the entire network with each new addition. In contrast, GraphSAGE can immediately generate embeddings for new nodes by simply sampling their neighbors, without any retraining or recomputation.\n\n\nAggregation\nAnother key idea is the aggregation. GraphSAGE makes a distinction between self-information and neighborhood information. While previous GNNs treat them equally and aggregate them, GraphSAGE treats them differently. Specifically, GraphSAGE introduces an additional step: it concatenates the self-information and the neighborhood information as the input of the convolution.\n\nZ_v = \\text{CONCAT}(X_v, X_{\\mathcal{N}(v)})\n\nwhere X_v is the feature of the node itself and X_{\\mathcal{N}(v)} is the aggregation of the features of its neighbors. GraphSAGE introduces different ways to aggregate information from neighbors:\nX_{\\mathcal{N}(v)} = \\text{AGGREGATE}_k(\\{X_u, \\forall u \\in \\mathcal{N}(v)\\})\nCommon aggregation functions include: - Mean aggregator: \\text{AGGREGATE} = \\text{mean}(\\{h_u, \\forall u \\in \\mathcal{N}(v)\\}) - Max-pooling: \\text{AGGREGATE} = \\max(\\{\\sigma(W_{\\text{pool}}h_u + b), \\forall u \\in \\mathcal{N}(v)\\}) - LSTM aggregator: Apply LSTM to randomly permuted neighbors\nThe concatenated feature Z_v is normalized by the L2 norm.\n\n\\hat{Z}_v = \\frac{Z_v}{\\|Z_v\\|_2}\n\nand then fed into the convolution.\n\nX_v^k = \\sigma(W^k \\hat{Z}_v + b^k)\n\n\n\n\nGraph Attention Networks (GAT): Differentiate Individual Neighbors\nA key innovation of GraphSAGE is to treat the self and neighborhood information differently. But should all neighbors be treated equally? Graph Attention Networks (GAT) address this by letting the model learn which neighbors to pay attention to.\n\n\nAttention Mechanism\n\nThe core idea is beautifully simple: instead of using fixed weights like GCN, let’s learn attention weights \\alpha_{ij} that determine how much node i should attend to node j. These weights are computed dynamically based on node features:\n\n\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik})}\n\nwhere e_{ij} represents the importance of the edge between node i and node j. Variable e_{ij} is a learnable parameter and can be negative, and the exponential function is applied to transform it to a non-negative value, with the normalization term \\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik}) to ensure the weights sum to 1.\nHow to compute e_{ij}? One simple choice is to use a neural network with a shared weight matrix W and a LeakyReLU activation function. Specifically:\n\nLet’s focus on computing e_{ij} for node i and its neighbor j.\nWe use a shared weight matrix W to transform the features of node i and j. \n\\mathbf{\\tilde h}_i  = \\mathbf{h}_i, \\quad \\mathbf{\\tilde h}_j  = W\\mathbf{h}_j\n\nWe concatenate the transformed features and apply a LeakyReLU activation function.\n\n\ne_{ij} = \\text{LeakyReLU}(\\mathbf{a}^T[\\mathbf{\\tilde h}_i, \\mathbf{\\tilde h}_j])\n\nwhere \\mathbf{a} is a trainable parameter vector that sums the two transformed features.\nOnce we have these attention weights, the node update is straightforward - just a weighted sum of neighbor features:\n\\mathbf{h}'_i = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}{\\bf W}_{\\text{feature}}\\mathbf{h}_j\\right)\nwhere {\\bf W}_{\\text{feature}} is a trainable weight matrix. To stabilize training, GAT uses multiple attention heads and concatenates their outputs:\n\\mathbf{h}'_i = \\parallel_{k=1}^K \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}^k{\\bf W}^k_{\\text{feature}}\\mathbf{h}_j\\right)\n\n\nGraph Isomorphism Network (GIN): Differentiate the Aggregation\nGraph Isomorphism Networks (GIN) is another popular GNN that born out of a question: what is the maximum discriminative power achievable by Graph Neural Networks? The answer lies in its theoretical connection to the Weisfeiler-Lehman (WL) test, a powerful algorithm for graph isomorphism testing.\n\n\nWeisfeiler-Lehman Test\nAre two graphs structurally identical? Graph isomorphism testing determines if two graphs are structurally identical, with applications in graph classification, clustering, and other tasks.\n\nWhile the general problem has no known polynomial-time solution, the WL test is an efficient heuristic that works well in practice. The WL test iteratively refines node labels by hashing the multiset of neighboring labels\n\nThe WL test works as follows:\n\nAssign all nodes the same initial label.\nFor each node, collect the labels of all its neighbors and aggregate them into a hash (e.g., new label). For example, the top node gets {0} from its neighbors, resulting in a collection {0,0}. A new label is created via a hash function h that maps {0, {0, 0}} to a new label 1.\nRepeat the process for a fixed number of iterations or until convergence.\n\nHere is the implementation of the WL test in Python:\n\n:tags: [hide-input]\n\nimport numpy as np\nfrom scipy import sparse\n\ndef weisfeiler_lehman_test(A, num_iterations):\n    n_nodes = A.shape[0]\n    labels = np.zeros(n_nodes, dtype=int)\n    color_map = {}\n    hash_fn = lambda x: color_map.setdefault(x, len(color_map))\n    for _ in range(num_iterations):\n\n        # Go through each node\n        labels_old = labels.copy()\n        for i in range(n_nodes):\n\n            # Collect the labels of all neighbors\n            neighbors = A[i].nonzero()[1]\n            neighbor_labels = labels_old[neighbors]\n\n            # Count the frequency of each label\n            unique, counts = np.unique(neighbor_labels, return_counts=True)\n\n            # Create a hash key by converting the frequency dictionary to a string\n            hash_key = str({unique[j]: counts[j] for j in range(len(unique))})\n\n            # Create a new label by hashing the frequency dictionary\n            label = hash_fn(hash_key)\n            labels[i] = label\n\n        # Check convergence\n        unique, counts = np.unique(labels, return_counts=True)\n        unique_old, counts_old = np.unique(labels_old, return_counts=True)\n        if np.array_equal(np.sort(counts), np.sort(counts_old)):\n            break\n    return labels\n\n\nedge_list = [(0, 1), (1, 2), (2, 0), (3, 4), (4, 5), (5, 3)]\n\nA = sparse.csr_matrix(\n    ([1] * len(edge_list), ([e[0] for e in edge_list], [e[1] for e in edge_list])),\n    shape=(6, 6),\n)\nA = A + A.T\nA.sort_indices()\n\nweisfeiler_lehman_test(A, A.shape[0])\n\nAfter these iterations: - Nodes with the same label are structurally identical, meaning that they are indistinguishable unless we label them differently. - Two graphs are structurally identical if and only if they have the same node labels after the WL test.\nThe WL test is a heuristic and can fail on some graphs. For example, it cannot distinguish regular graphs with the same number of nodes and edges.\nThe WL test above is called the 1-WL test. There are higher-order WL tests that can distinguish more graphs, which are the basis of advanced GNNs.\nCheck out [this note](https://www.moldesk.net/blog/weisfeiler-lehman-isomorphism-test/)\n\n\nGIN\nGIN {footcite}xu2018how is a GNN that is based on the WL test. The key idea is to focus on the parallel between the WL test and the GNN update rule. - In the WL test, we iteratively collect the labels of neighbors and aggregate them through a hash function. - In the GraphSAGE and GAT, the labels are the nodes’ features, and the aggregation is some arithmetic operations such as mean or max.\nThe key difference is that the hash function in the WL test always distinguishes different sets of neighbors’ labels, while the aggregation in GraphSAGE and GAT does not always do so. For example, if all nodes have the same feature (e.g., all 1), the aggregation by the mean or max will result in the same value for all nodes, whereas the hash function in the WL test can still distinguish different sets of neighbors’ labels by the count of each label.\nThe resulting convolution update rule is:\n\nh_v^{(k+1)} = \\text{MLP}^{(k)}\\left((1 + \\epsilon^{(k)}) \\cdot h_v^{(k)} + \\sum_{u \\in \\mathcal{N}(v)} h_u^{(k)}\\right)\n\nwhere \\text{MLP}^{(k)} is a multi-layer perceptron (MLP) with k layers, and \\epsilon^{(k)} is a fixed or trainable parameter.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/04-appendix.html",
    "href": "m09-graph-neural-networks/04-appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Let’s first implement Bruna’s spectral GCN.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport scipy.sparse as sp\nimport torch\nimport torch.nn as nn\nimport scipy.sparse.linalg as slinalg\n\nclass BrunaGraphConv(nn.Module):\n    \"\"\"\n    Bruna's Spectral Graph Convolution Layer\n\n    This implementation follows the original formulation by Joan Bruna et al.,\n    using the eigendecomposition of the graph Laplacian for spectral convolution.\n    \"\"\"\n\n    def __init__(self, in_features, out_features, n_nodes):\n        \"\"\"\n        Initialize the Bruna Graph Convolution layer\n\n        Args:\n            in_features (int): Number of input features\n            out_features (int): Number of output features\n        \"\"\"\n        super(BrunaGraphConv, self).__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        # Learnable spectral filter parameters\n        self.weight = nn.Parameter(\n            torch.FloatTensor(in_features, out_features, n_nodes-1)\n        )\n\n        # Initialize parameters\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        \"\"\"Initialize weights using Glorot initialization\"\"\"\n        nn.init.xavier_uniform_(self.weight)\n\n\n    @staticmethod\n    def get_laplacian_eigenvectors(adj):\n        \"\"\"\n        Compute eigendecomposition of the normalized graph Laplacian\n\n        Args:\n            adj: Adjacency matrix\n\n        Returns:\n            eigenvalues, eigenvectors of the normalized Laplacian\n        \"\"\"\n        # Compute normalized Laplacian\n        # Add self-loops\n        adj = adj + sp.eye(adj.shape[0])\n\n        # Compute degree matrix\n        deg = np.array(adj.sum(axis=1))\n        Dsqrt_inv = sp.diags(1.0 / np.sqrt(deg).flatten())\n\n        # Compute normalized Laplacian: D^(-1/2) A D^(-1/2)\n        laplacian = sp.eye(adj.shape[0]) - Dsqrt_inv @ adj @ Dsqrt_inv\n\n        # Compute eigendecomposition\n        # Using k=adj.shape[0]-1 to get all non-zero eigenvalues\n        eigenvals, eigenvecs = slinalg.eigsh(laplacian.tocsc(), k=adj.shape[0]-1,which='SM', tol=1e-6)\n\n        return torch.FloatTensor(eigenvals), torch.FloatTensor(eigenvecs)\n\n    def forward(self, x, eigenvecs):\n        \"\"\"\n        Forward pass implementing Bruna's spectral convolution\n\n        Args:\n            x: Input features [num_nodes, in_features]\n            eigenvecs: Eigenvectors of the graph Laplacian [num_nodes, num_nodes-1]\n\n        Returns:\n            Output features [num_nodes, out_features]\n        \"\"\"\n        # Transform to spectral domain\n        x_spectral = torch.matmul(eigenvecs.t(), x)  # [num_nodes-1, in_features]\n\n        # Initialize output tensor\n        out = torch.zeros(x.size(0), self.out_features, device=x.device)\n\n        # For each input-output feature pair\n        for i in range(self.in_features):\n            for j in range(self.out_features):\n                # Element-wise multiplication in spectral domain\n                # This is the actual spectral filtering operation\n                filtered = x_spectral[:, i] * self.weight[i, j, :]  # [num_spectrum]\n\n                # Transform back to spatial domain and accumulate\n                out[:, j] += torch.matmul(eigenvecs, filtered)\n\n        return out\n\nNext, we will train the model on the karate club network to predict the given node labels indicating nodes’ community memberships. We load the data by\n\n:tags: [hide-input]\n\nimport networkx as nx\nimport torch\nimport matplotlib.pyplot as plt\n\n# Load karate club network\nG = nx.karate_club_graph()\nadj = nx.to_scipy_sparse_array(G)\nfeatures = torch.eye(G.number_of_nodes())\nlabels = torch.tensor([G.nodes[i]['club'] == 'Officer' for i in G.nodes()], dtype=torch.long)\n\nWe apply the convolution twice with ReLu activation in between. This can be implemented by preparing two independent BrunaGraphConv layers, applying them consecutively, and adding a ReLu activation in between.\n\n:tags: [hide-input]\n\n# Define a simple GCN model\nclass SimpleGCN(nn.Module):\n    def __init__(self, in_features, out_features, hidden_features, n_nodes):\n        super(SimpleGCN, self).__init__()\n        self.conv1 = BrunaGraphConv(in_features, hidden_features, n_nodes)\n        self.relu = nn.ReLU()\n        self.conv2 = BrunaGraphConv(hidden_features, out_features, n_nodes)\n\n    def forward(self, x, eigenvecs):\n        x = self.conv1(x, eigenvecs)\n        x = self.relu(x)\n        x = self.conv2(x, eigenvecs)\n        return x\n\nWe then train the model by\n\n:tags: [hide-input]\n\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Get eigenvectors of the Laplacian\neigenvals, eigenvecs = BrunaGraphConv.get_laplacian_eigenvectors(adj)\n\n# Initialize the model\nhidden_features = 10\ninput_features = features.shape[1]\noutput_features = 2\nn_nodes = G.number_of_nodes()\nmodel = SimpleGCN(input_features, output_features, hidden_features, n_nodes)\n\n# Train the model\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Split the data into training and testing sets\ntrain_idx, test_idx = train_test_split(np.arange(G.number_of_nodes()), test_size=0.2, random_state=42)\ntrain_features = features[train_idx]\ntrain_labels = labels[train_idx]\ntest_features = features[test_idx]\ntest_labels = labels[test_idx]\n\n\nn_train = 100\nfor epoch in range(n_train):\n    model.train()\n    optimizer.zero_grad()\n    output = model(train_features, eigenvecs[train_idx, :])\n    loss = criterion(output, train_labels)\n    loss.backward()\n    optimizer.step()\n\n    # Evaluate the model\n    if epoch == 0 or (epoch+1) % 25 == 0:\n        model.eval()\n        with torch.no_grad():\n            output = model(test_features, eigenvecs[test_idx, :])\n            _, predicted = torch.max(output, 1)\n            accuracy = (predicted == test_labels).float().mean()\n            print(f'Epoch {epoch+1}/{n_train}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}')\n\nObserve that the accuracy increases as the training progresses. We can use the model to predict the labels. The model has a hidden layer, and let’s visualize the data in the hidden space.\n\n:tags: [hide-input]\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\n# Visualize the learned embeddings\nembeddings = model.conv1(features, eigenvecs).detach().numpy()\n\nxy = TSNE(n_components=2).fit_transform(embeddings)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.scatterplot(x = xy[:, 0].reshape(-1), y = xy[:, 1].reshape(-1), hue=labels.numpy(), palette='tab10', ax = ax)\nax.set_title(\"Learned Node Embeddings\")\nplt.show()",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/04-appendix.html#brunas-spectral-gcn",
    "href": "m09-graph-neural-networks/04-appendix.html#brunas-spectral-gcn",
    "title": "Appendix",
    "section": "",
    "text": "Let’s first implement Bruna’s spectral GCN.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport scipy.sparse as sp\nimport torch\nimport torch.nn as nn\nimport scipy.sparse.linalg as slinalg\n\nclass BrunaGraphConv(nn.Module):\n    \"\"\"\n    Bruna's Spectral Graph Convolution Layer\n\n    This implementation follows the original formulation by Joan Bruna et al.,\n    using the eigendecomposition of the graph Laplacian for spectral convolution.\n    \"\"\"\n\n    def __init__(self, in_features, out_features, n_nodes):\n        \"\"\"\n        Initialize the Bruna Graph Convolution layer\n\n        Args:\n            in_features (int): Number of input features\n            out_features (int): Number of output features\n        \"\"\"\n        super(BrunaGraphConv, self).__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        # Learnable spectral filter parameters\n        self.weight = nn.Parameter(\n            torch.FloatTensor(in_features, out_features, n_nodes-1)\n        )\n\n        # Initialize parameters\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        \"\"\"Initialize weights using Glorot initialization\"\"\"\n        nn.init.xavier_uniform_(self.weight)\n\n\n    @staticmethod\n    def get_laplacian_eigenvectors(adj):\n        \"\"\"\n        Compute eigendecomposition of the normalized graph Laplacian\n\n        Args:\n            adj: Adjacency matrix\n\n        Returns:\n            eigenvalues, eigenvectors of the normalized Laplacian\n        \"\"\"\n        # Compute normalized Laplacian\n        # Add self-loops\n        adj = adj + sp.eye(adj.shape[0])\n\n        # Compute degree matrix\n        deg = np.array(adj.sum(axis=1))\n        Dsqrt_inv = sp.diags(1.0 / np.sqrt(deg).flatten())\n\n        # Compute normalized Laplacian: D^(-1/2) A D^(-1/2)\n        laplacian = sp.eye(adj.shape[0]) - Dsqrt_inv @ adj @ Dsqrt_inv\n\n        # Compute eigendecomposition\n        # Using k=adj.shape[0]-1 to get all non-zero eigenvalues\n        eigenvals, eigenvecs = slinalg.eigsh(laplacian.tocsc(), k=adj.shape[0]-1,which='SM', tol=1e-6)\n\n        return torch.FloatTensor(eigenvals), torch.FloatTensor(eigenvecs)\n\n    def forward(self, x, eigenvecs):\n        \"\"\"\n        Forward pass implementing Bruna's spectral convolution\n\n        Args:\n            x: Input features [num_nodes, in_features]\n            eigenvecs: Eigenvectors of the graph Laplacian [num_nodes, num_nodes-1]\n\n        Returns:\n            Output features [num_nodes, out_features]\n        \"\"\"\n        # Transform to spectral domain\n        x_spectral = torch.matmul(eigenvecs.t(), x)  # [num_nodes-1, in_features]\n\n        # Initialize output tensor\n        out = torch.zeros(x.size(0), self.out_features, device=x.device)\n\n        # For each input-output feature pair\n        for i in range(self.in_features):\n            for j in range(self.out_features):\n                # Element-wise multiplication in spectral domain\n                # This is the actual spectral filtering operation\n                filtered = x_spectral[:, i] * self.weight[i, j, :]  # [num_spectrum]\n\n                # Transform back to spatial domain and accumulate\n                out[:, j] += torch.matmul(eigenvecs, filtered)\n\n        return out\n\nNext, we will train the model on the karate club network to predict the given node labels indicating nodes’ community memberships. We load the data by\n\n:tags: [hide-input]\n\nimport networkx as nx\nimport torch\nimport matplotlib.pyplot as plt\n\n# Load karate club network\nG = nx.karate_club_graph()\nadj = nx.to_scipy_sparse_array(G)\nfeatures = torch.eye(G.number_of_nodes())\nlabels = torch.tensor([G.nodes[i]['club'] == 'Officer' for i in G.nodes()], dtype=torch.long)\n\nWe apply the convolution twice with ReLu activation in between. This can be implemented by preparing two independent BrunaGraphConv layers, applying them consecutively, and adding a ReLu activation in between.\n\n:tags: [hide-input]\n\n# Define a simple GCN model\nclass SimpleGCN(nn.Module):\n    def __init__(self, in_features, out_features, hidden_features, n_nodes):\n        super(SimpleGCN, self).__init__()\n        self.conv1 = BrunaGraphConv(in_features, hidden_features, n_nodes)\n        self.relu = nn.ReLU()\n        self.conv2 = BrunaGraphConv(hidden_features, out_features, n_nodes)\n\n    def forward(self, x, eigenvecs):\n        x = self.conv1(x, eigenvecs)\n        x = self.relu(x)\n        x = self.conv2(x, eigenvecs)\n        return x\n\nWe then train the model by\n\n:tags: [hide-input]\n\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Get eigenvectors of the Laplacian\neigenvals, eigenvecs = BrunaGraphConv.get_laplacian_eigenvectors(adj)\n\n# Initialize the model\nhidden_features = 10\ninput_features = features.shape[1]\noutput_features = 2\nn_nodes = G.number_of_nodes()\nmodel = SimpleGCN(input_features, output_features, hidden_features, n_nodes)\n\n# Train the model\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Split the data into training and testing sets\ntrain_idx, test_idx = train_test_split(np.arange(G.number_of_nodes()), test_size=0.2, random_state=42)\ntrain_features = features[train_idx]\ntrain_labels = labels[train_idx]\ntest_features = features[test_idx]\ntest_labels = labels[test_idx]\n\n\nn_train = 100\nfor epoch in range(n_train):\n    model.train()\n    optimizer.zero_grad()\n    output = model(train_features, eigenvecs[train_idx, :])\n    loss = criterion(output, train_labels)\n    loss.backward()\n    optimizer.step()\n\n    # Evaluate the model\n    if epoch == 0 or (epoch+1) % 25 == 0:\n        model.eval()\n        with torch.no_grad():\n            output = model(test_features, eigenvecs[test_idx, :])\n            _, predicted = torch.max(output, 1)\n            accuracy = (predicted == test_labels).float().mean()\n            print(f'Epoch {epoch+1}/{n_train}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}')\n\nObserve that the accuracy increases as the training progresses. We can use the model to predict the labels. The model has a hidden layer, and let’s visualize the data in the hidden space.\n\n:tags: [hide-input]\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\n# Visualize the learned embeddings\nembeddings = model.conv1(features, eigenvecs).detach().numpy()\n\nxy = TSNE(n_components=2).fit_transform(embeddings)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.scatterplot(x = xy[:, 0].reshape(-1), y = xy[:, 1].reshape(-1), hue=labels.numpy(), palette='tab10', ax = ax)\nax.set_title(\"Learned Node Embeddings\")\nplt.show()",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/04-appendix.html#chebnet",
    "href": "m09-graph-neural-networks/04-appendix.html#chebnet",
    "title": "Appendix",
    "section": "2 ChebNet",
    "text": "2 ChebNet\nLet’s implement the ChebNet layer.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport scipy.sparse as sp\nfrom typing import Optional\n\n\ndef sparse_mx_to_torch_sparse(sparse_mx):\n    \"\"\"Convert scipy sparse matrix to torch sparse tensor.\"\"\"\n    sparse_mx = sparse_mx.tocoo()\n    indices = torch.from_numpy(\n        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n    )\n    values = torch.from_numpy(sparse_mx.data.astype(np.float32))\n    shape = torch.Size(sparse_mx.shape)\n    return torch.sparse_coo_tensor(indices, values, shape)\n\n\nclass ChebConv(nn.Module):\n    \"\"\"\n    Chebyshev Spectral Graph Convolutional Layer\n    \"\"\"\n\n    def __init__(self, in_channels: int, out_channels: int, K: int, bias: bool = True):\n        super(ChebConv, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.K = K\n\n        # Trainable parameters\n        self.weight = nn.Parameter(torch.Tensor(K, in_channels, out_channels))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(out_channels))\n        else:\n            self.register_parameter(\"bias\", None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        \"\"\"Initialize parameters.\"\"\"\n        nn.init.xavier_uniform_(self.weight)\n        if self.bias is not None:\n            nn.init.zeros_(self.bias)\n\n    def _normalize_laplacian(self, adj_matrix):\n        \"\"\"\n        Compute normalized Laplacian L = I - D^(-1/2)AD^(-1/2)\n        \"\"\"\n        # Convert to scipy if it's not already\n        if not sp.isspmatrix(adj_matrix):\n            adj_matrix = sp.csr_matrix(adj_matrix)\n\n        adj_matrix = adj_matrix.astype(float)\n\n        # Compute degree matrix D\n        rowsum = np.array(adj_matrix.sum(1)).flatten()\n        d_inv_sqrt = np.power(rowsum, -0.5)\n        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.0\n        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n\n        # Compute L = I - D^(-1/2)AD^(-1/2)\n        n = adj_matrix.shape[0]\n        L = sp.eye(n) - d_mat_inv_sqrt @ adj_matrix @ d_mat_inv_sqrt\n        return L\n\n    def _scale_laplacian(self, L):\n        \"\"\"\n        Scale Laplacian eigenvalues to [-1, 1] interval\n        L_scaled = 2L/lambda_max - I\n        \"\"\"\n        try:\n            # Compute largest eigenvalue\n            eigenval, _ = sp.linalg.eigsh(L, k=1, which=\"LM\", return_eigenvectors=False)\n            lambda_max = eigenval[0]\n        except:\n            # Approximate lambda_max = 2 if eigenvalue computation fails\n            lambda_max = 2.0\n\n        n = L.shape[0]\n        L_scaled = (2.0 / lambda_max) * L - sp.eye(n)\n        return L_scaled\n\n    def chebyshev_basis(self, L_sparse: torch.sparse.Tensor, X: torch.Tensor):\n        \"\"\"\n        Compute Chebyshev polynomials basis up to order K.\n        \"\"\"\n        # List to store Chebyshev polynomials\n        cheb_polynomials = []\n\n        # T_0(L) = I\n        cheb_polynomials.append(X)\n\n        if self.K &gt; 1:\n            # T_1(L) = L\n            X_1 = torch.sparse.mm(L_sparse, X)\n            cheb_polynomials.append(X_1)\n\n        # Recurrence T_k(L) = 2L·T_{k-1}(L) - T_{k-2}(L)\n        for k in range(2, self.K):\n            X_k = (\n                2 * torch.sparse.mm(L_sparse, cheb_polynomials[k - 1])\n                - cheb_polynomials[k - 2]\n            )\n            cheb_polynomials.append(X_k)\n\n        return torch.stack(cheb_polynomials, dim=0)  # [K, num_nodes, in_channels]\n\n    def forward(self, X: torch.Tensor, adj_matrix: sp.spmatrix):\n        \"\"\"\n        Forward pass.\n\n        Args:\n            X: Node features tensor of shape [num_nodes, in_channels]\n            adj_matrix: Adjacency matrix in scipy sparse format\n\n        Returns:\n            Output tensor of shape [num_nodes, out_channels]\n        \"\"\"\n        # Compute normalized and scaled Laplacian\n        L_norm = self._normalize_laplacian(adj_matrix)\n        L_scaled = self._scale_laplacian(L_norm)\n\n        # Convert to torch sparse tensor\n        L_scaled = sparse_mx_to_torch_sparse(L_scaled).to(X.device)\n\n        # Compute Chebyshev polynomials basis\n        Tx = self.chebyshev_basis(L_scaled, X)  # [K, num_nodes, in_channels]\n\n        # Perform convolution using learned weights\n        out = torch.einsum(\"kni,kio-&gt;no\", Tx, self.weight)\n\n        if self.bias is not None:\n            out += self.bias\n\n        return out\n\nWe stack the layers to form a simple GCN model.\n\n:tags: [hide-input]\n\nclass ChebNet(nn.Module):\n    \"\"\"\n    ChebNet model for node classification\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        hidden_channels: int,\n        out_channels: int,\n        K: int,\n        num_layers: int,\n        dropout: float = 0.5,\n    ):\n        super(ChebNet, self).__init__()\n\n        self.convs = nn.ModuleList()\n\n        # First layer\n        self.convs.append(ChebConv(in_channels, hidden_channels, K))\n\n        # Hidden layers\n        for _ in range(num_layers - 2):\n            self.convs.append(ChebConv(hidden_channels, hidden_channels, K))\n\n        # Output layer\n        self.convs.append(ChebConv(hidden_channels, out_channels, K))\n\n        self.dropout = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, X: torch.Tensor, adj_matrix: sp.spmatrix):\n        \"\"\"\n        Forward pass through all layers\n        \"\"\"\n        for i, conv in enumerate(self.convs[:-1]):\n            X = conv(X, adj_matrix)\n            X = self.activation(X)\n            X = self.dropout(X)\n\n        # Output layer\n        X = self.convs[-1](X, adj_matrix)\n        return X\n\nLet’s train the model on the karate club network.\n\n:tags: [hide-input]\n\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\nimport networkx as nx\nimport torch\nimport matplotlib.pyplot as plt\n\n# Load karate club network\nG = nx.karate_club_graph()\nadj = nx.to_scipy_sparse_array(G)\nfeatures = torch.eye(G.number_of_nodes())\nlabels = torch.tensor(\n    [G.nodes[i][\"club\"] == \"Officer\" for i in G.nodes()], dtype=torch.long\n)\n\n# Initialize the model\nhidden_features = 10\ninput_features = features.shape[1]\noutput_features = 2\nn_nodes = G.number_of_nodes()\nK = 3\nnum_layers = 2\ndropout = 0.5\n\nmodel = ChebNet(\n    input_features, hidden_features, output_features, K, num_layers, dropout\n)\n\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Train the model\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Split the data into training and testing sets\ntrain_idx, test_idx = train_test_split(\n    np.arange(G.number_of_nodes()), test_size=0.2, random_state=42\n)\ntrain_features = features[train_idx]\ntrain_labels = labels[train_idx]\ntest_features = features[test_idx]\ntest_labels = labels[test_idx]\n\n\nn_train = 100\nfor epoch in range(n_train):\n    model.train()\n    optimizer.zero_grad()\n    output = model(features, adj)\n    loss = criterion(output[train_idx], train_labels)\n    loss.backward()\n    optimizer.step()\n\n    # Evaluate the model\n    if epoch == 0 or (epoch + 1) % 25 == 0:\n        model.eval()\n        with torch.no_grad():\n            output = model(features, adj)\n            _, predicted = torch.max(output[test_idx], 1)\n            accuracy = (predicted == test_labels).float().mean()\n            print(\n                f\"Epoch {epoch+1}/{n_train}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}\"\n            )\n\nLet’s visualize the learned embeddings.\n\n:tags: [hide-input]\n\nmodel.eval()\nwith torch.no_grad():\n    # Get embeddings from the last hidden layer\n    X_hidden = features\n    for conv in model.convs[:-1]:\n        X_hidden = conv(X_hidden, adj)\n        X_hidden = model.activation(X_hidden)\n\n# Reduce dimensionality for visualization\nxy = TSNE(n_components=2).fit_transform(X_hidden.numpy())\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.scatterplot(\n    x=xy[:, 0].reshape(-1),\n    y=xy[:, 1].reshape(-1),\n    hue=labels.numpy(),\n    palette=\"tab10\",\n    ax=ax,\n)\nax.set_title(\"Learned Node Embeddings\")\nplt.show()",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/graph-convolutional-network.html",
    "href": "m09-graph-neural-networks/graph-convolutional-network.html",
    "title": "Graph Convolutional Networks",
    "section": "",
    "text": "We have seen that spectral filters give us a principled way to think about “convolution” on irregular graph structures, and controlling the frequency components brings out different aspects of the data. We now go one step further: instead of designing filters by hand, we can learn them from data for specific tasks."
  },
  {
    "objectID": "m09-graph-neural-networks/graph-convolutional-network.html#spectral-graph-convolutional-networks",
    "href": "m09-graph-neural-networks/graph-convolutional-network.html#spectral-graph-convolutional-networks",
    "title": "Graph Convolutional Networks",
    "section": "1 Spectral Graph Convolutional Networks",
    "text": "1 Spectral Graph Convolutional Networks\nA simplest form of learnable spectral filter is given by\n\n{\\bf L}_{\\text{learn}} = \\sum_{k=1}^K \\theta_k {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\nwhere {\\mathbf u}_k are the eigenvectors and \\theta_k are the learnable parameters. The variable K is the number of eigenvectors used (i.e., the rank of the filter). The weight \\theta_k is learned to maximize the performance of the task at hand.\nBuilding on this idea, {footcite}bruna2014spectral added a nonlinearity to the filter and proposed a spectral convolutional neural network (GCN) by\n\n{\\bf x}^{(\\ell+1)} = h\\left( L_{\\text{learn}} {\\bf x}^{(\\ell)}\\right),\n\nwhere h is an activation function, and {\\bf x}^{(\\ell)} is the feature vector of the \\ell-th convolution. They further extend this idea to convolve on multidimensional feature vectors, {\\bf X} \\in \\mathbb{R}^{N \\times f_{\\text{in}}} to produce new feature vectors of different dimensionality, {\\bf X}' \\in \\mathbb{R}^{N \\times f_{\\text{out}}}.\n\n\\begin{aligned}\n{\\bf X}^{(\\ell+1)}_i &= h\\left( \\sum_j L_{\\text{learn}}^{(i,j)} {\\bf X}^{(\\ell)}_j\\right),\\quad \\text{where} \\quad L^{(i,j)}_{\\text{learn}} = \\sum_{k=1}^K \\theta_{k, (i,j)} {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\\end{aligned}\n\nNotice that the learnable filter L_{\\text{learn}}^{(i,j)} is defined for each pair of input i and output j dimensions.\nMany GCNs simple when it comes to implementation despite the complicated formula. And this is one of my ways to learn GNNs. Check out the [Appendix for the Python implementation](appendix.md)."
  },
  {
    "objectID": "m09-graph-neural-networks/graph-convolutional-network.html#from-spectral-to-spatial",
    "href": "m09-graph-neural-networks/graph-convolutional-network.html#from-spectral-to-spatial",
    "title": "Graph Convolutional Networks",
    "section": "2 From Spectral to Spatial",
    "text": "2 From Spectral to Spatial\nSpectral GCNs are mathematically elegant but have two main limitations: 1. Computational Limitation: Computing the spectra of the Laplacian is expensive {\\cal O}(N^3) and prohibitive for large graphs 2. Spatial Locality: The learned filters are not spatially localized. A node can be influenced by all other nodes in the graph.\nThese two limitations motivate the development of spatial GCNs.\n\nChebNet\nChebNet {footcite}defferrard2016convolutional is one of the earliest spatial GCNs that bridges the gap between spectral and spatial domains. The key idea is to leverage Chebyshev polynomials to approximate {\\bf L}_{\\text{learn}} by\n\n{\\bf L}_{\\text{learn}} \\approx \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}), \\quad \\text{where} \\quad \\tilde{{\\bf L}} = \\frac{2}{\\lambda_{\\text{max}}}{\\bf L} - {\\bf I},\n\nwhere \\tilde{{\\bf L}} is the scaled and normalized Laplacian matrix in order to have eigenvalues in the range of [-1,1]. The Chebyshev polynomials T_k(\\tilde{{\\bf L}}) transforms the eigenvalues \\tilde{{\\bf L}} to the following recursively:\n\n\\begin{aligned}\nT_0(\\tilde{{\\bf L}}) &= {\\bf I} \\\\\nT_1(\\tilde{{\\bf L}}) &= \\tilde{{\\bf L}} \\\\\nT_k(\\tilde{{\\bf L}}) &= 2\\tilde{{\\bf L}} T_{k-1}(\\tilde{{\\bf L}}) - T_{k-2}(\\tilde{{\\bf L}})\n\\end{aligned}\n\nWe then replace {\\bf L}_{\\text{learn}} in the original spectral GCN with the Chebyshev polynomial approximation:\n\n{\\bf x}^{(\\ell+1)} = h\\left( \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}){\\bf x}^{(\\ell)}\\right),\n\nwhere: - T_k(\\tilde{{\\bf L}}) applies the k-th Chebyshev polynomial to the scaled Laplacian matrix - \\theta_k are the learnable parameters - K is the order of the polynomial (typically small, e.g., K=3)\n\n\nGraph Convolutional Networks by Kipf and Welling\nWhile ChebNet offers a principled way to approximate spectral convolutions, Kipf and Welling (2017) {footcite}kipf2017semi proposed an even simpler and highly effective variant called Graph Convolutional Networks (GCN).\n\n\nFirst-order Approximation\nThe key departure is to use the first-order approximation of the Chebyshev polynomials.\n\ng_{\\theta'} * x \\approx \\theta'_0x + \\theta'_1(L - I_N)x = \\theta'_0x - \\theta'_1D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}x\n\nThis is crude approximation but it leads to a much simpler form, leaving only two learnable parameters, instead of K parameters in the original ChebNet.\nAdditionally, they further simplify the formula by using the same \\theta for both remaining parameters (i.e., \\theta_0 = \\theta and \\theta_1 = -\\theta). The result is the following convolutional filter:\n\ng_{\\theta} * x \\approx \\theta(I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}})x\n\nWhile this is a very simple filter, one can stack multiple layers of convolutions to perform high-order graph convolutions.\n\n\nDeep GCNs can suffer from over-smoothing\nGCN models can be deep, and when they are too deep, they start suffering from an ill-posed problem called gradient vanishing/exploding, where the gradients of the loss function becomes too small or too large to update the model parameters. It is a common problem in deep learning.\nTo facilitate the training of deep GCNs, the authors introduce a very simple trick called renormalization. The idea is to add self-connections to the graph:\n\n\\tilde{A} = A + I_N, \\quad \\text{and} \\quad \\tilde{D}_{ii} = \\sum_j \\tilde{A}_{ij}\n\nAnd use \\tilde{A} and \\tilde{D} to form the convolutional filter.\nAltogether, this leads to the following layer-wise propagation rule:\nX^{(\\ell+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}X^{(\\ell)}W^{(\\ell)})\nwhere: - X^{(\\ell)} is the matrix of node features at layer \\ell - W^{(\\ell)} is the layer’s trainable weight matrix - \\sigma is a nonlinear activation function (e.g., ReLU)\nThese simplifications offer several advantages: - Efficiency: Linear complexity in number of edges - Localization: Each layer only aggregates information from immediate neighbors - Depth: Fewer parameters allow building deeper models - Performance: Despite (or perhaps due to) its simplicity, it often outperforms more complex models\n\n\n\n\n\n\nExercise\n\n\n\n:class: note\nLet’s implement a simple GCN model for node classification. Coding Exercise"
  },
  {
    "objectID": "m09-graph-neural-networks/popular-gnn.html",
    "href": "m09-graph-neural-networks/popular-gnn.html",
    "title": "Popular Graph Neural Networks",
    "section": "",
    "text": "In this note, we will introduce three popular GNNs: GraphSAGE, Graph Attention Networks (GAT), and Graph Isomorphism Network (GIN)."
  },
  {
    "objectID": "m09-graph-neural-networks/popular-gnn.html#graphsage-sample-and-aggregate",
    "href": "m09-graph-neural-networks/popular-gnn.html#graphsage-sample-and-aggregate",
    "title": "Popular Graph Neural Networks",
    "section": "1 GraphSAGE: Sample and Aggregate",
    "text": "1 GraphSAGE: Sample and Aggregate\nGraphSAGE {footcite}hamilton2017graphsage introduced a different GCN that can be generalized to unseen nodes (they called it “inductive”). While previous approaches like ChebNet and GCN operate on the entire graph, GraphSAGE proposes an inductive framework that generates embeddings by sampling and aggregating features from a node’s neighborhood.\n\n\nKey Ideas\nGraphSAGE involves two key ideas: (1) sampling and (2) aggregation.\n\n\nNeighborhood Sampling\nThe key idea is the neighborhood sampling. Instead of using all neighbors, GraphSAGE samples a fixed-size set of neighbors for each node. This controls memory complexity, a key limitation of the previous GNNs.\nAnother key advantage of neighborhood sampling is that it enables GraphSAGE to handle dynamic, growing networks. Consider a citation network where new papers (nodes) are continuously added. Traditional GCNs would need to recompute filters for the entire network with each new addition. In contrast, GraphSAGE can immediately generate embeddings for new nodes by simply sampling their neighbors, without any retraining or recomputation.\n\n\nAggregation\nAnother key idea is the aggregation. GraphSAGE makes a distinction between self-information and neighborhood information. While previous GNNs treat them equally and aggregate them, GraphSAGE treats them differently. Specifically, GraphSAGE introduces an additional step: it concatenates the self-information and the neighborhood information as the input of the convolution.\n\nZ_v = \\text{CONCAT}(X_v, X_{\\mathcal{N}(v)})\n\nwhere X_v is the feature of the node itself and X_{\\mathcal{N}(v)} is the aggregation of the features of its neighbors. GraphSAGE introduces different ways to aggregate information from neighbors:\nX_{\\mathcal{N}(v)} = \\text{AGGREGATE}_k(\\{X_u, \\forall u \\in \\mathcal{N}(v)\\})\nCommon aggregation functions include: - Mean aggregator: \\text{AGGREGATE} = \\text{mean}(\\{h_u, \\forall u \\in \\mathcal{N}(v)\\}) - Max-pooling: \\text{AGGREGATE} = \\max(\\{\\sigma(W_{\\text{pool}}h_u + b), \\forall u \\in \\mathcal{N}(v)\\}) - LSTM aggregator: Apply LSTM to randomly permuted neighbors\nThe concatenated feature Z_v is normalized by the L2 norm.\n\n\\hat{Z}_v = \\frac{Z_v}{\\|Z_v\\|_2}\n\nand then fed into the convolution.\n\nX_v^k = \\sigma(W^k \\hat{Z}_v + b^k)"
  },
  {
    "objectID": "m09-graph-neural-networks/popular-gnn.html#graph-attention-networks-gat-differentiate-individual-neighbors",
    "href": "m09-graph-neural-networks/popular-gnn.html#graph-attention-networks-gat-differentiate-individual-neighbors",
    "title": "Popular Graph Neural Networks",
    "section": "2 Graph Attention Networks (GAT): Differentiate Individual Neighbors",
    "text": "2 Graph Attention Networks (GAT): Differentiate Individual Neighbors\nA key innovation of GraphSAGE is to treat the self and neighborhood information differently. But should all neighbors be treated equally? Graph Attention Networks (GAT) address this by letting the model learn which neighbors to pay attention to.\n\nAttention Mechanism\n\nThe core idea is beautifully simple: instead of using fixed weights like GCN, let’s learn attention weights \\alpha_{ij} that determine how much node i should attend to node j. These weights are computed dynamically based on node features:\n\n\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik})}\n\nwhere e_{ij} represents the importance of the edge between node i and node j. Variable e_{ij} is a learnable parameter and can be negative, and the exponential function is applied to transform it to a non-negative value, with the normalization term \\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik}) to ensure the weights sum to 1.\nHow to compute e_{ij}? One simple choice is to use a neural network with a shared weight matrix W and a LeakyReLU activation function. Specifically:\n\nLet’s focus on computing e_{ij} for node i and its neighbor j.\nWe use a shared weight matrix W to transform the features of node i and j. \n\\mathbf{\\tilde h}_i  = \\mathbf{h}_i, \\quad \\mathbf{\\tilde h}_j  = W\\mathbf{h}_j\n\nWe concatenate the transformed features and apply a LeakyReLU activation function.\n\n\ne_{ij} = \\text{LeakyReLU}(\\mathbf{a}^T[\\mathbf{\\tilde h}_i, \\mathbf{\\tilde h}_j])\n\nwhere \\mathbf{a} is a trainable parameter vector that sums the two transformed features.\nOnce we have these attention weights, the node update is straightforward - just a weighted sum of neighbor features:\n\\mathbf{h}'_i = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}{\\bf W}_{\\text{feature}}\\mathbf{h}_j\\right)\nwhere {\\bf W}_{\\text{feature}} is a trainable weight matrix. To stabilize training, GAT uses multiple attention heads and concatenates their outputs:\n\\mathbf{h}'_i = \\parallel_{k=1}^K \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}^k{\\bf W}^k_{\\text{feature}}\\mathbf{h}_j\\right)"
  },
  {
    "objectID": "m09-graph-neural-networks/popular-gnn.html#graph-isomorphism-network-gin-differentiate-the-aggregation",
    "href": "m09-graph-neural-networks/popular-gnn.html#graph-isomorphism-network-gin-differentiate-the-aggregation",
    "title": "Popular Graph Neural Networks",
    "section": "3 Graph Isomorphism Network (GIN): Differentiate the Aggregation",
    "text": "3 Graph Isomorphism Network (GIN): Differentiate the Aggregation\nGraph Isomorphism Networks (GIN) is another popular GNN that born out of a question: what is the maximum discriminative power achievable by Graph Neural Networks? The answer lies in its theoretical connection to the Weisfeiler-Lehman (WL) test, a powerful algorithm for graph isomorphism testing.\n\nWeisfeiler-Lehman Test\nAre two graphs structurally identical? Graph isomorphism testing determines if two graphs are structurally identical, with applications in graph classification, clustering, and other tasks.\n\nWhile the general problem has no known polynomial-time solution, the WL test is an efficient heuristic that works well in practice. The WL test iteratively refines node labels by hashing the multiset of neighboring labels\n\nThe WL test works as follows:\n\nAssign all nodes the same initial label.\nFor each node, collect the labels of all its neighbors and aggregate them into a hash (e.g., new label). For example, the top node gets {0} from its neighbors, resulting in a collection {0,0}. A new label is created via a hash function h that maps {0, {0, 0}} to a new label 1.\nRepeat the process for a fixed number of iterations or until convergence.\n\nHere is the implementation of the WL test in Python:\n\n:tags: [hide-input]\n\nimport numpy as np\nfrom scipy import sparse\n\ndef weisfeiler_lehman_test(A, num_iterations):\n    n_nodes = A.shape[0]\n    labels = np.zeros(n_nodes, dtype=int)\n    color_map = {}\n    hash_fn = lambda x: color_map.setdefault(x, len(color_map))\n    for _ in range(num_iterations):\n\n        # Go through each node\n        labels_old = labels.copy()\n        for i in range(n_nodes):\n\n            # Collect the labels of all neighbors\n            neighbors = A[i].nonzero()[1]\n            neighbor_labels = labels_old[neighbors]\n\n            # Count the frequency of each label\n            unique, counts = np.unique(neighbor_labels, return_counts=True)\n\n            # Create a hash key by converting the frequency dictionary to a string\n            hash_key = str({unique[j]: counts[j] for j in range(len(unique))})\n\n            # Create a new label by hashing the frequency dictionary\n            label = hash_fn(hash_key)\n            labels[i] = label\n\n        # Check convergence\n        unique, counts = np.unique(labels, return_counts=True)\n        unique_old, counts_old = np.unique(labels_old, return_counts=True)\n        if np.array_equal(np.sort(counts), np.sort(counts_old)):\n            break\n    return labels\n\n\nedge_list = [(0, 1), (1, 2), (2, 0), (3, 4), (4, 5), (5, 3)]\n\nA = sparse.csr_matrix(\n    ([1] * len(edge_list), ([e[0] for e in edge_list], [e[1] for e in edge_list])),\n    shape=(6, 6),\n)\nA = A + A.T\nA.sort_indices()\n\nweisfeiler_lehman_test(A, A.shape[0])\n\nAfter these iterations: - Nodes with the same label are structurally identical, meaning that they are indistinguishable unless we label them differently. - Two graphs are structurally identical if and only if they have the same node labels after the WL test.\nThe WL test is a heuristic and can fail on some graphs. For example, it cannot distinguish regular graphs with the same number of nodes and edges.\nThe WL test above is called the 1-WL test. There are higher-order WL tests that can distinguish more graphs, which are the basis of advanced GNNs.\nCheck out [this note](https://www.moldesk.net/blog/weisfeiler-lehman-isomorphism-test/)\n\n\nGIN\nGIN {footcite}xu2018how is a GNN that is based on the WL test. The key idea is to focus on the parallel between the WL test and the GNN update rule. - In the WL test, we iteratively collect the labels of neighbors and aggregate them through a hash function. - In the GraphSAGE and GAT, the labels are the nodes’ features, and the aggregation is some arithmetic operations such as mean or max.\nThe key difference is that the hash function in the WL test always distinguishes different sets of neighbors’ labels, while the aggregation in GraphSAGE and GAT does not always do so. For example, if all nodes have the same feature (e.g., all 1), the aggregation by the mean or max will result in the same value for all nodes, whereas the hash function in the WL test can still distinguish different sets of neighbors’ labels by the count of each label.\nThe resulting convolution update rule is:\n\nh_v^{(k+1)} = \\text{MLP}^{(k)}\\left((1 + \\epsilon^{(k)}) \\cdot h_v^{(k)} + \\sum_{u \\in \\mathcal{N}(v)} h_u^{(k)}\\right)\n\nwhere \\text{MLP}^{(k)} is a multi-layer perceptron (MLP) with k layers, and \\epsilon^{(k)} is a fixed or trainable parameter."
  },
  {
    "objectID": "course/about.html",
    "href": "course/about.html",
    "title": "About us",
    "section": "",
    "text": "Networks are everywhere—from the Internet connecting billions of devices to the social connections that shape our daily lives. This course explores network data analysis from the ground up, combining hands-on coding with theoretical foundations to unlock the secrets of complex systems.",
    "crumbs": [
      "Home",
      "Course Information",
      "About us"
    ]
  },
  {
    "objectID": "course/about.html#about-us",
    "href": "course/about.html#about-us",
    "title": "About us",
    "section": "1 About us",
    "text": "1 About us\n\nInstructor\n\n\n\nWelcome! My name is Sadamori Kojaku, the instructor of this course. I started my career as a computer scientist but couldn’t resist to fall in love with Network Science right after I got Ph.D. Network Science is about a science on networks, and networks appear in many different forms in our daily lives. The internet, social media, and biological networks, power grid, and you name it. But when we abstract them into a bunch of dots connected by lines, we can compare them and understand them in a unified way. We can study them using the same toolkit no matter what the domain is, and can find universal patterns and principles that govern seemingly different systems. Sounds fun, right 😉?\nThis course will guide you through the fascinating world of networks, from foundational theory to hands-on coding and real-world applications. I hope you will enjoy and find the course useful in your future endeavors.\n\n\n\n\n\n\n\n\nTA\nTeaching Assistant is not yet assigned.\n\n\nAI Tutor (Minidora)\n\n\n\nMinidora is an AI tutor robot conceived in the 22nd century and deployed in the present era to support students. (the original character is designed by Fujiko Fujio for a famous Japanese manga called Doraemon). Minidora supports students in this course by providing dialogic explanations, quiz questions, and coding guidance on the course Discord.",
    "crumbs": [
      "Home",
      "Course Information",
      "About us"
    ]
  },
  {
    "objectID": "course/discord.html",
    "href": "course/discord.html",
    "title": "Discord",
    "section": "",
    "text": "We use a dedicated Discord server for this course to facilitate communication, Q&A, and collaboration outside of class. The Discord server is a space where you can:\n\nAsk questions about lectures, assignments, and projects\nDiscuss concepts and share resources with your peers\nGet support from the instructor, TA, and Minidora (the AI tutor)\nJoin study groups and participate in informal discussions\n\nInvitation links to the Discord server will be distributed via Brightspace. Please check the Brightspace announcements or course materials for the latest invite link.\nOnce you join, you’ll find channels for different topics (e.g., #random, #questions, #study-groups) and can interact with both classmates, AI tutor, and course staff. If you’re new to Discord, it’s a free platform available on web, desktop, and mobile.\n\n\n\nScreenshot of the course Discord server\n\n\nExample screenshot of the course Discord server interface.\nIf you have any trouble joining, please contact the instructor for assistance.",
    "crumbs": [
      "Home",
      "Course Information",
      "Discord"
    ]
  },
  {
    "objectID": "course/welcome.html",
    "href": "course/welcome.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to the course! In this class, we will explore the fascinating world of networks—from the social connections that shape our lives to the complex systems that power the internet, biology, and beyond.\nThis course is designed to provide you with both a theoretical foundation and hands-on experience in network science. You will learn how to analyze, model, and interpret network data using Python, and apply these skills to real-world problems.\n\n\n\nEngaging Lectures: Each week, we’ll dive into key concepts in network science, supported by interactive discussions and in-class activities.\nHands-on Coding: You’ll work with real network data using Python and modern data science tools.\nCollaborative Learning: Participate in group activities, discussions, and our dedicated Discord server for Q&A and support.\nProjects and Assignments: Apply your knowledge through coding assignments, quizzes, and a final project.\nSupport: Get help from the instructor, TA, and our AI tutor, Minidora.\n\n\n\n\n\nRead the About Us page to meet your instructor, TA, and Minidora.\nJoin the Discord server for announcements, help, and community.\nSet up your Python environment by following the Setup Guide.\nCheck out the Learning Activities to understand how the course is structured.",
    "crumbs": [
      "Home",
      "Course Information",
      "Welcome"
    ]
  },
  {
    "objectID": "course/welcome.html#what-to-expect",
    "href": "course/welcome.html#what-to-expect",
    "title": "Welcome",
    "section": "",
    "text": "Engaging Lectures: Each week, we’ll dive into key concepts in network science, supported by interactive discussions and in-class activities.\nHands-on Coding: You’ll work with real network data using Python and modern data science tools.\nCollaborative Learning: Participate in group activities, discussions, and our dedicated Discord server for Q&A and support.\nProjects and Assignments: Apply your knowledge through coding assignments, quizzes, and a final project.\nSupport: Get help from the instructor, TA, and our AI tutor, Minidora.",
    "crumbs": [
      "Home",
      "Course Information",
      "Welcome"
    ]
  },
  {
    "objectID": "course/welcome.html#how-to-get-started",
    "href": "course/welcome.html#how-to-get-started",
    "title": "Welcome",
    "section": "",
    "text": "Read the About Us page to meet your instructor, TA, and Minidora.\nJoin the Discord server for announcements, help, and community.\nSet up your Python environment by following the Setup Guide.\nCheck out the Learning Activities to understand how the course is structured.",
    "crumbs": [
      "Home",
      "Course Information",
      "Welcome"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html",
    "href": "m03-robustness/04-appendix.html",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "We will compute the average path length of a network of scientists. The network is constructed from {footcite:p}sinatra2016quantifying, where each node represents a scientist and two scientists are connected if they have co-authored a paper in Physical Review Journals from American Physical Society.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html#assignment",
    "href": "m03-robustness/04-appendix.html#assignment",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "We will compute the average path length of a network of scientists. The network is constructed from {footcite:p}sinatra2016quantifying, where each node represents a scientist and two scientists are connected if they have co-authored a paper in Physical Review Journals from American Physical Society.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m04-node-degree/what-to-learn.html",
    "href": "m04-node-degree/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn about the friendship paradox. Specifically, - Friendship paradox: what is it, why it’s important, and what are the consequences? - Keywords: friendship paradox, degree bias"
  },
  {
    "objectID": "m04-node-degree/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m04-node-degree/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn about the friendship paradox. Specifically, - Friendship paradox: what is it, why it’s important, and what are the consequences? - Keywords: friendship paradox, degree bias"
  },
  {
    "objectID": "m06-centrality/03-exercises.html",
    "href": "m06-centrality/03-exercises.html",
    "title": "Exercises & Assignments",
    "section": "",
    "text": "We will compute the various centrality measures for airport networks.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Exercises & Assignments"
    ]
  },
  {
    "objectID": "m06-centrality/what-to-learn.html",
    "href": "m06-centrality/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn centrality, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is centrality in networks? - How to operationalize centrality? - How to find centrality in networks? - Limitations of centrality - Keywords: degree centrality, closeness centrality, betweenness centrality, eigenvector centrality, PageRank, Katz centrality, HITS, random walk"
  },
  {
    "objectID": "m06-centrality/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m06-centrality/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn centrality, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is centrality in networks? - How to operationalize centrality? - How to find centrality in networks? - Limitations of centrality - Keywords: degree centrality, closeness centrality, betweenness centrality, eigenvector centrality, PageRank, Katz centrality, HITS, random walk"
  },
  {
    "objectID": "m08-embedding/00-preparation.html",
    "href": "m08-embedding/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying network embedding, ensure you understand: - From M01-M07: Network representations, linear algebra, eigenvalue theory, and Markov chain concepts - From M07: Stationary distributions and spectral properties of random walks\n\n\n\n\n\nEssential decomposition for dimensionality reduction: - Definition: For matrix A: A = U \\Sigma V^T - Components: U (left singular vectors), \\Sigma (singular values), V (right singular vectors) - Properties: Provides optimal low-rank approximation in Frobenius norm - Truncated SVD: Using only top-k singular values/vectors for compression\n\n\n\nMathematical foundation for embedding: - Frobenius norm: ||A||_F = \\sqrt{\\sum_{ij} A_{ij}^2} - Optimal approximation: SVD minimizes ||A - A_k||_F for rank-k matrix A_k - Information preservation: How much structure is retained in low dimensions\n\n\n\nClassical dimensionality reduction technique: - Objective: Find directions of maximum variance - Covariance matrix: C = \\frac{1}{n-1}X^TX for centered data matrix X - Solution: Eigenvectors of covariance matrix - Connection to SVD: PCA eigenvectors are SVD right singular vectors\n\n\n\n\n\n\nUnderstanding what we optimize in embedding: - Reconstruction error: How well embeddings recreate original data - Preservation metrics: Maintaining distances, similarities, or other properties - Regularization: Preventing overfitting and ensuring generalization\n\n\n\nEssential for neural embedding methods: - Gradient descent: \\theta_{t+1} = \\theta_t - \\alpha \\nabla_\\theta L(\\theta_t) - Stochastic gradient descent: Using random samples for efficiency - Learning rate scheduling: Adaptive step sizes - Convergence criteria: When to stop optimization\n\n\n\nFor embedding problems with constraints: - Orthogonality constraints: When embedding vectors must be orthogonal - Norm constraints: Limiting embedding vector magnitudes - Lagrange multipliers: Mathematical tool for handling constraints\n\n\n\n\n\n\nUnderstanding what makes a good distance measure: - Non-negativity: d(x,y) \\geq 0 - Symmetry: d(x,y) = d(y,x) - Triangle inequality: d(x,z) \\leq d(x,y) + d(y,z) - Identity: d(x,y) = 0 if and only if x = y\n\n\n\n\nEuclidean distance: ||x - y||_2\nCosine similarity: \\frac{x \\cdot y}{||x|| ||y||}\nManhattan distance: ||x - y||_1\nJaccard similarity: For set-based comparisons\n\n\n\n\nHow to evaluate if embeddings preserve important properties: - Distance preservation: Do similar nodes remain close? - Neighborhood preservation: Are local structures maintained? - Global structure: Are long-range relationships captured?\n\n\n\n\n\n\nUnderstanding challenges with high-dimensional spaces: - Distance concentration: All points become equidistant in high dimensions - Sparsity: High-dimensional spaces are mostly empty - Visualization challenges: Difficulty interpreting high-dimensional data\n\n\n\nAssumption underlying many embedding methods: - Manifold hypothesis: High-dimensional data lies on lower-dimensional manifolds - Local linearity: Small neighborhoods can be approximated linearly - Intrinsic dimensionality: True degrees of freedom in the data\n\n\n\n\n\n\nChallenges with large networks: - Matrix operations: O(n³) complexity for eigenvalue decomposition - Memory requirements: Storing large adjacency matrices - Approximation methods: Trading accuracy for computational efficiency\n\n\n\nEssential for large network analysis: - Sparse storage: Only storing non-zero entries - Iterative methods: Lanczos algorithm for eigenvalues - Random sampling: Approximating matrix operations\nThese mathematical foundations provide the theoretical basis for understanding how embedding methods transform high-dimensional network structures into meaningful low-dimensional representations."
  },
  {
    "objectID": "m08-embedding/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m08-embedding/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying network embedding, ensure you understand: - From M01-M07: Network representations, linear algebra, eigenvalue theory, and Markov chain concepts - From M07: Stationary distributions and spectral properties of random walks"
  },
  {
    "objectID": "m08-embedding/00-preparation.html#matrix-decomposition-theory",
    "href": "m08-embedding/00-preparation.html#matrix-decomposition-theory",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Essential decomposition for dimensionality reduction: - Definition: For matrix A: A = U \\Sigma V^T - Components: U (left singular vectors), \\Sigma (singular values), V (right singular vectors) - Properties: Provides optimal low-rank approximation in Frobenius norm - Truncated SVD: Using only top-k singular values/vectors for compression\n\n\n\nMathematical foundation for embedding: - Frobenius norm: ||A||_F = \\sqrt{\\sum_{ij} A_{ij}^2} - Optimal approximation: SVD minimizes ||A - A_k||_F for rank-k matrix A_k - Information preservation: How much structure is retained in low dimensions\n\n\n\nClassical dimensionality reduction technique: - Objective: Find directions of maximum variance - Covariance matrix: C = \\frac{1}{n-1}X^TX for centered data matrix X - Solution: Eigenvectors of covariance matrix - Connection to SVD: PCA eigenvectors are SVD right singular vectors"
  },
  {
    "objectID": "m08-embedding/00-preparation.html#optimization-fundamentals",
    "href": "m08-embedding/00-preparation.html#optimization-fundamentals",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding what we optimize in embedding: - Reconstruction error: How well embeddings recreate original data - Preservation metrics: Maintaining distances, similarities, or other properties - Regularization: Preventing overfitting and ensuring generalization\n\n\n\nEssential for neural embedding methods: - Gradient descent: \\theta_{t+1} = \\theta_t - \\alpha \\nabla_\\theta L(\\theta_t) - Stochastic gradient descent: Using random samples for efficiency - Learning rate scheduling: Adaptive step sizes - Convergence criteria: When to stop optimization\n\n\n\nFor embedding problems with constraints: - Orthogonality constraints: When embedding vectors must be orthogonal - Norm constraints: Limiting embedding vector magnitudes - Lagrange multipliers: Mathematical tool for handling constraints"
  },
  {
    "objectID": "m08-embedding/00-preparation.html#distance-and-similarity-measures",
    "href": "m08-embedding/00-preparation.html#distance-and-similarity-measures",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding what makes a good distance measure: - Non-negativity: d(x,y) \\geq 0 - Symmetry: d(x,y) = d(y,x) - Triangle inequality: d(x,z) \\leq d(x,y) + d(y,z) - Identity: d(x,y) = 0 if and only if x = y\n\n\n\n\nEuclidean distance: ||x - y||_2\nCosine similarity: \\frac{x \\cdot y}{||x|| ||y||}\nManhattan distance: ||x - y||_1\nJaccard similarity: For set-based comparisons\n\n\n\n\nHow to evaluate if embeddings preserve important properties: - Distance preservation: Do similar nodes remain close? - Neighborhood preservation: Are local structures maintained? - Global structure: Are long-range relationships captured?"
  },
  {
    "objectID": "m08-embedding/00-preparation.html#high-dimensional-data-analysis",
    "href": "m08-embedding/00-preparation.html#high-dimensional-data-analysis",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding challenges with high-dimensional spaces: - Distance concentration: All points become equidistant in high dimensions - Sparsity: High-dimensional spaces are mostly empty - Visualization challenges: Difficulty interpreting high-dimensional data\n\n\n\nAssumption underlying many embedding methods: - Manifold hypothesis: High-dimensional data lies on lower-dimensional manifolds - Local linearity: Small neighborhoods can be approximated linearly - Intrinsic dimensionality: True degrees of freedom in the data"
  },
  {
    "objectID": "m08-embedding/00-preparation.html#computational-considerations",
    "href": "m08-embedding/00-preparation.html#computational-considerations",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Challenges with large networks: - Matrix operations: O(n³) complexity for eigenvalue decomposition - Memory requirements: Storing large adjacency matrices - Approximation methods: Trading accuracy for computational efficiency\n\n\n\nEssential for large network analysis: - Sparse storage: Only storing non-zero entries - Iterative methods: Lanczos algorithm for eigenvalues - Random sampling: Approximating matrix operations\nThese mathematical foundations provide the theoretical basis for understanding how embedding methods transform high-dimensional network structures into meaningful low-dimensional representations."
  },
  {
    "objectID": "m08-embedding/03-exercises.html",
    "href": "m08-embedding/03-exercises.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\n\n\n\n\n\nIn this exercise, we implement DeepWalk step by step. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand how to generate random walks from a graph - Learn how to apply word2vec to graph data - Practice extracting and visualizing node embeddings - Apply clustering methods to embedded representations\nKey Steps: 1. Data preparation: Load the karate club network 2. Generate random walks: Implement random walk sampling function 3. Train word2vec model: Apply word2vec to the random walks 4. Clustering: Use K-means clustering on the embeddings\n\n\n\nIn this exercise, we implement the biased random walk mechanism that makes node2vec different from DeepWalk. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand the biased random walk mechanism in node2vec - Learn about the parameters p and q and their effects - Implement the alias sampling method for biased walks - Compare node2vec results with DeepWalk\nKey Steps: 1. Implement biased random walk: Create functions for node2vec random walks 2. Understand p and q parameters: Learn how they control walk behavior 3. Train node2vec model: Apply word2vec with biased random walks 4. Compare results: Analyze differences between node2vec and DeepWalk\n\n\n\n\n\n\nObjective: Compare different spectral embedding methods on the same network.\nTasks: 1. Implement spectral embedding using the adjacency matrix 2. Implement modularity embedding 3. Implement Laplacian Eigenmap 4. Compare the resulting embeddings visually 5. Analyze which method best captures community structure\n\n\n\nObjective: Understand how different parameters affect embedding quality.\nTasks: 1. Vary the embedding dimension (d) in spectral methods 2. Test different window sizes in word2vec-based methods 3. Experiment with different p and q values in node2vec 4. Compare clustering performance across parameter settings\n\n\n\nObjective: Apply embedding methods to a real-world network.\nTasks: 1. Choose a real network dataset (e.g., social network, citation network) 2. Apply both spectral and neural embedding methods 3. Evaluate embeddings using downstream tasks (clustering, classification) 4. Compare computational efficiency and embedding quality\n\n\n\n\n\nConceptual Understanding:\n\nWhat is the main difference between spectral and neural embedding methods?\nHow do random walks help bridge the gap between word2vec and graph data?\nWhat role do eigenvalues and eigenvectors play in spectral embedding?\n\nTechnical Implementation:\n\nWhy do we exclude the first eigenvector in Laplacian Eigenmap?\nHow does the window size in word2vec affect the final embeddings?\nWhat is the computational complexity of different embedding methods?\n\nPractical Applications:\n\nWhen would you choose spectral methods over neural methods?\nHow do the p and q parameters in node2vec affect the type of structure captured?\nWhat are the trade-offs between embedding dimension and computational cost?\n\n\n\n\n\n\nSoftware Packages: Refer to the 01-concepts.md for recommended implementations\nMathematical Details: See 04-appendix.md for formal proofs and derivations\nPreparation Material: Review 00-preparation.md for background on random walks and linear algebra",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#pen-and-paper-exercises",
    "href": "m08-embedding/03-exercises.html#pen-and-paper-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#programming-exercises",
    "href": "m08-embedding/03-exercises.html#programming-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this exercise, we implement DeepWalk step by step. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand how to generate random walks from a graph - Learn how to apply word2vec to graph data - Practice extracting and visualizing node embeddings - Apply clustering methods to embedded representations\nKey Steps: 1. Data preparation: Load the karate club network 2. Generate random walks: Implement random walk sampling function 3. Train word2vec model: Apply word2vec to the random walks 4. Clustering: Use K-means clustering on the embeddings\n\n\n\nIn this exercise, we implement the biased random walk mechanism that makes node2vec different from DeepWalk. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand the biased random walk mechanism in node2vec - Learn about the parameters p and q and their effects - Implement the alias sampling method for biased walks - Compare node2vec results with DeepWalk\nKey Steps: 1. Implement biased random walk: Create functions for node2vec random walks 2. Understand p and q parameters: Learn how they control walk behavior 3. Train node2vec model: Apply word2vec with biased random walks 4. Compare results: Analyze differences between node2vec and DeepWalk",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#additional-practice-exercises",
    "href": "m08-embedding/03-exercises.html#additional-practice-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Objective: Compare different spectral embedding methods on the same network.\nTasks: 1. Implement spectral embedding using the adjacency matrix 2. Implement modularity embedding 3. Implement Laplacian Eigenmap 4. Compare the resulting embeddings visually 5. Analyze which method best captures community structure\n\n\n\nObjective: Understand how different parameters affect embedding quality.\nTasks: 1. Vary the embedding dimension (d) in spectral methods 2. Test different window sizes in word2vec-based methods 3. Experiment with different p and q values in node2vec 4. Compare clustering performance across parameter settings\n\n\n\nObjective: Apply embedding methods to a real-world network.\nTasks: 1. Choose a real network dataset (e.g., social network, citation network) 2. Apply both spectral and neural embedding methods 3. Evaluate embeddings using downstream tasks (clustering, classification) 4. Compare computational efficiency and embedding quality",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#evaluation-questions",
    "href": "m08-embedding/03-exercises.html#evaluation-questions",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Conceptual Understanding:\n\nWhat is the main difference between spectral and neural embedding methods?\nHow do random walks help bridge the gap between word2vec and graph data?\nWhat role do eigenvalues and eigenvectors play in spectral embedding?\n\nTechnical Implementation:\n\nWhy do we exclude the first eigenvector in Laplacian Eigenmap?\nHow does the window size in word2vec affect the final embeddings?\nWhat is the computational complexity of different embedding methods?\n\nPractical Applications:\n\nWhen would you choose spectral methods over neural methods?\nHow do the p and q parameters in node2vec affect the type of structure captured?\nWhat are the trade-offs between embedding dimension and computational cost?",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#additional-resources",
    "href": "m08-embedding/03-exercises.html#additional-resources",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Software Packages: Refer to the 01-concepts.md for recommended implementations\nMathematical Details: See 04-appendix.md for formal proofs and derivations\nPreparation Material: Review 00-preparation.md for background on random walks and linear algebra",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/pen-and-paper.html",
    "href": "m08-embedding/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and paper exercises\n\n✍️ Pen and paper exercises"
  },
  {
    "objectID": "m08-embedding/spectral-vs-neural-embedding.html",
    "href": "m08-embedding/spectral-vs-neural-embedding.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Spectral vs Neural Embedding\nWe have learned two types of graph embedding methods: spectral methods and neural embedding methods. But which one is better than the other? We will compare the two types of methods from multiple aspects as follows.\n\nAnalytical Tractability: Spectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized laplacian matrices are shown to be optimal for detecting communities in the stochastic block model {footcite}nadakuditi2012graph. Neural embedding methods are less analytically tractable. But still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under a very specific condition {footcite}qiu2018network,kojaku2023network. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact an optimal embedding methods for community detection for the stochatic block model.\nScalability: A key limitation of the spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit learn package as TruncatedSVD), they might be unstable depending on the spectrum distribution of the matrix to be decomposed. Neural embedding methods are often more stable and scalable.\nFlexibility: Neural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincaré embeddings {footcite}nickel2017poincare for embedding networks in hyperbolic space."
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html",
    "href": "m09-graph-neural-networks/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying Graph Neural Networks, ensure you understand: - From M01-M08: Network representations, linear algebra, optimization, and embedding concepts - From M08: Matrix decomposition techniques and dimensionality reduction principles\n\n\n\n\n\n\n\n\nPerceptron: y = \\sigma(w^T x + b) where \\sigma is an activation function\nMulti-layer: Composition of linear transformations and nonlinear activations\nUniversal approximation: Neural networks can approximate arbitrary functions\n\n\n\n\nEssential nonlinear functions: - ReLU: \\text{ReLU}(x) = \\max(0, x) - most common, helps with gradient flow - Sigmoid: \\sigma(x) = \\frac{1}{1 + e^{-x}} - outputs in (0,1) range - Tanh: \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} - outputs in (-1,1) range - Softmax: \\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}} - for probability distributions\n\n\n\n\n\n\nComputing network output: - Layer computation: h^{(l+1)} = \\sigma(W^{(l)} h^{(l)} + b^{(l)}) - Composition: Output is function composition through all layers - Vectorization: Efficient batch processing\n\n\n\nComputing gradients for optimization: - Chain rule: \\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial h^{(l+1)}} \\frac{\\partial h^{(l+1)}}{\\partial W^{(l)}} - Gradient flow: How gradients propagate backward through layers - Vanishing gradients: Challenge in deep networks\n\n\n\n\n\n\n\nDifferent objectives for different tasks: - Mean Squared Error: \\text{MSE} = \\frac{1}{n}\\sum_i (y_i - \\hat{y}_i)^2 for regression - Cross-entropy: \\text{CE} = -\\sum_i y_i \\log(\\hat{y}_i) for classification - Custom losses: Task-specific objectives for graph problems\n\n\n\nAdvanced optimization techniques: - SGD with momentum: v_t = \\gamma v_{t-1} + \\alpha \\nabla_\\theta L - Adam optimizer: Adaptive learning rates with momentum - Learning rate scheduling: Decreasing rates over time - Batch normalization: Normalizing layer inputs for stable training\n\n\n\nPreventing overfitting: - L1/L2 regularization: Adding penalty terms to loss function - Dropout: Randomly setting some neurons to zero during training - Early stopping: Stopping training when validation loss stops improving\n\n\n\n\n\n\n\nManual features: Hand-crafted features based on domain knowledge\nLearned features: Features discovered automatically by neural networks\nEnd-to-end learning: Learning features jointly with final task\n\n\n\n\nUnderstanding learned representations: - Distributed representations: Dense vectors vs. one-hot encodings - Semantic similarity: Similar inputs have similar representations - Linear relationships: Arithmetic in embedding space (e.g., king - man + woman ≈ queen)\n\n\n\n\n\n\nFoundation for understanding graph convolutions: - Local connectivity: Neurons connect to local regions of input - Parameter sharing: Same filters applied across different positions - Translation invariance: Feature detection regardless of position\n\n\n\nDimensionality reduction and invariance: - Max pooling: Taking maximum value in local regions - Average pooling: Taking average value in local regions - Global pooling: Reducing to single value per feature map\n\n\n\n\n\n\nComputing weighted combinations: - Query-key-value: \\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V - Self-attention: When queries, keys, and values come from same source - Multi-head attention: Multiple attention mechanisms in parallel\n\n\n\n\nNode attention: Weighting importance of different neighbors\nGraph-level attention: Weighting importance of different nodes\nDynamic weights: Learned attention weights vs. fixed graph structure\n\n\n\n\n\n\n\n\nVariable size: Graphs have different numbers of nodes and edges\nNo natural ordering: Nodes don’t have canonical ordering like pixels\nIrregular structure: Unlike grids or sequences\n\n\n\n\nEssential property for graph neural networks: - Node permutation: Network output shouldn’t change if nodes are reordered - Symmetric functions: Functions that respect permutation invariance - Aggregation operations: Sum, max, mean preserve invariance\nThese deep learning foundations provide the necessary background for understanding how Graph Neural Networks adapt neural network concepts to work with the irregular structure of graphs and networks."
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m09-graph-neural-networks/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying Graph Neural Networks, ensure you understand: - From M01-M08: Network representations, linear algebra, optimization, and embedding concepts - From M08: Matrix decomposition techniques and dimensionality reduction principles"
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#neural-network-fundamentals",
    "href": "m09-graph-neural-networks/00-preparation.html#neural-network-fundamentals",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Perceptron: y = \\sigma(w^T x + b) where \\sigma is an activation function\nMulti-layer: Composition of linear transformations and nonlinear activations\nUniversal approximation: Neural networks can approximate arbitrary functions\n\n\n\n\nEssential nonlinear functions: - ReLU: \\text{ReLU}(x) = \\max(0, x) - most common, helps with gradient flow - Sigmoid: \\sigma(x) = \\frac{1}{1 + e^{-x}} - outputs in (0,1) range - Tanh: \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} - outputs in (-1,1) range - Softmax: \\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}} - for probability distributions\n\n\n\n\n\n\nComputing network output: - Layer computation: h^{(l+1)} = \\sigma(W^{(l)} h^{(l)} + b^{(l)}) - Composition: Output is function composition through all layers - Vectorization: Efficient batch processing\n\n\n\nComputing gradients for optimization: - Chain rule: \\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial h^{(l+1)}} \\frac{\\partial h^{(l+1)}}{\\partial W^{(l)}} - Gradient flow: How gradients propagate backward through layers - Vanishing gradients: Challenge in deep networks"
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#optimization-for-neural-networks",
    "href": "m09-graph-neural-networks/00-preparation.html#optimization-for-neural-networks",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Different objectives for different tasks: - Mean Squared Error: \\text{MSE} = \\frac{1}{n}\\sum_i (y_i - \\hat{y}_i)^2 for regression - Cross-entropy: \\text{CE} = -\\sum_i y_i \\log(\\hat{y}_i) for classification - Custom losses: Task-specific objectives for graph problems\n\n\n\nAdvanced optimization techniques: - SGD with momentum: v_t = \\gamma v_{t-1} + \\alpha \\nabla_\\theta L - Adam optimizer: Adaptive learning rates with momentum - Learning rate scheduling: Decreasing rates over time - Batch normalization: Normalizing layer inputs for stable training\n\n\n\nPreventing overfitting: - L1/L2 regularization: Adding penalty terms to loss function - Dropout: Randomly setting some neurons to zero during training - Early stopping: Stopping training when validation loss stops improving"
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#representation-learning",
    "href": "m09-graph-neural-networks/00-preparation.html#representation-learning",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Manual features: Hand-crafted features based on domain knowledge\nLearned features: Features discovered automatically by neural networks\nEnd-to-end learning: Learning features jointly with final task\n\n\n\n\nUnderstanding learned representations: - Distributed representations: Dense vectors vs. one-hot encodings - Semantic similarity: Similar inputs have similar representations - Linear relationships: Arithmetic in embedding space (e.g., king - man + woman ≈ queen)"
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#convolutional-neural-networks-cnns",
    "href": "m09-graph-neural-networks/00-preparation.html#convolutional-neural-networks-cnns",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Foundation for understanding graph convolutions: - Local connectivity: Neurons connect to local regions of input - Parameter sharing: Same filters applied across different positions - Translation invariance: Feature detection regardless of position\n\n\n\nDimensionality reduction and invariance: - Max pooling: Taking maximum value in local regions - Average pooling: Taking average value in local regions - Global pooling: Reducing to single value per feature map"
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#attention-mechanisms",
    "href": "m09-graph-neural-networks/00-preparation.html#attention-mechanisms",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Computing weighted combinations: - Query-key-value: \\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V - Self-attention: When queries, keys, and values come from same source - Multi-head attention: Multiple attention mechanisms in parallel\n\n\n\n\nNode attention: Weighting importance of different neighbors\nGraph-level attention: Weighting importance of different nodes\nDynamic weights: Learned attention weights vs. fixed graph structure"
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#deep-learning-for-irregular-data",
    "href": "m09-graph-neural-networks/00-preparation.html#deep-learning-for-irregular-data",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Variable size: Graphs have different numbers of nodes and edges\nNo natural ordering: Nodes don’t have canonical ordering like pixels\nIrregular structure: Unlike grids or sequences\n\n\n\n\nEssential property for graph neural networks: - Node permutation: Network output shouldn’t change if nodes are reordered - Symmetric functions: Functions that respect permutation invariance - Aggregation operations: Sum, max, mean preserve invariance\nThese deep learning foundations provide the necessary background for understanding how Graph Neural Networks adapt neural network concepts to work with the irregular structure of graphs and networks."
  },
  {
    "objectID": "m09-graph-neural-networks/pen-and-paper.html",
    "href": "m09-graph-neural-networks/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and paper exercises\n\n✍️ Pen and paper exercises"
  },
  {
    "objectID": "m08-embedding/01-concepts.html#what-is-network-embedding",
    "href": "m08-embedding/01-concepts.html#what-is-network-embedding",
    "title": "Network Embedding Concepts",
    "section": "2 What is Network Embedding?",
    "text": "2 What is Network Embedding?\nNetworks are high-dimensional discrete data that can be difficult to analyze with traditional machine learning methods that assume continuous and smooth data. Network embedding is a technique to represent networks in low-dimensional continuous spaces, enabling us to apply standard machine learning algorithms.\nThe goal of network embedding is to map each node in a network to a point in a low-dimensional space (typically \\mathbb{R}^d where d \\ll N) while preserving important structural properties of the network."
  },
  {
    "objectID": "m08-embedding/01-concepts.html#spectral-embedding",
    "href": "m08-embedding/01-concepts.html#spectral-embedding",
    "title": "Network Embedding Concepts",
    "section": "3 Spectral Embedding",
    "text": "3 Spectral Embedding\n\nNetwork Compression Approach\nLet us approach spectral embedding from the perspective of network compression. Suppose we have an adjacency matrix \\mathbf{A} of a network. The adjacency matrix is high-dimensional data, i.e., a matrix of size N \\times N for a network of N nodes. We want to compress it into a lower-dimensional matrix \\mathbf{U} of size N \\times d for a user-defined small integer d &lt; N. A good \\mathbf{U} should preserve the network structure and thus can reconstruct the original data \\mathbf{A} as closely as possible. This leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nwhere:\n\n\\mathbf{U}\\mathbf{U}^\\top is the outer product of \\mathbf{U} and represents the reconstructed network.\n\\|\\cdot\\|_F is the Frobenius norm, which is the sum of the squares of the elements in the matrix.\nJ(\\mathbf{U}) is the loss function that measures the difference between the original network \\mathbf{A} and the reconstructed network \\mathbf{U}\\mathbf{U}^\\top.\n\nBy minimizing the Frobenius norm with respect to \\mathbf{U}, we obtain the best low-dimensional embedding of the network.\n\n\nSpectral Decomposition Solution\nConsider the spectral decomposition of \\mathbf{A}:\n\n\\mathbf{A} = \\sum_{i=1}^N \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top\n\nwhere \\lambda_i are eigenvalues (weights) and \\mathbf{u}_i are eigenvectors. Each term \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top is a rank-one matrix that captures a part of the network’s structure. The larger the weight \\lambda_i, the more important that term is in describing the network.\nTo compress the network, we can select the d terms with the largest weights \\lambda_i. By combining the corresponding \\mathbf{u}_i vectors into a matrix \\mathbf{U}, we obtain a good low-dimensional embedding of the network.\n\nFor a formal proof, please refer to the Appendix section.\n\n\nModularity Embedding\nIn a similar vein, we can use the modularity matrix to generate a low-dimensional embedding of the network. Let us define the modularity matrix \\mathbf{Q} as follows:\n\nQ_{ij} = \\frac{1}{2m}A_{ij} - \\frac{k_i k_j}{4m^2}\n\nwhere k_i is the degree of node i, and m is the number of edges in the network.\nWe then compute the eigenvectors of \\mathbf{Q} and use them to embed the network into a low-dimensional space just as we did for the adjacency matrix. The modularity embedding can be used to bipartition the network into two communities using a simple algorithm: group nodes with the same sign of the second eigenvector {footcite}newman2006modularity.\n\n\nLaplacian Eigenmap\nLaplacian Eigenmap {footcite}belkin2003laplacian is another approach to compress a network into a low-dimensional space. The fundamental idea behind this method is to position connected nodes close to each other in the low-dimensional space. This approach leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J_{LE}(\\mathbf{U}),\\quad J_{LE}(\\mathbf{U}) = \\frac{1}{2}\\sum_{i,j} A_{ij} \\| u_i - u_j \\|^2\n\nIn this equation, \\| u_i - u_j \\|^2 represents the squared distance between nodes i and j in the low-dimensional space. The goal is to minimize this distance for connected nodes (where A_{ij} = 1). The factor \\frac{1}{2} is included for mathematical convenience in later calculations.\nTo solve this optimization problem, we rewrite J_{LE}(\\mathbf{U}) as follows:\n\n\\begin{aligned}\nJ_{LE}(\\mathbf{U}) &= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\| u_i - u_j \\|^2 \\\\\n&= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\left( \\| u_i \\|^2 - 2 u_i^\\top u_j + \\| u_j \\|^2 \\right) \\\\\n&= \\sum_{i}\\sum_{j} A_{ij} \\| u_i \\|^2 - \\sum_{i}\\sum_{j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i} k_i \\| u_i \\|^2 - \\sum_{i,j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i,j} L_{ij} u_i^\\top u_j\n\\end{aligned}\n\nwhere\n\nL_{ij} = \\begin{cases}\nk_i & \\text{if } i = j \\\\\n-A_{ij} & \\text{if } i \\neq j\n\\end{cases}\n\nThe minimization problem can be rewritten as:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nwhere\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\mathbf{u}_1 ^\\top \\\\\n\\mathbf{u}_2 ^\\top \\\\\n\\vdots \\\\\n\\mathbf{u}_N ^\\top \\\\\n\\end{bmatrix}\n\nSee the Appendix section for the detailed derivation.\nBy taking the derivative of J_{LE}(\\mathbf{U}) with respect to \\mathbf{U} and setting it to zero, we obtain the following equation:\n\n\\frac{\\partial J_{LE}}{\\partial \\mathbf{U}} = 0 \\implies \\mathbf{L} \\mathbf{U} = \\lambda \\mathbf{U}\n\nThe solution is the d eigenvectors associated with the d smallest eigenvalues of \\mathbf{L}.\nIt is important to note that the eigenvector corresponding to the smallest eigenvalue (which is always zero for connected graphs) is trivial - it’s the all-one vector. Therefore, in practice, we typically compute the d+1 smallest eigenvectors and discard the one corresponding to the zero eigenvalue."
  },
  {
    "objectID": "m08-embedding/01-concepts.html#neural-embedding",
    "href": "m08-embedding/01-concepts.html#neural-embedding",
    "title": "Network Embedding Concepts",
    "section": "4 Neural Embedding",
    "text": "4 Neural Embedding\n\nIntroduction to word2vec\nNeural embedding methods leverage neural network architectures to learn node representations. Before discussing graph-specific methods, we first introduce word2vec, which forms the foundation for many neural graph embedding techniques.\nword2vec is a neural network model that learns word embeddings in a continuous vector space. It was introduced by Tomas Mikolov and his colleagues at Google in 2013 {footcite}mikolov2013distributed.\n\n\nHow word2vec Works\n“You shall know a word by the company it keeps” {footcite}church1988word is a famous quote in linguistics. It means that you can understand the meaning of a word by looking at the words that appear in the same context. word2vec operates on the same principle.\nword2vec identifies a word’s context by examining the words within a fixed window around it. For example, in the sentence:\n\nThe quick brown fox jumps over a lazy dog\n\nThe context of the word fox includes quick, brown, jumps, over, and lazy. word2vec is trained to predict which words are likely to appear as the context of an input word.\nThere are two main architectures for word2vec:\n1. **Continuous Bag of Words (CBOW)**: Predicts the target word (center word) from the context words (surrounding words).\n2. **Skip-gram**: Predicts the context words (surrounding words) from the target word (center word).\nword2vec is a neural network model that looks like a bow tie. It has two layers of the vocabulary size coupled with a much smaller hidden layer.\n\n\nInput layer: The input layer consists of N neurons, where N is the size of the vocabulary (i.e., the number of unique words in the corpus). Each neuron corresponds to a unique word in the vocabulary. When a word is inputted, its corresponding neuron is activated and the other neurons are inhibited. Thus, the input layer is essentially a lookup mechanism that transforms the input word into a corresponding one-hot vector.\nOutput layer: The output layer also consists of N neurons, each corresponding to a unique word in the vocabulary. Unlike the input layer, multiple neurons can be activated for a single input. The strength of the activation of each neuron (with a normalization by the softmax function) represents the probability of the corresponding word being the input word’s context.\nHidden layer: The hidden layer is much smaller than the input and output layers. Multiple neurons in the hidden layer can be activated for a single input, and this activation pattern represents the word’s embedding.\n\nWe can consider word2vec as a dimensionality reduction technique that reduces the dimensionality of the input layer to the hidden layer based on the co-occurrence of words within a short distance. The distance is named the window size, which is a user-defined hyperparameter.\n\n\nKey Technical Components of word2vec\n\nSkip-gram Model\nThe skip-gram model trains word2vec by predicting context words given a target word. For example, given the sentence “The quick brown fox jumps over the lazy dog”, in the skip-gram model, given the target word “fox”, the model will try to predict the context words “quick”, “brown”, “jumps”, and “over”.\n\n\nHierarchical Softmax\nThe goal of word2vec is to predict context words given a target word. For example, if our target word is w_t and our context word is w_c, we want to find the probability of w_c given w_t. This probability is calculated using the softmax function:\n\nP(w_c | w_t) = \\frac{\\exp(\\mathbf{v}_{w_c} \\cdot \\mathbf{v}_{w_t})}{\\sum_{w \\in V} \\exp(\\mathbf{v}_w \\cdot \\mathbf{u}_{w_t})}\n\nHere, \\mathbf{v}_w and \\mathbf{u}_w represent the vector for word w as context and target respectively, and V is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!\nHierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.\n\n\n\n\nWhat’s Special About word2vec?\nWith word2vec, words are represented as dense vectors, enabling us to explore their relationships using simple linear algebra. This is in contrast to traditional natural language processing (NLP) methods, such as bag-of-words and topic modeling, which represent words as discrete units or high-dimensional vectors.\n\nword2vec embeddings can capture semantic relationships, such as analogies (e.g., man is to woman as king is to queen) and can visualize relationships between concepts (e.g., countries and their capitals form parallel vectors in the embedding space)."
  },
  {
    "objectID": "m08-embedding/01-concepts.html#graph-embedding-with-word2vec",
    "href": "m08-embedding/01-concepts.html#graph-embedding-with-word2vec",
    "title": "Network Embedding Concepts",
    "section": "5 Graph Embedding with word2vec",
    "text": "5 Graph Embedding with word2vec\nHow can we apply word2vec to graph data? There is a critical challenge: word2vec takes sequences of words as input, while graph data are discrete and unordered. A solution to fill this gap is random walk, which transforms graph data into a sequence of nodes. Once we have a sequence of nodes, we can treat it as a sequence of words and apply word2vec.\n\nDeepWalk\n\nDeepWalk is one of the pioneering works to apply word2vec to graph data {footcite}perozzi2014deepwalk. It views the nodes as words and the random walks on the graph as sentences, and applies word2vec to learn the node embeddings.\nMore specifically, the method contains the following steps:\n\nSample multiple random walks from the graph.\nTreat the random walks as sentences and feed them to word2vec to learn the node embeddings.\n\nDeepWalk typically uses the skip-gram model with hierarchical softmax for efficient training.\n\n\nnode2vec\nnode2vec is a sibling of DeepWalk proposed by {footcite}grover2016node2vec. Both use word2vec trained on random walks on networks. However, the following two components make them very different:\n\nBiased Random Walk\nnode2vec uses biased random walks that can move in different directions. The biased walk is parameterized by two parameters, p and q:\n\nP(v_{t+1} = x | v_t = v, v_{t-1} = t) \\propto\n\\begin{cases}\n\\frac{1}{p} & \\text{if } d(v,t) = 0 \\\\\n1 & \\text{if } d(v,t) = 1 \\\\\n\\frac{1}{q} & \\text{if } d(v,t) = 2 \\\\\n\\end{cases}\n\nwhere d(v,x) is the shortest path distance between node v and x. A smaller p leads to more bias towards the previous node, v_{t-1} = t. A smaller q leads to more bias towards the nodes that are further away from the previous node, v_{t-1} = t.\nBy adjusting the parameters p and q, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).\n\nBreadth-First Sampling (BFS): This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.\nDepth-First Sampling (DFS): This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.\n\n\nThe embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.\n\n\n\nNegative Sampling\nnode2vec uses negative sampling instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to {footcite}kojaku2021neurips and {footcite}dyer2014notes for more details.\n\n\n\nLINE\nLINE {footcite}tang2015line is another pioneering work to learn node embeddings by directly optimizing the graph structure. It is equivalent to node2vec with p=1, q=1, and window size 1."
  }
]