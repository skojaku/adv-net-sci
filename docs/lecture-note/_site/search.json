[
  {
    "objectID": "m09-graph-neural-networks/what-to-learn.html",
    "href": "m09-graph-neural-networks/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)"
  },
  {
    "objectID": "m09-graph-neural-networks/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m09-graph-neural-networks/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)"
  },
  {
    "objectID": "m09-graph-neural-networks/01-concepts.html",
    "href": "m09-graph-neural-networks/01-concepts.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)\n\n\n\n\n\n\n✍️ Pen and paper exercises\n\nThe pen and paper exercises will help you understand the mathematical foundations of graph neural networks, including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures\n\nThese exercises provide the theoretical foundation necessary to understand how graph neural networks process and learn from graph-structured data.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/01-concepts.html#what-to-learn-in-this-module",
    "href": "m09-graph-neural-networks/01-concepts.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to use neural networks to learn representations of graphs. We will learn: - Fourier transform on image - Fourier transform on graph - Spectral filters - Graph convolutional networks - Popular GNNs (GCN, GAT, GraphSAGE, and GIN)",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/01-concepts.html#theoretical-exercises",
    "href": "m09-graph-neural-networks/01-concepts.html#theoretical-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\nThe pen and paper exercises will help you understand the mathematical foundations of graph neural networks, including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures\n\nThese exercises provide the theoretical foundation necessary to understand how graph neural networks process and learn from graph-structured data.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/what-to-learn.html",
    "href": "m08-embedding/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec"
  },
  {
    "objectID": "m08-embedding/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m08-embedding/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec"
  },
  {
    "objectID": "m08-embedding/software.html",
    "href": "m08-embedding/software.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Software for Network Embedding\nThere are various software packages for network embeddings. But due to technical complexity, some of them do not faithfully implement the algorithms in the paper. We provide a list of software packages for network embeddings below.\n\nfastnode2vec. This is a very fast implementation of node2vec. However, it uses a uniform probability distribution for the negative sampling, which is different from the original node2vec paper that uses a different distribution. This leads to some degeneracy of the embedding quality in community detection tasks.\npytorch-geometric. This is a very popular package for graph neural networks. It also uses a uniform probability distribution for the negative sampling, potentially having the same issue as fastnode2vec.\ngnn-tools. This is a collection of my experiments on network embedding methods.\nMy collection. This is a lighter version of the gnn-tools collection."
  },
  {
    "objectID": "m08-embedding/04-appendix.html",
    "href": "m08-embedding/04-appendix.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The spectral embedding with the adjacency matrix is given by the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nWe will approach the solution step by step based on the following steps:\n\nWe start taking a derivative of J(\\mathbf{U}) with respect to \\mathbf{U}.\nWe then set the derivative to zero (i.e., \\nabla J(\\mathbf{U}) = 0) and solve for \\mathbf{U}.\nExpand the Frobenius norm:\nThe Frobenius norm for any matrix \\mathbf{M} is defined as:\n\\|\\mathbf{M}\\|_F^2 = \\sum_{i,j} M_{ij}^2 = \\text{Tr}(\\mathbf{M}\\mathbf{M}^\\top)\nApplying this to our problem:\nJ(\\mathbf{U}) = \\|\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top\\|_F^2 = \\text{Tr}[(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)^\\top]\nExpanding this:\n= \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top - 2\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top + \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nTake the derivative with respect to \\mathbf{U}:\nUsing matrix calculus rules:\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top)}{\\partial \\mathbf{U}} = 0\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 2\\mathbf{A}\\mathbf{U}\n\\frac{\\partial \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nCombining these:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -4\\mathbf{A}\\mathbf{U} + 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSimplifying:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSet the derivative to zero and solve:\n-2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = 0\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nThis equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\nAssume \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{\\Lambda}\nwhere \\mathbf{\\Lambda} is a diagonal matrix of eigenvalues.\nSince eigenvectors are orthonormal:\n\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}\nTherefore:\n\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{U}\nThis shows our equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}.\nTo minimize J(\\mathbf{U}), choose the eigenvectors corresponding to the d largest eigenvalues.\nTo understand why, consider the trace of our objective function:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - 2\\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top) + \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nSince \\mathbf{U} is orthogonal (\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}), and trace is invariant under cyclic permutations, we can simplify:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - \\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U})\nLet \\mathbf{U} = [\\mathbf{u}_1, ..., \\mathbf{u}_d] be the eigenvectors of \\mathbf{A} with corresponding eigenvalues \\lambda_1 \\geq ... \\geq \\lambda_d. Then:\n\\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U}) = \\sum_{i=1}^d \\lambda_i\nTo minimize J(\\mathbf{U}), maximize \\sum_{i=1}^d \\lambda_i by selecting the eigenvectors corresponding to the d largest eigenvalues.\n\nThe result is the collection of the d eigenvectors corresponding to the d largest eigenvalues, and it is one form of the spectral embedding.\n\n\n\nThe Laplacian Eigenmap is given by the following optimization problem:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nThe step where we rewrite J_{LE}(\\mathbf{U}) as \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U}) is crucial for leveraging matrix derivatives. Let’s break down this transformation step by step:\n\nFirst, we rewrite \\mathbf{U} by column vectors:\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\vert & \\vert & & \\vert \\\\\n\\mathbf{x}_1 & \\mathbf{x}_2 & \\cdots & \\mathbf{x}_d \\\\\n\\vert & \\vert & & \\vert\n\\end{bmatrix}\n\nwhere \\mathbf{x}_i is the i-th column of \\mathbf{U}.\nWe can expand the loss function J_{LE}(\\mathbf{U}):\n\nJ_{LE}(\\mathbf{U}) = \\sum_{i} \\sum_{j} L_{ij} u_i^\\top u_j = \\sum_{i} \\sum_{j} \\sum_{d'} L_{ij} u_{i,d'} u_{j,d'}\n\nRearranging the order of summation:\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\sum_{i} \\sum_{j} L_{ij} u_{i,d'} u_{j,d'}\n\nWe can rewrite this as a matrix multiplication for each d':\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\mathbf{x}_{d'}^\\top \\mathbf{L} \\mathbf{x}_{d'}\n\nwhere \\mathbf{x}_{d'} is the d'-th column of \\mathbf{U}.\nFinally, we can express this as a trace:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\n\nThis final form expresses our objective function in terms of matrix operations, which allows us to use matrix calculus to find the optimal solution. The trace representation is a useful technique to leverage matrix calculus.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/04-appendix.html#spectral-embedding-with-the-adjacency-matrix",
    "href": "m08-embedding/04-appendix.html#spectral-embedding-with-the-adjacency-matrix",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The spectral embedding with the adjacency matrix is given by the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nWe will approach the solution step by step based on the following steps:\n\nWe start taking a derivative of J(\\mathbf{U}) with respect to \\mathbf{U}.\nWe then set the derivative to zero (i.e., \\nabla J(\\mathbf{U}) = 0) and solve for \\mathbf{U}.\nExpand the Frobenius norm:\nThe Frobenius norm for any matrix \\mathbf{M} is defined as:\n\\|\\mathbf{M}\\|_F^2 = \\sum_{i,j} M_{ij}^2 = \\text{Tr}(\\mathbf{M}\\mathbf{M}^\\top)\nApplying this to our problem:\nJ(\\mathbf{U}) = \\|\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top\\|_F^2 = \\text{Tr}[(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)(\\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top)^\\top]\nExpanding this:\n= \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top - 2\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top + \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nTake the derivative with respect to \\mathbf{U}:\nUsing matrix calculus rules:\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top)}{\\partial \\mathbf{U}} = 0\n\\frac{\\partial \\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 2\\mathbf{A}\\mathbf{U}\n\\frac{\\partial \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)}{\\partial \\mathbf{U}} = 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nCombining these:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -4\\mathbf{A}\\mathbf{U} + 4\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSimplifying:\n\\frac{\\partial J}{\\partial \\mathbf{U}} = -2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nSet the derivative to zero and solve:\n-2\\mathbf{A}\\mathbf{U} + 2\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = 0\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\nThis equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\nAssume \\mathbf{U} consists of eigenvectors of \\mathbf{A}:\n\\mathbf{A}\\mathbf{U} = \\mathbf{U}\\mathbf{\\Lambda}\nwhere \\mathbf{\\Lambda} is a diagonal matrix of eigenvalues.\nSince eigenvectors are orthonormal:\n\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}\nTherefore:\n\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{U}\nThis shows our equation is satisfied when \\mathbf{U} consists of eigenvectors of \\mathbf{A}.\nTo minimize J(\\mathbf{U}), choose the eigenvectors corresponding to the d largest eigenvalues.\nTo understand why, consider the trace of our objective function:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - 2\\text{Tr}(\\mathbf{A}\\mathbf{U}\\mathbf{U}^\\top) + \\text{Tr}(\\mathbf{U}\\mathbf{U}^\\top\\mathbf{U}\\mathbf{U}^\\top)\nSince \\mathbf{U} is orthogonal (\\mathbf{U}^\\top\\mathbf{U} = \\mathbf{I}), and trace is invariant under cyclic permutations, we can simplify:\nJ(\\mathbf{U}) = \\text{Tr}(\\mathbf{A}\\mathbf{A}^\\top) - \\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U})\nLet \\mathbf{U} = [\\mathbf{u}_1, ..., \\mathbf{u}_d] be the eigenvectors of \\mathbf{A} with corresponding eigenvalues \\lambda_1 \\geq ... \\geq \\lambda_d. Then:\n\\text{Tr}(\\mathbf{U}^\\top\\mathbf{A}\\mathbf{U}) = \\sum_{i=1}^d \\lambda_i\nTo minimize J(\\mathbf{U}), maximize \\sum_{i=1}^d \\lambda_i by selecting the eigenvectors corresponding to the d largest eigenvalues.\n\nThe result is the collection of the d eigenvectors corresponding to the d largest eigenvalues, and it is one form of the spectral embedding.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/04-appendix.html#the-proof-of-the-laplacian-eigenmap",
    "href": "m08-embedding/04-appendix.html#the-proof-of-the-laplacian-eigenmap",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The Laplacian Eigenmap is given by the following optimization problem:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nThe step where we rewrite J_{LE}(\\mathbf{U}) as \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U}) is crucial for leveraging matrix derivatives. Let’s break down this transformation step by step:\n\nFirst, we rewrite \\mathbf{U} by column vectors:\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\vert & \\vert & & \\vert \\\\\n\\mathbf{x}_1 & \\mathbf{x}_2 & \\cdots & \\mathbf{x}_d \\\\\n\\vert & \\vert & & \\vert\n\\end{bmatrix}\n\nwhere \\mathbf{x}_i is the i-th column of \\mathbf{U}.\nWe can expand the loss function J_{LE}(\\mathbf{U}):\n\nJ_{LE}(\\mathbf{U}) = \\sum_{i} \\sum_{j} L_{ij} u_i^\\top u_j = \\sum_{i} \\sum_{j} \\sum_{d'} L_{ij} u_{i,d'} u_{j,d'}\n\nRearranging the order of summation:\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\sum_{i} \\sum_{j} L_{ij} u_{i,d'} u_{j,d'}\n\nWe can rewrite this as a matrix multiplication for each d':\n\nJ_{LE}(\\mathbf{U}) = \\sum_{d'} \\mathbf{x}_{d'}^\\top \\mathbf{L} \\mathbf{x}_{d'}\n\nwhere \\mathbf{x}_{d'} is the d'-th column of \\mathbf{U}.\nFinally, we can express this as a trace:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\n\nThis final form expresses our objective function in terms of matrix operations, which allows us to use matrix calculus to find the optimal solution. The trace representation is a useful technique to leverage matrix calculus.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html",
    "href": "m08-embedding/01-concepts.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec\n\n\n\nWe have learned two types of graph embedding methods: spectral methods and neural embedding methods. But which one is better than the other? We will compare the two types of methods from multiple aspects.\n\n\n\nSpectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized laplacian matrices are shown to be optimal for detecting communities in the stochastic block model {footcite}nadakuditi2012graph.\nNeural embedding methods are less analytically tractable. But still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under a very specific condition {footcite}qiu2018network,kojaku2023network. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact an optimal embedding methods for community detection for the stochatic block model.\n\n\n\nA key limitation of the spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit learn package as TruncatedSVD), they might be unstable depending on the spectrum distribution of the matrix to be decomposed.\nNeural embedding methods are often more stable and scalable, making them particularly suitable for large networks where computational efficiency is critical.\n\n\n\nNeural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincaré embeddings {footcite}nickel2017poincare for embedding networks in hyperbolic space.\n\nThis flexibility extends to implementation choices and software options. There are various software packages for network embeddings, though due to technical complexity, some of them do not faithfully implement the algorithms in the paper. We provide a list of software packages for network embeddings below:\n\nfastnode2vec. This is a very fast implementation of node2vec. However, it uses a uniform probability distribution for the negative sampling, which is different from the original node2vec paper that uses a different distribution. This leads to some degeneracy of the embedding quality in community detection tasks.\npytorch-geometric. This is a very popular package for graph neural networks. It also uses a uniform probability distribution for the negative sampling, potentially having the same issue as fastnode2vec.\ngnn-tools. This is a collection of my experiments on network embedding methods.\nMy collection. This is a lighter version of the gnn-tools collection.\n\n\n\n\n\n✍️ Pen and paper exercises",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#what-to-learn-in-this-module",
    "href": "m08-embedding/01-concepts.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn how to embed networks into low-dimensional spaces. We will learn: - Spectral embedding - Neural embedding - Keywords: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#comparing-spectral-and-neural-embedding-approaches",
    "href": "m08-embedding/01-concepts.html#comparing-spectral-and-neural-embedding-approaches",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "We have learned two types of graph embedding methods: spectral methods and neural embedding methods. But which one is better than the other? We will compare the two types of methods from multiple aspects.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#analytical-tractability",
    "href": "m08-embedding/01-concepts.html#analytical-tractability",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Spectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized laplacian matrices are shown to be optimal for detecting communities in the stochastic block model {footcite}nadakuditi2012graph.\nNeural embedding methods are less analytically tractable. But still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under a very specific condition {footcite}qiu2018network,kojaku2023network. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact an optimal embedding methods for community detection for the stochatic block model.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#scalability-and-performance",
    "href": "m08-embedding/01-concepts.html#scalability-and-performance",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "A key limitation of the spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit learn package as TruncatedSVD), they might be unstable depending on the spectrum distribution of the matrix to be decomposed.\nNeural embedding methods are often more stable and scalable, making them particularly suitable for large networks where computational efficiency is critical.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#flexibility-and-extensions",
    "href": "m08-embedding/01-concepts.html#flexibility-and-extensions",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Neural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincaré embeddings {footcite}nickel2017poincare for embedding networks in hyperbolic space.\n\nThis flexibility extends to implementation choices and software options. There are various software packages for network embeddings, though due to technical complexity, some of them do not faithfully implement the algorithms in the paper. We provide a list of software packages for network embeddings below:\n\nfastnode2vec. This is a very fast implementation of node2vec. However, it uses a uniform probability distribution for the negative sampling, which is different from the original node2vec paper that uses a different distribution. This leads to some degeneracy of the embedding quality in community detection tasks.\npytorch-geometric. This is a very popular package for graph neural networks. It also uses a uniform probability distribution for the negative sampling, potentially having the same issue as fastnode2vec.\ngnn-tools. This is a collection of my experiments on network embedding methods.\nMy collection. This is a lighter version of the gnn-tools collection.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/01-concepts.html#exercises",
    "href": "m08-embedding/01-concepts.html#exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/what-to-learn.html",
    "href": "m07-random-walks/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn random walks, one of the most fundamental techniques in network analysis. We will learn: - What is a random walk? - How to simulate a random walk on a network? - What is the behavior of a random walk on a network? - Implicit connections to community detection and network centralities - Keywords: random walk, community detection, network centralities"
  },
  {
    "objectID": "m07-random-walks/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m07-random-walks/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn random walks, one of the most fundamental techniques in network analysis. We will learn: - What is a random walk? - How to simulate a random walk on a network? - What is the behavior of a random walk on a network? - Implicit connections to community detection and network centralities - Keywords: random walk, community detection, network centralities"
  },
  {
    "objectID": "m07-random-walks/00-preparation.html",
    "href": "m07-random-walks/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying random walks, ensure you understand: - From M01-M06: Network representations, eigenvalue theory, matrix operations - From M06: Advanced concepts like matrix series convergence and spectral properties\n\n\n\n\n\nFoundation for understanding random processes: - Probability distributions: Discrete probability mass functions - Conditional probability: P(A|B) = \\frac{P(A \\cap B)}{P(B)} - Independence: When events don’t influence each other - Law of total probability: P(A) = \\sum_i P(A|B_i)P(B_i)\n\n\n\nUnderstanding time-dependent random systems: - Random variable sequences: X_0, X_1, X_2, \\ldots - State space: Set of possible values for each X_t - Transition probabilities: P(X_{t+1} = j | X_t = i)\n\n\n\n\n\n\nThe defining characteristic of Markov chains: P(X_{t+1} = j | X_t = i, X_{t-1} = i_{t-1}, \\ldots, X_0 = i_0) = P(X_{t+1} = j | X_t = i)\nInterpretation: Future state depends only on present state, not on history.\n\n\n\nMatrix representation of state transitions: - Stochastic matrix: Rows sum to 1, all entries non-negative - Chapman-Kolmogorov equation: P^{(n+m)} = P^{(n)} \\cdot P^{(m)} - n-step transition probabilities: (P^n)_{ij} = P(X_n = j | X_0 = i)\n\n\n\nUnderstanding different types of states: - Accessible: State j is accessible from state i if P^{(n)}_{ij} &gt; 0 for some n - Communicating: States i and j communicate if each is accessible from the other - Irreducible: All states communicate with each other - Periodic: State i has period d if returns are only possible at multiples of d steps\n\n\n\n\n\n\nProbability distributions that don’t change over time: - Definition: \\pi P = \\pi where \\pi is a row vector - Existence: Guaranteed for finite, irreducible chains - Uniqueness: Unique for irreducible chains\n\n\n\nWhen and how chains reach equilibrium: - Ergodic theorem: For irreducible, aperiodic chains: \\lim_{n \\to \\infty} P^{(n)}_{ij} = \\pi_j - Rate of convergence: How quickly the chain approaches stationary distribution - Mixing time: Time needed to get close to stationary distribution\n\n\n\n\n\n\nConnection between eigenvalues and chain behavior: - Dominant eigenvalue: Always equals 1 for stochastic matrices - Subdominant eigenvalue: Controls convergence rate - Spectral gap: Difference between largest and second-largest eigenvalues\n\n\n\nSpecial properties of transition matrices: - Principal eigenvalue: Always 1 - Principal eigenvector: Corresponds to stationary distribution - Non-negative entries: All eigenvector entries are non-negative\n\n\n\n\n\n\nSpecific application of Markov chains to networks: - State space: Nodes of the graph - Transition probabilities: Based on edge structure - Uniformity: Equal probability to each neighbor\n\n\n\nUnderstanding how information spreads: - Diffusion processes: How properties spread through networks - Equilibrium: Long-term distribution of walkers or information\nThese probability and linear algebra foundations are essential for understanding how random walks reveal network structure through their stationary distributions and convergence properties.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m07-random-walks/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying random walks, ensure you understand: - From M01-M06: Network representations, eigenvalue theory, matrix operations - From M06: Advanced concepts like matrix series convergence and spectral properties",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#probability-theory-for-stochastic-processes",
    "href": "m07-random-walks/00-preparation.html#probability-theory-for-stochastic-processes",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Foundation for understanding random processes: - Probability distributions: Discrete probability mass functions - Conditional probability: P(A|B) = \\frac{P(A \\cap B)}{P(B)} - Independence: When events don’t influence each other - Law of total probability: P(A) = \\sum_i P(A|B_i)P(B_i)\n\n\n\nUnderstanding time-dependent random systems: - Random variable sequences: X_0, X_1, X_2, \\ldots - State space: Set of possible values for each X_t - Transition probabilities: P(X_{t+1} = j | X_t = i)",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#markov-chain-fundamentals",
    "href": "m07-random-walks/00-preparation.html#markov-chain-fundamentals",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The defining characteristic of Markov chains: P(X_{t+1} = j | X_t = i, X_{t-1} = i_{t-1}, \\ldots, X_0 = i_0) = P(X_{t+1} = j | X_t = i)\nInterpretation: Future state depends only on present state, not on history.\n\n\n\nMatrix representation of state transitions: - Stochastic matrix: Rows sum to 1, all entries non-negative - Chapman-Kolmogorov equation: P^{(n+m)} = P^{(n)} \\cdot P^{(m)} - n-step transition probabilities: (P^n)_{ij} = P(X_n = j | X_0 = i)\n\n\n\nUnderstanding different types of states: - Accessible: State j is accessible from state i if P^{(n)}_{ij} &gt; 0 for some n - Communicating: States i and j communicate if each is accessible from the other - Irreducible: All states communicate with each other - Periodic: State i has period d if returns are only possible at multiples of d steps",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#limit-behavior-and-convergence",
    "href": "m07-random-walks/00-preparation.html#limit-behavior-and-convergence",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Probability distributions that don’t change over time: - Definition: \\pi P = \\pi where \\pi is a row vector - Existence: Guaranteed for finite, irreducible chains - Uniqueness: Unique for irreducible chains\n\n\n\nWhen and how chains reach equilibrium: - Ergodic theorem: For irreducible, aperiodic chains: \\lim_{n \\to \\infty} P^{(n)}_{ij} = \\pi_j - Rate of convergence: How quickly the chain approaches stationary distribution - Mixing time: Time needed to get close to stationary distribution",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#linear-algebra-for-markov-chains",
    "href": "m07-random-walks/00-preparation.html#linear-algebra-for-markov-chains",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Connection between eigenvalues and chain behavior: - Dominant eigenvalue: Always equals 1 for stochastic matrices - Subdominant eigenvalue: Controls convergence rate - Spectral gap: Difference between largest and second-largest eigenvalues\n\n\n\nSpecial properties of transition matrices: - Principal eigenvalue: Always 1 - Principal eigenvector: Corresponds to stationary distribution - Non-negative entries: All eigenvector entries are non-negative",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/00-preparation.html#applications-context",
    "href": "m07-random-walks/00-preparation.html#applications-context",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Specific application of Markov chains to networks: - State space: Nodes of the graph - Transition probabilities: Based on edge structure - Uniformity: Equal probability to each neighbor\n\n\n\nUnderstanding how information spreads: - Diffusion processes: How properties spread through networks - Equilibrium: Long-term distribution of walkers or information\nThese probability and linear algebra foundations are essential for understanding how random walks reveal network structure through their stationary distributions and convergence properties.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/pen-and-paper.html",
    "href": "m06-centrality/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and paper exercises\n\n️️School"
  },
  {
    "objectID": "m06-centrality/00-preparation.html",
    "href": "m06-centrality/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying centrality measures, ensure you understand: - From M01-M05: Network representations, eigenvalue concepts from clustering - Linear algebra: Matrix operations, eigenvalue decomposition from M05\n\n\n\n\n\n\n\nUnderstanding powers of matrices: - A^k represents k-step relationships in networks - Interpretation: A^k_{ij} = number of walks of length k from node i to j - Convergence: How A^k behaves as k \\to \\infty\n\n\n\nInfinite series involving matrices: - Geometric series: (I - \\alpha A)^{-1} = I + \\alpha A + \\alpha^2 A^2 + \\ldots - Convergence conditions: When does the series converge? - Spectral radius: Determines convergence: series converges if |\\alpha| &lt; 1/\\rho(A)\n\n\n\n\n\n\nFor non-negative matrices (like adjacency matrices): - Largest eigenvalue: Is real and positive - Principal eigenvector: Has all non-negative entries - Uniqueness: Principal eigenvector is unique (up to scaling) - Dominance: Largest eigenvalue strictly dominates others for irreducible matrices\n\n\n\n\nDefinition: \\rho(A) = \\max_i |\\lambda_i| (magnitude of largest eigenvalue)\nSignificance: Controls convergence of matrix powers and series\nComputation: Can be found using power iteration method\n\n\n\n\n\n\n\n\nDifferent ways to normalize vectors: - L1 norm: ||v||_1 = \\sum_i |v_i| (sum to 1 for probability distributions) - L2 norm: ||v||_2 = \\sqrt{\\sum_i v_i^2} (unit length vectors) - Max norm: ||v||_\\infty = \\max_i |v_i| (scale largest element to 1)\n\n\n\n\nRow stochastic: Each row sums to 1 (transition matrices)\nColumn stochastic: Each column sums to 1\n\nDoubly stochastic: Both rows and columns sum to 1\n\n\n\n\n\n\n\nAlgorithm for finding largest eigenvalue and eigenvector: 1. Start with random vector v^{(0)} 2. Iterate: v^{(k+1)} = \\frac{Av^{(k)}}{||Av^{(k)}||} 3. Converges to principal eigenvector\n\n\n\nDepends on ratio |\\lambda_2|/|\\lambda_1|\nFaster convergence when this ratio is small\nAcceleration techniques: Methods to improve convergence\n\n\n\n\n\n\n\n\nDiagonalization: A = PDP^{-1} where D is diagonal\nApplications: Computing matrix powers efficiently: A^k = PD^kP^{-1}\n\n\n\n\n\n\n\n\n\nConnectivity: Related to eigenvalue gaps\nMixing time: How quickly random walks converge\nExpansion: How well-connected different parts of the network are\n\n\n\n\n\nSparse matrices: Most real networks are sparse\nEfficient algorithms: Exploiting sparsity for large networks\nNumerical stability: Avoiding computational errors\n\nThese advanced linear algebra concepts provide the mathematical foundation for understanding how centrality measures capture different notions of node importance through matrix operations.",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m06-centrality/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying centrality measures, ensure you understand: - From M01-M05: Network representations, eigenvalue concepts from clustering - Linear algebra: Matrix operations, eigenvalue decomposition from M05",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#advanced-matrix-theory",
    "href": "m06-centrality/00-preparation.html#advanced-matrix-theory",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding powers of matrices: - A^k represents k-step relationships in networks - Interpretation: A^k_{ij} = number of walks of length k from node i to j - Convergence: How A^k behaves as k \\to \\infty\n\n\n\nInfinite series involving matrices: - Geometric series: (I - \\alpha A)^{-1} = I + \\alpha A + \\alpha^2 A^2 + \\ldots - Convergence conditions: When does the series converge? - Spectral radius: Determines convergence: series converges if |\\alpha| &lt; 1/\\rho(A)\n\n\n\n\n\n\nFor non-negative matrices (like adjacency matrices): - Largest eigenvalue: Is real and positive - Principal eigenvector: Has all non-negative entries - Uniqueness: Principal eigenvector is unique (up to scaling) - Dominance: Largest eigenvalue strictly dominates others for irreducible matrices\n\n\n\n\nDefinition: \\rho(A) = \\max_i |\\lambda_i| (magnitude of largest eigenvalue)\nSignificance: Controls convergence of matrix powers and series\nComputation: Can be found using power iteration method",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#normalization-techniques",
    "href": "m06-centrality/00-preparation.html#normalization-techniques",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Different ways to normalize vectors: - L1 norm: ||v||_1 = \\sum_i |v_i| (sum to 1 for probability distributions) - L2 norm: ||v||_2 = \\sqrt{\\sum_i v_i^2} (unit length vectors) - Max norm: ||v||_\\infty = \\max_i |v_i| (scale largest element to 1)\n\n\n\n\nRow stochastic: Each row sums to 1 (transition matrices)\nColumn stochastic: Each column sums to 1\n\nDoubly stochastic: Both rows and columns sum to 1",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#iterative-methods",
    "href": "m06-centrality/00-preparation.html#iterative-methods",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Algorithm for finding largest eigenvalue and eigenvector: 1. Start with random vector v^{(0)} 2. Iterate: v^{(k+1)} = \\frac{Av^{(k)}}{||Av^{(k)}||} 3. Converges to principal eigenvector\n\n\n\nDepends on ratio |\\lambda_2|/|\\lambda_1|\nFaster convergence when this ratio is small\nAcceleration techniques: Methods to improve convergence\n\n\n\n\n\n\n\n\nDiagonalization: A = PDP^{-1} where D is diagonal\nApplications: Computing matrix powers efficiently: A^k = PD^kP^{-1}",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/00-preparation.html#applications-to-network-analysis",
    "href": "m06-centrality/00-preparation.html#applications-to-network-analysis",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Connectivity: Related to eigenvalue gaps\nMixing time: How quickly random walks converge\nExpansion: How well-connected different parts of the network are\n\n\n\n\n\nSparse matrices: Most real networks are sparse\nEfficient algorithms: Exploiting sparsity for large networks\nNumerical stability: Avoiding computational errors\n\nThese advanced linear algebra concepts provide the mathematical foundation for understanding how centrality measures capture different notions of node importance through matrix operations.",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/what-is-community.html",
    "href": "m05-clustering/what-is-community.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Birds of a feather\n\n\nBirds of a feather flock together, and so do many other things. For instance, we have a group of friends with similar interests who hang out together frequently but may not interact as much with other groups.\nIn networks, communities are groups of nodes that share similar connection patterns. These communities do not always mean densely-connected nodes. Sometimes, a community can be nodes that are not connected to each other, but connect similarly to other groups. For instance, in a user-movie rating network, a community might be users with similar movie tastes, even if they don’t directly connect to each other.\n\n\n\nCommunity structure in a social network\n\n\nCommunities reflect underlying mechanisms of network formation and underpin the dynamics of information propagation. Examples include:\n\nHomophily: The tendency of similar nodes to form connections.\nFunctional groups: Nodes that collaborate for specific purposes.\nHierarchical structure: Smaller communities existing within larger ones.\nInformation flow: The patterns of information, influence, or disease propagation through the network.\n\nThis is why network scientists are sooo obsessed with community structure in networks. See {footcite}fortunato2010community,fortunato2016community,peixoto2019bayesian for comprehensive reviews on network communities."
  },
  {
    "objectID": "m05-clustering/what-is-community.html#birds-of-a-feather-flock-together",
    "href": "m05-clustering/what-is-community.html#birds-of-a-feather-flock-together",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Birds of a feather\n\n\nBirds of a feather flock together, and so do many other things. For instance, we have a group of friends with similar interests who hang out together frequently but may not interact as much with other groups.\nIn networks, communities are groups of nodes that share similar connection patterns. These communities do not always mean densely-connected nodes. Sometimes, a community can be nodes that are not connected to each other, but connect similarly to other groups. For instance, in a user-movie rating network, a community might be users with similar movie tastes, even if they don’t directly connect to each other.\n\n\n\nCommunity structure in a social network\n\n\nCommunities reflect underlying mechanisms of network formation and underpin the dynamics of information propagation. Examples include:\n\nHomophily: The tendency of similar nodes to form connections.\nFunctional groups: Nodes that collaborate for specific purposes.\nHierarchical structure: Smaller communities existing within larger ones.\nInformation flow: The patterns of information, influence, or disease propagation through the network.\n\nThis is why network scientists are sooo obsessed with community structure in networks. See {footcite}fortunato2010community,fortunato2016community,peixoto2019bayesian for comprehensive reviews on network communities."
  },
  {
    "objectID": "m05-clustering/00-preparation.html",
    "href": "m05-clustering/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying clustering methods, ensure you understand: - From M01-M04: Basic network representations, degree distributions, and sampling bias concepts - Mathematical foundations: Sampling theory and statistical bias from M04\n\n\n\n\n\nEssential matrix operations for clustering algorithms:\n\n\n\nMatrix multiplication: C = AB where C_{ij} = \\sum_k A_{ik}B_{kj}\nMatrix transpose: (A^T)_{ij} = A_{ji}\nIdentity matrix: I where I_{ii} = 1 and I_{ij} = 0 for i \\neq j\n\n\n\n\n\nSymmetric: A = A^T (important for undirected graphs)\nPositive semidefinite: All eigenvalues are non-negative\nSpectral theorem: Symmetric matrices can be diagonalized with real eigenvalues\n\n\n\n\n\n\n\nFor matrix M and vector v: Mv = \\lambda v where \\lambda is an eigenvalue and v is the corresponding eigenvector.\n\n\n\n\nOrthogonality: Eigenvectors of symmetric matrices are orthogonal\nReal eigenvalues: Symmetric matrices have real eigenvalues\nEigenvector basis: Eigenvectors form a basis for the vector space\n\n\n\n\n\nExpression x^T M x for vector x and matrix M: - Interpretation: Measures how vector x interacts with matrix M - Optimization: Many clustering problems minimize quadratic forms - Geometric meaning: Related to distances and similarities\n\n\n\n\n\n\nBasic understanding of optimization with constraints: - Objective function: What we want to minimize or maximize - Constraints: Restrictions on feasible solutions - Lagrange multipliers: Method for handling equality constraints\n\n\n\n\nDiscrete vs. continuous: Converting integer problems to real-valued problems\nApproximation quality: Understanding when relaxations provide good solutions\n\n\n\n\n\n\n\nUnderstanding graph partitioning: - Cut: Set of edges between two groups of nodes - Minimum cut: Finding the smallest cut between node groups - Balanced cuts: Ensuring groups are roughly equal in size\n\n\n\n\nGraph spectrum: Set of eigenvalues of graph matrices\nConnectivity and eigenvalues: How eigenvalues relate to graph structure\nFiedler vector: Second smallest eigenvector and its clustering properties\n\n\n\n\n\n\n\n\nTime complexity: Understanding O(n²), O(n³) for matrix operations\nSpace complexity: Memory requirements for large matrices\nNumerical stability: Issues with floating-point computations\n\n\n\n\n\nSparse matrices: Efficient storage for large, sparse adjacency matrices\nPriority queues: For optimization algorithms\n\nThese mathematical foundations are essential for understanding how clustering algorithms transform network structure problems into linear algebra problems that can be solved efficiently.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m05-clustering/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying clustering methods, ensure you understand: - From M01-M04: Basic network representations, degree distributions, and sampling bias concepts - Mathematical foundations: Sampling theory and statistical bias from M04",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#linear-algebra-fundamentals",
    "href": "m05-clustering/00-preparation.html#linear-algebra-fundamentals",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Essential matrix operations for clustering algorithms:\n\n\n\nMatrix multiplication: C = AB where C_{ij} = \\sum_k A_{ik}B_{kj}\nMatrix transpose: (A^T)_{ij} = A_{ji}\nIdentity matrix: I where I_{ii} = 1 and I_{ij} = 0 for i \\neq j\n\n\n\n\n\nSymmetric: A = A^T (important for undirected graphs)\nPositive semidefinite: All eigenvalues are non-negative\nSpectral theorem: Symmetric matrices can be diagonalized with real eigenvalues\n\n\n\n\n\n\n\nFor matrix M and vector v: Mv = \\lambda v where \\lambda is an eigenvalue and v is the corresponding eigenvector.\n\n\n\n\nOrthogonality: Eigenvectors of symmetric matrices are orthogonal\nReal eigenvalues: Symmetric matrices have real eigenvalues\nEigenvector basis: Eigenvectors form a basis for the vector space\n\n\n\n\n\nExpression x^T M x for vector x and matrix M: - Interpretation: Measures how vector x interacts with matrix M - Optimization: Many clustering problems minimize quadratic forms - Geometric meaning: Related to distances and similarities",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#optimization-prerequisites",
    "href": "m05-clustering/00-preparation.html#optimization-prerequisites",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Basic understanding of optimization with constraints: - Objective function: What we want to minimize or maximize - Constraints: Restrictions on feasible solutions - Lagrange multipliers: Method for handling equality constraints\n\n\n\n\nDiscrete vs. continuous: Converting integer problems to real-valued problems\nApproximation quality: Understanding when relaxations provide good solutions",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#graph-theory-prerequisites",
    "href": "m05-clustering/00-preparation.html#graph-theory-prerequisites",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding graph partitioning: - Cut: Set of edges between two groups of nodes - Minimum cut: Finding the smallest cut between node groups - Balanced cuts: Ensuring groups are roughly equal in size\n\n\n\n\nGraph spectrum: Set of eigenvalues of graph matrices\nConnectivity and eigenvalues: How eigenvalues relate to graph structure\nFiedler vector: Second smallest eigenvector and its clustering properties",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/00-preparation.html#computational-prerequisites",
    "href": "m05-clustering/00-preparation.html#computational-prerequisites",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Time complexity: Understanding O(n²), O(n³) for matrix operations\nSpace complexity: Memory requirements for large matrices\nNumerical stability: Issues with floating-point computations\n\n\n\n\n\nSparse matrices: Efficient storage for large, sparse adjacency matrices\nPriority queues: For optimization algorithms\n\nThese mathematical foundations are essential for understanding how clustering algorithms transform network structure problems into linear algebra problems that can be solved efficiently.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html",
    "href": "m04-friendship-paradox/03-exercises.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Objective: Experience the friendship paradox interactively\n\n🎉 Fun Challenge: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this Friendship Paradox Game! 🎮✨\n\nQuestions to consider: - Can you create a network where the friendship paradox is absent? - In other words, can you create a graph where your friends have the same number of friends as you? - What network structures minimize or maximize the friendship paradox effect?\n\n\n\nObjective: Apply the friendship paradox to disease control strategies\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this Vaccination Game! 🎮✨\n\nQuestions to explore: - How does random vaccination compare to targeted vaccination? - Why is vaccinating highly connected individuals more effective? - What happens when vaccination resources are limited?\n\n\n\n\n\n\nObjective: Understand the fundamentals of network data visualization\n📝 Exercise: Data Visualization Basics\nThis exercise covers: - Principles of effective data visualization - Common pitfalls in network visualization - Best practices for degree distribution plots\n\n\n\n\n\n\n  \nObjective: Master the techniques for analyzing and visualizing degree distributions\n📝 Exercise: Plotting Degree Distribution\nThis coding exercise covers: - Computing degree distributions - Plotting degree distributions effectively - Understanding complementary cumulative distribution functions (CCDF) - Comparing degree distributions of nodes vs. friends - Mathematical proofs of the friendship paradox\nKey concepts to implement: 1. Basic degree distribution computation 2. Log-log plotting for heavy-tailed distributions 3. CCDF calculation and visualization 4. Friend sampling and degree bias analysis 5. Mathematical verification of the friendship paradox\n\n\n\nAdvanced Challenge: Implement the first sampling method mentioned in the coding section: - Sample a node uniformly at random and then sample a friend of the node - Compare this with edge-based sampling - Analyze the differences in resulting degree distributions\nResearch Questions: - How do different sampling methods affect the friendship paradox? - Can you derive the mathematical relationship for node-first sampling? - What are the practical implications of each sampling method?\n\n\n\n\n\n\n\nExplain why the friendship paradox occurs in mathematical terms\nDescribe the relationship between CCDF slope and network heterogeneity\nConnect the friendship paradox to the Molloy-Reed condition for giant components\n\n\n\n\n\nDesign a vaccination strategy for a social network\nIdentify potential biases in social network surveys\nPropose methods to mitigate sampling bias in network studies\n\n\n\n\n\nProve that \\langle k' \\rangle = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} \\geq \\langle k \\rangle\nDerive the relationship between power-law exponent and CCDF slope\nCalculate the exact friendship paradox magnitude for specific network types",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html#interactive-exercises",
    "href": "m04-friendship-paradox/03-exercises.html#interactive-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Objective: Experience the friendship paradox interactively\n\n🎉 Fun Challenge: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this Friendship Paradox Game! 🎮✨\n\nQuestions to consider: - Can you create a network where the friendship paradox is absent? - In other words, can you create a graph where your friends have the same number of friends as you? - What network structures minimize or maximize the friendship paradox effect?\n\n\n\nObjective: Apply the friendship paradox to disease control strategies\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this Vaccination Game! 🎮✨\n\nQuestions to explore: - How does random vaccination compare to targeted vaccination? - Why is vaccinating highly connected individuals more effective? - What happens when vaccination resources are limited?",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html#pen-and-paper-exercises",
    "href": "m04-friendship-paradox/03-exercises.html#pen-and-paper-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Objective: Understand the fundamentals of network data visualization\n📝 Exercise: Data Visualization Basics\nThis exercise covers: - Principles of effective data visualization - Common pitfalls in network visualization - Best practices for degree distribution plots",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html#coding-exercises",
    "href": "m04-friendship-paradox/03-exercises.html#coding-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Objective: Master the techniques for analyzing and visualizing degree distributions\n📝 Exercise: Plotting Degree Distribution\nThis coding exercise covers: - Computing degree distributions - Plotting degree distributions effectively - Understanding complementary cumulative distribution functions (CCDF) - Comparing degree distributions of nodes vs. friends - Mathematical proofs of the friendship paradox\nKey concepts to implement: 1. Basic degree distribution computation 2. Log-log plotting for heavy-tailed distributions 3. CCDF calculation and visualization 4. Friend sampling and degree bias analysis 5. Mathematical verification of the friendship paradox\n\n\n\nAdvanced Challenge: Implement the first sampling method mentioned in the coding section: - Sample a node uniformly at random and then sample a friend of the node - Compare this with edge-based sampling - Analyze the differences in resulting degree distributions\nResearch Questions: - How do different sampling methods affect the friendship paradox? - Can you derive the mathematical relationship for node-first sampling? - What are the practical implications of each sampling method?",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/03-exercises.html#assessment-questions",
    "href": "m04-friendship-paradox/03-exercises.html#assessment-questions",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Explain why the friendship paradox occurs in mathematical terms\nDescribe the relationship between CCDF slope and network heterogeneity\nConnect the friendship paradox to the Molloy-Reed condition for giant components\n\n\n\n\n\nDesign a vaccination strategy for a social network\nIdentify potential biases in social network surveys\nPropose methods to mitigate sampling bias in network studies\n\n\n\n\n\nProve that \\langle k' \\rangle = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} \\geq \\langle k \\rangle\nDerive the relationship between power-law exponent and CCDF slope\nCalculate the exact friendship paradox magnitude for specific network types",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html",
    "href": "m04-friendship-paradox/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying the friendship paradox, ensure you understand: - From M01-M03: Basic network concepts (degree, adjacency matrix, connectivity) - General math: Basic calculus and linear algebra\n\n\n\n\n\nUnderstanding of discrete probability distributions: - Probability mass function: P(X = k) for discrete random variable X - Expected value: E[X] = \\sum_{k} k \\cdot P(X = k)\n- Variance: \\text{Var}(X) = E[X^2] - (E[X])^2\n\n\n\nEssential for understanding biased sampling: - Conditional probability: P(A|B) = \\frac{P(A \\cap B)}{P(B)} - Law of total expectation: E[X] = E[E[X|Y]]\n\n\n\n\n\n\n\nPopulation parameters: True values in the complete dataset\nSample statistics: Measured values from a subset\nSampling bias: When sample doesn’t represent population\n\n\n\n\n\nSimple random sampling: Each individual has equal probability of selection\nWeighted sampling: Selection probability proportional to some attribute\nSize-biased sampling: Larger items more likely to be selected\n\n\n\n\nFor convex functions and random variables: E[f(X)] \\geq f(E[X])\nThis inequality is fundamental to understanding why averages of friends differ from friends of averages.\n\n\n\n\n\n\n\nFirst moment: Mean \\mu = E[X]\nSecond moment: E[X^2]\n\nRelationship: E[X^2] \\geq (E[X])^2 with equality only when X is constant\n\n\n\n\n\nMatrix operations: For adjacency matrix manipulations\nVector operations: For degree calculations\n\n\n\n\n\n\n\nUnderstanding how data collection methods can introduce bias: - Response bias: Who is more likely to participate in surveys - Selection effects: How sampling frames affect results\n\n\n\nBasic concepts about disease spread: - Contact networks: How diseases spread through social connections - Vaccination strategies: Targeting high-contact individuals\nThese mathematical foundations will help you understand the counterintuitive but mathematically precise friendship paradox phenomenon.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m04-friendship-paradox/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying the friendship paradox, ensure you understand: - From M01-M03: Basic network concepts (degree, adjacency matrix, connectivity) - General math: Basic calculus and linear algebra",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#probability-theory-fundamentals",
    "href": "m04-friendship-paradox/00-preparation.html#probability-theory-fundamentals",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding of discrete probability distributions: - Probability mass function: P(X = k) for discrete random variable X - Expected value: E[X] = \\sum_{k} k \\cdot P(X = k)\n- Variance: \\text{Var}(X) = E[X^2] - (E[X])^2\n\n\n\nEssential for understanding biased sampling: - Conditional probability: P(A|B) = \\frac{P(A \\cap B)}{P(B)} - Law of total expectation: E[X] = E[E[X|Y]]",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#sampling-theory",
    "href": "m04-friendship-paradox/00-preparation.html#sampling-theory",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Population parameters: True values in the complete dataset\nSample statistics: Measured values from a subset\nSampling bias: When sample doesn’t represent population\n\n\n\n\n\nSimple random sampling: Each individual has equal probability of selection\nWeighted sampling: Selection probability proportional to some attribute\nSize-biased sampling: Larger items more likely to be selected\n\n\n\n\nFor convex functions and random variables: E[f(X)] \\geq f(E[X])\nThis inequality is fundamental to understanding why averages of friends differ from friends of averages.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#mathematical-prerequisites",
    "href": "m04-friendship-paradox/00-preparation.html#mathematical-prerequisites",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "First moment: Mean \\mu = E[X]\nSecond moment: E[X^2]\n\nRelationship: E[X^2] \\geq (E[X])^2 with equality only when X is constant\n\n\n\n\n\nMatrix operations: For adjacency matrix manipulations\nVector operations: For degree calculations",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/00-preparation.html#applications-context",
    "href": "m04-friendship-paradox/00-preparation.html#applications-context",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding how data collection methods can introduce bias: - Response bias: Who is more likely to participate in surveys - Selection effects: How sampling frames affect results\n\n\n\nBasic concepts about disease spread: - Contact networks: How diseases spread through social connections - Vaccination strategies: Targeting high-contact individuals\nThese mathematical foundations will help you understand the counterintuitive but mathematically precise friendship paradox phenomenon.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/00-preparation.html",
    "href": "m03-robustness/00-preparation.html",
    "title": "Preparation",
    "section": "",
    "text": "Before studying network robustness, ensure you understand: - From M01: Basic graph representations and connectivity concepts - From M02: Shortest path calculations and average path length measurement",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Preparation"
    ]
  },
  {
    "objectID": "m03-robustness/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m03-robustness/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Preparation",
    "section": "",
    "text": "Before studying network robustness, ensure you understand: - From M01: Basic graph representations and connectivity concepts - From M02: Shortest path calculations and average path length measurement",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Preparation"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html",
    "href": "m02-small-world/03-exercises.html",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "✍️ It’s a small world!! 6 degrees of separation {footcite}esteban-moro-worksheet",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html#pen-and-paper-exercise-why-is-our-social-network-small-world",
    "href": "m02-small-world/03-exercises.html#pen-and-paper-exercise-why-is-our-social-network-small-world",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "✍️ It’s a small world!! 6 degrees of separation {footcite}esteban-moro-worksheet",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m02-small-world/03-exercises.html#assignment",
    "href": "m02-small-world/03-exercises.html#assignment",
    "title": "Exercises and Assignments",
    "section": "2 Assignment",
    "text": "2 Assignment\n\nFor students enrolled in SSIE 641, you will receive a dedicated link to the assignment repository from the instructor.\nFor those who are not enrolled, fork this assignment repository at Github.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "course/discord.html",
    "href": "course/discord.html",
    "title": "Discord",
    "section": "",
    "text": "We use a dedicated Discord server for this course to facilitate communication, Q&A, and collaboration outside of class. The Discord server is a space where you can:\n\nAsk questions about lectures, assignments, and projects\nDiscuss concepts and share resources with your peers\nGet support from the instructor, TA, and Minidora (the AI tutor)\nJoin study groups and participate in informal discussions\n\nInvitation links to the Discord server will be distributed via Brightspace. Please check the Brightspace announcements or course materials for the latest invite link.\nOnce you join, you’ll find channels for different topics (e.g., #random, #questions, #study-groups) and can interact with both classmates, AI tutor, and course staff. If you’re new to Discord, it’s a free platform available on web, desktop, and mobile.\n\n\n\nScreenshot of the course Discord server\n\n\nExample screenshot of the course Discord server interface.\nIf you have any trouble joining, please contact the instructor for assistance.",
    "crumbs": [
      "Home",
      "Course Information",
      "Discord"
    ]
  },
  {
    "objectID": "course/about.html",
    "href": "course/about.html",
    "title": "About us",
    "section": "",
    "text": "Networks are everywhere—from the Internet connecting billions of devices to the social connections that shape our daily lives. This course explores network data analysis from the ground up, combining hands-on coding with theoretical foundations to unlock the secrets of complex systems.",
    "crumbs": [
      "Home",
      "Course Information",
      "About us"
    ]
  },
  {
    "objectID": "course/about.html#about-us",
    "href": "course/about.html#about-us",
    "title": "About us",
    "section": "1 About us",
    "text": "1 About us\n\nInstructor\n\n\n\nWelcome! My name is Sadamori Kojaku, the instructor of this course. I started my career as a computer scientist but couldn’t resist to fall in love with Network Science right after I got Ph.D. Network Science is about a science on networks, and networks appear in many different forms in our daily lives. The internet, social media, and biological networks, power grid, and you name it. But when we abstract them into a bunch of dots connected by lines, we can compare them and understand them in a unified way. We can study them using the same toolkit no matter what the domain is, and can find universal patterns and principles that govern seemingly different systems. Sounds fun, right 😉?\nThis course will guide you through the fascinating world of networks, from foundational theory to hands-on coding and real-world applications. I hope you will enjoy and find the course useful in your future endeavors.\n\n\n\n\n\n\n\n\nTA\nTeaching Assistant is not yet assigned.\n\n\nAI Tutor (Minidora)\n\n\n\nMinidora is an AI tutor robot conceived in the 22nd century and deployed in the present era to support students. (the original character is designed by Fujiko Fujio for a famous Japanese manga called Doraemon). Minidora supports students in this course by providing dialogic explanations, quiz questions, and coding guidance on the course Discord.",
    "crumbs": [
      "Home",
      "Course Information",
      "About us"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html",
    "href": "m09-graph-neural-networks/image-processing.html",
    "title": "Preliminaries: Image Processing",
    "section": "",
    "text": "Graph Neural Networks are a type of neural network for graph data. node2vec and deepwalk stem from the idea of language modeling. In this module, we will focus on another branch of graph neural networks that stem from image processing."
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html#edge-detection-problem-in-image-processing",
    "href": "m09-graph-neural-networks/image-processing.html#edge-detection-problem-in-image-processing",
    "title": "Preliminaries: Image Processing",
    "section": "1 Edge Detection Problem in Image Processing",
    "text": "1 Edge Detection Problem in Image Processing\nEdge detection is a classical problem in image processing. The goal is to identify the boundaries of objects in an image.\n\nTo approach the problem, let us first remind that an image is a matrix of pixels. Each pixel has RGB values, each of which represents the intensity of red, green, and blue color. To simplify the problem, we focus on grayscale images, in which each pixel has only one value representing the brightness. In this case, an image can be represented as a 2D matrix, where each element in the matrix represents the brightness of a pixel.\n\n\nAn example\nHuman eyes are very sensitive to brightness changes. An edge in an image appears when there is a significant brightness change between adjacent pixels. To be more concrete, let’s consider a small example consisting of 6x6 pixels, with a vertical line from the top to the bottom, where the brightness is higher than the neighboring pixels. This is an edge we want to detect.\n\nX = \\begin{bmatrix}\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10\n\\end{bmatrix}\n\nLet’s zoom on the pixel at (3, 3) and its surrounding pixels.\n\nZ = \\begin{bmatrix}\n10 & 80 & 10 \\\\\n\\textcolor{blue}{10} & \\textcolor{red}{80} & \\textcolor{purple}{10} \\\\\n10 & 80 & 10\n\\end{bmatrix}\n\nwhere the central pixel is highlighted in red. Since we are interested in the edge which is a sudden change in brightness along the horizontal direction, we take a derivative at the central pixel by\n\n\\nabla Z_{22} = \\textcolor{blue}{Z_{2,1}} - \\textcolor{purple}{Z_{2,3}}\n\nFollowing the same process, we can compute the derivative at all pixels, which gives us the (horizontal) derivative of the image.\n\n\\begin{bmatrix}\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & -\n\\end{bmatrix}\n\nThe symbol - indicates that the derivative is not defined because one of the neighboring pixels is out of the image boundary. We observe that the derivative is high at the edge and low elsewhere. This is a simple but effective way to detect edges in an image.\nWe can consider a derivative operator along the vertical direction that computes the difference between the vertical neighboring pixels.\n\n\\nabla Z_{22} = Z_{1,2} - Z_{3,2}\n\nAnd, when applied to the entire image, the result is\n\n\\begin{bmatrix}\n- & - & - & - & -  & - \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n- & - & - & - & - & -\n\\end{bmatrix}\n\nThe all entries are zero, meaning that there is no edge in the vertical direction.\nWe can combine the horizontal and vertical derivatives to get the gradient of the image. For example,\n\n\\nabla Z_{22} = Z_{12} - Z_{32} + Z_{21} - Z_{23}\n\nWhen applied to the entire image, the result is the same as the horizontal derivative.\n\n\nConvolution\nWe observe that there is a repeated pattern in the derivative computation: we are taking addition and subtraction of neighbiring pixels. This motivates us to generalize the operation to a more general form.\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j}\n\nwhere K is a 3 \\times 3 matrix, and w=h=3 represent the width and height of the kernel.\n\nK = \\begin{bmatrix}\nK_{11} & K_{12} & K_{13} \\\\\nK_{21} & K_{22} & K_{23} \\\\\nK_{31} & K_{32} & K_{33}\n\\end{bmatrix}\n\nThe matrix K is called a kernel, and applying it to the image is called convolution.\nThe index of the kernel is conventionally reversed. Namely, we reorder the entries of the kernel such that\n\n$$\n\\begin{bmatrix}\nK_{33} & K_{32} & K_{31} \\\\\nK_{23} & K_{22} & K_{21} \\\\\nK_{13} & K_{12} & K_{11}\n\\end{bmatrix}\n$$\n\nThen, take the element-wise product with $Z$\n\n$$\n\\begin{bmatrix}\nZ_{11} K_{33} & Z_{12} K_{32} & Z_{13} K_{31} \\\\\nZ_{21} K_{23} & Z_{22} K_{22} & Z_{23} K_{21} \\\\\nZ_{31} K_{13} & Z_{32} K_{12} & Z_{33} K_{11}\n\\end{bmatrix}\n$$\n\nand sum up all the elements to get the new pixel value $\\nabla Z_{22}$.\nWhy do we reverse the kernel? This is to match with the mathematical definition of convolution, which will be introduced later.\nIn the previous example, we used a $3 \\times 3$ kernels called the Prewitt operator, which in terms of $K$ is\n\n$$\nK_h = \\begin{bmatrix}\n-1 & 0 & 1 \\\\\n-1 & 0 & 1 \\\\\n-1 & 0 & 1\n\\end{bmatrix}\n\\quad \\text{or} \\quad\nK_v = \\begin{bmatrix}\n-1 & -1 & -1 \\\\\n0 & 0 & 0 \\\\\n1 & 1 & 1\n\\end{bmatrix}\n$$\n\nwhere $K_h$ is the horizontal Prewitt operator and $K_v$ is the vertical Prewitt operator.\nA kernel represents a local pattern we want to detect. The new pixel value after the convolution is maximized when the pattern is most similar to the kernel in terms of the inner product. This can be confirmed by:\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j} = \\langle \\hat K, Z \\rangle\n\nwhere \\langle \\cdot, \\cdot \\rangle is the inner product, and \\hat K is the order-reversed kernel.\nCheck out this awesome interactive demo to see how different kernels work: [Demo](https://setosa.io/ev/image-kernels/)"
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html#fourier-transform",
    "href": "m09-graph-neural-networks/image-processing.html#fourier-transform",
    "title": "Preliminaries: Image Processing",
    "section": "2 Fourier Transform",
    "text": "2 Fourier Transform\n\nConvolution computes the new pixel values by sliding a kernel over an image. How is the resulting image related to the original image?\nTo answer this question, let us consider a row of an image and convolve it with a kernel K.\n\n\\begin{aligned}\nX &= \\begin{bmatrix}\nX_1 & X_2 & X_3 & X_4 & X_5 & X_6\n\\end{bmatrix} \\\\\nK &= \\begin{bmatrix}\nK_1 & K_2 & K_3\n\\end{bmatrix}\n\\end{aligned}\n\nThe convolution of X and K is\n\nX * K = \\begin{bmatrix}\nX_1 K_3 + X_2 K_2 + X_3 K_1 & X_2 K_3 + X_3 K_2 + X_4 K_1 & X_3 K_3 + X_4 K_2 + X_5 K_1 & X_4 K_3 + X_5 K_2 + X_6 K_1\n\\end{bmatrix}\n\n…which is complicated, right? 😅 So let’s make it simple by using a useful theorem called the convolution theorem.\nThe convolution theorem gives us a simpler way to think about convolution. Instead of doing the complex sliding window operation in the original domain (like pixel values), we can:\n\nTransform both signals to the frequency domain using Fourier transform\nMultiply them together (much simpler!)\nTransform back to get the same result\n\nMathematically, the above steps can be written as:\n\n\\mathcal{F}(X), \\mathcal{F}(K) - Transform both signals to frequency domain (Fourier transform)\n\\mathcal{F}(X) \\cdot \\mathcal{F}(K) - Multiply the transformed signals\n\\mathcal{F}^{-1}(\\mathcal{F}(X) \\cdot \\mathcal{F}(K)) - Transform back to get X * K\n\nwhere \\mathcal{F}^{-1} is the inverse Fourier transform that brings us back to the original domain. This is much easier than computing the convolution directly!\nFor a discrete signal x[n] with N points, the Fourier transform \\mathcal{F} is defined as:\n\n\\mathcal{F}(x)[k] = \\sum_{n=0}^{N-1} x[n] \\cdot e^{-2\\pi i \\frac{nk}{N}}\n\nwhere i is the imaginary unit. Or equivalently,\n\n\\mathcal{F}(x)[k] = \\sum_{n=0}^{N-1} x[n] \\cdot \\left[ \\cos\\left(2\\pi \\frac{nk}{N}\\right) - i \\sin\\left(2\\pi \\frac{nk}{N}\\right) \\right]\n\nusing Euler’s formula e^{ix} = \\cos(x) + i\\sin(x).\nComplex number can be thought of as a way to represent a 2D vector using a single value (which is a computer science perspective; mathematically, it is a bit more subtle). For example, $e^{i\\pi/2} = \\cos(\\pi/2) + i\\sin(\\pi/2)$ represents the 2D vector $(\\cos(\\pi/2), \\sin(\\pi/2))$. In the context of Fourier transform, we interpret $e^{-2\\pi i \\frac{nk}{N}}$ as two *base waves*, i.e., sine and cosine, with phase $\\frac{2\\pi k}{N}$.\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Euler%27s_formula.svg/360px-Euler%27s_formula.svg.png)\nIn simple terms, \\mathcal{F} takes a signal (like our row of pixel values) and breaks it down into sine and cosine waves of different frequencies. Each frequency component k tells us “how much” of that frequency exists in our original signal. Don’t worry too much about the complex math. The key idea is that \\mathcal{F} represents a signal as a sum of multiple waves with different frequencies, so we can understand the signal in terms of its frequencies rather than its original values.\n\n3Blue1Brown makes a beautiful video explaining Fourier transform: [Video](https://www.youtube.com/watch?v=spUNpyF58BY). Here is a great interactive demo on Fourier transform by Jez Swanson: [Demo](https://www.jezzamon.com/fourier/).\n\nAn example for the Fourier transform\nNow, let’s perform the convolution using the Fourier transform using an example.\n\nimport numpy as np\nX = np.array([10, 10, 80, 10, 10, 10])\nK = np.array([-1, 0, 1])\n\nLet us first perform the convolution directly.\n\n# Pad X with zeros on both sides to handle boundary\nn_conv = len(X) - len(K) + 1  # Now we get full length output\nXKconv = np.zeros(n_conv)\n\nfor i in range(n_conv):\n    XKconv[i] = np.sum(X[i:(i+len(K))] * K[::-1]) # Reverse the kernel and take element-wise product and sum up\nXKconv\n\nLet us now perform the convolution using the Fourier transform. We compute the Fourier transform of X and K.\n\n# Step 1: Transform X and K to frequency domain\nFX = np.fft.fft(X)\n# Pad K with zeros to match the length of X before FFT\nK_padded = np.pad(K, (0, len(X) - len(K)), 'constant') # [-1  0  1  0  0  0]\nFK = np.fft.fft(K_padded)\nprint(\"FX:\", FX)\n\n\nWe add zeros to K to make it the same length as X before applying the Fourier transform. This is necessary because the convolution theorem requires the signals to have the same length.\nFX is the Fourier transform of X, which is a complex number. Each entry FX[k] represents the weight of the cosine wave in its real part and the weight of the sine wave in its imaginary part, with phase 2\\pi k / N. Similarly for FK.\n\nNext, we multiply the transformed signals.\n\nFXKconv = FX * FK\n\nThis is the convolution in the frequency domain. Finally, we transform back to get the convolution.\n\nXKconv_ft = np.real(np.fft.ifft(FXKconv))\nXKconv_ft\n\n\nWe take the real part. The imaginary part is due to numerical artifacts that do not matter in practice.\nThe Fourier transform convolution produces a longer output than direct convolution because it includes partial overlaps between K and X at the boundaries. Since we only want the full overlaps, we need to truncate the first two elements of XKconv_ft (as K has length 3) to match the length of the direct convolution result.\nFor example, let’s look at what happens at the beginning of the convolution:\n\nAt position -2: Only the last element of K overlaps with X: [0, 0, 10] * [-1, 0, 1] = 10\nAt position -1: Two elements of K overlap with X: [0, 10, 10] * [-1, 0, 1] = 10\nAt position 0: Full overlap begins: [10, 10, 80] * [-1, 0, 1] = 70\n\nThe Fourier transform method gives us all these positions (-2, -1, 0, …), but we only want the full overlaps starting from position 0, which is why we truncate the first two elements.\n\n\nXKconv_ft = XKconv_ft[2:]\nXKconv_ft\n\nThis gives us the same result as the direct convolution up to numerical errors."
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html#fourier-transform-of-images",
    "href": "m09-graph-neural-networks/image-processing.html#fourier-transform-of-images",
    "title": "Preliminaries: Image Processing",
    "section": "3 Fourier Transform of Images",
    "text": "3 Fourier Transform of Images\nLet’s extend the above example to an image which is a 2D matrix. The idea is the same: we take the Fourier transform of each row and column of the image, and then multiply them together to get the convolution in the frequency domain. More specifically, for an image X with size H \\times W, the Fourier transform of X is\n\n\\begin{aligned}\n\\mathcal{F}(X)[h, w] &= \\sum_{k=0}^{H-1} \\sum_{\\ell=0}^{W-1} X[k, \\ell] \\cdot e^{-2\\pi i \\frac{hk}{H}} \\cdot e^{-2\\pi i \\frac{w\\ell}{W}} \\\\\n&= \\sum_{k=0}^{H-1} \\sum_{\\ell=0}^{W-1} X[k, \\ell] e^{-2\\pi i \\left(\\frac{hk}{H} + \\frac{w\\ell}{W}\\right)}\n\\end{aligned}\n\nComparing with the 1D case, we see that the 2D Fourier transform is functionally the same as the 1D Fourier transform, except that we now have two indices h and w to represent the frequency in both dimensions. The basis waves are 2D waves as shown below.\nCosine waves\n\n:tags: [hide-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef basis_function(img_size=256, u=0, v=0):\n  '''\n  img_size : square size of image f(x,y)\n  u,v : spatial space indice\n  '''\n  N = img_size\n  x = np.linspace(0, N-1, N)\n  y = np.linspace(0, N-1, N)\n  x_, y_ = np.meshgrid(x, y)\n  bf = np.exp(-1j*2*np.pi*(u*x_/N+v*y_/N))\n  if u == 0 and v == 0:\n    bf = np.round(bf)\n  real = np.real(bf) # The cosine part\n  imag = np.imag(bf) # The sine part\n  return real, imag\n\nsize = 16\nbf_arr_real = np.zeros((size*size,size,size))\nbf_arr_imag = np.zeros((size*size,size,size))\nind = 0\nfor col in range(size):\n  for row in range(size):\n    re,imag = basis_function(img_size=size, u=row, v=col)\n    bf_arr_real[ind] = re\n    bf_arr_imag[ind] = imag\n    ind += 1\n\n# real part\n_, axs = plt.subplots(size, size, figsize=(7, 7))\naxs = axs.flatten()\nfor img, ax in zip(bf_arr_real, axs):\n  ax.set_axis_off()\n  ax.imshow(img,cmap='gray')\n\nSine waves\n\n:tags: [hide-input]\n# imaginary part\n_, axs = plt.subplots(size, size, figsize=(7, 7))\naxs = axs.flatten()\nfor img, ax in zip(bf_arr_imag, axs):\n  ax.set_axis_off()\n  ax.imshow(img,cmap='gray')\n\nThe Fourier transform of an image is a decomposition of an image into the sum of these basis waves.\n\nAn example of Fourier transform\nLet us apply the Fourier transform to an image.\n\n:tags: [hide-input]\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Read image from URL\ndef read_jpeg_from_url(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    # Convert to RGB mode if needed (in case it's RGBA)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    return img\n\ndef image_to_numpy(img):\n    return np.array(img)\n\ndef to_gray_scale(img_np):\n    return np.mean(img_np, axis=2)\n\n# URL of the image\nurl = \"https://www.binghamton.edu/news/images/uploads/features/20180815_peacequad02_jwc.jpg\"\n\nimg = read_jpeg_from_url(url)\nimg_np = image_to_numpy(img)\nimg_gray = to_gray_scale(img_np)\n\nplt.imshow(img_gray, cmap='gray')\n\nTake the Fourier transform of the image.\n\nft_img_gray = np.fft.fft2(img_gray)\n\nThis decomposes the image into a sum of basis waves. Let’s see the weights of the basis waves.\n\n:tags: [hide-input]\nimport matplotlib\n\nweight = np.abs(ft_img_gray)\n\n# real part\nfig1, ax1 = plt.subplots(figsize=(5, 5))\n\nax1.imshow(weight, cmap='gray', norm=matplotlib.colors.LogNorm(), aspect='equal')\ncbar = fig1.colorbar(ax1.images[0], ax=ax1, orientation='horizontal')\ncbar.set_label('Fourier transform magnitude')\n\nThe corresponding basis waves look like this:\n\n:tags: [hide-input]\nsize = 16\nbf_arr_real = np.zeros((size*size,size,size))\nbf_arr_imag = np.zeros((size*size,size,size))\nind = 0\nfor col in range(-size//2, size//2):\n  for row in range(-size//2, size//2):\n    re,imag = basis_function(img_size=size, u=row, v=col)\n    bf_arr_real[ind] = re\n    bf_arr_imag[ind] = imag\n    ind += 1\n\n# real part\nfig, axs = plt.subplots(size, size, figsize=(7, 7))\naxs = axs.flatten()\nfor img, ax in zip(bf_arr_real, axs):\n  ax.set_axis_off()\n  ax.imshow(img,cmap='gray')\n\nfig.suptitle('Real Part of Basis Functions')\n\n\n# imaginary part\nfig, axs = plt.subplots(size, size, figsize=(7, 7))\naxs = axs.flatten()\nfor img, ax in zip(bf_arr_imag, axs):\n  ax.set_axis_off()\n  ax.imshow(img,cmap='gray')\n\nfig.suptitle('Imaginary Part of Basis Functions')\n\nNow, let’s see the convolution of the image with a Prewitt operator.\n\nK = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]]) # Prewitt operator\n\nK_padd = np.zeros((img_gray.shape[0], img_gray.shape[1]))\nK_padd[:K.shape[0], :K.shape[1]] = K\n\n# convolution\nFK = np.fft.fft2(K_padd)\n\nThe Fourier transform of the Prewitt operator looks like this:\n\nplt.imshow(np.abs(FK), cmap='gray')\ncbar = plt.colorbar()\n\nWe can think of the frequency domain of the kernel as a filter that suppresses some frequencies and allows others to pass through. In the example of the Prewitt operator, the kernel FK has a low value around the center of the image. The product FX \\cdot FK then suppresses the low-frequency components of the image, and we are left with the high-frequency components that correspond to the horizontal edges. We can think of this as a high-pass filter that only allows high-frequency components to pass through.\nLet’s see the convolution result.\n\n:tags: [hide-input]\nFX = np.fft.fft2(img_gray)\nconv_img_gray = np.real(np.fft.ifft2(FX * FK))\nplt.imshow(conv_img_gray, cmap='gray')\n\nWe observe that the horizontal edges are highlighted.\nA widespread application of the 2D Fourier transform is JPEG format. Here's how it works:\n\n(1) It first breaks the image into small 8x8 squares.\n(2) It converts each square into frequencies using the Discrete Cosine Transform. The sine part is discarded for compression.\n(3) It keeps the important low frequencies that our eyes can see well.\n(4) It throws away most of the high frequencies that our eyes don't notice much.\n\nThese steps make the file much smaller while still looking good to us."
  },
  {
    "objectID": "m09-graph-neural-networks/image-processing.html#a-key-lesson-from-image-processing",
    "href": "m09-graph-neural-networks/image-processing.html#a-key-lesson-from-image-processing",
    "title": "Preliminaries: Image Processing",
    "section": "4 A key lesson from image processing",
    "text": "4 A key lesson from image processing\nWe have seen an equivalence between convolution in the pixel (spatial) domain and multiplication in the frequency domain. Using the Fourier transform, an image is decomposed into a sum of basis waves. The kernel can be thought of as a filter that suppresses some basis waves and allows others to pass through.\nThis idea is the key to understand graph convolutional networks we will see in the next page."
  },
  {
    "objectID": "m09-graph-neural-networks/from-image-to-graph.html",
    "href": "m09-graph-neural-networks/from-image-to-graph.html",
    "title": "From Image to Graph",
    "section": "",
    "text": "We can think of a convolution of an image from the perspective of networks. In the convolution of an image, a pixel is convolved with its neighbors. We can regard each pixel as a node, and each node is connected to its neighboring nodes (pixels) that are involved in the convolution.\n\nBuilding on this analogy, we can extend the idea of convolution to general graph data. Each node has a pixel value(s) (e.g., feature vector), which is convolved with the values of its neighbors in the graph. This is the key idea of graph convolutional networks. But, there is a key difference: while the number of neighbors for an image is homogeneous, the number of neighbors for a node in a graph can be heterogeneous. Each pixel has the same number of neighbors (except for the boundary pixels), but nodes in a graph can have very different numbers of neighbors. This makes it non-trivial to define the “kernel” for graph convolution."
  },
  {
    "objectID": "m09-graph-neural-networks/from-image-to-graph.html#analogy-between-image-and-graph-data",
    "href": "m09-graph-neural-networks/from-image-to-graph.html#analogy-between-image-and-graph-data",
    "title": "From Image to Graph",
    "section": "",
    "text": "We can think of a convolution of an image from the perspective of networks. In the convolution of an image, a pixel is convolved with its neighbors. We can regard each pixel as a node, and each node is connected to its neighboring nodes (pixels) that are involved in the convolution.\n\nBuilding on this analogy, we can extend the idea of convolution to general graph data. Each node has a pixel value(s) (e.g., feature vector), which is convolved with the values of its neighbors in the graph. This is the key idea of graph convolutional networks. But, there is a key difference: while the number of neighbors for an image is homogeneous, the number of neighbors for a node in a graph can be heterogeneous. Each pixel has the same number of neighbors (except for the boundary pixels), but nodes in a graph can have very different numbers of neighbors. This makes it non-trivial to define the “kernel” for graph convolution."
  },
  {
    "objectID": "m09-graph-neural-networks/from-image-to-graph.html#spectral-filter-on-graphs",
    "href": "m09-graph-neural-networks/from-image-to-graph.html#spectral-filter-on-graphs",
    "title": "From Image to Graph",
    "section": "2 Spectral filter on graphs",
    "text": "2 Spectral filter on graphs\nJust like we can define a convolution on images in the frequency domain, we can also define a ‘’frequency domain’’ for graphs.\nConsider a network of N nodes, where each node has a feature variable {\\mathbf x}_i \\in \\mathbb{R}. We are interested in:\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2,\n\nwhere A_{ij} is the adjacency matrix of the graph. The quantity J represents the total variation of x between connected nodes; a small J means that connected nodes have similar x (low variation; low frequency), while a large J means that connected nodes have very different x (high variation; high frequency).\nWe can rewrite J as\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 = {\\bf x}^\\top {\\bf L} {\\bf x},\n\nwhere {\\bf L} is the Laplacian matrix of the graph given by\n\nL_{ij} = \\begin{cases}\n-1 & \\text{if } i \\text{ and } j \\text{ are connected} \\\\\nk_i & \\text{if } i = j \\\\\n0 & \\text{otherwise}\n\\end{cases}.\n\nand {\\bf x} = [x_1,x_2,\\ldots, x_N]^\\top is a column vector of feature variables.\n\n\n\n\n\n\nDetailed derivation\n\n\n\n:tag: note :class: dropdown\nThe above derivation shows that the total variation of x between connected nodes is proportional to {\\bf x}^\\top {\\bf L} {\\bf x}.\n\n\\begin{aligned}\nJ &= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 \\\\\n&= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\underbrace{A_{ij}\\left( x_i^2 +x_j^2\\right)}_{\\text{symmetric}} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2\\underbrace{\\sum_{j=1}^N A_{ij}}_{\\text{degree of node } i, k_i} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2 k_i - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\underbrace{[x_1,x_2,\\ldots, x_N]}_{{\\bf x}} \\underbrace{\\begin{bmatrix} k_1 & 0 & \\cdots & 0 \\\\ 0 & k_2 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & k_N \\end{bmatrix}}_{{\\bf D}} \\underbrace{\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N \\end{bmatrix}}_{{\\bf x}} - 2\\underbrace{\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}}_{{\\bf x}^\\top {\\mathbf A} {\\bf x}} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf D} {\\bf x} - {\\bf x}^\\top {\\mathbf A} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf L} {\\bf x},\n\\end{aligned}\n\n\n\nLet us showcase the analogy between the Fourier transform and the Laplacian matrix. In the Fourier transform, a signal is decomposed into sinusoidal basis functions. Similarly, for a graph, we can decompose the variation J into eigenvector bases.\n\nJ = \\sum_{i=1}^N \\lambda_i  {\\bf x}^\\top {\\mathbf u}_i {\\mathbf u}_i^\\top {\\bf x} = \\sum_{i=1}^N \\lambda_i  ||{\\bf x}^\\top {\\mathbf u}_i||^2.\n\nwhere {\\mathbf u}_i is the eigenvector corresponding to the eigenvalue \\lambda_i. - The term ({\\bf x}^\\top {\\mathbf u}_i) is a dot-product between the feature vector {\\bf x} and the eigenvector {\\mathbf u}_i, which measures how much {\\bf x} coheres with eigenvector {\\mathbf u}_i, similar to how Fourier coefficients measure coherency with sinusoids. - Each ||{\\bf x}^\\top {\\mathbf u}_i||^2 is the ‘’strength’’ of {\\bf x} with respect to the eigenvector {\\mathbf u}_i, and the total variation J is a weighted sum of these strengths.\nSome eigenvectors correspond to low-frequency components, while others correspond to high-frequency components. For example, the total variation J for an eigenvector {\\mathbf u}_i is given by\n\nJ = \\frac{1}{2} \\sum_{j}\\sum_{\\ell} A_{j\\ell}(u_{ij} - u_{i\\ell})^2 = {\\mathbf u}_i^\\top {\\mathbf L} {\\mathbf u}_i = \\lambda_i.\n\nThis equation provides key insight into the meaning of eigenvalues:\n\nFor an eigenvector {\\mathbf u}_i, its eigenvalue \\lambda_i measures the total variation for {\\mathbf u}_i.\nLarge eigenvalues mean large differences between neighbors (high frequency), while small eigenvalues mean small differences (low frequency).\n\nThus, if {\\bf x} aligns well with {\\mathbf u}_i with a large \\lambda_i, then {\\bf x} has a strong high-frequency component; if {\\bf x} aligns well with {\\mathbf u}_i with a small \\lambda_i, then {\\bf x} has strong low-frequency component.\n\nSpectral Filtering\nEigenvalues \\lambda_i can be thought of as a filter that controls which frequency components pass through. Instead of using the filter associated with the Laplacian matrix, we can design a filter h(\\lambda_i) to control which frequency components pass through. This leads to the idea of spectral filtering. Two common filters are:\n\nLow-pass Filter: h_{\\text{low}}(\\lambda) = \\frac{1}{1 + \\alpha\\lambda}\n\nPreserves low frequencies (small λ)\nSuppresses high frequencies (large λ)\nResults in smoother signals\n\nHigh-pass Filter: h_{\\text{high}}(\\lambda) = \\frac{\\alpha\\lambda}{1 + \\alpha\\lambda}\n\nPreserves high frequencies\nSuppresses low frequencies\nEmphasizes differences between neighbors\n\n\n\n:tags: [remove-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context(\"talk\")\n\nalpha = 1\nlambdas = np.linspace(0, 10, 100)\nh_low = 1 / (1 + alpha * lambdas)\nh_high = (alpha * lambdas) / (1 + alpha * lambdas)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\nsns.lineplot(x=lambdas, y=h_low, label=\"Low-pass filter\", ax=axes[0])\naxes[0].legend(frameon=False).remove()\nsns.lineplot(x=lambdas, y=h_high, label=\"High-pass filter\", ax=axes[1])\naxes[1].legend(frameon=False).remove()\naxes[0].set_title(\"Low-pass filter\")\naxes[1].set_title(\"High-pass filter\")\nfig.text(0.5, 0.01, \"Eigenvalue $\\lambda$\", ha=\"center\")\naxes[0].set_ylabel(\"Filter response $h(\\lambda)$\")\nsns.despine()\nplt.tight_layout()\n\n\n\nExample\nLet us showcase the idea of spectral filtering with a simple example with the karate club network.\n\n:tags: [remove-input]\nimport igraph as ig\nimport numpy as np\nfrom scipy import sparse\nimport matplotlib as mpl\n\nG = ig.Graph.Famous(\"Zachary\")\nA = G.get_adjacency_sparse()\n\nWe will first compute the laplacian matrix and its eigendecomposition.\n\n# Compute Laplacian matrix\ndeg = np.array(A.sum(axis=1)).reshape(-1)\nD = sparse.diags(deg)\nL = D - A\n\n# Compute eigendecomposition\nevals, evecs = np.linalg.eigh(L.toarray())\n\n# Sort eigenvalues and eigenvectors\norder = np.argsort(evals)\nevals = evals[order]\nevecs = evecs[:, order]\n\nNow, let’s create a low-pass and high-pass filter.\n\nalpha = 2\nL_low = evecs @ np.diag(1 / (1 + alpha * evals)) @ evecs.T\nL_high = evecs @ np.diag(alpha * evals / (1 + alpha * evals)) @ evecs.T\n\nprint(\"Size of low-pass filter:\", L_low.shape)\nprint(\"Size of high-pass filter:\", L_high.shape)\n\nNotice that the high-pass filter and low-pass filter are matrices of the same size as the adjacency matrix A, which defines a ‘convolution’ on the graph as follows:\n\n{\\bf x}' = {\\bf L}_{\\text{low}} {\\bf x} \\quad \\text{or} \\quad {\\bf x}' = {\\bf L}_{\\text{high}} {\\bf x}.\n\nwhere {\\bf L}_{\\text{low}} and {\\bf L}_{\\text{high}} are the low-pass and high-pass filters, respectively, and {\\bf x}' is the convolved feature vector.\nNow, let’s see how these filters work. Our first example is a random feature vector.\n\n# Random feature vector\nx = np.random.randn(A.shape[0], 1)\n\n# Convolve with low-pass filter\nx_low = L_low @ x\n\n# Convolve with high-pass filter\nx_high = L_high @ x\n\nLet us visualize the results.\n\n:tags: [hide-input]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\nnorm = mpl.colors.Normalize(vmin=-0.3, vmax=0.3)\n\n# Original\nvalues = x.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\n# Low-pass filter applied\nvalues = L_low @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\n# High-pass filter applied\nvalues = L_high @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\nWe observe that the low-pass filter results in smoother {\\bf x} between connected nodes (i.e., neighboring nodes have similar {\\bf x}). The original {\\bf x} and {\\bf x}'_{\\text{low}} are very similar because random variables are high-frequency components. In contrast, when we apply the high-pass filter, {\\bf x}'_{\\text{high}} is similar to {\\bf x} because the high-frequency components are not filtered.\nLet’s now use an eigenvector as our feature vector {\\bf x}.\n\n:tags: [hide-input]\neigen_centrality = np.array(G.eigenvector_centrality()).reshape(-1, 1)\nlow_pass_eigen = L_low @ eigen_centrality\nhigh_pass_eigen = L_high @ eigen_centrality\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\n\nnorm = mpl.colors.Normalize(vmin=-0, vmax=0.3)\nvalues = eigen_centrality.reshape(-1)# high_pass_random.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\nvalues = low_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\nvalues = high_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\nThe high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality."
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html",
    "href": "m09-graph-neural-networks/03-exercises.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\nThe pen and paper exercises cover fundamental concepts including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: note\nLet’s implement a simple GCN model for node classification. Coding Exercise\n\n\nThis coding exercise will guide you through:\n\nBuilding a GCN from Scratch: Implementing the basic GCN layer\nNode Classification: Training GCN for semi-supervised node classification\nSpectral Filtering: Understanding how GCNs relate to spectral graph theory\nComparison with Other Methods: Benchmarking against traditional approaches\n\n\n\n\nThrough these exercises, you will:\n\nUnderstand the Mathematics: Connect spectral graph theory to practical GNN implementations\nImplement Core Algorithms: Build GCN, GraphSAGE, GAT, and GIN from fundamental principles\nApply to Real Problems: Use GNNs for node classification, graph classification, and link prediction\nAnalyze Performance: Compare different GNN architectures and understand their strengths/weaknesses\nDebug and Optimize: Learn common pitfalls and optimization strategies for GNNs\n\n\n\n\n\nBasic GCN Implementation\n\nImplement the GCN layer forward pass\nAdd self-loops and normalization\nTrain on Cora dataset for node classification\n\nSpectral Analysis\n\nVisualize graph spectra and eigenvectors\nImplement spectral filtering\nCompare low-pass vs high-pass filters\n\nAdvanced Architectures\n\nImplement GraphSAGE with different aggregators\nBuild GAT with attention visualization\nCreate GIN and test on graph isomorphism\n\nPractical Applications\n\nSocial network analysis\nCitation network node classification\nMolecular property prediction\n\n\nThese exercises bridge theory and practice, ensuring you understand both the mathematical foundations and practical implementation details of Graph Neural Networks.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html#theoretical-exercises",
    "href": "m09-graph-neural-networks/03-exercises.html#theoretical-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\nThe pen and paper exercises cover fundamental concepts including:\n\nSpectral Graph Theory: Understanding eigenvalues and eigenvectors of graph matrices\nFourier Analysis on Graphs: Extending classical signal processing to graph domains\nConvolution Operations: Defining convolution for irregular graph structures\nMessage Passing: Mathematical formulation of information aggregation in graphs\nNetwork Architecture Design: Principles for designing effective GNN architectures",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/03-exercises.html#programming-exercises",
    "href": "m09-graph-neural-networks/03-exercises.html#programming-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Exercise\n\n\n\n:class: note\nLet’s implement a simple GCN model for node classification. Coding Exercise\n\n\nThis coding exercise will guide you through:\n\nBuilding a GCN from Scratch: Implementing the basic GCN layer\nNode Classification: Training GCN for semi-supervised node classification\nSpectral Filtering: Understanding how GCNs relate to spectral graph theory\nComparison with Other Methods: Benchmarking against traditional approaches\n\n\n\n\nThrough these exercises, you will:\n\nUnderstand the Mathematics: Connect spectral graph theory to practical GNN implementations\nImplement Core Algorithms: Build GCN, GraphSAGE, GAT, and GIN from fundamental principles\nApply to Real Problems: Use GNNs for node classification, graph classification, and link prediction\nAnalyze Performance: Compare different GNN architectures and understand their strengths/weaknesses\nDebug and Optimize: Learn common pitfalls and optimization strategies for GNNs\n\n\n\n\n\nBasic GCN Implementation\n\nImplement the GCN layer forward pass\nAdd self-loops and normalization\nTrain on Cora dataset for node classification\n\nSpectral Analysis\n\nVisualize graph spectra and eigenvectors\nImplement spectral filtering\nCompare low-pass vs high-pass filters\n\nAdvanced Architectures\n\nImplement GraphSAGE with different aggregators\nBuild GAT with attention visualization\nCreate GIN and test on graph isomorphism\n\nPractical Applications\n\nSocial network analysis\nCitation network node classification\nMolecular property prediction\n\n\nThese exercises bridge theory and practice, ensuring you understand both the mathematical foundations and practical implementation details of Graph Neural Networks.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/word2vec.html",
    "href": "m08-embedding/word2vec.html",
    "title": "word2vec",
    "section": "",
    "text": "In this section, we will introduce word2vec, a powerful technique for learning word embeddings. word2vec is a neural network model that learns words embeddings in a continuous vector space. It was introduced by Tomas Mikolov and his colleagues at Google in 2013 {footcite}mikolov2013distributed."
  },
  {
    "objectID": "m08-embedding/word2vec.html#how-it-works",
    "href": "m08-embedding/word2vec.html#how-it-works",
    "title": "word2vec",
    "section": "1 How it works",
    "text": "1 How it works\n“You shall know a word by the company it keeps” {footcite}church1988word is a famous quote in linguistics. It means that you can understand the meaning of a word by looking at the words that appear in the same context. word2vec operates on the same principle. word2vec identifies a word’s context by examining the words within a fixed window around it. For example, in the sentence:\n\nThe quick brown fox jumps over a lazy dog\n\nThe context of the word fox includes quick, brown, jumps, over, and lazy. word2vec is trained to predict which words are likely to appear as the context of an input word.\nThere are two main architectures for word2vec:\n1. **Continuous Bag of Words (CBOW)**: Predicts the target word (center word) from the context words (surrounding words).\n2. **Skip-gram**: Predicts the context words (surrounding words) from the target word (center word).\nSo how are word embeddings learned? word2vec is a neural network model that looks like a bow tie. It has two layers of the vocabulary size coupled with a much smaller hidden layer.\n\n\nInput layer: The input layer consists of N neurons, where N is the size of the vocabulary (i.e., the number of unique words in the corpus). Each neuron corresponds to a unique word in the vocabulary. When a word is inputted, its corresponding neuron is activated and the other neurons are inhibited. Thus, the input layer is essentially a lookup mechanism that transforms the input word into a corresponding one-hot vector.\nOutput layer: The output layer also consists of N neurons, each corresponding to a unique word in the vocabulary. Unlike the input layer, multiple neurons can be activated for a single input. The strength of the activation of each neuron (with a normalization by the softmax function) represents the probability of the corresponding word being the input word’s context.\nHidden layer: The hidden layer is much smaller than the input and output layers. Multiple neurons in the hidden layer can be activated for a single input, and this activation pattern represents the word’s embedding.\n\nWe can consider word2vec as a dimensionality reduction technique that reduces the dimensionality of the input layer to the hidden layer based on the co-occurrence of words within a short distance. The distance is named the window size, which is a user-defined hyperparameter."
  },
  {
    "objectID": "m08-embedding/word2vec.html#whats-special-about-word2vec",
    "href": "m08-embedding/word2vec.html#whats-special-about-word2vec",
    "title": "word2vec",
    "section": "2 What’s special about word2vec?",
    "text": "2 What’s special about word2vec?\nWith word2vec, words are represented as dense vectors, enabling us to explore their relationships using simple linear algebra. This is in contrast to traditional natural language processing (NLP) methods, such as bag-of-words and topic modeling, which represent words as discrete units or high-dimensional vectors.\n\nTo showcase the effectiveness of word2vec, let’s walk through an example using the gensim library.\n\nimport gensim\nimport gensim.downloader\nfrom gensim.models import Word2Vec\n\n# Load pre-trained word2vec model from Google News\nmodel = gensim.downloader.load('word2vec-google-news-300')\n\nOur first example is to find the words most similar to king.\n\n# Example usage\nword = \"king\"\nsimilar_words = model.most_similar(word)\nprint(f\"Words most similar to '{word}':\")\nfor similar_word, similarity in similar_words:\n    print(f\"{similar_word}: {similarity:.4f}\")\n\nA cool (yet controversial) application of word embeddings is analogy solving. Let us consider the following puzzle:\n\nman is to woman as king is to ___ ?\n\nWe can use word embeddings to solve this puzzle.\n\n# We solve the puzzle by\n#\n#  vec(king) - vec(man) + vec(woman)\n#\n# To solve this, we use the model.most_similar function, with positive words being \"king\" and \"woman\" (additive), and negative words being \"man\" (subtractive).\n#\nmodel.most_similar(positive=['woman', \"king\"], negative=['man'], topn=5)\n\nThe last example is to visualize the word embeddings.\n\n:tags: [hide-input]\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ncountries = ['Germany', 'France', 'Italy', 'Spain', 'Portugal', 'Greece']\ncapital_words = ['Berlin', 'Paris', 'Rome', 'Madrid', 'Lisbon', 'Athens']\n\n# Get the word embeddings for the countries and capitals\ncountry_embeddings = np.array([model[country] for country in countries])\ncapital_embeddings = np.array([model[capital] for capital in capital_words])\n\n# Compute the PCA\npca = PCA(n_components=2)\nembeddings = np.vstack([country_embeddings, capital_embeddings])\nembeddings_pca = pca.fit_transform(embeddings)\n\n# Create a DataFrame for seaborn\ndf = pd.DataFrame(embeddings_pca, columns=['PC1', 'PC2'])\ndf['Label'] = countries + capital_words\ndf['Type'] = ['Country'] * len(countries) + ['Capital'] * len(capital_words)\n\n# Plot the data\nplt.figure(figsize=(12, 10))\n\n# Create a scatter plot with seaborn\nscatter_plot = sns.scatterplot(data=df, x='PC1', y='PC2', hue='Type', style='Type', s=200, palette='deep', markers=['o', 's'])\n\n# Annotate the points\nfor i in range(len(df)):\n    plt.text(df['PC1'][i], df['PC2'][i] + 0.08, df['Label'][i], fontsize=12, ha='center', va='bottom',\n             bbox=dict(facecolor='white', edgecolor='none', alpha=0.8))\n\n# Draw arrows between countries and capitals\nfor i in range(len(countries)):\n    plt.arrow(df['PC1'][i], df['PC2'][i], df['PC1'][i + len(countries)] - df['PC1'][i], df['PC2'][i + len(countries)] - df['PC2'][i],\n              color='gray', alpha=0.6, linewidth=1.5, head_width=0.02, head_length=0.03)\n\nplt.legend(title='Type', title_fontsize='13', fontsize='11')\nplt.title('PCA of Country and Capital Word Embeddings', fontsize=16)\nplt.xlabel('Principal Component 1', fontsize=14)\nplt.ylabel('Principal Component 2', fontsize=14)\nax = plt.gca()\nax.set_axis_off()\n\nWe can see that word2vec places the words representing countries close to each other and so do the words representing their capitals. The country-capital relationship is also roughly preserved, e.g., Germany-Berlin vector is roughly parallel to France-Paris vector."
  },
  {
    "objectID": "m08-embedding/graph-embedding-w-word2vec.html",
    "href": "m08-embedding/graph-embedding-w-word2vec.html",
    "title": "Graph embedding with word2vec",
    "section": "",
    "text": "How can we apply word2vec to graph data? There is a critical challenge: word2vec takes sequence of words as input, while graph data are discrete and unordered. A solution to fill this gap is random walk, which transforms graph data into a sequence of nodes. Once we have a sequence of nodes, we can treat it as a sequence of words and apply word2vec."
  },
  {
    "objectID": "m08-embedding/graph-embedding-w-word2vec.html#deepwalk",
    "href": "m08-embedding/graph-embedding-w-word2vec.html#deepwalk",
    "title": "Graph embedding with word2vec",
    "section": "1 DeepWalk",
    "text": "1 DeepWalk\n\nDeepWalk is one of the pioneering works to apply word2vec to graph data {footcite}perozzi2014deepwalk. It views the nodes as words and the nodes random walks on the graph as sentences, and applies word2vec to learn the node embeddings.\nMore specifically, the method contains the following steps:\n\nSample multiple random walks from the graph.\nTreat the random walks as sentences and feed them to word2vev to learn the node embeddings.\n\nThere are some technical details that we need to be aware of, which we will learn by implementing DeepWalk in the following exercise.\n\nExercise 01: Implement DeepWalk\nIn this exercise, we implement DeepWalk step by step.\n\n\nStep 1: Data preparation\nWe will use the karate club network as an example.\nLoad the data\n\n:tags: [hide-input]\n\nimport igraph\nimport networkx as nx\nimport numpy as np\nimport seaborn as sns\n\ng = igraph.Graph.Famous(\"Zachary\")\nA = g.get_adjacency_sparse()\n\n# Add the community labels to the nodes for visualization\ng.vs[\"label\"] = np.unique([d[1]['club'] for d in nx.karate_club_graph().nodes(data=True)], return_inverse=True)[1]\n\npalette = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[palette[label] for label in g.vs[\"label\"]], bbox=(300, 300))\n\n\n\nStep 2: Generate random walks\nNext, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network. Let us first implement a function to sample random walks from a given network.\n\ndef random_walk(net, start_node, walk_length):\n    # Initialize the walk with the starting node\n    walk = [start_node]\n\n    # Continue the walk until the desired length is reached\n    while len(walk) &lt; walk_length:\n        # Get the current node (the last node in the walk)\n        cur = walk[-1]\n\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n\n        # If the current node has neighbors, randomly choose one and add it to the walk\n        if len(cur_nbrs) &gt; 0:\n            walk.append(np.random.choice(cur_nbrs))\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    # Return the generated walk\n    return walk\n\nGenerate 10 random walks of length 50 starting from each node.\n\nn_nodes = g.vcount()\nn_walkers_per_node = 10\nwalk_length = 50\nwalks = []\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(random_walk(A, i, walk_length))\n\n\n\nStep 3: Train the word2vec model\nThen, we feed the random walks to the word2vec model.\n\nfrom gensim.models import Word2Vec\n\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\nHere,\n\nvector_size is the dimension of the embedding vectors.\nwindow indicates the maximum distance between a word and its context words. For example, in the random walk [0, 1, 2, 3, 4, 5, 6, 7], the context words of node 2 are [0, 1, 3, 4, 5] when window=3.\nmin_count is the minimum number of times a word must appear in the training data to be included in the vocabulary.\n\nTwo parameters sg=1 and hs=1 indicate that we are using the skip-gram model with negative sampling. Let us understand what they mean in detail as follows.\n\nSkip-gram model: it trains word2vec by predicting context words given a target word. For example, given the sentence “The quick brown fox jumps over the lazy dog”, in the skip-gram model, given the target word “fox”, the model will try to predict the context words “quick”, “brown”, “jumps”, and “over”. If sg=0, the input and output are swapped: the model will predict the target word from the context words, e.g., given the context words “quick”, “brown”, “jumps”, and “over”, the model will predict the target word “fox”.\nHierarchical softmax: To understand hierarchical softmax better, let’s break down how the word2vec model works. The goal of word2vec is to predict context words given a target word. For example, if our target word is w_t and our context word is w_c, we want to find the probability of w_c given w_t. This probability is calculated using the softmax function:\n\n  P(w_c | w_t) = \\frac{\\exp(\\mathbf{v}_{w_c} \\cdot \\mathbf{v}_{w_t})}{\\sum_{w \\in V} \\exp(\\mathbf{v}_w \\cdot \\mathbf{u}_{w_t})}\n\nHere, \\mathbf{v}_w and \\mathbf{u}_w represent the vector for word w as context and target respectively, and V is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!\nHierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.\n\n\nBy using the skip-gram model with hierarchical softmax, we can efficiently learn high-quality word embeddings even when dealing with large vocabularies.\nNow, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the wv attribute. The embedding of node i is given by model.wv[i].\n\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\nembedding is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.\nPrint the first 3 nodes\n\n:tags: [hide-input]\n\nembedding[:3]\n\nLet’s visualize the node embeddings using UMAP.\n\n:tags: [hide-input]\nimport umap\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource, HoverTool\n\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nshow(p)\n\n\n\nStep 4: Clustering\nOne of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as K-means and Gaussian mixture model. Let’s see what we can get from the node embeddings.\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Determine the optimal number of clusters using the silhouette score\ndef Kmeans_with_silhouette(embedding, n_clusters_range=(2, 10)):\n    silhouette_scores = []\n\n    # Iterate over a range of cluster numbers from 2 to 9\n    for n_clusters in range(*n_clusters_range):\n        # Create a KMeans object with the current number of clusters\n        kmeans = KMeans(n_clusters=n_clusters)\n\n        # Fit the KMeans model to the embedding data\n        kmeans.fit(embedding)\n\n        # Calculate the silhouette score for the current clustering\n        score = silhouette_score(embedding, kmeans.labels_)\n\n        # Append the number of clusters and its corresponding silhouette score to the list\n        silhouette_scores.append((n_clusters, score))\n\n    # Find the number of clusters that has the highest silhouette score\n    optimal_n_clusters = max(silhouette_scores, key=lambda x: x[1])[0]\n\n    # Create a KMeans object with the optimal number of clusters\n    kmeans = KMeans(n_clusters=optimal_n_clusters)\n\n    # Fit the KMeans model to the embedding data with the optimal number of clusters\n    kmeans.fit(embedding)\n\n    # Return the labels (cluster assignments) for each data point\n    return kmeans.labels_\n\n\nimport seaborn as sns\nlabels = Kmeans_with_silhouette(embedding)\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500))"
  },
  {
    "objectID": "m08-embedding/graph-embedding-w-word2vec.html#node2vec",
    "href": "m08-embedding/graph-embedding-w-word2vec.html#node2vec",
    "title": "Graph embedding with word2vec",
    "section": "2 node2vec",
    "text": "2 node2vec\nnode2vec is a sibling of DeepWalk proposed by {footcite}grover2016node2vec. Both use word2vec trained on random walks on networks. So, it appears that they are very similar. However, the following two components make them very different.\n\nBiased random walk: node2vec uses biased random walks that can move in different directions. The bias walk is parameterized by two parameters, p and q:\n\n  P(v_{t+1} = x | v_t = v, v_{t-1} = t) \\propto\n  \\begin{cases}\n  \\frac{1}{p} & \\text{if } d(v,t) = 0 \\\\\n  1 & \\text{if } d(v,t) = 1 \\\\\n  \\frac{1}{q} & \\text{if } d(v,t) = 2 \\\\\n  \\end{cases}\n  \nwhere d(v,x) is the shortest path distance between node v and x. A smaller p leads to more biased towards the previous node, v_{t-1} = t. A smaller q leads to more biased towards the nodes that are further away from the previous node, v_{t-1} = t.\nBy adjusting the parameters p and q, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).\n\nBreadth-First Sampling (BFS): This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.\nDepth-First Sampling (DFS): This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.\n\n\nThe embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.\n\nNegative sampling: node2vec uses negative sampling, instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to {footcite}kojaku2021neurips and {footcite}dyer2014notes for more details.\n\n\nExercise 02: Implement node2vec\nLet’s implement the biased random walk for node2vec\n\ndef node2vec_random_walk(net, start_node, walk_length, p, q):\n    \"\"\"\n    Sample a random walk starting from start_node.\n    \"\"\"\n    # Initialize the walk with the start_node\n    walk = [start_node]\n\n    # Continue the walk until it reaches the desired length\n    while len(walk) &lt; walk_length:\n        # Get the current node in the walk\n        cur = walk[-1]\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n        # Check if the current node has any neighbors\n        if len(cur_nbrs) &gt; 0:\n            # If the walk has just started, randomly choose the next node from the neighbors\n            if len(walk) == 1:\n                walk.append(np.random.choice(cur_nbrs))\n            else:\n                # Get the previous node in the walk\n                prev = walk[-2]\n                # Use the alias sampling method to choose the next node based on the bias parameters p and q\n                next_node = alias_sample(net, cur_nbrs, prev, p, q)\n                # Append the chosen next node to the walk\n                walk.append(next_node)\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    return walk\n\ndef alias_sample(net, neighbors, prev, p, q):\n    \"\"\"\n    Helper function to sample the next node in the walk.\n    \"\"\"\n    # Implement the logic to sample the next node based on the bias parameters p and q\n    # You can use the formula provided in the instructions to calculate the probabilities\n    # and then sample the next node accordingly.\n    # Initialize an empty list to store the unnormalized probabilities for each neighbor\n    unnormalized_probs = []\n\n    # Iterate over each neighbor of the current node\n    for neighbor in neighbors:\n        # If the neighbor is the same as the previous node in the walk\n        if neighbor == prev:\n            # Append the probability 1/p to the unnormalized probabilities list\n            unnormalized_probs.append(1 / p)\n        # If the neighbor is connected to the previous node in the walk\n        elif neighbor in net[prev].indices:\n            # Append the probability 1 to the unnormalized probabilities list\n            unnormalized_probs.append(1)\n        # If the neighbor is not connected to the previous node in the walk\n        else:\n            # Append the probability 1/q to the unnormalized probabilities list\n            unnormalized_probs.append(1 / q)\n\n    # Calculate the normalization constant by summing all unnormalized probabilities\n    norm_const = sum(unnormalized_probs)\n\n    # Normalize the probabilities by dividing each unnormalized probability by the normalization constant\n    normalized_probs = [float(prob) / norm_const for prob in unnormalized_probs]\n\n    # Randomly choose the next node from the neighbors based on the normalized probabilities\n    next_node = np.random.choice(neighbors, size=1, p=normalized_probs)[0]\n\n    # Return the chosen next node\n    return next_node\n\nNow, let’s set up the word2vec model for node2vec.\n\nwalks = []\np = 1\nq = 0.1\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(node2vec_random_walk(A, i, walk_length, p, q))\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\nwhere hs=0 indicates that we are using negative sampling. Notice that we set sg=1 and hs=1 instead of sg=1 and hs=0 in DeepWalk. This is because node2vec uses the skip-gram model with negative sampling.\nNow, we extract the node embeddings from the word2vec model.\n\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\nLet’s visualize the node embeddings from node2vec.\n\n:tags: [hide-input]\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]],\n    name = [str(i) for i in range(n_nodes)]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nhover = HoverTool()\nhover.tooltips = [\n    (\"Name\", \"@name\"),\n    (\"Community\", \"@community\")\n]\np.add_tools(hover)\n\nshow(p)\n\nThe results for clustering are as follows:\n\nimport seaborn as sns\n\nlabels = Kmeans_with_silhouette(embedding)\n\n\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500), vertex_label=[\"%d\" %  d for d in  np.arange(n_nodes)])"
  },
  {
    "objectID": "m08-embedding/graph-embedding-w-word2vec.html#line",
    "href": "m08-embedding/graph-embedding-w-word2vec.html#line",
    "title": "Graph embedding with word2vec",
    "section": "3 LINE",
    "text": "3 LINE\nLINE {footcite}tang2015line is another pioneering work to learn node embeddings by directly optimizing the graph structure. It is equivalent to node2vec with p=1, q=1, and window size 1."
  },
  {
    "objectID": "m07-random-walks/unifying-centrality-and-communities.html",
    "href": "m07-random-walks/unifying-centrality-and-communities.html",
    "title": "Random walks unify centrality and communities",
    "section": "",
    "text": "Modularity can be intepreted as a random walk perspective. Modularity is given by\n\nQ = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)\n\nwhere m is the number of edges in the network, A_{ij} is the adjacency matrix, d_i is the degree of node i, c_i is the community of node i, and \\delta(c_i, c_j) is the Kronecker delta function (which is 1 if c_i = c_j and 0 otherwise).\nWe can rewrite the modularity using the language of random walks as follows.\n\n\\begin{aligned}\nQ &= \\sum_{ij} \\left(\\frac{A_{ij}}{2m}  - \\frac{d_i}{2m} \\frac{d_j}{2m} \\right) \\delta(c_i, c_j) \\\\\n&= \\sum_{ij} \\left(\\pi_i P_{ij}  - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)\n\\end{aligned}\n where \\pi_i is the stationary distribution of the random walk given by\n\n\\pi_i = \\frac{d_i}{2m}\n\nand P_{ij} is the transition probability between nodes i and j.\nLet's break down this derivation step by step:\n\n1. We start with the original modularity formula:\n\n   $$Q = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)$$\n\n2. First, we move the constant $1/(2m)$ to the inside of the parentheses:\n\n   $$Q = \\sum_{ij} \\left(\\frac{A_{ij}}{2m} - \\frac{d_i d_j}{2m^2} \\right) \\delta(c_i, c_j)$$\n\n3. Now, we recognize that $\\frac{A_{ij}}{2m}$ can be rewritten as:\n\n   $$\\frac{A_{ij}}{2m} = \\frac{d_i}{2m} \\cdot \\frac{A_{ij}}{d_i} = \\pi_i P_{ij}$$\n\n4. We also recognize that $\\frac{d_i}{2m}$ is the stationary distribution of the random walk, which we denote as $\\pi_i$:\n\n   $$\\frac{d_i}{2m} = \\pi_i$$\n\n5. Substituting these into our equation:\n\n   $$Q = \\sum_{ij} \\left(\\pi_i P_{ij} - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)$$\n\nThe expression suggests that:\n\nThe first term, \\pi_i P_{ij} \\delta(c_i, c_j), represents the probability that a walker is at node i and moves to node j within the same community by one step.\nThe second term, \\pi_i \\pi_j, represents the probability that a walker is at node i and moves to another node j within the same community after long steps.\n\nIn summary, modularity compares short-term and long-term random walk probabilities. High modularity indicates that a random walker is more likely to stay within the same community after one step than after many steps.\nBuilding on this perspective from random walks, Delvenne et al. {footcite}`delvenne2010stability` extends the modularity by comparing multi-step and long-step transition probabilities of a random walk. This approach, known as \"Markov stability\", shows that the number of steps acts as a \"resolution parameter\" that determines the scale of detectable communities."
  },
  {
    "objectID": "m07-random-walks/unifying-centrality-and-communities.html#modularity-interpretation-from-random-walk-perspective",
    "href": "m07-random-walks/unifying-centrality-and-communities.html#modularity-interpretation-from-random-walk-perspective",
    "title": "Random walks unify centrality and communities",
    "section": "",
    "text": "Modularity can be intepreted as a random walk perspective. Modularity is given by\n\nQ = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)\n\nwhere m is the number of edges in the network, A_{ij} is the adjacency matrix, d_i is the degree of node i, c_i is the community of node i, and \\delta(c_i, c_j) is the Kronecker delta function (which is 1 if c_i = c_j and 0 otherwise).\nWe can rewrite the modularity using the language of random walks as follows.\n\n\\begin{aligned}\nQ &= \\sum_{ij} \\left(\\frac{A_{ij}}{2m}  - \\frac{d_i}{2m} \\frac{d_j}{2m} \\right) \\delta(c_i, c_j) \\\\\n&= \\sum_{ij} \\left(\\pi_i P_{ij}  - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)\n\\end{aligned}\n where \\pi_i is the stationary distribution of the random walk given by\n\n\\pi_i = \\frac{d_i}{2m}\n\nand P_{ij} is the transition probability between nodes i and j.\nLet's break down this derivation step by step:\n\n1. We start with the original modularity formula:\n\n   $$Q = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)$$\n\n2. First, we move the constant $1/(2m)$ to the inside of the parentheses:\n\n   $$Q = \\sum_{ij} \\left(\\frac{A_{ij}}{2m} - \\frac{d_i d_j}{2m^2} \\right) \\delta(c_i, c_j)$$\n\n3. Now, we recognize that $\\frac{A_{ij}}{2m}$ can be rewritten as:\n\n   $$\\frac{A_{ij}}{2m} = \\frac{d_i}{2m} \\cdot \\frac{A_{ij}}{d_i} = \\pi_i P_{ij}$$\n\n4. We also recognize that $\\frac{d_i}{2m}$ is the stationary distribution of the random walk, which we denote as $\\pi_i$:\n\n   $$\\frac{d_i}{2m} = \\pi_i$$\n\n5. Substituting these into our equation:\n\n   $$Q = \\sum_{ij} \\left(\\pi_i P_{ij} - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)$$\n\nThe expression suggests that:\n\nThe first term, \\pi_i P_{ij} \\delta(c_i, c_j), represents the probability that a walker is at node i and moves to node j within the same community by one step.\nThe second term, \\pi_i \\pi_j, represents the probability that a walker is at node i and moves to another node j within the same community after long steps.\n\nIn summary, modularity compares short-term and long-term random walk probabilities. High modularity indicates that a random walker is more likely to stay within the same community after one step than after many steps.\nBuilding on this perspective from random walks, Delvenne et al. {footcite}`delvenne2010stability` extends the modularity by comparing multi-step and long-step transition probabilities of a random walk. This approach, known as \"Markov stability\", shows that the number of steps acts as a \"resolution parameter\" that determines the scale of detectable communities."
  },
  {
    "objectID": "m07-random-walks/unifying-centrality-and-communities.html#pagerank-interpretation-from-random-walk-perspective",
    "href": "m07-random-walks/unifying-centrality-and-communities.html#pagerank-interpretation-from-random-walk-perspective",
    "title": "Random walks unify centrality and communities",
    "section": "2 PageRank: Interpretation from random walk perspective",
    "text": "2 PageRank: Interpretation from random walk perspective\nPageRank can be interpreted from a random walk perspective:\n\nc_i = (1-\\beta) \\sum_j P_{ji} c_j + \\beta \\cdot \\frac{1}{N}\n\nWhere: - c_i is the PageRank of node i - P_{ji} is the transition probability from node j to node i - \\beta is the teleportation probability - N is the total number of nodes\nThis equation represents a random walk where: 1. With probability (1-\\beta), the walker follows a link to the next node. 2. With probability \\beta, the walker teleports to a random node in the network.\nThe PageRank c_i is the stationary distribution of this random walk, representing the long-term probability of finding the walker at node i.\nThis sounds odd at first glance. But it makes sense when you think about what PageRank was invented for, i.e., Web search. It characterizes a web surfer as a random walker that chooses the next page by randomly jumping to a random page with probability $\\beta$ or by following a link to a page with probability $1-\\beta$. The web page with the largest PageRank means that the page is most likely to be visited by this random web surfer."
  },
  {
    "objectID": "m07-random-walks/random-walks-math.html",
    "href": "m07-random-walks/random-walks-math.html",
    "title": "Characteristics of Random Walks",
    "section": "",
    "text": "Let’s dive into the math behind random walks in a way that’s easy to understand.\nImagine you’re at node i at time t. You randomly move to a neighboring node j. The probability of this move, called the transition probability p_{ij}, is:\n\np_{ij} = \\frac{A_{ij}}{k_i},\n\nHere, A_{ij} is an element of the adjacency matrix, and k_i is the degree of node i. For a network with N nodes, we can represent all transition probabilities in a transition probability matrix P:\n\n\\mathbf{P} = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1N} \\\\\np_{21} & p_{22} & \\cdots & p_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{N1} & p_{N2} & \\cdots & p_{NN}\n\\end{pmatrix}\n\nThis matrix P encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps. For instance:\n\nAfter one step: P_{ij} = p_{ij}\nAfter two steps: \\left(\\mathbf{P}^{2}\\right)_{ij} = \\sum_{k} P_{ik} P_{kj}\nAfter T steps: \\left(\\mathbf{P}^{T}\\right)_{ij}\n\nLet's explore why $\\mathbf{P}^2$ represents the transition probabilities after two steps.\n\nFirst, recall that $\\mathbf{P}_{ij}$ is the probability of moving from node $i$ to node $j$ in one step. Now, consider a two-step walk from $i$ to $j$. We can express this as:\n\n$$(\\mathbf{P}^2)_{ij} = \\sum_k \\mathbf{P}_{ik} \\mathbf{P}_{kj}$$\n\nThis equation encapsulates a key idea: to go from $i$ to $j$ in two steps, we must pass through some intermediate node $k$. Let's break this down step by step:\n\n1. The probability of the first step ($i$ to $k$) is $\\mathbf{P}_{ik}$.\n2. The probability of the second step ($k$ to $j$) is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ → $k$ → $j$) is the product $\\mathbf{P}_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nLikewise, for three steps, we have:\n\n$$(\\mathbf{P}^3)_{ij} = \\sum_k \\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$$\n\nwhere:\n1. The probability of going from $i$ to $k$ in two steps is $\\left( \\mathbf{P}\\right)^2_{ik}$.\n2. The probability of going from $k$ to $j$ in one step is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ →...→$k$ → $j$) is the product $\\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nAnd we can extend this reasoning for any number of steps $t$.\n\nIn summary, for any number of steps $t$, $\\left( \\mathbf{P}^t \\right)_{ij}$ gives the probability of being at node $j$ after $t$ steps, starting from node $i$.\n\nAs T becomes very large, the probability distribution of being at each node, \\mathbf{x}(t), approaches a constant value:\n\n\\mathbf{x}(t+1) =\\mathbf{x}(t) \\mathbf{P}\n\nThis is an eigenvector equation. The solution, given by the Perron-Frobenius theorem, is called the stationary distribution:\n\n\\mathbf{x}(\\infty) = \\mathbb{\\pi}, \\; \\mathbf{\\pi} = [\\pi_1, \\ldots, \\pi_N]\n\nFor undirected networks, this stationary distribution always exists and is proportional to the degree of each node:\n\n\\pi_j = \\frac{k_j}{\\sum_{\\ell} k_\\ell} \\propto k_j\n\nThis means the probability of being at node j in the long run is proportional to the degree of node j. The normalization ensures that the sum of all probabilities is 1, i.e., \\sum_{j=1}^N \\pi_j = 1."
  },
  {
    "objectID": "m07-random-walks/random-walks-math.html#stationary-state",
    "href": "m07-random-walks/random-walks-math.html#stationary-state",
    "title": "Characteristics of Random Walks",
    "section": "",
    "text": "Let’s dive into the math behind random walks in a way that’s easy to understand.\nImagine you’re at node i at time t. You randomly move to a neighboring node j. The probability of this move, called the transition probability p_{ij}, is:\n\np_{ij} = \\frac{A_{ij}}{k_i},\n\nHere, A_{ij} is an element of the adjacency matrix, and k_i is the degree of node i. For a network with N nodes, we can represent all transition probabilities in a transition probability matrix P:\n\n\\mathbf{P} = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1N} \\\\\np_{21} & p_{22} & \\cdots & p_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{N1} & p_{N2} & \\cdots & p_{NN}\n\\end{pmatrix}\n\nThis matrix P encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps. For instance:\n\nAfter one step: P_{ij} = p_{ij}\nAfter two steps: \\left(\\mathbf{P}^{2}\\right)_{ij} = \\sum_{k} P_{ik} P_{kj}\nAfter T steps: \\left(\\mathbf{P}^{T}\\right)_{ij}\n\nLet's explore why $\\mathbf{P}^2$ represents the transition probabilities after two steps.\n\nFirst, recall that $\\mathbf{P}_{ij}$ is the probability of moving from node $i$ to node $j$ in one step. Now, consider a two-step walk from $i$ to $j$. We can express this as:\n\n$$(\\mathbf{P}^2)_{ij} = \\sum_k \\mathbf{P}_{ik} \\mathbf{P}_{kj}$$\n\nThis equation encapsulates a key idea: to go from $i$ to $j$ in two steps, we must pass through some intermediate node $k$. Let's break this down step by step:\n\n1. The probability of the first step ($i$ to $k$) is $\\mathbf{P}_{ik}$.\n2. The probability of the second step ($k$ to $j$) is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ → $k$ → $j$) is the product $\\mathbf{P}_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nLikewise, for three steps, we have:\n\n$$(\\mathbf{P}^3)_{ij} = \\sum_k \\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$$\n\nwhere:\n1. The probability of going from $i$ to $k$ in two steps is $\\left( \\mathbf{P}\\right)^2_{ik}$.\n2. The probability of going from $k$ to $j$ in one step is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ →...→$k$ → $j$) is the product $\\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nAnd we can extend this reasoning for any number of steps $t$.\n\nIn summary, for any number of steps $t$, $\\left( \\mathbf{P}^t \\right)_{ij}$ gives the probability of being at node $j$ after $t$ steps, starting from node $i$.\n\nAs T becomes very large, the probability distribution of being at each node, \\mathbf{x}(t), approaches a constant value:\n\n\\mathbf{x}(t+1) =\\mathbf{x}(t) \\mathbf{P}\n\nThis is an eigenvector equation. The solution, given by the Perron-Frobenius theorem, is called the stationary distribution:\n\n\\mathbf{x}(\\infty) = \\mathbb{\\pi}, \\; \\mathbf{\\pi} = [\\pi_1, \\ldots, \\pi_N]\n\nFor undirected networks, this stationary distribution always exists and is proportional to the degree of each node:\n\n\\pi_j = \\frac{k_j}{\\sum_{\\ell} k_\\ell} \\propto k_j\n\nThis means the probability of being at node j in the long run is proportional to the degree of node j. The normalization ensures that the sum of all probabilities is 1, i.e., \\sum_{j=1}^N \\pi_j = 1."
  },
  {
    "objectID": "m07-random-walks/random-walks-math.html#experiment",
    "href": "m07-random-walks/random-walks-math.html#experiment",
    "title": "Characteristics of Random Walks",
    "section": "2 Experiment",
    "text": "2 Experiment\nLet us demonstrate the above math by using a small network using Python. Let us consider a small network of 5 nodes, which looks like this:\n\nimport igraph as ig\nimport numpy as np\nedge_list = []\nfor i in range(5):\n    for j in range(i+1, 5):\n        edge_list.append((i, j))\n        edge_list.append((i+5, j+5))\nedge_list.append((0, 6))\n\ng = ig.Graph(edge_list)\nig.plot(g, vertex_size=20, vertex_label=np.arange(g.vcount()))\n\nThe transition probability matrix P is given by:\n\nimport scipy.sparse as sparse\n\nA = g.get_adjacency_sparse()\ndeg = np.array(A.sum(axis=1)).flatten()\nDinv = sparse.diags(1/deg)\nP = Dinv @ A\nP.toarray()\n\nLet us compute the stationary distribution by using the power method.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.zeros(g.vcount())\nx[1] = 1 # Start from node 1\nT = 100\nxt = []\nfor t in range(T):\n    x = x.reshape(1, -1) @ P\n    xt.append(x)\n\nxt = np.vstack(xt) # Stack the results vertically\n\nfig, ax = plt.subplots(figsize=(7,5))\npalette = sns.color_palette().as_hex()\nfor i in range(g.vcount()):\n    sns.lineplot(x=range(T), y=xt[:, i], label=f\"Node {i}\", ax=ax, color=palette[i])\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Probability\")\nax.set_title(\"Stationary distribution of a random walk\")\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\nWe see that the distributions of the walker converges, and there are three characteristic features in the convergence: 1. The distribution of the walker occilates with a decying amplitude and eventually converges. 2. Nodes of the same degree converge to the same stationary probability. 3. Nodes with higher degree converge to the higher stationary probability.\nTo validate the last two observation, let us compare the stationary distribution of a random walker with the expected stationary distribution, which is proportional to the degree of the nodes.\n\nimport pandas as pd\n\nn_edges = np.sum(deg) / 2\nexpected_stationary_dist = deg / (2 * n_edges)\n\npd.DataFrame({\n    \"Expected stationary distribution\": expected_stationary_dist,\n    \"Stationary distribution of a random walk\": xt[-1].flatten()\n}).style.format(\"{:.4f}\").set_caption(\"Comparison of Expected and Observed Stationary Distributions\").background_gradient(cmap='cividis', axis = None)"
  },
  {
    "objectID": "m07-random-walks/random-walks-math.html#time-to-reach-the-stationary-state",
    "href": "m07-random-walks/random-walks-math.html#time-to-reach-the-stationary-state",
    "title": "Characteristics of Random Walks",
    "section": "3 Time to reach the stationary state",
    "text": "3 Time to reach the stationary state\nLet’s explore how quickly a random walker reaches its stationary state. The convergence speed is influenced by two main factors: edge density and community structure. In sparse networks, the walker needs more steps to explore the entire network. Additionally, the walker tends to remain within its starting community for some time.\nThe mixing time, denoted as t_{\\text{mix}}, is defined as the minimum number of steps required for a random walk to get close to the stationary distribution, regardless of the starting point, with the maximum error less than \\epsilon:\nt_{\\text{mix}} = \\min\\{t : \\max_{{\\bf x}(0)} \\|{\\bf x}(t) - {\\bf \\pi}\\|_{1} \\leq \\epsilon\\}\nwhere \\|{\\bf x}(t) - {\\bf \\pi}\\|_{1} = 2\\max_{i} |x_i(t) - \\pi_i| represents the L1 distance between two probability distributions. The choice of \\epsilon is arbitrary.\nWe know that the distribution of a walker after t steps is given by:\n\n\\mathbf{x}(t) =  \\mathbf{x}(0) \\mathbf{P} ^{t}\n\nTo find this distribution, we need to compute \\mathbf{P}^t. However, we face a challenge: \\mathbf{P} is not diagonalizable.\nA diagonalizable matrix \\mathbf{S} can be written as \\mathbf{S} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1}, where \\mathbf{\\Lambda} is a diagonal matrix and \\mathbf{Q} is an orthogonal matrix. Visually, it looks like this:\n\nIt is useful because we can then compute the power of the matrix as follows:\n\n\\mathbf{S}^t = \\mathbf{Q} \\mathbf{\\Lambda}^t \\mathbf{Q}^{-1}\n\nAnd it is easy to find {\\bf Q} and {\\bf \\Lambda} by using eigenvalue decomposition if {\\bf S} is symmetric and consists only of real values. Namely, the eigenvectors form {\\cal Q} and the eigenvalues form the diagonal matrix {\\cal \\Lambda}.\nLet us demonstrate the above relation by calculating $\\mathbf{S}^2$.\n$$\n\\begin{align}\n\\mathbf{S}^2 &= \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1} \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1} \\\\\n&= \\mathbf{Q} \\mathbf{\\Lambda}^2 \\mathbf{Q}^{-1}.\n\\end{align}\n$$\n(Note that $\\mathbf{Q} \\mathbf{Q}^{-1} = {\\bf I}$.)\n\n![](../figs/diagonalizable-squared.jpg)\n\n\\mathbf{P} is also diagonalizable but not symmetric like \\mathbf{\\overline A} so that we cannot use the above relation directly. So we do a trick by rewriteing \\mathbf{P} as:\n\n\\mathbf{P} = \\mathbf{D}^{-1} \\mathbf{A} = \\mathbf{D}^{-\\frac{1}{2}} \\overline {\\bf A} \\mathbf{D}^{\\frac{1}{2}}\n\nwhere \\overline{\\bf A} = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} is the normalized adjacency matrix.\nThe advantage is that \\overline{\\bf A} is diagonalizable: \\overline{\\bf A} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^\\top. Using this, we can compute \\mathbf{P}^t:\n\n\\mathbf{P}^t = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q} \\mathbf{\\Lambda}^t \\mathbf{Q}^\\top \\mathbf{D}^{\\frac{1}{2}} = \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R ^\\top\n\nwhere \\mathbf{Q}_L = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q} and \\mathbf{Q}_R = \\mathbf{D}^{\\frac{1}{2}} \\mathbf{Q}.\nLet us demonstrate the above relation by calculating $\\mathbf{P}^2$.\n\n$$\n\\begin{align}\n\\mathbf{P}^2 &= \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} \\mathbf{D}^{\\frac{1}{2}} \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} \\mathbf{D}^{\\frac{1}{2}}\\\\\n&=  \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} ^2 \\mathbf{D}^{\\frac{1}{2}}\\\\\n&= \\mathbf{Q}_L \\mathbf{\\Lambda}^2 \\mathbf{Q}_R ^\\top\n\\end{align}\nThe probability distribution after t steps is then:\n\n\\mathbf{x}(t) = \\mathbf{x}(0) \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R ^\\top\n\nWe can rewrite this in a more intuitive form:\n\n\\begin{pmatrix}\nx_1(t) \\\\\nx_2(t) \\\\\n\\vdots \\\\\nx_N(t)\n\\end{pmatrix}\n=\n\\sum_{\\ell=1}^N\n\\left[\n\\lambda_\\ell^t\n\\begin{pmatrix}\nq^{(L)}_{\\ell 1} \\\\\nq^{(L)}_{\\ell 2} \\\\\n\\vdots \\\\\nq^{(L)}_{\\ell N}\n\\end{pmatrix}\n\\langle\\mathbf{q}^{(R)}_{\\ell},  \\mathbf{x}(0) \\rangle\n\\right]\n\nVisualize the above equation by using the following figure.\n\n![](../figs/diagonalizable-sum.jpg)\n\nThe term \\lambda_\\ell^t represents the contribution of each eigenvalue to the stationary distribution over time. As t increases, all terms decay exponentially except for the largest eigenvalue (\\lambda_1 = 1). This explains how the random walk converges to the stationary distribution:\n\n\\pi_i = \\lim_{t\\to\\infty} x_i(t) = \\begin{pmatrix} q^{(L)}_{1 1} \\\\ q^{(L)}_{1 2} \\\\ \\vdots \\\\ q^{(L)}_{1 N} \\end{pmatrix} \\langle\\mathbf{q}^{(R)}_{1},  \\mathbf{x}(0) \\rangle\n\nThe second largest eigenvalue primarily determines the convergence speed to the stationary distribution. A larger second eigenvalue leads to slower convergence. Thus, the mixing time is closely related to the second largest eigenvalue.\nLevin-Peres-Wilmer theorem states that the mixing time is bounded by the relaxation time as\n\nt_{\\text{mix}} &lt; \\tau \\log \\left( \\frac{1}{\\epsilon \\min_{i} \\pi_i} \\right), \\quad \\tau = \\frac{1}{1-\\lambda_2}\n\nwhere \\lambda_2 is the second largest eigenvalue of the normalized adjacency matrix. The mixing time is known to be bounded by the relaxation time as\nMore commonly, it is expressed using the second smallest eigenvalue \\mu of the normalized laplacian matrix as\n\nt_{\\text{mix}} \\leq \\frac{1}{\\mu}\n\nwhere \\mu = 1-\\lambda_2.\n\nCompute the mixing time\nLet us demonstrate the above math by using the network of two cliques.\n\n\nNormalized Adjacency Matrix\nFirst, let us construct the normalized adjacency matrix \\overline{\\bf A} of the network.\n\nDinv_sqrt = sparse.diags(1.0/np.sqrt(deg))\nA_norm = Dinv_sqrt @ A @ Dinv_sqrt\n\nNext, let us compute the eigenvalues and eigenvectors of the normalized adjacency matrix.\n\nevals, evecs = np.linalg.eigh(A_norm.toarray())\n\n`evals` and `evecs` are sorted in descending order of the eigenvalues. `evecs[:, 0]` is the eigenvector corresponding to the largest eigenvalue, which is always 1.\nThere is a similar function called `np.linalg.eig` which returns the eigenvalues and eigenvectors. It can be used for any matrices, while `np.linalg.eigh` is specifically for symmetric matrices. `np.linalg.eigh` is faster and more stable and therefore preferred if your matrix is symmetric. `np.linalg.eig` is more susceptible to numerical errors and therefore less stable.\nThe eigenvalues and eigenvectors are shown below.\n\npd.DataFrame({\n    \"Eigenvalue\": evals\n}).T.style.background_gradient(cmap='cividis', axis = 1).set_caption(\"Eigenvalues of the normalized adjacency matrix\")\n\n\npd.DataFrame({\n    \"Eigenvector %i\" % i: evecs[:, i]\n    for i in range(10)\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Eigenvectors of the normalized adjacency matrix\")\n\nNotice that the largest eigenvalue is 1, which is always true for a normalized adjacency matrix. The largest eigenvector (the leftmost one) is associated with the stationary distribution of the random walk.\nThe sign of the eigenvector is indeterminate, which means we can choose the sign of the eigenvector arbitrarily. In fact, `np.linalg.eigh` returns the eigenvector whose sign can vary for a different run.\nWe decompose \\overline{\\bf A} as\n\\overline {\\bf A} = {\\bf Q}{\\bf \\Lambda}{\\bf Q}^\\top\nwhere {\\bf Q} corresponds to eigvecs and {\\bf \\Lambda} corresponds to np.diag(evals) (since {\\bf \\Lambda} is a diagonal matrix). Let’s see if this is correct:\n\npd.DataFrame(A_norm.toarray()).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Normalized Adjacency Matrix\")\n\n\nA_norm_reconstructed = evecs @ np.diag(evals) @ evecs.T\npd.DataFrame(A_norm_reconstructed).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Reconstruction of the Normalized Adjacency Matrix\")\n\nNotice that the reconstruction is not perfect due to the numerical error, although overall the structure is correct.\n\n\nMulti-step Transition Probability\nLet us first conform whether we can compute the transition probability after t steps by using the eigenvalues and eigenvectors.\n\nt = 5\nx_0 = np.zeros(g.vcount())\nx_0[0] = 1\n\n# Compute x_t by using the eigenvalues and eigenvectors\nQ_L = np.diag(1.0/np.sqrt(deg)) @ evecs\nQ_R = np.diag(np.sqrt(deg)) @ evecs\nx_t = x_0 @ Q_L @ np.diag(evals**t) @ Q_R.T\n\n# Compute x_t by using the power iteration\nx_t_power = x_0.copy()\nfor i in range(t):\n    x_t_power = x_t_power @ P\n\npd.DataFrame({\n    \"Eigenvector\": x_t.flatten(),\n    \"Power iteration\": x_t_power.flatten()\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Comparison of Eigenvector and Power Iteration\")\n\n\n\nRelaxation Time and Mixing Time\nLet us measure the relaxation time of the random walk.\n\nevals, evecs = np.linalg.eigh(A_norm.toarray())\nlambda_2 = -np.sort(-evals)[1]\ntau = 1 / lambda_2\nprint(f\"The relaxation time of the random walk is {tau:.4f}.\")"
  },
  {
    "objectID": "m07-random-walks/amida-kuji.html",
    "href": "m07-random-walks/amida-kuji.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Ladder Lottery\n\n\n\n\n\n\nLadder Lottery\n\n\n\n:class: tip\nLadder Lottery is a fun East Asian game, also known as “鬼腳圖” (Guijiaotu) in Chinese, “阿弥陀籤” (Amida-kuzi) in Japanese, “사다리타기” (Sadaritagi) in Korean, and “Ladder Lottery” in English. The game is played as follows: 1. A player is given a board with a set of vertical lines. 2. The player chooses a line and starts to move along the line 3. When hitting a horizontal line, the player must move along the horizontal line and then continue to move along the next vertical line. 4. The player wins if the player can hit a marked line at the bottom of the board. 5. You cannot see the horizontal lines in advance!\nPlay the {{ ‘Ladder Lottery Game! 🎮✨’.replace(‘BASE_URL’, base_url) }} and try to answer the following questions:\n\nIs tehre a strategy to maximize the probability of winning?\nHow does the probability of winning change as the number of horizontal lines increases?"
  },
  {
    "objectID": "m07-random-walks/02-coding.html",
    "href": "m07-random-walks/02-coding.html",
    "title": "Random Walks: Implementation and Applications",
    "section": "",
    "text": "Suppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network. It is surprising that this seemingly random, brainless behavior can tell us something deep about the structure of the city.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#introduction-random-walks-everywhere",
    "href": "m07-random-walks/02-coding.html#introduction-random-walks-everywhere",
    "title": "Random Walks: Implementation and Applications",
    "section": "",
    "text": "Suppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network. It is surprising that this seemingly random, brainless behavior can tell us something deep about the structure of the city.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#random-walks-in-a-network",
    "href": "m07-random-walks/02-coding.html#random-walks-in-a-network",
    "title": "Random Walks: Implementation and Applications",
    "section": "2 Random walks in a network",
    "text": "2 Random walks in a network\nA random walk in undirected networks is the following process: 1. Start at a node i 2. Randomly choose an edge to traverse to a neighbor node j 3. Repeat step 2 until you have taken T steps.\nIn case of directed networks, a random walker can only move along the edge direction, and it can be that the random walker is stuck in a so-called \"dead end\" that does not have any outgoing edges.\nHow does this simple process tell us something about the network structure? To get some insights, let us play with a simple interactive visualization.\n\n\n\n\n\n\nRandom Walk Simulation\n\n\n\n:class: tip\nPlay with the Random Walk Simulator! 🎮✨ and try to answer the following questions:\n\nWhen the random walker makes many steps, where does it tend to visit most frequently?\nWhen the walker makes only a few steps, where does it tend to visit?\nDoes the behavior of the walker inform us about centrality of the nodes?\nDoes the behavior of the walker inform us about communities in the network?",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#implementing-random-walks-in-python",
    "href": "m07-random-walks/02-coding.html#implementing-random-walks-in-python",
    "title": "Random Walks: Implementation and Applications",
    "section": "3 Implementing Random Walks in Python",
    "text": "3 Implementing Random Walks in Python\n\nSimulating Random Walks\nWe will simulate random walks on a simple graph of five nodes as follows.\n\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n\nA random walk is characterized by the transition probabilities between nodes.\n\nP_{ij} = \\frac{A_{ij}}{k_i}\n\nLet us first compute the transition probabilities and store them in a matrix, \\mathbf{P}.\n\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] &gt; 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i-&gt;ij\", A, 1 / k)\n\n\nprint(\"Transition probability matrix:\\n\", P)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n\nEach row and column of \\mathbf{P} corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\nNow, let us simulate a random walk on this graph. We represent a position of the walker by a vector, \\mathbf{x}, with five elements, each of which represents a node. We mark the node that the walker is currently at by 1 and others as 0.\n\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n\nThis vector representation is convenient to get the probabilities of transitions to other nodes from the current node:\n\n\\mathbf{x} \\mathbf{P}\n\nwhich is translated into the following code:\n\nprobs = x @ P\nprint(\"Position of the walker after one step:\\n\", probs)\n\nWe can then draw the next node based on the probabilities\n\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position of the walker after one step:\\n\", x)\n\nBy repeating this process, we can simulate the random walk.\n\n\nExercise 01\nWrite the following function to simulate the random walk for a given number of steps and return the x for each step.\n\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x (np.ndarray): The initial position of the walker.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#expected-behavior-of-random-walks",
    "href": "m07-random-walks/02-coding.html#expected-behavior-of-random-walks",
    "title": "Random Walks: Implementation and Applications",
    "section": "4 Expected behavior of random walks",
    "text": "4 Expected behavior of random walks\nWhat is the expected position of the walker after multiple steps? It is easy to compute the expected position of the walker after one step from initial position x(0):\n\n\\mathbb{E}[x(1)] = x(0) P\n\nwhere x(t) is the probability distribution of the walker at time t. In Python, the expected position of the walker at time t=1 is given by\n\nx_0 = np.array([1, 0, 0, 0, 0])\nx_1 = x_0 @ P\nprint(\"Expected position of the walker after one step:\\n\", x_1)\n\nFor the second step, the expected position of the walker is given by\n\n\\mathbb{E}[x(2)] = \\mathbb{E}[x(1) P] = \\mathbb{E}[x(0) P] P = x(0) P^2\n\nIn other words,\n\nx_2 = x_1 @ P\nprint(\"Expected position of the walker after two steps:\\n\", x_2)\n\nFollowing the same argument, the expected position of the walker at time t is given by\n\n\\mathbb{E}[x(t)] = x(0) P^t\n\n\nExercise 02\nWrite a function to compute the expected position of the walker at time t using the above formula:\n\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n    \"\"\"\n    # Your code here\n    pass\n\n\n\nExercise 03\nPlot each element of x(t) as a function of t for t=0,1,2,\\ldots, 1000. Try different initial positions and compare the results!\nSteps: 1. Define the initial position of the walker. 2. Compute the expected position of the walker at time t using the function you wrote above. 3. Draw a line for each element of x(t), totalling 5 lines. 4. Create multiple such plots for different initial positions and compare them.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#mathematical-foundation-stationary-state",
    "href": "m07-random-walks/02-coding.html#mathematical-foundation-stationary-state",
    "title": "Random Walks: Implementation and Applications",
    "section": "5 Mathematical Foundation: Stationary State",
    "text": "5 Mathematical Foundation: Stationary State\nLet’s dive into the math behind random walks in a way that’s easy to understand.\nImagine you’re at node i at time t. You randomly move to a neighboring node j. The probability of this move, called the transition probability p_{ij}, is:\n\np_{ij} = \\frac{A_{ij}}{k_i},\n\nHere, A_{ij} is an element of the adjacency matrix, and k_i is the degree of node i. For a network with N nodes, we can represent all transition probabilities in a transition probability matrix P:\n\n\\mathbf{P} = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1N} \\\\\np_{21} & p_{22} & \\cdots & p_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{N1} & p_{N2} & \\cdots & p_{NN}\n\\end{pmatrix}\n\nThis matrix P encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps. For instance:\n\nAfter one step: P_{ij} = p_{ij}\nAfter two steps: \\left(\\mathbf{P}^{2}\\right)_{ij} = \\sum_{k} P_{ik} P_{kj}\nAfter T steps: \\left(\\mathbf{P}^{T}\\right)_{ij}\n\nLet's explore why $\\mathbf{P}^2$ represents the transition probabilities after two steps.\n\nFirst, recall that $\\mathbf{P}_{ij}$ is the probability of moving from node $i$ to node $j$ in one step. Now, consider a two-step walk from $i$ to $j$. We can express this as:\n\n$$(\\mathbf{P}^2)_{ij} = \\sum_k \\mathbf{P}_{ik} \\mathbf{P}_{kj}$$\n\nThis equation encapsulates a key idea: to go from $i$ to $j$ in two steps, we must pass through some intermediate node $k$. Let's break this down step by step:\n\n1. The probability of the first step ($i$ to $k$) is $\\mathbf{P}_{ik}$.\n2. The probability of the second step ($k$ to $j$) is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ → $k$ → $j$) is the product $\\mathbf{P}_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nLikewise, for three steps, we have:\n\n$$(\\mathbf{P}^3)_{ij} = \\sum_k \\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$$\n\nwhere:\n1. The probability of going from $i$ to $k$ in two steps is $\\left( \\mathbf{P}\\right)^2_{ik}$.\n2. The probability of going from $k$ to $j$ in one step is $\\mathbf{P}_{kj}$.\n3. The probability of this specific path ($i$ →...→$k$ → $j$) is the product $\\left( \\mathbf{P}\\right)^2_{ik} \\mathbf{P}_{kj}$.\n4. We sum over all possible intermediate nodes $k$ to get the total probability.\n\nAnd we can extend this reasoning for any number of steps $t$.\n\nIn summary, for any number of steps $t$, $\\left( \\mathbf{P}^t \\right)_{ij}$ gives the probability of being at node $j$ after $t$ steps, starting from node $i$.\n\nAs T becomes very large, the probability distribution of being at each node, \\mathbf{x}(t), approaches a constant value:\n\n\\mathbf{x}(t+1) =\\mathbf{x}(t) \\mathbf{P}\n\nThis is an eigenvector equation. The solution, given by the Perron-Frobenius theorem, is called the stationary distribution:\n\n\\mathbf{x}(\\infty) = \\mathbb{\\pi}, \\; \\mathbf{\\pi} = [\\pi_1, \\ldots, \\pi_N]\n\nFor undirected networks, this stationary distribution always exists and is proportional to the degree of each node:\n\n\\pi_j = \\frac{k_j}{\\sum_{\\ell} k_\\ell} \\propto k_j\n\nThis means the probability of being at node j in the long run is proportional to the degree of node j. The normalization ensures that the sum of all probabilities is 1, i.e., \\sum_{j=1}^N \\pi_j = 1.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#practical-demonstration",
    "href": "m07-random-walks/02-coding.html#practical-demonstration",
    "title": "Random Walks: Implementation and Applications",
    "section": "6 Practical Demonstration",
    "text": "6 Practical Demonstration\nLet us demonstrate the above math by using a small network using Python. Let us consider a small network of 5 nodes, which looks like this:\n\nimport igraph as ig\nimport numpy as np\nedge_list = []\nfor i in range(5):\n    for j in range(i+1, 5):\n        edge_list.append((i, j))\n        edge_list.append((i+5, j+5))\nedge_list.append((0, 6))\n\ng = ig.Graph(edge_list)\nig.plot(g, vertex_size=20, vertex_label=np.arange(g.vcount()))\n\nThe transition probability matrix P is given by:\n\nimport scipy.sparse as sparse\n\nA = g.get_adjacency_sparse()\ndeg = np.array(A.sum(axis=1)).flatten()\nDinv = sparse.diags(1/deg)\nP = Dinv @ A\nP.toarray()\n\nLet us compute the stationary distribution by using the power method.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.zeros(g.vcount())\nx[1] = 1 # Start from node 1\nT = 100\nxt = []\nfor t in range(T):\n    x = x.reshape(1, -1) @ P\n    xt.append(x)\n\nxt = np.vstack(xt) # Stack the results vertically\n\nfig, ax = plt.subplots(figsize=(7,5))\npalette = sns.color_palette().as_hex()\nfor i in range(g.vcount()):\n    sns.lineplot(x=range(T), y=xt[:, i], label=f\"Node {i}\", ax=ax, color=palette[i])\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Probability\")\nax.set_title(\"Stationary distribution of a random walk\")\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\nWe see that the distributions of the walker converges, and there are three characteristic features in the convergence: 1. The distribution of the walker oscillates with a decaying amplitude and eventually converges. 2. Nodes of the same degree converge to the same stationary probability. 3. Nodes with higher degree converge to the higher stationary probability.\nTo validate the last two observation, let us compare the stationary distribution of a random walker with the expected stationary distribution, which is proportional to the degree of the nodes.\n\nimport pandas as pd\n\nn_edges = np.sum(deg) / 2\nexpected_stationary_dist = deg / (2 * n_edges)\n\npd.DataFrame({\n    \"Expected stationary distribution\": expected_stationary_dist,\n    \"Stationary distribution of a random walk\": xt[-1].flatten()\n}).style.format(\"{:.4f}\").set_caption(\"Comparison of Expected and Observed Stationary Distributions\").background_gradient(cmap='cividis', axis = None)",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#community-structure",
    "href": "m07-random-walks/02-coding.html#community-structure",
    "title": "Random Walks: Implementation and Applications",
    "section": "7 Community structure",
    "text": "7 Community structure\nRandom walks can capture community structure of a network. To see this, let us consider a network of a ring of cliques.\n\nimport networkx as nx\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nn_cliques = 3\nn_nodes_per_clique = 5\n\nG = nx.ring_of_cliques(n_cliques, n_nodes_per_clique)\ng = igraph.Graph().Adjacency(nx.to_numpy_array(G).tolist()).as_undirected()\nmembership = np.repeat(np.arange(n_cliques), n_nodes_per_clique)\n\ncolor_map = [sns.color_palette()[i] for i in membership]\nigraph.plot(g, vertex_size=20, vertex_color=color_map)\n\nLet us compute the expected position of the walker after 1 to 10 steps.\nCompute the transition matrix:\n\n:tags: [hide-cell]\nfrom scipy import sparse\n\n# Get the adjacency matrix and degree\nA = g.get_adjacency_sparse()\nk = np.array(g.degree())\n\n# This is an efficient way to compute the transition matrix\n# using scipy.sparse\nP = sparse.diags(1 / k) @ A\n\nCompute the expected position of the walker after 1 to 300 steps:\n\n:tags: [hide-cell]\n\nx_t = np.zeros(g.vcount())\nx_t[2] = 1\nx_list = [x_t]\nfor t in range(300):\n    x_t = x_t @ P\n    x_list.append(x_t)\nx_list = np.array(x_list)\n\nPlot the expected position of the walker at each step:\n\n:tags: [hide-input]\n\ncmap = sns.color_palette(\"viridis\", as_cmap=True)\n\nsns.set_style('white')\nsns.set(font_scale=1.2)\nsns.set_style('ticks')\n\nfig, axes = plt.subplots(figsize=(15,10), ncols = 3, nrows = 2)\n\nt_list = [0, 1, 3, 5, 10, 299]\nfor i, t in enumerate(t_list):\n    igraph.plot(g, vertex_size=20, vertex_color=[cmap(x_list[t][j] / np.max(x_list[t])) for j in range(g.vcount())], target = axes[i//3][i%3])\n    axes[i//3][i%3].set_title(f\"$t$ = {t}\", fontsize = 25)\n\nwhere the color of each node represents the probability of the walker being at that node.\nAn important observation is that the walker spends more time in the clique that it started from and then diffuse to others. Thus, the position of the walker before reaching the steady state tells us the community structure of the network.\n\nExercise 04\n\nGenerate a network of 100 nodes with 4 communities using a stochastic block model, with inter-community edge probability 0.05 and intra-community edge probability 0.2. Then, compute the expected position of the walker starting from node zero after x steps. Plot the results for x = 0, 5, 10, 1000.\nIncrease the inter-community edge probability to 0.15 and repeat the simulation. Compare the results with the previous simulation.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#advanced-topics-mixing-time-and-spectral-analysis",
    "href": "m07-random-walks/02-coding.html#advanced-topics-mixing-time-and-spectral-analysis",
    "title": "Random Walks: Implementation and Applications",
    "section": "8 Advanced Topics: Mixing Time and Spectral Analysis",
    "text": "8 Advanced Topics: Mixing Time and Spectral Analysis\n\nTime to reach the stationary state\nLet’s explore how quickly a random walker reaches its stationary state. The convergence speed is influenced by two main factors: edge density and community structure. In sparse networks, the walker needs more steps to explore the entire network. Additionally, the walker tends to remain within its starting community for some time.\nThe mixing time, denoted as t_{\\text{mix}}, is defined as the minimum number of steps required for a random walk to get close to the stationary distribution, regardless of the starting point, with the maximum error less than \\epsilon:\nt_{\\text{mix}} = \\min\\{t : \\max_{{\\bf x}(0)} \\|{\\bf x}(t) - {\\bf \\pi}\\|_{1} \\leq \\epsilon\\}\nwhere \\|{\\bf x}(t) - {\\bf \\pi}\\|_{1} = 2\\max_{i} |x_i(t) - \\pi_i| represents the L1 distance between two probability distributions. The choice of \\epsilon is arbitrary.\nWe know that the distribution of a walker after t steps is given by:\n\n\\mathbf{x}(t) =  \\mathbf{x}(0) \\mathbf{P} ^{t}\n\nTo find this distribution, we need to compute \\mathbf{P}^t. However, we face a challenge: \\mathbf{P} is not diagonalizable.\nA diagonalizable matrix \\mathbf{S} can be written as \\mathbf{S} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1}, where \\mathbf{\\Lambda} is a diagonal matrix and \\mathbf{Q} is an orthogonal matrix. Visually, it looks like this:\n\nIt is useful because we can then compute the power of the matrix as follows:\n\n\\mathbf{S}^t = \\mathbf{Q} \\mathbf{\\Lambda}^t \\mathbf{Q}^{-1}\n\nAnd it is easy to find {\\bf Q} and {\\bf \\Lambda} by using eigenvalue decomposition if {\\bf S} is symmetric and consists only of real values. Namely, the eigenvectors form {\\cal Q} and the eigenvalues form the diagonal matrix {\\cal \\Lambda}.\nLet us demonstrate the above relation by calculating $\\mathbf{S}^2$.\n$$\n\\begin{align}\n\\mathbf{S}^2 &= \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1} \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{-1} \\\\\n&= \\mathbf{Q} \\mathbf{\\Lambda}^2 \\mathbf{Q}^{-1}.\n\\end{align}\n$$\n(Note that $\\mathbf{Q} \\mathbf{Q}^{-1} = {\\bf I}$.)\n\n![](../figs/diagonalizable-squared.jpg)\n\n\\mathbf{P} is also diagonalizable but not symmetric like \\mathbf{\\overline A} so that we cannot use the above relation directly. So we do a trick by rewriteing \\mathbf{P} as:\n\n\\mathbf{P} = \\mathbf{D}^{-1} \\mathbf{A} = \\mathbf{D}^{-\\frac{1}{2}} \\overline {\\bf A} \\mathbf{D}^{\\frac{1}{2}}\n\nwhere \\overline{\\bf A} = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} is the normalized adjacency matrix.\nThe advantage is that \\overline{\\bf A} is diagonalizable: \\overline{\\bf A} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^\\top. Using this, we can compute \\mathbf{P}^t:\n\n\\mathbf{P}^t = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q} \\mathbf{\\Lambda}^t \\mathbf{Q}^\\top \\mathbf{D}^{\\frac{1}{2}} = \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R ^\\top\n\nwhere \\mathbf{Q}_L = \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{Q} and \\mathbf{Q}_R = \\mathbf{D}^{\\frac{1}{2}} \\mathbf{Q}.\nLet us demonstrate the above relation by calculating $\\mathbf{P}^2$.\n\n$$\n\\begin{align}\n\\mathbf{P}^2 &= \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} \\mathbf{D}^{\\frac{1}{2}} \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} \\mathbf{D}^{\\frac{1}{2}}\\\\\n&=  \\mathbf{D}^{-\\frac{1}{2}} \\overline{\\bf A} ^2 \\mathbf{D}^{\\frac{1}{2}}\\\\\n&= \\mathbf{Q}_L \\mathbf{\\Lambda}^2 \\mathbf{Q}_R ^\\top\n\\end{align}\nThe probability distribution after t steps is then:\n\n\\mathbf{x}(t) = \\mathbf{x}(0) \\mathbf{Q}_L \\mathbf{\\Lambda}^t \\mathbf{Q}_R ^\\top\n\nWe can rewrite this in a more intuitive form:\n\n\\begin{pmatrix}\nx_1(t) \\\\\nx_2(t) \\\\\n\\vdots \\\\\nx_N(t)\n\\end{pmatrix}\n=\n\\sum_{\\ell=1}^N\n\\left[\n\\lambda_\\ell^t\n\\begin{pmatrix}\nq^{(L)}_{\\ell 1} \\\\\nq^{(L)}_{\\ell 2} \\\\\n\\vdots \\\\\nq^{(L)}_{\\ell N}\n\\end{pmatrix}\n\\langle\\mathbf{q}^{(R)}_{\\ell},  \\mathbf{x}(0) \\rangle\n\\right]\n\nVisualize the above equation by using the following figure.\n\n![](../figs/diagonalizable-sum.jpg)\n\nThe term \\lambda_\\ell^t represents the contribution of each eigenvalue to the stationary distribution over time. As t increases, all terms decay exponentially except for the largest eigenvalue (\\lambda_1 = 1). This explains how the random walk converges to the stationary distribution:\n\n\\pi_i = \\lim_{t\\to\\infty} x_i(t) = \\begin{pmatrix} q^{(L)}_{1 1} \\\\ q^{(L)}_{1 2} \\\\ \\vdots \\\\ q^{(L)}_{1 N} \\end{pmatrix} \\langle\\mathbf{q}^{(R)}_{1},  \\mathbf{x}(0) \\rangle\n\nThe second largest eigenvalue primarily determines the convergence speed to the stationary distribution. A larger second eigenvalue leads to slower convergence. Thus, the mixing time is closely related to the second largest eigenvalue.\nLevin-Peres-Wilmer theorem states that the mixing time is bounded by the relaxation time as\n\nt_{\\text{mix}} &lt; \\tau \\log \\left( \\frac{1}{\\epsilon \\min_{i} \\pi_i} \\right), \\quad \\tau = \\frac{1}{1-\\lambda_2}\n\nwhere \\lambda_2 is the second largest eigenvalue of the normalized adjacency matrix. The mixing time is known to be bounded by the relaxation time as\nMore commonly, it is expressed using the second smallest eigenvalue \\mu of the normalized laplacian matrix as\n\nt_{\\text{mix}} \\leq \\frac{1}{\\mu}\n\nwhere \\mu = 1-\\lambda_2.\n\n\nCompute the mixing time\nLet us demonstrate the above math by using the network of two cliques.\n\n\nNormalized Adjacency Matrix\nFirst, let us construct the normalized adjacency matrix \\overline{\\bf A} of the network.\n\nDinv_sqrt = sparse.diags(1.0/np.sqrt(deg))\nA_norm = Dinv_sqrt @ A @ Dinv_sqrt\n\nNext, let us compute the eigenvalues and eigenvectors of the normalized adjacency matrix.\n\nevals, evecs = np.linalg.eigh(A_norm.toarray())\n\n`evals` and `evecs` are sorted in descending order of the eigenvalues. `evecs[:, 0]` is the eigenvector corresponding to the largest eigenvalue, which is always 1.\nThere is a similar function called `np.linalg.eig` which returns the eigenvalues and eigenvectors. It can be used for any matrices, while `np.linalg.eigh` is specifically for symmetric matrices. `np.linalg.eigh` is faster and more stable and therefore preferred if your matrix is symmetric. `np.linalg.eig` is more susceptible to numerical errors and therefore less stable.\nThe eigenvalues and eigenvectors are shown below.\n\npd.DataFrame({\n    \"Eigenvalue\": evals\n}).T.style.background_gradient(cmap='cividis', axis = 1).set_caption(\"Eigenvalues of the normalized adjacency matrix\")\n\n\npd.DataFrame({\n    \"Eigenvector %i\" % i: evecs[:, i]\n    for i in range(10)\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Eigenvectors of the normalized adjacency matrix\")\n\nNotice that the largest eigenvalue is 1, which is always true for a normalized adjacency matrix. The largest eigenvector (the leftmost one) is associated with the stationary distribution of the random walk.\nThe sign of the eigenvector is indeterminate, which means we can choose the sign of the eigenvector arbitrarily. In fact, `np.linalg.eigh` returns the eigenvector whose sign can vary for a different run.\nWe decompose \\overline{\\bf A} as\n\\overline {\\bf A} = {\\bf Q}{\\bf \\Lambda}{\\bf Q}^\\top\nwhere {\\bf Q} corresponds to eigvecs and {\\bf \\Lambda} corresponds to np.diag(evals) (since {\\bf \\Lambda} is a diagonal matrix). Let’s see if this is correct:\n\npd.DataFrame(A_norm.toarray()).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Normalized Adjacency Matrix\")\n\n\nA_norm_reconstructed = evecs @ np.diag(evals) @ evecs.T\npd.DataFrame(A_norm_reconstructed).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Reconstruction of the Normalized Adjacency Matrix\")\n\nNotice that the reconstruction is not perfect due to the numerical error, although overall the structure is correct.\n\n\nMulti-step Transition Probability\nLet us first conform whether we can compute the transition probability after t steps by using the eigenvalues and eigenvectors.\n\nt = 5\nx_0 = np.zeros(g.vcount())\nx_0[0] = 1\n\n# Compute x_t by using the eigenvalues and eigenvectors\nQ_L = np.diag(1.0/np.sqrt(deg)) @ evecs\nQ_R = np.diag(np.sqrt(deg)) @ evecs\nx_t = x_0 @ Q_L @ np.diag(evals**t) @ Q_R.T\n\n# Compute x_t by using the power iteration\nx_t_power = x_0.copy()\nfor i in range(t):\n    x_t_power = x_t_power @ P\n\npd.DataFrame({\n    \"Eigenvector\": x_t.flatten(),\n    \"Power iteration\": x_t_power.flatten()\n}).style.background_gradient(cmap='cividis', axis = None).set_caption(\"Comparison of Eigenvector and Power Iteration\")\n\n\n\nRelaxation Time and Mixing Time\nLet us measure the relaxation time of the random walk.\n\nevals, evecs = np.linalg.eigh(A_norm.toarray())\nlambda_2 = -np.sort(-evals)[1]\ntau = 1 / lambda_2\nprint(f\"The relaxation time of the random walk is {tau:.4f}.\")",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#unifying-centrality-and-communities",
    "href": "m07-random-walks/02-coding.html#unifying-centrality-and-communities",
    "title": "Random Walks: Implementation and Applications",
    "section": "9 Unifying Centrality and Communities",
    "text": "9 Unifying Centrality and Communities\n\nModularity: Random Walk Perspective\nModularity can be interpreted from a random walk perspective. Modularity is given by\n\nQ = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)\n\nwhere m is the number of edges in the network, A_{ij} is the adjacency matrix, d_i is the degree of node i, c_i is the community of node i, and \\delta(c_i, c_j) is the Kronecker delta function (which is 1 if c_i = c_j and 0 otherwise).\nWe can rewrite the modularity using the language of random walks as follows.\n\n\\begin{aligned}\nQ &= \\sum_{ij} \\left(\\frac{A_{ij}}{2m}  - \\frac{d_i}{2m} \\frac{d_j}{2m} \\right) \\delta(c_i, c_j) \\\\\n&= \\sum_{ij} \\left(\\pi_i P_{ij}  - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)\n\\end{aligned}\n where \\pi_i is the stationary distribution of the random walk given by\n\n\\pi_i = \\frac{d_i}{2m}\n\nand P_{ij} is the transition probability between nodes i and j.\nLet's break down this derivation step by step:\n\n1. We start with the original modularity formula:\n\n   $$Q = \\frac{1}{2m} \\sum_{ij} \\left( A_{ij} - \\frac{d_i d_j}{2m} \\right) \\delta(c_i, c_j)$$\n\n2. First, we move the constant $1/(2m)$ to the inside of the parentheses:\n\n   $$Q = \\sum_{ij} \\left(\\frac{A_{ij}}{2m} - \\frac{d_i d_j}{2m^2} \\right) \\delta(c_i, c_j)$$\n\n3. Now, we recognize that $\\frac{A_{ij}}{2m}$ can be rewritten as:\n\n   $$\\frac{A_{ij}}{2m} = \\frac{d_i}{2m} \\cdot \\frac{A_{ij}}{d_i} = \\pi_i P_{ij}$$\n\n4. We also recognize that $\\frac{d_i}{2m}$ is the stationary distribution of the random walk, which we denote as $\\pi_i$:\n\n   $$\\frac{d_i}{2m} = \\pi_i$$\n\n5. Substituting these into our equation:\n\n   $$Q = \\sum_{ij} \\left(\\pi_i P_{ij} - \\pi_i \\pi_j \\right) \\delta(c_i, c_j)$$\n\nThe expression suggests that:\n\nThe first term, \\pi_i P_{ij} \\delta(c_i, c_j), represents the probability that a walker is at node i and moves to node j within the same community by one step.\nThe second term, \\pi_i \\pi_j, represents the probability that a walker is at node i and moves to another node j within the same community after long steps.\n\nIn summary, modularity compares short-term and long-term random walk probabilities. High modularity indicates that a random walker is more likely to stay within the same community after one step than after many steps.\nBuilding on this perspective from random walks, Delvenne et al. {footcite}`delvenne2010stability` extends the modularity by comparing multi-step and long-step transition probabilities of a random walk. This approach, known as \"Markov stability\", shows that the number of steps acts as a \"resolution parameter\" that determines the scale of detectable communities.\n\n\nPageRank: Random Walk Perspective\nPageRank can be interpreted from a random walk perspective:\n\nc_i = (1-\\beta) \\sum_j P_{ji} c_j + \\beta \\cdot \\frac{1}{N}\n\nWhere: - c_i is the PageRank of node i - P_{ji} is the transition probability from node j to node i - \\beta is the teleportation probability - N is the total number of nodes\nThis equation represents a random walk where: 1. With probability (1-\\beta), the walker follows a link to the next node. 2. With probability \\beta, the walker teleports to a random node in the network.\nThe PageRank c_i is the stationary distribution of this random walk, representing the long-term probability of finding the walker at node i.\nThis sounds odd at first glance. But it makes sense when you think about what PageRank was invented for, i.e., Web search. It characterizes a web surfer as a random walker that chooses the next page by randomly jumping to a random page with probability $\\beta$ or by following a link to a page with probability $1-\\beta$. The web page with the largest PageRank means that the page is most likely to be visited by this random web surfer.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/02-coding.html#summary",
    "href": "m07-random-walks/02-coding.html#summary",
    "title": "Random Walks: Implementation and Applications",
    "section": "10 Summary",
    "text": "10 Summary\nRandom walks provide a powerful unified framework for understanding both centrality measures and community structure in networks. Through our exploration, we’ve seen how:\n\nImplementation: Random walks can be efficiently simulated and analyzed using matrix operations\nStationary distributions: Connect to centrality measures, with degree centrality emerging naturally\nTemporal dynamics: Reveal community structure through short-term vs. long-term behavior\nMathematical foundation: Links to spectral graph theory and eigenvalue analysis\nApplications: Provide new interpretations of modularity and PageRank\n\nThis unified perspective opens up new possibilities for network analysis and algorithm design, making random walks one of the most versatile tools in network science.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/eigencentrality.html",
    "href": "m06-centrality/eigencentrality.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "“A man is known by the company he keeps” is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire. It suggests that a person’s character is reflected by the people this person is friends with. This idea can be applied to define the centrality of a node in a network.\n\n\nOne considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here’s the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet’s think about it for a moment. We want our centrality measure to be positive. It wouldn’t make much sense to have negative importance! So, we’re looking for an eigenvector where all the elements are positive. And a good news is that there’s a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associted with the largest eigenvalue always has all positive elements.\nThis centrality is called Eigenvector centrality.\n\n\n\nEigenvector centrality has several problems. One is that it does not handle directed networks very well. A natural extension of eigenvector centrality to directed networks is the HITS centrality. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet’s put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbb{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree $d_j$ of the authority, namely\n\n$$\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n$$\n\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting $x_i = d_i$.\n:::\n\n## Katz centrality\n\nEigenvector centrality tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. A solution is to add a little bit of score to all nodes.\n\n$$\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n$$\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nDerive the solution of the Katz centrality.\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe equation can be solved by\n\n$$\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n$$\n\nwhere $\\mathbf{1}$ is the vector of ones. By rewriting the equation, we get\n\n$$\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n$$\n\nBy taking the inverse of $\\mathbf{I} - \\lambda \\mathbf{A}$, we get\n\n$$\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n$$\n\n\nYou’ve probably heard PageRank, a celebrated idea behind Google Search. It is like a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers."
  },
  {
    "objectID": "m06-centrality/eigencentrality.html#eigenvector-centrality",
    "href": "m06-centrality/eigencentrality.html#eigenvector-centrality",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "One considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here’s the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet’s think about it for a moment. We want our centrality measure to be positive. It wouldn’t make much sense to have negative importance! So, we’re looking for an eigenvector where all the elements are positive. And a good news is that there’s a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associted with the largest eigenvalue always has all positive elements.\nThis centrality is called Eigenvector centrality."
  },
  {
    "objectID": "m06-centrality/eigencentrality.html#hyperlink-induced-topic-search-hits-centrality",
    "href": "m06-centrality/eigencentrality.html#hyperlink-induced-topic-search-hits-centrality",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Eigenvector centrality has several problems. One is that it does not handle directed networks very well. A natural extension of eigenvector centrality to directed networks is the HITS centrality. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet’s put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbb{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree $d_j$ of the authority, namely\n\n$$\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n$$\n\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting $x_i = d_i$.\n:::\n\n## Katz centrality\n\nEigenvector centrality tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. A solution is to add a little bit of score to all nodes.\n\n$$\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n$$\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nDerive the solution of the Katz centrality.\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe equation can be solved by\n\n$$\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n$$\n\nwhere $\\mathbf{1}$ is the vector of ones. By rewriting the equation, we get\n\n$$\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n$$\n\nBy taking the inverse of $\\mathbf{I} - \\lambda \\mathbf{A}$, we get\n\n$$\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n$$\n\n\nYou’ve probably heard PageRank, a celebrated idea behind Google Search. It is like a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers."
  },
  {
    "objectID": "m06-centrality/eigencentrality.html#pagerank",
    "href": "m06-centrality/eigencentrality.html#pagerank",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "You’ve probably heard PageRank, a celebrated idea behind Google Search. It is like a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers."
  },
  {
    "objectID": "m06-centrality/02-coding.html#network-of-university-students",
    "href": "m06-centrality/02-coding.html#network-of-university-students",
    "title": "Advanced Topics in Network Science",
    "section": "1.1 Network of university students",
    "text": "1.1 Network of university students\nLet’s compute the centrality of the network using Python igraph.\n# Uncomment if you use Colab\n#!pip install igraph\nimport igraph\nnames  = ['Sarah', 'Mike', 'Emma', 'Alex', 'Olivia', 'James', 'Sophia', 'Ethan', 'Ava', 'Noah', 'Lily', 'Lucas', 'Henry']\nedge_list = [(0, 1), (0, 2), (1, 2), (2, 3), (3, 4), (3, 5), (3, 6), (4, 5), (6, 7), (6, 8), (6, 9), (7, 8), (7, 9), (8, 9), (9, 10), (9, 11), (9, 12)]\ng = igraph.Graph()\ng.add_vertices(13)\ng.vs[\"name\"] = names\ng.add_edges(edge_list)\nigraph.plot(g, vertex_label=g.vs[\"name\"])\nigraph offers a wide range of centrality measures as methods of the igraph.Graph class.\n\nDegree centrality: igraph.Graph.degree()\nCloseness centrality: igraph.Graph.closeness()\nBetweenness centrality: igraph.Graph.betweenness()\nHarmonic centrality: igraph.Graph.harmonic_centrality()\nEccentricity: igraph.Graph.eccentricity()\nEigenvector centrality: igraph.Graph.eigenvector_centrality()\nPageRank centrality: igraph.Graph.personalized_pagerank()\n\nFor example, the closeness centrality is computed by\ng.closeness()\n\nComputing Katz centrality\nLet’s compute the Katz centrality without using igraph. Let us first define the adjacency matrix of the graph\nA = g.get_adjacency_sparse()\nwhich is the scipy CSR sparse matrix. The Katz centrality is given by\n$$\n = + \n$$\nSo, how do we solve this? We can use a linear solver but here we will use a simple method:\n\nInitialize \\mathbf{c} with a random vector.\nCompute the right hand side of the equation and update \\mathbf{c}.\nRepeat the process until \\mathbf{c} converges.\n\nLet’s implement this.\nimport numpy as np\n\nalpha, beta = 0.1, 0.05 # Hyperparameters\nn_nodes = g.vcount() # number of nodes\nc = np.random.rand(n_nodes, 1) # column random vector\n\nfor _ in range(100):\n    c_next = beta * np.ones((n_nodes, 1)) + alpha * A * c\n    if np.linalg.norm(c_next - c) &lt; 1e-6:\n        break\n    c = c_next\nprint(c)\n\nDoes the centrality converge?\nChange the hyperparameter and see how the result changes 😉 If the centrality diverges, think about why it diverges.\n\nHint: Katz centrality can be analytically computed by\n$$\n = ( - )^{-1} \n$$\n\n\nExercise (Optional)\nCompute the PageRank centrality of this graph",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/02-coding.html#network-of-ancient-roman-roads",
    "href": "m06-centrality/02-coding.html#network-of-ancient-roman-roads",
    "title": "Advanced Topics in Network Science",
    "section": "1.2 Network of ancient Roman roads",
    "text": "1.2 Network of ancient Roman roads\n\nLoad the data & construct the network\nimport pandas as pd\n\nroot = \"https://raw.githubusercontent.com/skojaku/adv-net-sci/main/data/roman-roads\"\nnode_table = pd.read_csv(f\"{root}/node_table.csv\")\nedge_table = pd.read_csv(f\"{root}/edge_table.csv\")\nThe node table:\nnode_table.head(3)\nThe edge table:\nedge_table.head(3)\nLet’s construct a network from the node and edge tables.\nimport igraph\n\ng = igraph.Graph() # create an empty graph\ng.add_vertices(node_table[\"node_id\"].values) # add nodes\ng.add_edges(list(zip(edge_table[\"src\"].values, edge_table[\"trg\"].values))) # add edges\nwhich looks like this:\ncoord = list(zip(node_table[\"lon\"].values, -node_table[\"lat\"].values))\nigraph.plot(g, layout = coord, vertex_size = 5)\n\n\nExercise 🏛️\n\nCompute the following centrality measures:\n\nDegree centrality 🔢\nEigenvector centrality\nPageRank centrality\nKatz centrality\nBetweenness centrality\nCloseness centrality\n\nPlot the centrality measures on the map and see in which centrality Rome is the most important node. 🗺️🏛️ (as beautiful as possible!!)",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/stochastic-block-model.html",
    "href": "m05-clustering/stochastic-block-model.html",
    "title": "Stochastic Block Model",
    "section": "",
    "text": "Let’s talk about two ways to look at communities in networks.\nIn modularity maximization, we are given a network and asked to find the best way to group its parts into communities.\nLet’s flip that idea on its head! 🙃 Instead of starting with a network and looking for communities, we start with the communities and ask, “What kind of network would we get if the nodes form these communities?”. This is the idea of the Stochastic Block Model (SBM).\nWhile modularity maximization is about finding hidden patterns, SBM is about imagining what a network would look like based on a given community structure. Two sides of the same coin, each giving us a unique perspective on community detection."
  },
  {
    "objectID": "m05-clustering/stochastic-block-model.html#model",
    "href": "m05-clustering/stochastic-block-model.html#model",
    "title": "Stochastic Block Model",
    "section": "1 Model",
    "text": "1 Model\nIn stochastic block model, we describe a network using probabilities given a community structure. Specifically, let us consider two nodes i and j who belong to community c_i and c_j. Then, the probability of an edge between i and j is given by their community membership.\n\nP(A_{ij}=1|c_i, c_j) = p_{c_i,c_j}\n\nwhere p_{c_i,c_j} is the probability of an edge between nodes in community c_i and c_j, respectively. Notice that the edge probability is fully specified by the community membership of the nodes. This means that nodes in a community are connected with the same probability irrespective of the nodes themselves, and the nodes in different two communities are also connected with the same probability. As a result, when plotting the adjacency matrix, we observe “blocks” of different edge densities, which is why we say that SBM is a “block model”.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Plot\nplt.figure(figsize=(8, 8))\nplt.imshow(A, cmap='binary')\nplt.title(\"Adjacency Matrix of Stochastic Block Model\")\nplt.xlabel(\"Node Index\")\nplt.ylabel(\"Node Index\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "m05-clustering/stochastic-block-model.html#characterizing-network-structures-with-the-sbm",
    "href": "m05-clustering/stochastic-block-model.html#characterizing-network-structures-with-the-sbm",
    "title": "Stochastic Block Model",
    "section": "2 Characterizing network structures with the SBM",
    "text": "2 Characterizing network structures with the SBM\nStochastic Block Model is a flexible model that can be used to describe a wide range of network structures.\nLet’s start with communities where nodes within a community are more likely to be connected to each other than nodes in different communities. We can describe this using SBM by:\n\nP_{c,c'} = \\begin{cases}\n    p_{\\text{in}} & \\text{if } c = c' \\\\\n    p_{\\text{out}} & \\text{if } c \\neq c'\n\\end{cases}\n\n\np_{\\text{in}} is the chance of a connection between nodes in the same community\np_{\\text{out}} is the chance of a connection between nodes in different communities\n\nUsually, we set p_{\\text{in}} &gt; p_{\\text{out}}, because nodes in the same community tend to be more connected.\nBut, there’s more SBM can do:\n\nDisassortative communities: What if we flip things around and set p_{\\text{in}} &lt; p_{\\text{out}}? Now we have communities where nodes prefer to connect with nodes from other communities. This is not in line with the communities we have focused on so far. Yet, it is still a valid model of community structure, and SBM allows for this generalization of community structure easily.\nRandom networks: If we make p_{\\text{in}} = p_{\\text{out}}, we get a completely random network where every node has an equal chance of connecting to any other node. This is what we call an Erdős-Rényi network.\n\nIn sum, SBM has been used as a playground for network scientists. We can use it to create many interesting network structures and study how they behave."
  },
  {
    "objectID": "m05-clustering/stochastic-block-model.html#generating-networks-with-sbm",
    "href": "m05-clustering/stochastic-block-model.html#generating-networks-with-sbm",
    "title": "Stochastic Block Model",
    "section": "3 Generating networks with SBM",
    "text": "3 Generating networks with SBM\nIt is easy to generate networks with SBM using igraph. For example, the assortativity communities can be generated as follows.\n\nimport igraph\n\np_in = 0.1\np_out = 0.001\nblock_sizes = [100, 200, 300]\nn = sum(block_sizes)\n\npref_matrix = [\n    [p_in, p_out, p_out],\n    [p_out, p_in, p_out],\n    [p_out, p_out, p_in]\n]\n\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Plot the network\nimport seaborn as sns\npalette = sns.color_palette()\n\ncommunity_colors = sum([[palette[i]] * block_sizes[i] for i in range(len(block_sizes))], [])\nigraph.plot(g, vertex_color=community_colors)\n\n\npref_matrix is the matrix of connection probabilities between communities. Its (i,j)th-element is the probability of a connection between nodes in community i and j."
  },
  {
    "objectID": "m05-clustering/stochastic-block-model.html#detecting-communities-with-sbm",
    "href": "m05-clustering/stochastic-block-model.html#detecting-communities-with-sbm",
    "title": "Stochastic Block Model",
    "section": "4 Detecting communities with SBM",
    "text": "4 Detecting communities with SBM\nImagine you’re a detective trying to figure out how a network was created. You have a hunch about the community structure, and you want to know if it matches the network you see. That’s exactly what we’re going to do to find out communities!\nHere’s how we can describe the probability of seeing a particular network, given a community structure:\n\nP(\\left\\{A_{ij}\\right\\}_{ij}) = \\prod_{i&lt;j} P(A_{ij}=1|c_i, c_j)^{A_{ij}} (1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}\n\nLet’s break this down into simpler terms:\n\nFirst, \\left\\{A_{ij}\\right\\}_{ij} is just a fancy way of saying “all the connections in our network”. Think of it as a big table showing who’s connected to whom.\nWe use \\prod_{i &lt; j} instead of \\prod_{i,j} because we’re dealing with an undirected network. This means if Alice is friends with Bob, Bob is also friends with Alice. We only need to count this friendship once, not twice!\nThe last part, P(A_{ij}=1|c_i, c_j)^A_{ij}(1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}, might look scary, but it’s actually quite clever. It’s a shorthand way of saying “what’s the chance of this connection existing or not existing?” If the connection exists (A_{ij}=1), we use the first part. If it doesn’t (A_{ij}=0), we use the second part. It’s a two-in-one formula.\n\nHere’s a neat trick we can use to make our lives easier. We can take the logarithm of both sides of our equation. This turns our big product (multiplication) into a simpler sum (addition).\n\n{\\cal L}=\\log P(\\left\\{A_{ij}\\right\\}_{ij}) = \\sum_{i&lt;j} A_{ij} \\log P(A_{ij}=1|c_i, c_j) + (1-A_{ij}) \\log (1-P(A_{ij}=1|c_i, c_j))\n\nWe call this the likelihood function. It tells us how likely we are to see this network given our community guess. We can play around with different community assignments and edge probabilities to see which one gives us the highest likelihood. To make this game easier, let’s first figure out the best edge probabilities for a given community assignment.\nOur likelihood function has a special shape - it is a concave function with respect to p_{c,c'}. This means that the likelihood function is a hill with only one peak when we look at it in terms of edge probability p_{c,c'}.\n\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef concave_function(x):\n    return -(x - 0.5)**2 + 0.25\n\nx = np.linspace(0, 1, 100)\ny = concave_function(x)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, 'b-', linewidth=2)\nplt.title('Schematic of Likelihood Function (Concave)')\nplt.xlabel('Edge Probability p_c,c\\'')\nplt.ylabel('Likelihood')\nplt.axvline(x=0.5, color='r', linestyle='--', label='Maximum')\nplt.annotate('Global Maximum', xy=(0.5, 0.25), xytext=(0.6, 0.2),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.legend()\nplt.grid(True)\nplt.show()\n\nSo, what does this mean for us? The top of this hill (our maximum value) is flat, and there’s only one flat spot on the whole hill. So if we can find a spot where the hill isn’t sloping at all (that’s what we mean by “zero gradient”), we’ve found the very top of the hill! 🏔️\nIn math terms, we take the derivative of our likelihood function with respect to p_{c,c'} and set it to zero, i.e., \\partial {\\cal L}  / \\partial p_{cc'} = 0. Here is what we get:\n\n\\begin{aligned}\n\\frac{\\partial {\\cal L}}{\\partial p_{c,c'}} &= 0 \\\\\n\\Rightarrow & \\sum_{i&lt;j} \\left[A_{ij} \\frac{1}{p_{c_i,c_j}} \\delta(c_i,c)\\delta(c_j,c') -(1-A_{ij}) \\frac{1}{1-p_{c_i,c_j}}\\delta(c_i,c')\\delta(c_j,c') \\right] = 0 \\\\\n\\Rightarrow &\n\\frac{m_{cc'}}{p_{c_i,c_j}} - \\frac{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') }{1-p_{c_i,c_j}} = 0 & \\text{if } c \\neq  c' \\\\\n\\Rightarrow & p_{c,c'} = \\frac{m_{cc'}}{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c')}\n\\end{aligned}\n\nLet’s break down these equations:\n\nm_{cc'} is the number of edges between nodes in community c and those in community c'.\nThe derivative \\partial \\log p_{cc} / \\partial p_{cc} is just 1/p_{cc}.\n\nThe denominator \\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') is the total number of pairs of nodes that belong to communities c and c'. It is given by\n\n\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') =\n\\begin{cases}\nn_cn_{c'} & \\text{if } c \\neq c' \\\\\n\\frac{n_c (n_c - 1)}{2} & \\text{if } c = c'\n\\end{cases}\n\nWhy do we have two different equations for p_{c,c'}? It’s because we are counting each pair of nodes only by once. It is easy to verify when looking at the adjacency matrix:\n\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Create the plot\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Plot the adjacency matrix\nax.matshow(A, cmap='binary')\nmask = np.triu(np.ones_like(A, dtype=bool), k=1)\n\n# Highlight the upper triangle with yellow overlay\nax.matshow(np.ma.masked_array(np.ones_like(A), ~mask), cmap='Reds_r', alpha=0.3)\n\n# Add a title\nplt.title(\"Adjacency Matrix with Highlighted Upper Triangle\")\n\nplt.show()\n\nThe upper triangle of the adjacency matrix represents i &lt; j over which we take the sum. When c=c' (the diagonal block), we count only the upper half of the block, resulting in \\frac{n_c (n_c - 1)}{2}. When c \\neq c' (different communities), we count all connections between them, resulting in n_cn_{c'}.\nWe have now obtaind the likelihood function based only on the community assignment. Maximizing {\\cal L} with respect to the community assignment gives us the most likely community assignment for the network."
  },
  {
    "objectID": "m05-clustering/pattern-matching.html",
    "href": "m05-clustering/pattern-matching.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Community detection (pattern matching)\nCommunity detection is an abstract unsupervised problem. It is abstract because there is no clear-cut definition or ground truth to compare against. The concept of a community in a network is subjective and highly context-dependent.\nA classical approach to community detection is based on pattern matching. Namely, we first explicitly define a community by a specific connectivity pattern of its members. Then, we search for these communities in the network.\n\n\n\n\n\n\nFigure 1: Cliques of different sizes. Taken from https://pythonhosted.org/trustedanalytics/python_api/graphs/graph-/kclique_percolation.html\n\n\n\nPerhaps, the strictest definition of a community is a clique: a group of nodes all connected to each other. Examples include triangles (3-node cliques) and fully-connected squares (4-node cliques). However, cliques are often too rigid for real-world networks. In social networks, for instance, large groups of friends rarely have every member connected to every other, yet we want to accept such “in-perfect” social circles as communities. This leads to the idea of relaxed versions of cliques, called pseudo-cliques.\nPseudo-cliques are defined by relaxing at least one of the following three dimensions of strictness:\n\nDegree: Not all nodes need to connect to every other node.\n\nk-plex: each node connects to all but k others in the group {footcite}seidman1978graph.\nk-core: each node connects to k others in the group {footcite}seidman1983network.\n\nDensity: The overall connection density can be lower.\n\n\\rho-dense subgraphs, with a minimum edge density of \\rho {footcite}goldberg1984finding.\n\nDistance: Nodes can be further apart.\n\nn-clique, where all nodes are within n steps of each other {footcite}luce1950connectivity.\n\nCombination of the above:\n\nn-clan and n-club {footcite}mokken1979cliques\nk-truss, a maximal subgraph where all edges participate in at least k-2 triangles {footcite}saito2008extracting,cohen2009graph,wang2010triangulation.\n\\rho-dense core, a subgraph with minimum conductance \\rho {footcite}koujaku2016dense.\n\n\n\n\n\n\n\n\nFigure 2: Illustation of different pseudo cliques. Taken from {footcite}koujaku2016dense."
  },
  {
    "objectID": "m05-clustering/modularity-02.html",
    "href": "m05-clustering/modularity-02.html",
    "title": "Modularity (Cont.)",
    "section": "",
    "text": "Figure 1: Illustration of how modularity measures assortativity relative to a null model.\nLet’s dive into the modularity formula! To put modularity into math terms, we need a few ingredients: - m: The total number of strings (edges) in our bag - n: The total number of balls (nodes) we have - A_{ij}: This tells us if ball i and ball j are connected by a string - \\delta(c_i,c_j): This is our color-checker. It gives us a 1 if balls i and j are the same color (same community), and 0 if they’re different.\nNow, the probability of pulling out a string out of m string and finding matching colors on both ends is:\n\\frac{1}{m} \\sum_{i=1}^n \\sum_{j=i+1}^n A_{ij} \\delta(c_i,c_j) = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j)\nWe set A_{ii} = 0 by assuming our network doesn’t have any “selfie strings” (where a ball is connected to itself). Also, we changed our edge counting a bit. Instead of counting each string once (which gave us m), we’re now counting each string twice (once from each end). That’s why we use 2m in the equation.\nNow, imagine we’ve cut all the strings, and we’re going to draw two balls at random with replacement. Here’s how our new bag looks: - We have 2m balls in total (1 string has 2 balls, and thus m strings have 2m balls in total). - A node with k edges correspond to the k of 2m balls in the bag. - The color of each ball in our bag matches the color (or community) of its node in the network.\nNow, what’s the chance of pulling out two balls of the same color?\n\\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\nwhere k_i is the degree (i.e., the number of edges) of node i, and C is the total number of communities (i.e., colors).\nHere’s what it means in simple terms: - We look at each color (c) one by one (the outer sum). - For each color, we figure out how many balls of that color are in our bag (\\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i)). - We divide by 2m to get the probability of drawing a ball of that color. - We then calculate the chance of grabbing that color twice in a row (\\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2). - Finally, we add up these chances for all C colors.\nPutting altogether, the modularity is defined by\n\\begin{align}\nQ &=\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\\end{align}\nEquivalently, a standard expression is given by\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)"
  },
  {
    "objectID": "m05-clustering/modularity-02.html#modularity-demo",
    "href": "m05-clustering/modularity-02.html#modularity-demo",
    "title": "Modularity (Cont.)",
    "section": "1 Modularity Demo",
    "text": "1 Modularity Demo\nLet’s learn how the modularity works by playing with a community detection game!\n\n\n\n\n\n\nExercise 1\n\n\n\n:class: tip\nFind communities by maximizing the modularity. {{ “Modularity maximization (two communities) 🎮”.replace(‘BASE_URL’, base_url) }}\n\n\nOne of the good things about modularity is that it can figure out how many communities there should be all by itself! 🕵️‍♀️ Let’s have some fun with this idea. We’re going to play the same game again, but this time, we’ll start with a different number of communities. See how the modularity score changes as we move things around.\n\n\n\n\n\n\nExercise 2\n\n\n\n:class: tip\nFind communities by maximizing the modularity. {{ “Modularity maximization (four communities) 🎮”.replace(‘BASE_URL’, base_url) }}\n\n\nNow, let’s take our modularity maximization for a real-world example! 🥋 We’re going to use the famous karate club network. This network represents friendships between members of a university karate club. It’s a classic in the world of network science, and it’s perfect for seeing how modularity works in practice.\n\n\n\n\n\n\nExercise 3\n\n\n\n:class: tip\nFind communities by maximizing the modularity. {{ “Modularity maximization (four communities) 🎮”.replace(‘BASE_URL’, base_url) }}"
  },
  {
    "objectID": "m05-clustering/modularity-02.html#limitation-of-modularity",
    "href": "m05-clustering/modularity-02.html#limitation-of-modularity",
    "title": "Modularity (Cont.)",
    "section": "2 Limitation of Modularity",
    "text": "2 Limitation of Modularity\nLike many other community detection methods, modularity is not a silver bullet. Thanks to extensive research, we know many limitations of modularity. Let’s take a look at a few of them.\n\nResolution limit\nThe modularity finds two cliques connected by a single edge as two separate communities. But what if we add another community to this network? Our intuition tells us that, because communities are local structure, the two cliques should remain separated by the modularity. But is this the case?\n\n\n\n\n\n\nExercise 4\n\n\n\n:class: tip\nFind communities by maximizing the modularity. {{ “Modularity maximization (four communities) 🎮”.replace(‘BASE_URL’, base_url) }}\n\n\n\n\n\n\nClick here to see the solution\n\n\n\n\n\nThe best modularity score actually comes from merging our two cliques into one big community. This behavior is what we call the Resolution limit {footcite}fortunato2007resolution. Modularity can’t quite make out communities that are smaller than a certain size!\nThink of it like this: modularity is trying to see the big picture, but it misses the little details. In network terms, the number of edges m_c in a community c has to be bigger than a certain size. This size is related to the total number of edges m in the whole network. We write this mathematically as {\\cal O}(m).\n\n### Spurious communities\n\nWhat if the network does not have any communities at all? Does the modularity find no communities? To find out, let's run the modularity on a random network, where each pair of nodes is connected randomly with the same probability.\n\n::: {.callout-note title=\"Exercise 5\"}\n:class: tip\n\nFind communities by maximizing the modularity. {{ \"&lt;a href='BASE_URL/vis/community-detection/index.html?scoreType=modularity&numCommunities=3&randomness=0.8&dataFile=random-net.json'&gt;Modularity maximization (four communities) 🎮&lt;/a&gt;\".replace('BASE_URL', base_url) }}\n\n::: {.callout collapse=\"true\"}\n## Click here to see the solution\n\nSurprise, surprise! 😮 Modularity finds communities even in our random network, and with a very high score too! It's like finding shapes in clouds - sometimes our brains (or algorithms) see patterns where there aren't any.\n\nThe wild thing is that the modularity score for this random network is even higher than what we saw for our network with two clear cliques!\n\nThis teaches us two important lessons:\n1. We can't compare modularity scores between different networks. It's like comparing apples and oranges! 🍎🍊\n2. A high modularity score doesn't always mean we've found communities.\n\nInterested readers can read more about this in [this tweet by Tiago Peixoto](https://twitter.com/tiagopeixoto/status/1466352013856358400) and the discussion [here](https://reticular.hypotheses.org/1924).\n\n&lt;blockquote class=\"twitter-tweet\" style=\"max-width: 550px;\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Modularity maximization is not a reliable method to find communities in networks. Here&#39;s a simple example showing why:&lt;br&gt;&lt;br&gt;1. Generate an Erdős-Rényi random graph with N nodes and average degree &lt;k&gt;.&lt;br&gt;&lt;br&gt;2. Find the maximum modularity partition. &lt;a href=\"https://t.co/MTt5DdFXSX\"&gt;pic.twitter.com/MTt5DdFXSX&lt;/a&gt;&lt;/p&gt;&mdash; Tiago Peixoto (@tiagopeixoto) &lt;a href=\"https://twitter.com/tiagopeixoto/status/1466352013856358400?ref_src=twsrc%5Etfw\"&gt;December 2, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n3 So should we avoid modularity?\nThe simple answer is no. Modularity is still a powerful tool for finding communities in networks. Like any other method, it has its limitations. And knowing these limitations is crucial for using it effectively. There is “free lunch” in community detection {footcite}peel2017ground.\nWhen these implicit assumptions are met, modularity is in fact a very powerful method for community detection. For example, it is in fact an “optimal” method for a certain class of networks {footcite}nadakuditi2012graph.\nSo, keep modularity in your toolbox. Just remember to use it wisely!"
  },
  {
    "objectID": "m05-clustering/modularity-02.html#so-should-we-avoid-modularity",
    "href": "m05-clustering/modularity-02.html#so-should-we-avoid-modularity",
    "title": "Modularity (Cont.)",
    "section": "3 So should we avoid modularity?",
    "text": "3 So should we avoid modularity?\nThe simple answer is no. Modularity is still a powerful tool for finding communities in networks. Like any other method, it has its limitations. And knowing these limitations is crucial for using it effectively. There is “free lunch” in community detection {footcite}peel2017ground.\nWhen these implicit assumptions are met, modularity is in fact a very powerful method for community detection. For example, it is in fact an “optimal” method for a certain class of networks {footcite}nadakuditi2012graph.\nSo, keep modularity in your toolbox. Just remember to use it wisely!"
  },
  {
    "objectID": "m05-clustering/03-exercises.html#modularity-maximization",
    "href": "m05-clustering/03-exercises.html#modularity-maximization",
    "title": "Advanced Topics in Network Science",
    "section": "1.1 Modularity maximization",
    "text": "1.1 Modularity maximization\nLet us showcase how to use igraph to detect communities with modularity. We will use the Karate Club Network as an example.\n\nimport igraph\ng = igraph.Graph.Famous(\"Zachary\")\nigraph.plot(g, vertex_size=20)\n\nWhen it comes to maximizing modularity, there are a variety of algorithms to choose from. Two of the most popular ones are the Louvain and Leiden algorithms, both of which are implemented in igraph. The Louvain algorithm has been around for quite some time and is a classic choice, while the Leiden algorithm is a newer bee that often yields better accuracy. For our example, we’ll be using the Leiden algorithm, and I think you’ll find it really effective!\n\ncommunities = g.community_leiden(resolution=1, objective_function= \"modularity\")\n\nWhat is resolution? It is a parameter that helps us tackle the resolution limit of the modularity maximization algorithm {footcite}fortunato2007resolution! In simple terms, when we use the resolution parameter \\rho, the modularity formula can be rewritten as follow:\n\nQ(M) = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left(A_{ij} - \\rho \\frac{k_i k_j}{2m}\\right) \\delta(c_i, c_j)\n\nHere, the parameter \\rho plays a crucial role in balancing the positive and negative parts of the equation. The resolution limit comes into play because of the diminishing effect of the negative term as the number of edges m increases. The parameter \\rho can adjust this balance and allow us to circumvent the resolution limit.\nWhat is communities? This is a list of communities, where each community is represented by a list of nodes by their indices.\n\nprint(communities)\n\nLet us visualize the communities by coloring the nodes in the graph.\n\nimport seaborn as sns\ncommunity_membership = communities.membership\npalette = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[palette[i] for i in community_membership])\n\n\ncommunity_membership: This is a list of community membership for each node.\npalette: This is a list of colors to use for the communities.\nigraph.plot(g, vertex_color=[palette[i] for i in community_membership]): This plots the graph ‘g’ with nodes colored by their community.\n\n\nExercise 01 🏋️‍♀️💪🧠\n\nSelect a network of your choice from Netzschleuder. For convenience, choose a network of nodes less than 5000.\nDownload the csv version of the data by clicking something like “3KiB” under csv column.\nUnzip the file and find “edges.csv”, open it with a text editor to familiarize yourself with the format.\nLoad the data using pandas.\nGet the source and target nodes from the data to create an edge list.\nConstruct a graph from the edge list, either using igraph or scipy.\nFind communities by maximizing the modularity and visualize them.\nTry at least three different values of the resolution parameter and observe how the community structure changes.\n\n\n# Your code here",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/03-exercises.html#stochstic-block-model",
    "href": "m05-clustering/03-exercises.html#stochstic-block-model",
    "title": "Advanced Topics in Network Science",
    "section": "1.2 Stochstic Block Model",
    "text": "1.2 Stochstic Block Model\nLet us turn the SBM as our community detection tool using graph-tool. This is a powerful library for network analysis, with a focus on the stochastic block model.\n\n#\n# Uncomment the following code if you are using Google Colab\n#\n#!wget https://downloads.skewed.de/skewed-keyring/skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n#!dpkg -i skewed-keyring_1.0_all_$(lsb_release -s -c).deb\n#!echo \"deb [signed-by=/usr/share/keyrings/skewed-keyring.gpg] https://downloads.skewed.de/apt $(lsb_release -s -c) main\" &gt; /etc/apt/sources.list.d/skewed.list\n#!apt-get update\n#!apt-get install python3-graph-tool python3-matplotlib python3-cairo\n#!apt purge python3-cairo\n#!apt install libcairo2-dev pkg-config python3-dev\n#!pip install --force-reinstall pycairo\n#!pip install zstandard\n\nWe will identify the communities using the stochastic block model as follows. First, we will convert the graph object in igraph to that in graph-tool.\n\nimport graph_tool.all  as gt\nimport numpy as np\nimport igraph\n\n# igraph object\ng = igraph.Graph.Famous(\"Zachary\")\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Convert the graph object in igraph to that in graph-tool\nedges = g.get_edgelist()\nr, c = zip(*edges)\ng_gt = gt.Graph(directed=False)\ng_gt.add_edge_list(np.vstack([r, c]).T)\n\nThen, we will fit the stochastic block model to the graph.\n\n# Fit the stochastic block model\nstate = gt.minimize_blockmodel_dl(\n     g_gt,\n     state_args={\"deg_corr\": False, \"B_min\":2, \"B_max\":10},\n)\nb = state.get_blocks()\n\n\nB_min and B_max are the minimum and maximum number of communities to consider.\ndeg_corr is a boolean flag to switch to the degree-corrected SBM {footcite}karrer2011stochastic.\n\nHere's a fun fact: the likelihood maximization on its own can't figure out how many communities there should be. But `graph-tool` has a clever trick to circumvent this limitation.\n`graph-tool` actually fits multiple SBMs, each with a different number of communities. Then, it picks the most plausible one based on a model selection criterion.\nLet’s visualize the communities to see what we got.\n\n:tags: [\"hide-input\"]\n# Convert the block assignments to a list\ncommunity_membership = b.get_array()\n\n# The community labels may consist of non-consecutive integers, e.g., 10, 8, 1, 4, ...\n# So we reassign the community labels to be 0, 1, 2, ...\ncommunity_membership = np.unique(community_membership, return_inverse=True)[1]\ncommunity_membership\n\n\n# Create a color palette\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npalette = sns.color_palette().as_hex()\n# Plot the graph with nodes colored by their community\nfig, ax = plt.subplots(figsize=(10, 8))\nigraph.plot(\n    g,\n    target=ax,\n    vertex_color=[palette[i] for i in community_membership],\n)\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\nWhat we’re seeing here isn’t a failure at all. In fact, it’s the best partition according to our stochastic block model. The model has discovered something called a core-periphery structure {footcite}borgatti2000models. Let me break that down:\n\nThink of a major international airport (the core) and smaller regional airports (the periphery).\nMajor international airports have many flights connecting to each other (densely connected).\nSmaller regional airports have fewer connections among themselves (sparsely connected).\nMany regional airports have flights to major hubs (periphery connected to the core).\n\nThat’s exactly what our model found in this network.\nIf we look at the adjacency matrix, we would see something that looks like an upside-down “L”. This shape is like a signature for core-periphery structures.\n\n# Convert igraph Graph to adjacency matrix\nA = np.array(g.get_adjacency().data)\n\n# Sort nodes based on their community (core first, then periphery)\nsorted_indices = np.argsort(community_membership)\nA_sorted = A[sorted_indices][:, sorted_indices]\n\n# Plot the sorted adjacency matrix\nplt.figure(figsize=(10, 8))\nplt.imshow(A_sorted, cmap='binary')\nplt.title(\"Sorted Adjacency Matrix: Core-Periphery Structure\")\nplt.xlabel(\"Node Index (sorted)\")\nplt.ylabel(\"Node Index (sorted)\")\n\nplt.tight_layout()\nplt.show()\n\n\nExercise 02 🏋️‍♀️💪🧠\n\nSelect a network of your choice from Netzschleuder. For convenience, choose a network of nodes less than 5000.\nDownload the csv version of the data by clicking something like “3KiB” under csv column.\nUnzip the file and find “edges.csv”, open it with a text editor to familiarize yourself with the format.\nLoad the data using pandas.\nGet the source and target nodes from the data to create an edge list.\nConstruct a graph from the edge list, either using igraph or scipy.\nFind communities by fitting the stochastic block model and visualize them.\nTry deg_corr=True and compare the results with those from deg_corr=False.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html",
    "href": "m05-clustering/01-concepts.html",
    "title": "Module 5: Clustering Concepts",
    "section": "",
    "text": "In this module, we will learn community detection, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is community structure in networks? - How to operationalize community structure? - How to find communities in networks? - Limitations of community detection - Keywords: community detection, assortativity, modularity, resolution limit, rugged landscape, random graph, label switching algorithm, Louvain algorithm, stochastic block model, the configuration model.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#what-to-learn-in-this-module",
    "href": "m05-clustering/01-concepts.html#what-to-learn-in-this-module",
    "title": "Module 5: Clustering Concepts",
    "section": "",
    "text": "In this module, we will learn community detection, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is community structure in networks? - How to operationalize community structure? - How to find communities in networks? - Limitations of community detection - Keywords: community detection, assortativity, modularity, resolution limit, rugged landscape, random graph, label switching algorithm, Louvain algorithm, stochastic block model, the configuration model.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#understanding-communities-in-networks",
    "href": "m05-clustering/01-concepts.html#understanding-communities-in-networks",
    "title": "Module 5: Clustering Concepts",
    "section": "2 Understanding communities in networks",
    "text": "2 Understanding communities in networks\nBirds of a feather flock together, and so do many other things. For instance, we have a group of friends with similar interests who hang out together frequently but may not interact as much with other groups.\n\n\n\nBirds of a feather\n\n\nIn networks, communities are groups of nodes that share similar connection patterns. These communities do not always mean densely-connected nodes. Sometimes, a community can be nodes that are not connected to each other, but connect similarly to other groups. For instance, in a user-movie rating network, a community might be users with similar movie tastes, even if they don’t directly connect to each other.\n\n\n\nCommunity structure in a social network\n\n\nCommunities reflect underlying mechanisms of network formation and underpin the dynamics of information propagation. Examples include:\n\nHomophily: The tendency of similar nodes to form connections.\nFunctional groups: Nodes that collaborate for specific purposes.\nHierarchical structure: Smaller communities existing within larger ones.\nInformation flow: The patterns of information, influence, or disease propagation through the network.\n\nThis is why network scientists are sooo obsessed with community structure in networks. See {footcite}fortunato2010community,fortunato2016community,peixoto2019bayesian for comprehensive reviews on network communities.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#pattern-matching-approach",
    "href": "m05-clustering/01-concepts.html#pattern-matching-approach",
    "title": "Module 5: Clustering Concepts",
    "section": "3 Pattern matching approach",
    "text": "3 Pattern matching approach\nCommunity detection is an abstract unsupervised problem. It is abstract because there is no clear-cut definition or ground truth to compare against. The concept of a community in a network is subjective and highly context-dependent.\nA classical approach to community detection is based on pattern matching. Namely, we first explicitly define a community by a specific connectivity pattern of its members. Then, we search for these communities in the network.\n\n\n\n\n\n\nFigure 1: Cliques of different sizes. Taken from https://pythonhosted.org/trustedanalytics/python_api/graphs/graph-/kclique_percolation.html\n\n\n\nPerhaps, the strictest definition of a community is a clique: a group of nodes all connected to each other. Examples include triangles (3-node cliques) and fully-connected squares (4-node cliques). However, cliques are often too rigid for real-world networks. In social networks, for instance, large groups of friends rarely have every member connected to every other, yet we want to accept such “in-perfect” social circles as communities. This leads to the idea of relaxed versions of cliques, called pseudo-cliques.\nPseudo-cliques are defined by relaxing at least one of the following three dimensions of strictness:\n\nDegree: Not all nodes need to connect to every other node.\n\nk-plex: each node connects to all but k others in the group {footcite}seidman1978graph.\nk-core: each node connects to k others in the group {footcite}seidman1983network.\n\nDensity: The overall connection density can be lower.\n\n\\rho-dense subgraphs, with a minimum edge density of \\rho {footcite}goldberg1984finding.\n\nDistance: Nodes can be further apart.\n\nn-clique, where all nodes are within n steps of each other {footcite}luce1950connectivity.\n\nCombination of the above:\n\nn-clan and n-club {footcite}mokken1979cliques\nk-truss, a maximal subgraph where all edges participate in at least k-2 triangles {footcite}saito2008extracting,cohen2009graph,wang2010triangulation.\n\\rho-dense core, a subgraph with minimum conductance \\rho {footcite}koujaku2016dense.\n\n\n\n\n\n\n\n\nFigure 2: Illustation of different pseudo cliques. Taken from {footcite}koujaku2016dense.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#graph-cut-optimization-approach",
    "href": "m05-clustering/01-concepts.html#graph-cut-optimization-approach",
    "title": "Module 5: Clustering Concepts",
    "section": "4 Graph cut optimization approach",
    "text": "4 Graph cut optimization approach\nAnother approach from computer science is to treat a community detection problem as an optimization problem. An early example is the graph cut problem, which asks to find the minimum number of edges to cut the graph into two disconnected components.\nSpecifically, let us consider cutting the network into two communities. Let V_1 and V_2 be the set of nodes in the two communities. Then, the cut is the number of edges between the two communities, which is given by\n\n\\begin{align}\n\\text{Cut}(V_1, V_2) = \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\\end{align}\n\nNow, the community detection problem is translated into an optimization problem, with the goal of finding a cut V_1, V_2 that minimizes \\text{Cut}(V_1, V_2).\nThe description of this problem is not complete 😈. Let’s find out what is missing by playing with the optimization problem.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCan you identify what is missing in the description of the graph cut problem? Without this, the best cut is trivial. {{ “Graph Cut Problem 🎮”.replace(‘BASE_URL’, base_url) }}\n\n\n\n\n\n\nClick to reveal the answer!\nThe missing element is a constraint: each community must contain at least one node. Without this, the trivial solution of placing all nodes in a single community would always yield a cut of zero.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#modularity-measuring-assortativity-against-null-models",
    "href": "m05-clustering/01-concepts.html#modularity-measuring-assortativity-against-null-models",
    "title": "Module 5: Clustering Concepts",
    "section": "5 Modularity: measuring assortativity against null models",
    "text": "5 Modularity: measuring assortativity against null models\nModularity is by far the most widely used method for community detection. Modularity can be derived in many ways, but we will follow the one derived from assortativity.\nAssortativity is a measure of the tendency of nodes to connect with nodes of the same attribute. The attribute, in our case, is the community that the node belongs to, and we say that a network is assortative if nodes of the same community are more likely to connect with each other than nodes of different communities.\nLet’s think about assortativity by using color balls and strings! 🎨🧵\nImagine we’re playing a game as follows:\n\nPicture each connection in our network as two colored balls joined by a piece of string. 🔴🟢–🔵🟡\nThe color of each ball shows which community it belongs to.\nNow, let’s toss all these ball-and-string pairs into a big bag.\nWe’ll keep pulling out strings with replacement and checking if the balls on each end match colors.\n\nThe more color matches we find, the more assortative our network is. But, there’s a catch! What if we got lots of matches just by luck? For example, if all our balls were the same color, we’d always get a match. But that doesn’t tell us much about our communities. So, to be extra clever, we compare our results to a “random” version (null model):\n\nWe snip all the strings and mix up all the balls.\nThen we draw pairs of balls at random with replacement and see how often the colors match.\n\nBy comparing our original network to this mixed-up version, we can see if our communities are really sticking together more than we’d expect by chance. This comparison against the random version is the heart of modularity. Unlike graph cut methods that aim to maximize assortativity directly, modularity measures assortativity relative to a null model.\n\n\n\n\n\n\nFigure 3: Illustration of how modularity measures assortativity relative to a null model.\n\n\n\nNow, let’s put on our math hats and make this colorful game a bit more precise. Let’s introduce some helpful symbols to describe our network: - N: This is our total number of nodes (or balls in our game) - M: The number of edges (or strings) connecting our nodes - A_{ij}: Adjacency matrix. If A_{ij} = 1, it means node i and node j are connected. If A_{ij} = 0, they’re not connected. - k_i: Degree of node i, i.e., how many edges a node has. - c_i: Community of node i, i.e., which community a node belongs to. - \\delta(c_i, c_j): Kronecker delta function. It gives us 1 if nodes i and j are the same color, and 0 if they’re different.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nWhat is the probability of color matches for a given network? Derive the probability by using \\sum, M, A_{ij}, \\delta(c_i, c_j).\n\n\n\n\n\n\nHint\n\n\n\n\n\nLet’s think about our colorful bag of balls and strings! 🎨🧵 First, ask yourself: 1. How many strings do we have in total? (This is our M!) 2. Now, out of all these strings, how many are the same color on both ends?\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nWhat is the probability of color matches for the random version? Derive the probability by using \\sum, M, \\delta(c_i, c_j), k_i,k_j.\n\n\n\n\n\n\nHint 1. Imagine a big bag full of colorful balls, but this time without any strings. 🔴🟢🔵🟡 2. Now, think about picking one ball out of the bag. What are the chances of picking a specific color? 3. Then, put that ball back and pick another one. What are the odds this second ball matches the color of the first one?\n\n\n\n\n\nThe full modularity formula is covered in the coding section 😉.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/01-concepts.html#pen-and-paper-exercise",
    "href": "m05-clustering/01-concepts.html#pen-and-paper-exercise",
    "title": "Module 5: Clustering Concepts",
    "section": "6 Pen and Paper Exercise",
    "text": "6 Pen and Paper Exercise\n✍️ Pen and Paper Exercise 🚢",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html",
    "href": "m03-robustness/03-exercises.html",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "✍️ Pen and Paper Exercise",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#percolation-theory-and-network-connectivity",
    "href": "m03-robustness/03-exercises.html#percolation-theory-and-network-connectivity",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Consider a random network of N nodes, where every pair of nodes are connected by an edge with a certain probability. The degree k of a node follows a binomial distribution, which we approximate by a Poisson random variable with mean \\langle k \\rangle and variance \\langle k \\rangle.\n\nDerive \\langle k^2 \\rangle using \\langle k \\rangle.\n\nHint: Variance is defined as \\text{Var}(k) = \\langle (k-\\langle k \\rangle)^2 \\rangle.\n\nCompute the ratio \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}.\nCheck when the network satisfies the Molloy-Reed criterion.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSolution for Q1: To derive \\langle k^2 \\rangle, we start with the definition of variance\n\\text{Var}(k) = \\langle (k - \\langle k \\rangle)^2 \\rangle\nExpanding the square, we get\n\\text{Var}(k) = \\langle k^2 \\rangle - 2\\langle k \\rangle \\langle k \\rangle + \\langle k \\rangle^2\nSince \\text{Var}(k) = \\langle k \\rangle for a Poisson distribution, we can substitute and rearrange\n\\langle k \\rangle = \\langle k^2 \\rangle - \\langle k \\rangle^2\nSolving for \\langle k^2 \\rangle, we obtain\n\\langle k^2 \\rangle = \\langle k \\rangle + \\langle k \\rangle^2\nSolution for Q2: \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} = 1 + \\langle k \\rangle\nSolution for Q3: \\langle k \\rangle &gt;1. In other words, if a node has on average more than one neighbor, the random network is likely to have a giant component.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#network-design-challenges",
    "href": "m03-robustness/03-exercises.html#network-design-challenges",
    "title": "Exercises and Assignments",
    "section": "2 Network Design Challenges",
    "text": "2 Network Design Challenges\n🚀 Interactive Demo",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html",
    "href": "m03-robustness/01-concepts.html",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will explore network robustness through the lens of infrastructure design. Starting from the historical challenge of building cost-effective power grids, we will learn:\n\nHow minimum spanning trees provide optimal cost-efficiency for network connectivity\nWhy real-world networks have redundancies beyond minimum connectivity requirements\nHow networks respond to random failures versus targeted attacks\nQuantitative measures of network robustness and percolation theory\nDesign principles for balancing cost efficiency with resilience\n\nKeywords: minimum spanning tree, Kruskal’s algorithm, Prim’s algorithm, network redundancy, random failures, targeted attacks, connectivity loss, R-index, percolation, robustness paradox",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#what-to-learn-in-this-module",
    "href": "m03-robustness/01-concepts.html#what-to-learn-in-this-module",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will explore network robustness through the lens of infrastructure design. Starting from the historical challenge of building cost-effective power grids, we will learn:\n\nHow minimum spanning trees provide optimal cost-efficiency for network connectivity\nWhy real-world networks have redundancies beyond minimum connectivity requirements\nHow networks respond to random failures versus targeted attacks\nQuantitative measures of network robustness and percolation theory\nDesign principles for balancing cost efficiency with resilience\n\nKeywords: minimum spanning tree, Kruskal’s algorithm, Prim’s algorithm, network redundancy, random failures, targeted attacks, connectivity loss, R-index, percolation, robustness paradox",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#pen-and-paper-exercise-from-mst-to-robust-grid-design",
    "href": "m03-robustness/01-concepts.html#pen-and-paper-exercise-from-mst-to-robust-grid-design",
    "title": "Core Concepts",
    "section": "2 Pen-and-Paper Exercise: From MST to Robust Grid Design",
    "text": "2 Pen-and-Paper Exercise: From MST to Robust Grid Design\n\n✍️ Pen and Paper Exercise: Starting with a minimum spanning tree for cost efficiency, design a power grid network that maintains connectivity even when key components fail.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#power-grid-design-challenge",
    "href": "m03-robustness/01-concepts.html#power-grid-design-challenge",
    "title": "Core Concepts",
    "section": "4 Power Grid Design Challenge",
    "text": "4 Power Grid Design Challenge\nIn the aftermath of World War I, the newly formed Czechoslovakia faced massive reconstruction challenges. Cities and towns across Moravia needed electricity, but the young nation had limited resources. Every resources spent on unnecessary infrastructure was a resource not available for hospitals, schools, or economic recovery. Engineers at the West Moravian Power Company faced a critical question: How do you connect every town and village to the electrical grid while using the minimum length of cable?\n\n\nOtakar Borůvka (1899-1995) was a Czech mathematician who is best known for his work on the minimum spanning tree problem.\n\nThe problem reached mathematician Otakar Borůvka through his friend at the power company. Borůvka’s 1926 solution gave us the first systematic approach to what we now call the minimum spanning tree problem: finding the cheapest way to connect all locations in a network.\n\nMinimum Spanning Tree\nA minimum spanning tree (MST) of a weighted network is a tree that:\n\nSpans all nodes (connects every location in the network)\nIs a tree (connected with no cycles - no redundant loops)\nHas minimum total weight among all possible spanning trees\n\nOtakar Borůvka delivered the first algorithm to solve this problem: Borůvka’s algorithm. But it is not the only algorithm to find the minimum spanning tree. In fact, there are several algorithms. We will cover two algorithms: Kruskal’s algorithm and Prim’s algorithm, which are easier to understand and implement.\n\n\nFinding the Minimum Spanning Tree\n\n\n\n\n\nKruskal’s Algorithm\nKruskal’s algorithm embodies a remarkably simple yet powerful intuition: always choose the cheapest available option, but never create wasteful loops. While sounds heuristic, this algorithm in fact leads to the global optimial solution!\nThe algorithm works by first sorting every possible connection from cheapest to most expensive like arranging all the cable segments by cost. Then, it examines each connection in order, asking a crucial question: “If I add this cable, will it create a redundant loop?” If the answer is no, the cable joins the growing network. If adding it would create a cycle—meaning the two locations are already connected through some other path—the algorithm skips it as wasteful. This process continues until every location is connected, guaranteeing both minimum cost and complete coverage.\n\n\nPrim’s Algorithm\nPrim’s algorithm takes a fundamentally different approach, embodying the intuition of organic growth from a single starting point. Picture an engineer beginning at the central power plant and asking: “What’s the cheapest way to connect one more location to our existing grid?” This local growth strategy builds the network incrementally, always expanding from what’s already been constructed.\nThe algorithm begins by selecting any location as its starting point, often the power plant in our analogy. From this initial seed, it repeatedly identifies the cheapest connection that would bring a new, unconnected location into the growing network. Unlike Kruskal’s global view, Prim’s algorithm maintains a clear distinction between locations already in the network and those still waiting to be connected. At each step, it finds the minimum-cost bridge between these two groups, gradually expanding the connected region until it encompasses every location.\nThis local expansion strategy mirrors how many real-world infrastructure projects actually develop. Engineers often start from existing facilities and expand outward, always seeking the most cost-effective way to serve additional areas. Prim’s algorithm formalizes this natural growth process.\n\n    \n    \n    \n    mo.vstack(%0A%20%20%20%20%5B%0A%20%20%20%20%20%20%20%20unique_weights%2C%0A%20%20%20%20%20%20%20%20time_step%2C%0A%20%20%20%20%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%20%20%20%20%22**Instructions**%3A%20Move%20the%20slider%20to%20see%20how%20each%20algorithm%20builds%20the%20MST%20step%20by%20step.%22%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%5D%0A)\n\n\n    \n    \n    \n    fig\n\n\n\n\n\n\n\nNote\n\n\n\nTwo algorithms find the same minimum spanning tree when all connection costs are different. If there are connections with the same cost, there are multiple minimum spanning trees of the same cost, and which tree to find depends on the algorithm. In particular, Prim’s algorithm finds different trees when starting from different locations.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#why-minimum-spanning-tree-is-not-enough",
    "href": "m03-robustness/01-concepts.html#why-minimum-spanning-tree-is-not-enough",
    "title": "Core Concepts",
    "section": "5 Why Minimum Spanning Tree is Not Enough",
    "text": "5 Why Minimum Spanning Tree is Not Enough\nMinimum spanning tree is an efficient way to connect all locations in a network with the minimum total cost. However, such a network is vulnerable to failures, e.g., the network can be disconnected when a single node fails, in particular those close to the center of the network. This is why our power grid has a lot of redundancies beyond the minimum spanning tree, for the sake of resilience against failures.\n\n\n\n\n\n\nFigure 1: This is the power grid of the United States.\n\n\n\n\nMeasuring Network Damage\nNot every failure is equal. Some failures are more damaging than others. For example, removing somee nodes in a grid network can be catastrophic, while removing other nodes can be more tolerable.\nWhile there can be many metrics to quantify network damage, we will focus on a purely topological metric: the fraction of nodes remaining in the largest connected component after removal.\n\n\\text{Connectivity} = \\frac{\\text{Size of largest component after removal}}{\\text{Original network size}}\n\n\n\n\n\n\n\nFigure 2\n\n\n\nThe robustness profile plots connectivity against the fraction of nodes removed, revealing how networks fragment. Crucially, the shape of this profile depends entirely on the order in which nodes are removed - random removal creates one pattern, while strategic targeting creates dramatically different patterns.\n\n\n\n\n\n\nFigure 3\n\n\n\nTo compare networks with a single metric, we use the R-index - the area under this curve:\n\nR = \\frac{1}{N} \\sum_{k=1}^{N-1} y_k\n\nThe robustness index is a measure of how robust a network is to under a sequential failure of nodes. The higher the R-index, the more robust the network is.\nNetworks can exhibit different robustness profiles under different attack strategies. One form of an attack is a random failure, where nodes are removed randomly. Another form of an attack is a targeted attack, where nodes are removed strategically.\nRandom failures are like earthquakes or equipment malfunctions; they strike unpredictably. In power grids, generators might fail due to technical problems. In computer networks, servers might crash randomly.\nEven if a network survives random failures beautifully, it might crumble under targeted attacks. Adversaries strategically choose which nodes to attack for maximum damage. The most intuitive strategy targets high-degree nodes (hubs) first, i.e., like targeting the busiest airports to disrupt air travel.\n\n\nThe asymmetry between random failures and targeted attacks is one of the most counterintuitive discoveries in network science. A network that seems robust can have hidden vulnerabilities that smart adversaries can exploit.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#theoretical-framework-for-network-robustness",
    "href": "m03-robustness/01-concepts.html#theoretical-framework-for-network-robustness",
    "title": "Core Concepts",
    "section": "6 Theoretical Framework for Network Robustness",
    "text": "6 Theoretical Framework for Network Robustness\nTo understand these patterns mathematically, we can view network attacks as the reverse process of percolation. Percolation theory studies phase transitions in connectivity by asking: as we randomly add nodes to a grid, when does a giant connected component emerge? Network robustness asks the opposite: as we remove nodes, when does the giant component disappear?\n\n\nPercolation theory originated in physics to understand how liquids flow through porous materials. The same mathematics explains how networks fragment under node removal - a beautiful example of how physics concepts illuminate network behavior.\n\n    \n    \n    \n    p_slider\n\n\n    \n    \n    \n    percolation_visualization()\n\n\n\nPercolation vs. Robustness: Two Sides of the Same Coin\nPercolation theory asks: “Starting from isolation, how many nodes must we connect to form a giant component?” - increasing connectivity from p = 0 to p = 1.\nRobustness analysis asks: “Starting from full connectivity, how many nodes must we remove to fragment the network?” - decreasing connectivity from p = 1 to p = 0.\nThese are mathematically equivalent processes, just viewed in opposite directions along the same connectivity parameter.\n\nThe Phase Transition\nImagine a grid where each square randomly becomes a “puddle” with probability p. As p increases, something dramatic happens - suddenly, a giant puddle spanning the entire grid appears! This phase transition occurs at a critical probability p_c. Crucially, the exact timing doesn’t matter; only the fraction of nodes present or removed determines connectivity.\n\n    \n    \n    \n    p_slider\n\n\n    \n    \n    \n    phase_transition_plot()\n\n\n\nThe Molloy-Reed Criterion\nFor networks with arbitrary degree distributions, the Molloy-Reed criterion determines whether a giant component exists - that is, whether the network contains a single large connected component that includes most of the nodes:\n\n\\kappa = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} &gt; 2\n\nwhere \\langle k \\rangle is the average degree and \\langle k^2 \\rangle is the average of squared degrees. The ratio \\kappa measures degree heterogeneity - networks with hubs have high \\kappa, while degree homogeneous networks have low \\kappa. When \\kappa &gt; 2, a giant component forms that dominates the network connectivity. See the Appendix for the proof of the Molloy-Reed criterion.\nThe Molloy-Reed criterion is a powerful tool to predict the existence of a giant component in a network and allows us to find the critical fraction of nodes that must be removed to break the network. This critial fraction depends on the strategy of the attack, along with the degree distribution. For simplicity, let us restrict ourselves into the random failures. For the random failure case, the critical fraction is given by:\n\nf_c = 1 - \\frac{1}{\\kappa - 1}\n\nThe value of \\kappa depends on the degree distribution, and below, we showcase two examples of degree distributions.\n\nDegree homogeneous network\nIn case of a degree homogeneous network like a random network considered in the exercise above, the critical fraction is given by:\n\nf_c = 1 - \\frac{1}{\\langle k \\rangle}\n\ngiven that \\langle k^2 \\rangle = \\langle k \\rangle^2 and thus \\kappa = \\langle k \\rangle. This suggests that the threshold is determined by the average degree \\langle k \\rangle. A large \\langle k \\rangle results in a larger f_c, meaning that the network is more robust against random failures.\n\n\nDegree heterogeneous network\nMost real-world networks are degree heterogeneous, i.e., the degree distribution P(k) \\sim k^{-\\gamma} follows a power law (called scale-free network). The power-law degree distribution has infinite second moment, i.e., \\langle k^2 \\rangle = \\infty and thus f_c = 1.0, which means that all nodes must be removed to break the network into disconnected components. This is the case where the number of nodes is infinite (i.e., so that a node has a very large degree for the degree distribution to be a valid power law). When restricting the maximum degree to be finite, the critical fraction is given by:\n\nf_c =\n\\begin{cases}\n1 - \\dfrac{1}{\\frac{\\gamma-2}{3-\\gamma} k_{\\text{min}} ^{\\gamma-2} k_{\\text{max}}^{3-\\gamma} -1} & \\text{if } 2 &lt; \\gamma &lt; 3 \\\\\n1 - \\dfrac{1}{\\frac{\\gamma-2}{\\gamma-3} k_{\\text{min}} - 1} & \\text{if } \\gamma &gt; 3 \\\\\n\\end{cases}\n\nwhere k_{\\text{min}} and k_{\\text{max}} are the minimum and maximum degree, respectively. The variable \\gamma is the exponent of the power law degree distribution, controlling the degree heterogeneity, where a lower \\gamma results in a more degree heterogeneous network.\n\nFor regime 2 &lt; \\gamma &lt; 3, the critical threshold f_c is determined by the extreme values of the degree distribution, k_{\\text{min}} and k_{\\text{max}}. And f_c \\rightarrow 1 when the maximum degree k_{\\text{max}} \\in [k_{\\text{min}}, N-1] increases. Notably, in this regime, the maximum degree k_{\\text{max}} increases as the network size N increases, and this makes f_c \\rightarrow 1.\nFor regime \\gamma &gt; 3, the critical threshold f_c is influenced by the minimum degree k_{\\text{min}}. In contrast to k_{\\text{max}}, k_{\\text{min}} remains constant as the network size N grows. Consequently, the network disintegrates when a finite fraction of its nodes are removed.\n\n\n    \n    \n    \n    chart_fc\n\n\n\n\nRobustness Under Attack\nWhile scale-free networks show remarkable robustness against random failures, they exhibit a fundamental vulnerability to targeted attacks that deliberately target high-degree nodes (hubs). This asymmetry reveals the “Achilles’ heel” property of complex networks, where the same structural features that provide robustness against random failures create critical vulnerabilities to strategic attacks.\nRather than removing nodes randomly, an adversary with knowledge of the network structure can systematically remove the highest-degree nodes first, followed by the next highest-degree nodes, and so on. Under this targeted hub removal strategy, scale-free networks fragment rapidly and dramatically. The critical threshold for attacks, f_c^{\\text{attack}}, is dramatically lower than for random failures. While random failures require f_c^{\\text{random}} \\approx 1 (nearly all nodes must be removed), targeted attacks need only f_c^{\\text{attack}} \\ll 1 (a small fraction of hubs) to fragment the network.\nTo understand how networks fragment under targeted attacks, we must consider two key effects that occur when the highest-degree nodes are systematically removed. First, the removal of hub nodes changes the maximum degree of the remaining network from k_{\\max} to a new lower value k'_{\\max}. Second, since these removed hubs had many connections, their elimination also removes many links from the network, effectively changing the degree distribution of the surviving nodes.\nThe mathematical analysis of this process relies on mapping the attack problem back to the random failure framework through careful accounting of these structural changes. When we remove an f fraction of the highest-degree nodes in a scale-free network, the new maximum degree becomes k'_{\\max} = k_{\\min} f^{1/(1-\\gamma)}, where the power-law exponent \\gamma determines how rapidly the degree sequence declines.\nFor scale-free networks with degree exponent \\gamma, the critical attack threshold f_c satisfies:\n\nf_c^{\\frac{2-\\gamma}{1-\\gamma}} = \\frac{2 + 2^{-\\gamma}}{3-\\gamma} k_{\\min} \\left(f_c^{\\frac{3-\\gamma}{1-\\gamma}} - 1\\right)\n\nThe fractional exponents (2-\\gamma)/(1-\\gamma) and (3-\\gamma)/(1-\\gamma) arise from the power-law degree distribution and determine how quickly the network fragments as hubs are removed. For networks with \\gamma &lt; 3 (highly heterogeneous degree distributions), these exponents are negative, leading to extremely small values of f_c, i.e., meaning just a tiny fraction of hub removal can destroy network connectivity.\nThis vulnerability has profound real-world implications across multiple domains. Power grids invest heavily in protecting major substations and transmission hubs because their failure could cascade throughout the system. Internet infrastructure includes hub redundancy and protection protocols to maintain connectivity when major routing nodes are compromised. Transportation networks maintain backup routes and alternative pathways when major airports or train stations fail. Even biological systems have evolved protective mechanisms for critical proteins that serve as hubs in cellular networks.\nThe robustness paradox demonstrates that no single network structure can be optimal against all types of failures. There’s always a fundamental trade-off between efficiency, which naturally favors hub-based architectures for optimal resource distribution, and security, which requires redundancy and distributed connectivity to prevent catastrophic failures from targeted attacks.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#design-principles-for-robust-networks",
    "href": "m03-robustness/01-concepts.html#design-principles-for-robust-networks",
    "title": "Core Concepts",
    "section": "7 Design Principles for Robust Networks",
    "text": "7 Design Principles for Robust Networks\nHow do we design networks that resist both random failures and targeted attacks? Key principles include:\n\nBalanced Degree Distribution: Avoid both extreme homogeneity and extreme hub concentration\nMultiple Redundant Pathways: Ensure removing any single node doesn’t isolate large portions\nStrategic Hub Protection: In hub-based networks, invest heavily in protecting critical nodes\nHierarchical Design: Combine local clusters with hub connections and redundant backbones\nAdaptive Responses: Design systems that can reconfigure when attacks are detected\n\nThese strategies reflect lessons learned from our historical power grid challenge: moving beyond the minimum spanning tree to create networks that balance efficiency with resilience.\n\n\n    \n    \n    \n    import%20marimo%20as%20mo%0Aimport%20matplotlib.pyplot%20as%20plt%0Aimport%20pandas%20as%20pd%0Aimport%20numpy%20as%20np%0Afrom%20scipy.ndimage%20import%20label%0Afrom%20matplotlib.colors%20import%20ListedColormap%0Afrom%20scipy.sparse%20import%20csr_matrix%0Afrom%20scipy.sparse.csgraph%20import%20connected_components%0A\n\n\n    \n    \n    \n    %23%20Control%20for%20edge%20weight%20uniqueness%0Aunique_weights%20%3D%20mo.ui.checkbox(%0A%20%20%20%20label%3D%22Use%20unique%20edge%20weights%20(when%20unchecked%2C%20some%20edges%20have%20same%20weight)%22%2C%0A%20%20%20%20value%3DTrue%2C%0A)%0A%0A%23%20Time%20step%20slider%20-%20fixed%20to%20accommodate%20MST%20(max%206%20edges%20for%207%20nodes)%0Atime_step%20%3D%20mo.ui.slider(%0A%20%20%20%20start%3D0%2C%0A%20%20%20%20stop%3D6%2C%20%20%23%20Fixed%20max%20for%20power%20grid%20(7%20nodes%20%3D%206%20MST%20edges)%0A%20%20%20%20step%3D1%2C%0A%20%20%20%20value%3D6%2C%20%20%23%20Start%20at%20final%20state%0A%20%20%20%20label%3D%22Algorithm%20Time%20Step%20(0%3Dstart%2C%206%3Dcomplete%20MST)%22%2C%0A)\n\n\n    \n    \n    \n    def%20create_power_grid_graph(use_unique_weights%3DTrue)%3A%0A%20%20%20%20%22%22%22Create%20power%20grid%20graph%20with%20nodes%20and%20edges%22%22%22%0A%0A%20%20%20%20%23%20Define%20nodes%20with%20positions%0A%20%20%20%20nodes%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%22A%22%3A%20(0%2C%201)%2C%0A%20%20%20%20%20%20%20%20%22B%22%3A%20(1%2C%202)%2C%0A%20%20%20%20%20%20%20%20%22C%22%3A%20(1%2C%200)%2C%0A%20%20%20%20%20%20%20%20%22D%22%3A%20(2%2C%202.5)%2C%0A%20%20%20%20%20%20%20%20%22E%22%3A%20(2%2C%201.5)%2C%0A%20%20%20%20%20%20%20%20%22F%22%3A%20(2%2C%200.5)%2C%0A%20%20%20%20%20%20%20%20%22G%22%3A%20(2%2C%20-0.5)%2C%0A%20%20%20%20%7D%0A%0A%20%20%20%20if%20use_unique_weights%3A%0A%20%20%20%20%20%20%20%20%23%20All%20weights%20are%20unique%0A%20%20%20%20%20%20%20%20edges%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22A%22%2C%20%22B%22%2C%208)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22A%22%2C%20%22C%22%2C%2012)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22B%22%2C%20%22D%22%2C%205)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22B%22%2C%20%22E%22%2C%207)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22C%22%2C%20%22F%22%2C%206)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22C%22%2C%20%22G%22%2C%204)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22D%22%2C%20%22E%22%2C%203)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22E%22%2C%20%22F%22%2C%209)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22F%22%2C%20%22G%22%2C%202)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22D%22%2C%20%22C%22%2C%2011)%2C%0A%20%20%20%20%20%20%20%20%5D%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%23%20Some%20weights%20are%20the%20same%20-%20multiple%20MSTs%20possible%0A%20%20%20%20%20%20%20%20edges%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22A%22%2C%20%22B%22%2C%208)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22A%22%2C%20%22C%22%2C%2012)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22B%22%2C%20%22D%22%2C%205)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22B%22%2C%20%22E%22%2C%207)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22C%22%2C%20%22F%22%2C%206)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22C%22%2C%20%22G%22%2C%204)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22D%22%2C%20%22E%22%2C%203)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22E%22%2C%20%22F%22%2C%2011)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22F%22%2C%20%22G%22%2C%202)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%22D%22%2C%20%22C%22%2C%2011)%2C%0A%20%20%20%20%20%20%20%20%5D%0A%0A%20%20%20%20return%20nodes%2C%20edges%0A%0A%0A%23%20Create%20the%20graph%20based%20on%20current%20setting%0Anodes%2C%20edges%20%3D%20create_power_grid_graph(unique_weights.value)%0A%0Adef%20kruskal_algorithm(nodes_dict%2C%20edges_list)%3A%0A%20%20%20%20%22%22%22Kruskal's%20algorithm%20implementation%20without%20networkx%22%22%22%0A%0A%20%20%20%20%23%20Step%201%3A%20Sort%20edges%20by%20weight%20(global%20perspective)%0A%20%20%20%20sorted_edges%20%3D%20sorted(edges_list%2C%20key%3Dlambda%20x%3A%20x%5B2%5D)%0A%0A%20%20%20%20%23%20Initialize%20Union-Find%20data%20structure%0A%20%20%20%20parent%20%3D%20%7B%7D%0A%20%20%20%20rank%20%3D%20%7B%7D%0A%0A%20%20%20%20%23%20Initialize%20all%20nodes%20in%20Union-Find%0A%20%20%20%20for%20node%20in%20nodes_dict%3A%0A%20%20%20%20%20%20%20%20parent%5Bnode%5D%20%3D%20node%0A%20%20%20%20%20%20%20%20rank%5Bnode%5D%20%3D%200%0A%0A%20%20%20%20def%20find(x)%3A%0A%20%20%20%20%20%20%20%20if%20parent%5Bx%5D%20!%3D%20x%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20parent%5Bx%5D%20%3D%20find(parent%5Bx%5D)%0A%20%20%20%20%20%20%20%20return%20parent%5Bx%5D%0A%0A%20%20%20%20def%20union(x%2C%20y)%3A%0A%20%20%20%20%20%20%20%20px%2C%20py%20%3D%20find(x)%2C%20find(y)%0A%20%20%20%20%20%20%20%20if%20px%20%3D%3D%20py%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20False%0A%20%20%20%20%20%20%20%20if%20rank%5Bpx%5D%20%3C%20rank%5Bpy%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20px%2C%20py%20%3D%20py%2C%20px%0A%20%20%20%20%20%20%20%20parent%5Bpy%5D%20%3D%20px%0A%20%20%20%20%20%20%20%20if%20rank%5Bpx%5D%20%3D%3D%20rank%5Bpy%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20rank%5Bpx%5D%20%2B%3D%201%0A%20%20%20%20%20%20%20%20return%20True%0A%0A%20%20%20%20mst_edges%20%3D%20%5B%5D%0A%20%20%20%20steps%20%3D%20%5B%5D%0A%0A%20%20%20%20for%20u%2C%20v%2C%20weight%20in%20sorted_edges%3A%0A%20%20%20%20%20%20%20%20if%20union(u%2C%20v)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20mst_edges.append((u%2C%20v%2C%20weight))%0A%20%20%20%20%20%20%20%20%20%20%20%20steps.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22edge%22%3A%20(u%2C%20v)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22weight%22%3A%20weight%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22action%22%3A%20%22added%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22reason%22%3A%20f%22Connects%20%7Bu%7D%20and%20%7Bv%7D%20without%20creating%20cycle%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Continue%20until%20we%20have%20a%20spanning%20tree%20OR%20all%20edges%20are%20processed%0A%20%20%20%20%20%20%20%20if%20len(mst_edges)%20%3D%3D%20len(nodes_dict)%20-%201%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20break%0A%0A%20%20%20%20return%20mst_edges%2C%20steps%0A%0A%0Adef%20prim_algorithm(nodes_dict%2C%20edges_list%2C%20start_node%3D%22A%22)%3A%0A%20%20%20%20%22%22%22Prim's%20algorithm%20implementation%20without%20networkx%22%22%22%0A%0A%20%20%20%20%23%20Create%20adjacency%20list%0A%20%20%20%20adj%20%3D%20%7Bnode%3A%20%5B%5D%20for%20node%20in%20nodes_dict%7D%0A%20%20%20%20for%20u%2C%20v%2C%20weight%20in%20edges_list%3A%0A%20%20%20%20%20%20%20%20adj%5Bu%5D.append((v%2C%20weight))%0A%20%20%20%20%20%20%20%20adj%5Bv%5D.append((u%2C%20weight))%0A%0A%20%20%20%20visited%20%3D%20%7Bstart_node%7D%0A%20%20%20%20mst_edges%20%3D%20%5B%5D%0A%20%20%20%20steps%20%3D%20%5B%5D%0A%0A%20%20%20%20steps.append(%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22node%22%3A%20start_node%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22action%22%3A%20%22start%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22reason%22%3A%20f%22Starting%20from%20%7Bstart_node%7D%22%2C%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20)%0A%0A%20%20%20%20while%20len(visited)%20%3C%20len(nodes_dict)%3A%0A%20%20%20%20%20%20%20%20min_weight%20%3D%20float(%22inf%22)%0A%20%20%20%20%20%20%20%20min_edge%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20%23%20Find%20cheapest%20edge%20from%20visited%20to%20unvisited%20nodes%0A%20%20%20%20%20%20%20%20for%20node%20in%20visited%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20neighbor%2C%20weight%20in%20adj%5Bnode%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20neighbor%20not%20in%20visited%20and%20weight%20%3C%20min_weight%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20min_weight%20%3D%20weight%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20min_edge%20%3D%20(node%2C%20neighbor%2C%20weight)%0A%0A%20%20%20%20%20%20%20%20if%20min_edge%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20u%2C%20v%2C%20weight%20%3D%20min_edge%0A%20%20%20%20%20%20%20%20%20%20%20%20visited.add(v)%0A%20%20%20%20%20%20%20%20%20%20%20%20mst_edges.append((u%2C%20v%2C%20weight))%0A%20%20%20%20%20%20%20%20%20%20%20%20steps.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22edge%22%3A%20(u%2C%20v)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22weight%22%3A%20weight%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22action%22%3A%20%22added%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22reason%22%3A%20f%22Cheapest%20connection%20from%20visited%20set%20to%20%7Bv%7D%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20return%20mst_edges%2C%20steps%0A%0A%0A%23%20Run%20both%20algorithms%0Akruskal_mst%2C%20kruskal_steps%20%3D%20kruskal_algorithm(nodes%2C%20edges)%0Aprim_mst%2C%20prim_steps%20%3D%20prim_algorithm(nodes%2C%20edges)%0A%0A%23%20Calculate%20total%20weights%0Akruskal_weight%20%3D%20sum(w%20for%20_%2C%20_%2C%20w%20in%20kruskal_mst)%0Aprim_weight%20%3D%20sum(w%20for%20_%2C%20_%2C%20w%20in%20prim_mst)%0A%0A%23%20Display%20algorithm%20results%20with%20current%20step%20information%0Aweight_match%20%3D%20%22%E2%9C%85%20Same%22%20if%20kruskal_weight%20%3D%3D%20prim_weight%20else%20%22%E2%9D%8C%20Different%22%0A%0A%23%20Get%20current%20step%20information%0Acurrent_step%20%3D%20time_step.value%0Amax_steps%20%3D%20len(%5Bs%20for%20s%20in%20kruskal_steps%20if%20s%5B%22action%22%5D%20%3D%3D%20%22added%22%5D)\n\n\n    \n    \n    \n    def%20visualize_both_algorithms()%3A%0A%20%20%20%20%22%22%22Create%20side-by-side%20visualization%20of%20both%20algorithms%20with%20time%20step%20control%22%22%22%0A%0A%20%20%20%20fig%2C%20(ax1%2C%20ax2)%20%3D%20plt.subplots(1%2C%202%2C%20figsize%3D(16%2C%208))%0A%0A%20%20%20%20%23%20Get%20edges%20to%20show%20up%20to%20current%20time%20step%20for%20each%20algorithm%0A%20%20%20%20current_step%20%3D%20time_step.value%0A%0A%20%20%20%20%23%20For%20Kruskal%3A%20edges%20added%20in%20order%20they%20appear%20in%20steps%0A%20%20%20%20kruskal_edges_to_show%20%3D%20%5B%5D%0A%20%20%20%20for%20i%2C%20step%20in%20enumerate(kruskal_steps)%3A%0A%20%20%20%20%20%20%20%20if%20i%20%3E%3D%20current_step%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20if%20step%5B%22action%22%5D%20%3D%3D%20%22added%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20u%2C%20v%20%3D%20step%5B%22edge%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20weight%20%3D%20step%5B%22weight%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20kruskal_edges_to_show.append((u%2C%20v%2C%20weight))%0A%0A%20%20%20%20%23%20For%20Prim%3A%20edges%20added%20in%20order%20they%20appear%20in%20steps%0A%20%20%20%20prim_edges_to_show%20%3D%20%5B%5D%0A%20%20%20%20for%20i%2C%20step%20in%20enumerate(prim_steps%5B1%3A%5D%2C%201)%3A%20%20%23%20Skip%20the%20'start'%20step%0A%20%20%20%20%20%20%20%20if%20i%20%3E%20current_step%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20if%20step%5B%22action%22%5D%20%3D%3D%20%22added%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20u%2C%20v%20%3D%20step%5B%22edge%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20weight%20%3D%20step%5B%22weight%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20prim_edges_to_show.append((u%2C%20v%2C%20weight))%0A%0A%20%20%20%20algorithms%20%3D%20%5B%0A%20%20%20%20%20%20%20%20(ax1%2C%20%22Kruskal's%20Algorithm%22%2C%20kruskal_edges_to_show)%2C%0A%20%20%20%20%20%20%20%20(ax2%2C%20%22Prim's%20Algorithm%22%2C%20prim_edges_to_show)%2C%0A%20%20%20%20%5D%0A%0A%20%20%20%20for%20ax%2C%20title%2C%20edges_to_show%20in%20algorithms%3A%0A%20%20%20%20%20%20%20%20ax.clear()%0A%20%20%20%20%20%20%20%20ax.set_facecolor(%22white%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Draw%20all%20possible%20edges%20-%20dashed%20for%20unconnected%0A%20%20%20%20%20%20%20%20mst_edge_set%20%3D%20set((u%2C%20v)%20for%20u%2C%20v%2C%20_%20in%20edges_to_show)%20%7C%20set(%0A%20%20%20%20%20%20%20%20%20%20%20%20(v%2C%20u)%20for%20u%2C%20v%2C%20_%20in%20edges_to_show%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20for%20u%2C%20v%2C%20weight%20in%20edges%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20x1%2C%20y1%20%3D%20nodes%5Bu%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20x2%2C%20y2%20%3D%20nodes%5Bv%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20(u%2C%20v)%20in%20mst_edge_set%20or%20(v%2C%20u)%20in%20mst_edge_set%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20MST%20edge%20-%20solid%20black%20line%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ax.plot(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Bx1%2C%20x2%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5By1%2C%20y2%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22black%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20linewidth%3D3%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20solid_capstyle%3D%22round%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Non-MST%20edge%20-%20dashed%20grey%20line%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ax.plot(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Bx1%2C%20x2%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5By1%2C%20y2%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22grey%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20linewidth%3D2%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20linestyle%3D%22--%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20alpha%3D0.7%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Add%20edge%20weight%20labels%20with%20larger%20font%0A%20%20%20%20%20%20%20%20%20%20%20%20mid_x%2C%20mid_y%20%3D%20(x1%20%2B%20x2)%20%2F%202%2C%20(y1%20%2B%20y2)%20%2F%202%0A%20%20%20%20%20%20%20%20%20%20%20%20ax.text(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mid_x%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mid_y%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20str(weight)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontsize%3D20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20bbox%3Ddict(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20boxstyle%3D%22round%2Cpad%3D0.2%22%2C%20facecolor%3D%22white%22%2C%20alpha%3D0.9%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ha%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20va%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontweight%3D%22bold%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Draw%20nodes%20-%20color%20based%20on%20connection%20status%0A%20%20%20%20%20%20%20%20connected_nodes%20%3D%20set()%0A%20%20%20%20%20%20%20%20if%20%22Prim%22%20in%20title%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20Prim%2C%20start%20with%20node%20A%20always%20connected%0A%20%20%20%20%20%20%20%20%20%20%20%20connected_nodes.add(%22A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20u%2C%20v%2C%20_%20in%20edges_to_show%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_nodes.add(u)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_nodes.add(v)%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20Kruskal%2C%20find%20all%20nodes%20in%20connected%20components%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20edges_to_show%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Build%20Union-Find%20to%20determine%20connected%20components%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20parent%20%3D%20%7Bnode%3A%20node%20for%20node%20in%20nodes%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20find_root(x)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20parent%5Bx%5D%20!%3D%20x%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20parent%5Bx%5D%20%3D%20find_root(parent%5Bx%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20parent%5Bx%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20union_nodes(x%2C%20y)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20px%2C%20py%20%3D%20find_root(x)%2C%20find_root(y)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20px%20!%3D%20py%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20parent%5Bpy%5D%20%3D%20px%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Apply%20edges%20to%20build%20connected%20components%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20u%2C%20v%2C%20_%20in%20edges_to_show%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20union_nodes(u%2C%20v)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Find%20all%20nodes%20connected%20to%20any%20component%20that%20has%20edges%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_roots%20%3D%20set()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20u%2C%20v%2C%20_%20in%20edges_to_show%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_roots.add(find_root(u))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_roots.add(find_root(v))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20node%20in%20nodes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20find_root(node)%20in%20connected_roots%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20connected_nodes.add(node)%0A%0A%20%20%20%20%20%20%20%20for%20node%2C%20(x%2C%20y)%20in%20nodes.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20color%20%3D%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%23f5cbcc%22%20if%20node%20in%20connected_nodes%20else%20%22%23d0e2f3%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20%20%23%20light%20red%20%3A%20light%20blue%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Draw%20larger%20circle%20with%20black%20border%0A%20%20%20%20%20%20%20%20%20%20%20%20circle%20%3D%20plt.Circle((x%2C%20y)%2C%200.15%2C%20color%3Dcolor%2C%20zorder%3D5)%0A%20%20%20%20%20%20%20%20%20%20%20%20ax.add_patch(circle)%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Add%20black%20border%0A%20%20%20%20%20%20%20%20%20%20%20%20border_circle%20%3D%20plt.Circle(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(x%2C%20y)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%200.15%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fill%3DFalse%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20edgecolor%3D%22black%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20linewidth%3D2%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zorder%3D6%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20ax.add_patch(border_circle)%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Larger%20text%0A%20%20%20%20%20%20%20%20%20%20%20%20ax.text(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20x%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20y%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20node%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ha%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20va%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontsize%3D20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontweight%3D%22bold%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zorder%3D7%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Clean%20title%0A%20%20%20%20%20%20%20%20ax.set_title(title%2C%20fontsize%3D22%2C%20fontweight%3D%22bold%22%2C%20pad%3D20)%0A%20%20%20%20%20%20%20%20ax.set_aspect(%22equal%22)%0A%20%20%20%20%20%20%20%20ax.axis(%22off%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Set%20axis%20limits%20with%20padding%0A%20%20%20%20%20%20%20%20x_coords%20%3D%20%5Bx%20for%20x%2C%20y%20in%20nodes.values()%5D%0A%20%20%20%20%20%20%20%20y_coords%20%3D%20%5By%20for%20x%2C%20y%20in%20nodes.values()%5D%0A%20%20%20%20%20%20%20%20ax.set_xlim(min(x_coords)%20-%200.3%2C%20max(x_coords)%20%2B%200.3)%0A%20%20%20%20%20%20%20%20ax.set_ylim(min(y_coords)%20-%200.3%2C%20max(y_coords)%20%2B%200.3)%0A%0A%20%20%20%20plt.tight_layout()%0A%20%20%20%20return%20fig%0A%0A%0A%23%20Create%20and%20display%20the%20visualization%0Afig%20%3D%20visualize_both_algorithms()\n\n\n\n    \n    \n    \n    %23%20Create%20a%20slider%20to%20control%20the%20puddle%20probability%0Ap_slider%20%3D%20mo.ui.slider(%0A%20%20%20%20start%3D0.0%2C%0A%20%20%20%20stop%3D1.0%2C%0A%20%20%20%20step%3D0.01%2C%0A%20%20%20%20value%3D0.5%2C%0A%20%20%20%20label%3D%22Puddle%20Probability%20(p)%22%0A)\n\n\n    \n    \n    \n    np.random.seed(42)%20%20%23%20For%20reproducible%20results%20during%20demo%0A%23%20Grid%20parameters%0Agrid_size%20%3D%2050%0AS%20%3D%20np.random.random((grid_size%2C%20grid_size))%0A%0Adef%20percolation_visualization()%3A%0A%0A%20%20%20%20%23%20Generate%20the%20percolation%20grid%20based%20on%20slider%20value%0A%20%20%20%20np.random.seed(42)%20%20%23%20For%20reproducible%20results%20during%20demo%0A%20%20%20%20grid%20%3D%20S%20%3C%20p_slider.value%0A%0A%20%20%20%20%23%20Find%20connected%20components%20(puddles%20that%20touch%20each%20other)%0A%20%20%20%20labeled_array%2C%20num_features%20%3D%20label(grid)%0A%0A%20%20%20%20%23%20Find%20the%20largest%20connected%20component%0A%20%20%20%20if%20num_features%20%3E%200%3A%0A%20%20%20%20%20%20%20%20sizes%20%3D%20%5B(labeled_array%20%3D%3D%20i).sum()%20for%20i%20in%20range(1%2C%20num_features%20%2B%201)%5D%0A%20%20%20%20%20%20%20%20largest_size%20%3D%20max(sizes)%0A%20%20%20%20%20%20%20%20largest_fraction%20%3D%20largest_size%20%2F%20(grid_size%20*%20grid_size)%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20largest_size%20%3D%200%0A%20%20%20%20%20%20%20%20largest_fraction%20%3D%200.0%0A%0A%20%20%20%20%23%20Create%20visualization%0A%20%20%20%20plt.figure(figsize%3D(8%2C%208))%0A%0A%20%20%20%20%23%20Create%20a%20display%20grid%20that%20shows%20largest%20component%20in%20red%0A%20%20%20%20display_grid%20%3D%20np.zeros_like(grid%2C%20dtype%3Dint)%0A%0A%20%20%20%20%23%20Find%20the%20largest%20component%0A%20%20%20%20if%20num_features%20%3E%200%3A%0A%20%20%20%20%20%20%20%20%23%20Find%20which%20label%20corresponds%20to%20the%20largest%20component%0A%20%20%20%20%20%20%20%20largest_label%20%3D%20np.argmax(sizes)%20%2B%201%20%20%23%20%2B1%20because%20labels%20start%20from%201%0A%0A%20%20%20%20%20%20%20%20%23%20Set%20display%20values%3A%200%3Dwhite%2C%201%3Dblue%20(small%20components)%2C%202%3Dred%20(largest%20component)%0A%20%20%20%20%20%20%20%20display_grid%5Bgrid%5D%20%3D%201%20%20%23%20All%20puddles%20start%20as%20blue%0A%20%20%20%20%20%20%20%20display_grid%5Blabeled_array%20%3D%3D%20largest_label%5D%20%3D%202%20%20%23%20Largest%20component%20in%20red%0A%0A%20%20%20%20%23%20Create%20custom%20colormap%3A%20white%20for%20empty%2C%20blue%20for%20small%20components%2C%20red%20for%20largest%0A%20%20%20%20colors%20%3D%20%5B'white'%2C%20'%234472C4'%2C%20'%23E74C3C'%5D%20%20%23%20white%2C%20blue%2C%20red%0A%20%20%20%20cmap%20%3D%20ListedColormap(colors)%0A%0A%20%20%20%20%23%20Plot%20the%20grid%0A%20%20%20%20ax%20%3D%20plt.imshow(display_grid%2C%20cmap%3Dcmap%2C%20interpolation%3D'nearest')%0A%0A%20%20%20%20%23%20Styling%0A%20%20%20%20plt.title(f'Percolation%20Grid%20(p%20%3D%20%7Bp_slider.value%3A.2f%7D)%5Cn'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'Largest%20Component%20(Red)%3A%20%7Blargest_size%7D%20squares%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'(%7Blargest_fraction%3A.1%25%7D%20of%20grid)'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20fontsize%3D14%2C%20pad%3D20)%0A%20%20%20%20plt.xlabel('Grid%20Position')%0A%20%20%20%20plt.ylabel('Grid%20Position')%0A%0A%20%20%20%20%23%20Add%20grid%20lines%20for%20clarity%0A%20%20%20%20plt.xticks(np.arange(-0.5%2C%20grid_size%2C%2010)%2C%20minor%3DTrue)%0A%20%20%20%20plt.yticks(np.arange(-0.5%2C%20grid_size%2C%2010)%2C%20minor%3DTrue)%0A%20%20%20%20plt.grid(which%3D'minor'%2C%20color%3D'gray'%2C%20linestyle%3D'-'%2C%20alpha%3D0.3)%0A%20%20%20%20plt.tick_params(which%3D'minor'%2C%20size%3D0)%0A%0A%20%20%20%20%23%20Add%20a%20legend%0A%20%20%20%20from%20matplotlib.patches%20import%20Patch%0A%20%20%20%20legend_elements%20%3D%20%5B%0A%20%20%20%20%20%20%20%20Patch(facecolor%3D'white'%2C%20edgecolor%3D'black'%2C%20label%3D'Empty')%2C%0A%20%20%20%20%20%20%20%20Patch(facecolor%3D'%234472C4'%2C%20label%3D'Small%20Components')%2C%0A%20%20%20%20%20%20%20%20Patch(facecolor%3D'%23E74C3C'%2C%20label%3D'Largest%20Component')%0A%20%20%20%20%5D%0A%20%20%20%20plt.legend(handles%3Dlegend_elements%2C%20loc%3D'upper%20right'%2C%20bbox_to_anchor%3D(1.15%2C%201))%0A%0A%20%20%20%20%23%20Return%20the%20plot%0A%20%20%20%20return%20ax\n\n\n    \n    \n    \n    %23%20Generate%20data%20for%20the%20phase%20transition%20plot%0Aprob_values%20%3D%20np.linspace(0%2C%201%2C%20100)%0Acomponent_fractions%20%3D%20%5B%5D%0A%0A%23grid_size_phase%20%3D%2050%20%20%23%20Use%20smaller%20grid%20for%20faster%20computation%0A%0A%23%20Calculate%20largest%20component%20size%20for%20different%20probabilities%0Anp.random.seed(42)%20%20%23%20Fixed%20seed%20for%20consistent%20results%0A%23S%20%3D%20np.random.random((grid_size_phase%2C%20grid_size_phase))%0Afor%20prob%20in%20prob_values%3A%0A%20%20%20%20%23%20Generate%20random%20grid%0A%20%20%20%20phase_grid%20%3D%20S%20%3C%20prob%0A%0A%20%20%20%20%23%20Find%20connected%20components%0A%20%20%20%20labeled_phase%2C%20num_phase%20%3D%20label(phase_grid)%0A%0A%20%20%20%20if%20num_phase%20%3E%200%3A%0A%20%20%20%20%20%20%20%20phase_sizes%20%3D%20%5B(labeled_phase%20%3D%3D%20i).sum()%20for%20i%20in%20range(1%2C%20num_phase%20%2B%201)%5D%0A%20%20%20%20%20%20%20%20largest_phase%20%3D%20max(phase_sizes)%20%2F%20(grid_size%20*%20grid_size)%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20largest_phase%20%3D%200.0%0A%0A%20%20%20%20component_fractions.append(largest_phase)\n\n\n    \n    \n    \n    def%20phase_transition_plot()%3A%0A%20%20%20%20%23%20Create%20the%20phase%20transition%20plot%0A%20%20%20%20plt.figure(figsize%3D(8%2C%206))%0A%0A%20%20%20%20%23%20Plot%20the%20phase%20transition%20curve%0A%20%20%20%20plt.plot(prob_values%2C%20component_fractions%2C%20'b-'%2C%20linewidth%3D2%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20label%3D'Largest%20Component%20Size')%0A%0A%20%20%20%20%23%20Highlight%20current%20probability%0A%20%20%20%20current_idx%20%3D%20int(p_slider.value%20*%2099)%20%20%23%20Convert%20to%20index%0A%20%20%20%20plt.plot(p_slider.value%2C%20component_fractions%5Bcurrent_idx%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20'ro'%2C%20markersize%3D10%2C%20label%3Df'Current%20p%20%3D%20%7Bp_slider.value%3A.2f%7D')%0A%0A%20%20%20%20%23%20Mark%20approximate%20critical%20point%20(for%202D%20lattice%2C%20pc%20%E2%89%88%200.593)%0A%20%20%20%20critical_p%20%3D%200.593%0A%20%20%20%20plt.axvline(x%3Dcritical_p%2C%20color%3D'gray'%2C%20linestyle%3D'--'%2C%20alpha%3D0.7%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20label%3Df'Critical%20point%20(p_c%20%E2%89%88%20%7Bcritical_p%7D)')%0A%0A%20%20%20%20%23%20Styling%0A%20%20%20%20plt.xlabel('Probability%20(p)'%2C%20fontsize%3D12)%0A%20%20%20%20plt.ylabel('Fraction%20of%20Grid%20in%20Largest%20Component'%2C%20fontsize%3D12)%0A%20%20%20%20plt.title('Percolation%20Phase%20Transition'%2C%20fontsize%3D14)%0A%20%20%20%20plt.grid(True%2C%20alpha%3D0.3)%0A%20%20%20%20plt.legend(frameon%3DFalse)%0A%20%20%20%20plt.xlim(0%2C%201)%0A%20%20%20%20plt.ylim(0%2C%201)%0A%0A%20%20%20%20%23%20Add%20phase%20labels%0A%20%20%20%20plt.text(0.2%2C%200.2%2C%20'Disconnected%5CnPhase'%2C%20fontsize%3D15%2C%20ha%3D'center'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20bbox%3Ddict(boxstyle%3D'round'%2C%20facecolor%3D'lightblue'%2C%20alpha%3D0.7))%0A%20%20%20%20plt.text(0.8%2C%200.2%2C%20'Connected%5CnPhase'%2C%20fontsize%3D15%2C%20ha%3D'center'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20bbox%3Ddict(boxstyle%3D'round'%2C%20facecolor%3D'%23f5cbcc'%2C%20alpha%3D0.7))%0A%0A%20%20%20%20return%20plt.gca()\n\n\n\n    \n    \n    \n    def%20compute_fc_powerlaw(gamma%2C%20k_min%2C%20k_max)%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20Compute%20the%20critical%20fraction%20f_c%20for%20a%20power-law%20degree%20distribution.%0A%0A%20%20%20%20Parameters%0A%20%20%20%20----------%0A%20%20%20%20gamma%20%3A%20float%0A%20%20%20%20%20%20%20%20Exponent%20of%20the%20power-law%20degree%20distribution.%0A%20%20%20%20k_min%20%3A%20float%0A%20%20%20%20%20%20%20%20Minimum%20degree%20in%20the%20network.%0A%20%20%20%20k_max%20%3A%20float%0A%20%20%20%20%20%20%20%20Maximum%20degree%20in%20the%20network.%0A%0A%20%20%20%20Returns%0A%20%20%20%20-------%0A%20%20%20%20f_c%20%3A%20float%0A%20%20%20%20%20%20%20%20Critical%20fraction%20of%20nodes%20that%20must%20be%20removed%20to%20break%20the%20network.%0A%20%20%20%20%22%22%22%0A%20%20%20%20if%20gamma%20%3E%203%3A%0A%20%20%20%20%20%20%20%20denom%20%3D%20(gamma%20-%202)%20%2F%20(gamma%20-%203)%20*%20k_min%20-%201%0A%20%20%20%20%20%20%20%20if%20denom%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%201.0%0A%20%20%20%20%20%20%20%20f_c%20%3D%201%20-%201%20%2F%20denom%0A%20%20%20%20elif%202%20%3C%20gamma%20%3C%203%3A%0A%20%20%20%20%20%20%20%20denom%20%3D%20(gamma%20-%202)%20%2F%20(3-gamma)%20*%20(k_min%20**%20(gamma%20-%202))%20*%20(k_max%20**%20(3%20-%20gamma))%20-%201%0A%20%20%20%20%20%20%20%20if%20denom%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%201.0%0A%20%20%20%20%20%20%20%20f_c%20%3D%201%20-%201%20%2F%20denom%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20raise%20ValueError(%22gamma%20must%20be%20%3E%202%20for%20a%20giant%20component%20to%20exist.%22)%0A%20%20%20%20return%20f_c\n\n\n    \n    \n    \n    import%20altair%20as%20alt%0A%0Akmax_values%20%3D%20np.arange(50%2C%201000%2C%2020)%0Agammas%20%3D%20%5B2.1%2C%202.5%2C%202.9%5D%0Agamma_labels%20%3D%20%7B2.1%3A%20%22gamma%20%3D%202.1%22%2C%202.5%3A%20%22gamma%20%3D%202.5%22%2C%202.9%3A%20%22gamma%20%3D%202.9%22%7D%0Acolors%20%3D%20%7B2.1%3A%20%22red%22%2C%202.5%3A%20%22blue%22%2C%202.9%3A%20%22orange%22%7D%0Alinestyles%20%3D%20%7B2.1%3A%20%22solid%22%2C%202.5%3A%20%22dashed%22%2C%202.9%3A%20%22dashed%22%7D%0A%0A%23%20Prepare%20data%20for%20Altair%0Adata%20%3D%20%5B%5D%0Afor%20gamma%20in%20gammas%3A%0A%20%20%20%20for%20kmax%20in%20kmax_values%3A%0A%20%20%20%20%20%20%20%20fc%20%3D%20compute_fc_powerlaw(gamma%2C%201%2C%20kmax)%0A%20%20%20%20%20%20%20%20data.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22Maximum%20degree%22%3A%20kmax%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22Critical%20fraction%22%3A%20fc%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22gamma%22%3A%20gamma_labels%5Bgamma%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22color%22%3A%20colors%5Bgamma%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22linestyle%22%3A%20linestyles%5Bgamma%5D%0A%20%20%20%20%20%20%20%20%7D)%0A%0Adf%20%3D%20pd.DataFrame(data)%0A%0A%23%20Altair%20plot%0A%0A%23%20Find%20the%20minimum%20y%20value%20(critical%20fraction)%20in%20the%20data%0Amin_fc%20%3D%20df%5B%22Critical%20fraction%22%5D.min()%0A%0Achart_fc%20%3D%20alt.Chart(df).mark_line().encode(%0A%20%20%20%20x%3Dalt.X(%0A%20%20%20%20%20%20%20%20%22Maximum%20degree%3AQ%22%2C%0A%20%20%20%20%20%20%20%20title%3D%22Maximum%20degree%22%2C%0A%20%20%20%20%20%20%20%20axis%3Dalt.Axis(titleFontSize%3D18%2C%20labelFontSize%3D14)%0A%20%20%20%20)%2C%0A%20%20%20%20y%3Dalt.Y(%0A%20%20%20%20%20%20%20%20%22Critical%20fraction%3AQ%22%2C%0A%20%20%20%20%20%20%20%20title%3D%22%24f_c%24%22%2C%0A%20%20%20%20%20%20%20%20scale%3Dalt.Scale(domain%3D%5Bmin_fc%2C%201.0%5D)%2C%0A%20%20%20%20%20%20%20%20axis%3Dalt.Axis(titleFontSize%3D18%2C%20labelFontSize%3D14)%0A%20%20%20%20)%2C%0A%20%20%20%20color%3Dalt.Color(%0A%20%20%20%20%20%20%20%20%22gamma%3AN%22%2C%0A%20%20%20%20%20%20%20%20scale%3Dalt.Scale(domain%3Dlist(gamma_labels.values())%2C%20range%3D%5Bcolors%5Bg%5D%20for%20g%20in%20gammas%5D)%2C%0A%20%20%20%20%20%20%20%20legend%3Dalt.Legend(title%3D%22gamma%22%2C%20titleFontSize%3D16%2C%20labelFontSize%3D14)%0A%20%20%20%20)%2C%0A%20%20%20%20strokeDash%3Dalt.StrokeDash(%0A%20%20%20%20%20%20%20%20%22gamma%3AN%22%2C%0A%20%20%20%20%20%20%20%20scale%3Dalt.Scale(domain%3Dlist(gamma_labels.values())%2C%20range%3D%5B%5B%5D%2C%20%5B5%2C5%5D%2C%20%5B5%2C5%5D%5D)%2C%0A%20%20%20%20%20%20%20%20legend%3DNone%0A%20%20%20%20)%0A).properties(%0A%20%20%20%20width%3D300%2C%0A%20%20%20%20height%3D300%2C%0A%20%20%20%20title%3Dalt.TitleParams(%0A%20%20%20%20%20%20%20%20text%3D%22Critical%20Fraction%20(k_min%20%3D%201)%22%2C%0A%20%20%20%20%20%20%20%20fontSize%3D20%0A%20%20%20%20)%0A)",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#references",
    "href": "m03-robustness/01-concepts.html#references",
    "title": "Core Concepts",
    "section": "8 References",
    "text": "8 References\n\nBorůvka, O. (1926). O jistém problému minimálním [About a certain minimal problem]. Práce Moravské Přírodovědecké Společnosti, 3, 37-58. [Original work on minimum spanning trees]\nMolloy, M., & Reed, B. (1995). A critical point for random graphs with a given degree sequence. Random Structures & Algorithms, 6(2-3), 161-180. [Molloy-Reed criterion]\nAlbert, R., Jeong, H., & Barabási, A. L. (2000). Error and attack tolerance of complex networks. Nature, 406(6794), 378-382. [Seminal paper on network robustness and the “Achilles’ heel” property]\nCohen, R., Erez, K., ben-Avraham, D., & Havlin, S. (2000). Resilience of the Internet to random breakdowns. Physical Review Letters, 85(21), 4626-4629. [Mathematical framework for random failures]\nCohen, R., Erez, K., ben-Avraham, D., & Havlin, S. (2001). Breakdown of the Internet under intentional attack. Physical Review Letters, 86(16), 3682-3685. [Mathematical analysis of targeted attacks]\nCallaway, D. S., Newman, M. E., Strogatz, S. H., & Watts, D. J. (2000). Network robustness and fragility: Percolation on random graphs. Physical Review Letters, 85(25), 5468-5471. [Percolation theory approach to network robustness]\nCohen, R., & Havlin, S. (2010). Complex Networks: Structure, Robustness and Function. Cambridge University Press. [Comprehensive treatment of network robustness theory]\nNewman, M. E. J. (2018). Networks. Oxford University Press. [Modern textbook covering network robustness and percolation]",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html",
    "href": "m02-small-world/04-appendix.html",
    "title": "Appendix - Brief Introduction to igraph",
    "section": "",
    "text": "The Erdős-Rényi random graph model is one of the fundamental models in network science, serving as our baseline for understanding what makes small-world networks special. There are two variants of this model: G(n,m) which creates n vertices with exactly m randomly chosen edges, and G(n,p) which creates n vertices where each possible edge exists with probability p. We focus on the G(n,p) model because it provides better analytical tractability for deriving mathematical properties.\n\n\n\n\n\n\nFigure 1: Erdős-Rényi random graph model.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Appendix - Brief Introduction to igraph"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html#erdős-rényi-random-graphs",
    "href": "m02-small-world/04-appendix.html#erdős-rényi-random-graphs",
    "title": "Appendix - Brief Introduction to igraph",
    "section": "",
    "text": "The Erdős-Rényi random graph model is one of the fundamental models in network science, serving as our baseline for understanding what makes small-world networks special. There are two variants of this model: G(n,m) which creates n vertices with exactly m randomly chosen edges, and G(n,p) which creates n vertices where each possible edge exists with probability p. We focus on the G(n,p) model because it provides better analytical tractability for deriving mathematical properties.\n\n\n\n\n\n\nFigure 1: Erdős-Rényi random graph model.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Appendix - Brief Introduction to igraph"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html#clustering-coefficient",
    "href": "m02-small-world/04-appendix.html#clustering-coefficient",
    "title": "Appendix - Brief Introduction to igraph",
    "section": "2 Clustering Coefficient",
    "text": "2 Clustering Coefficient\nThe clustering coefficient measures the probability that two neighbors of a node are also connected to each other. For Erdős-Rényi random graphs, we can derive the expected clustering coefficient analytically by exploiting the independence of edge formation.\nConsider a node i with degree k_i in an Erdős-Rényi graph G(n,p). The local clustering coefficient is defined as C_i = \\frac{2e_i}{k_i(k_i-1)}, where e_i is the number of edges between neighbors of node i. The key insight is that in the G(n,p) model, each possible edge exists with probability p independently of all other edges.\nFor a node with k neighbors, there are \\binom{k}{2} = \\frac{k(k-1)}{2} possible edges between its neighbors. Since each potential edge exists with probability p, the expected number of edges between neighbors is E[e_i | k_i = k] = \\frac{k(k-1)}{2} \\cdot p. Therefore, the expected local clustering coefficient for a node with degree k becomes:\nE[C_i | k_i = k] = \\frac{2 \\cdot \\frac{k(k-1)}{2} \\cdot p}{k(k-1)} = p\nThis result shows that the expected local clustering coefficient is simply p, independent of the node degree. Since this holds for all vertices regardless of their degree, the expected global clustering coefficient is also E[C] = p = \\frac{\\langle k \\rangle}{n-1}, where \\langle k \\rangle = p(n-1) is the expected degree.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Appendix - Brief Introduction to igraph"
    ]
  },
  {
    "objectID": "m02-small-world/04-appendix.html#average-path-length-derivation",
    "href": "m02-small-world/04-appendix.html#average-path-length-derivation",
    "title": "Appendix - Brief Introduction to igraph",
    "section": "3 Average Path Length Derivation",
    "text": "3 Average Path Length Derivation\nThe average path length in Erdős-Rényi graphs can be derived using a tree-expansion argument that reveals why these networks exhibit the small-world property of short distances.\nConsider an Erdős-Rényi model with average degree k = p(n-1). We can analyze the network structure by imagining a breadth-first expansion from any starting node, treating the resulting structure as a tree (this approximation works well because triangles and cycles are rare in sparse random graphs). From the root node, we can reach approximately 1 + k nodes in the first step. In the second step, each of these k nodes connects to roughly k new nodes (avoiding already-visited nodes), giving us 1 + k + k^2 total reachable nodes. Continuing this pattern, after h steps we can reach approximately 1 + k + k^2 + \\ldots + k^h \\approx k^h nodes.\nThe critical insight is that since Erdős-Rényi random graphs have few triangles and local clusters, most nodes in the network are reached only at the final step of this expansion process. When the expansion covers the entire network, we have k^h \\approx n. Solving for h: h \\approx \\log_{k}(n) = \\frac{\\log(n)}{\\log(k)} = \\frac{\\log(n)}{\\log(p(n-1))}.\nThis derivation reveals that the average shortest path length (diameter) of an Erdős-Rényi graph scales logarithmically with network size: \\langle d \\rangle \\approx \\frac{\\log(n)}{\\log(k)}. This logarithmic scaling demonstrates the “small-world” property inherent even in random graphs: even in large networks, the typical distance between nodes grows only logarithmically with network size, making the world surprisingly small despite its size.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Appendix - Brief Introduction to igraph"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html",
    "href": "m02-small-world/01-concepts.html",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will learn small-world experiments and conduct a small small-world experiment . We will learn:\n\nSmall-world experiment by Milgram\nDifferent concepts of distance: path, walks, circuits, cycles, connectedness\nHow to measure a distance between two nodes\nKeywords: small-world experiment, six degrees of separation, path, walks, circuits, cycles, connectedness, connected component, weakly connected component, strongly connected component.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#what-to-learn-in-this-module",
    "href": "m02-small-world/01-concepts.html#what-to-learn-in-this-module",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will learn small-world experiments and conduct a small small-world experiment . We will learn:\n\nSmall-world experiment by Milgram\nDifferent concepts of distance: path, walks, circuits, cycles, connectedness\nHow to measure a distance between two nodes\nKeywords: small-world experiment, six degrees of separation, path, walks, circuits, cycles, connectedness, connected component, weakly connected component, strongly connected component.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#small-world-experiment",
    "href": "m02-small-world/01-concepts.html#small-world-experiment",
    "title": "Core Concepts",
    "section": "2 Small-world experiment",
    "text": "2 Small-world experiment\n\n\nStanley Milgram (1933-1984) was an American social psychologist best known for his controversial obedience experiments at Yale University in the early 1960s. Beyond the obedience studies, Milgram conducted groundbreaking research on social networks, including the famous “small world” experiment that revealed the surprisingly short chains connecting any two people in society.\nHow far are two people in a social network? Milgram and his colleagues conducted a series of expriment to find out in the 1960s.\n\n\n\n\n\n\nFigure 1: Milgram’s small world experiment.\n\n\n\nThe experiment went as follows:\n\nMilgram first sent out packets to randomly selected people in Omaha, Nebraska, and Wichita, Kansas.\nThe recipient was asked to send the packet to the target person in Boston if they knew them. If not, they were to forward it to someone they knew on a first-name basis who might know the target.\nThe recipient continued to forward the packet to their acquaintances until it reached the target.\n\nThe results were surprising: out of the 160 letters sent, 64 successfully reached the target person by the chain of nearly six people, which was later called six degrees of separation. The results imply that, despite the fact that there were hundreds of millions of people in the United States, their social network was significantly compact, with two random people being connected to each other in only a few steps.\n\n\nThe term “Six degrees of separation” is commonly associated with Milgram’s experiment, but Milgram never used it. John Guare coined the term for his 1991 play and movie “Six Degrees of Separation.”\nThe results were later confirmed independently.\n\nYahoo research replicate the Milgram’s experiment by using emails. Started from more than 24,000 people, only 384 people reached the one of the 18 target person in 13 countries. Among the successful ones, the average length of the chain was about 4. When taken into account the broken chain, the average length was estimated between 5 and 7. (Goel, Muhamad, and Watts 2009)\nResearchers in Facebook and University of Milan analyzed the social network n Facebook, which consisted of 721 million active users and 69 billion friendships. The average length of the shortest chain was found to be 4.74. (Backstrom et al. 2012)",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#wikirace-experiencing-small-world-networks",
    "href": "m02-small-world/01-concepts.html#wikirace-experiencing-small-world-networks",
    "title": "Core Concepts",
    "section": "3 Wikirace: Experiencing Small-World Networks",
    "text": "3 Wikirace: Experiencing Small-World Networks\nLet us feel how small a large network can be by playing the Wikirace game.\n\n\n\nAt the end of the module, we will measure the average path length in a social network. Before jumping on, let us arm with some coding techniques to handle the network in the next two sections.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#why-is-small-world-networks-non-trivial",
    "href": "m02-small-world/01-concepts.html#why-is-small-world-networks-non-trivial",
    "title": "Core Concepts",
    "section": "4 Why is small-world networks non-trivial?",
    "text": "4 Why is small-world networks non-trivial?\n\n\n\n\nWhen we think about social networks, it’s natural to imagine that most people are friends with others who are nearby—friends of friends, classmates, colleagues, or neighbors. These are local connections, and they tend to form tightly-knit groups where everyone knows each other. In network terms, this means there are many triangles: if Alice is friends with Bob, and Bob is friends with Carol, then Alice is also likely to be friends with Carol.\nHowever, if a network only had these local, clustered connections, it would be difficult for information or influence to travel quickly across the entire network. You would have to go through many intermediaries to reach someone far away, resulting in a large diameter (the longest shortest path between any two nodes).\nWhat makes small-world networks non-trivial and surprising is that, despite having lots of local clustering (many triangles), they also have a few long-range connections—edges that link distant parts of the network. These “shortcuts” dramatically reduce the average distance between nodes. As a result, even in a huge network, you can reach almost anyone in just a few steps. This combination of high clustering and short path lengths is what defines the small-world property.\nIn summary:\n\nLocal connections create clustering (many triangles), but by themselves would make the network “large” in terms of path length.\nSmall-world networks have both high clustering and short average path lengths, thanks to a few edges that connect distant parts of the network.\nThis structure is non-trivial because it cannot be explained by local connections alone; the presence of long-range links is essential for the “small world” phenomenon.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#quantifying-small-world-properties",
    "href": "m02-small-world/01-concepts.html#quantifying-small-world-properties",
    "title": "Core Concepts",
    "section": "5 Quantifying Small-World Properties",
    "text": "5 Quantifying Small-World Properties\n\n\n\n\nLet us approach the small-world properties from mathematical angle. Two key characteristics of small-world networks are:\n\nShort average path length: You can reach distant parts of the network quickly.\nHigh clustering: Friends of friends are often friends.\n\n\nShort Average Path Length\n\n\nA path is a walk without repeated nodes. The shortest paths are the paths with the smallest number of edges.\nLet’s understand what average path length means. When we talk about how “far apart” two nodes are in a network, we mean the shortest number of edges you need to traverse to get from one node to the other. This is called the distance between nodes.\n\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nA\n\n\n\nB\n\nB\n\n\n\nA--B\n\n\n\n\nC\n\nC\n\n\n\nA--C\n\n\n\n\nB--C\n\n\n\n\nD\n\nD\n\n\n\nB--D\n\n\n\n\nC--D\n\n\n\n\n\n\n\nFigure 2: Simple network example for understanding shortest paths\n\n\n\n\n\nIn this simple network, let’s find the distance between nodes A and D:\n\nPath 1: A \\rightarrow B \\rightarrow D (2 edges)\nPath 2: A \\rightarrow C \\rightarrow D (2 edges)\nPath 3: A \\rightarrow C \\rightarrow B \\rightarrow D (3 edges)\n\nEven though there are multiple paths, the shortest path length (distance) from A to D is 2 edges.\nBuilding on this, let us calculate the average path length between two nodes. We have four nodes in the network, so there are 6 pairs of nodes. Let us enumerate them as follows:\n\n\n\n\n\n\n\n\nPair\nShortest Path\nLength\n\n\n\n\nA - B\nA \\rightarrow B\n1\n\n\nA - C\nA \\rightarrow C\n1\n\n\nA - D\nA \\rightarrow B \\rightarrow D or A \\rightarrow C \\rightarrow D\n2\n\n\nB - C\nB \\rightarrow C\n1\n\n\nB - D\nB \\rightarrow D\n1\n\n\nC - D\nC \\rightarrow D\n1\n\n\n\nThe average path length is simply the average of all these distances, which is 7 / 6 \\simeq 1.16.\n\n\nClustering Coefficient\nIn social networks, your friends tend to know each other. If you have a friend Alice, and Alice has friends Bob and Carol, local clustering asks: “Are Bob and Carol also friends with each other?” High local clustering means that your friends tend to know each other, creating dense local neighborhoods or cliques.\nThere are three ways to measure clustering: local clustering, average local clustering, and global clustering. The key difference is the focus of the measurement:\n\nLocal clustering focuses on the clustering of the neighbors of a specific node\nAverage local clustering focuses on the clustering of the neighbors of a node\nGlobal clustering focuses on the clustering of the entire network.\n\nLet us explain each of them one by one.\n\nLocal Clustering\nLocal clustering asks: given all your friends, how many of triangles you and your friends form, relative to the maximum possible number of triangles?\nThe local clustering coefficient C_i of a node i is defined as:\n\nC_i = \\dfrac{\\text{\\# of triangles involving } i \\text{ and its neighbors}}{\\text{\\# of edges possibly exist in the neighborhood of } i}\n\nOr alternatively, using the adjacency matrix A and the degree k_i of node i, \n\\begin{aligned}\nC_i = \\frac{\\sum_{j}\\sum_{\\ell} A_{ij}A_{j\\ell} A_{\\ell i} }{k_i(k_i-1)}\n\\end{aligned}\n\n\n\n\n\n\n\nNote: Derivation of the local clustering coefficient\n\n\n\n\n\nNumerator A_{ij}A_{j\\ell} A_{\\ell i} is a binary indicator of whether three nodes i, j, and \\ell form a triangle; A_{ij}A_{j\\ell} A_{\\ell i}=1 if a cycle i \\rightarrow j \\rightarrow \\ell \\rightarrow i exists, and 0 otherwise. By summing up all nodes, we have the number of triangles in the neighbors of i given by \\sum_{j}\\sum_{\\ell} A_{ij}A_{j\\ell} A_{\\ell i} / 2. Note that we divide the sum by 2 because the same triangle forms two cycles, i.g., i \\rightarrow j \\rightarrow \\ell \\rightarrow i and i \\rightarrow \\ell \\rightarrow j \\rightarrow i.\nThe number of possible triangles in the neighborhood of i is given by \\binom{k_i}{2} = k_i(k_i-1)/2.\nPutting them together:\n\nC_i = \\frac{\\sum_{j}\\sum_{\\ell} A_{ij}A_{j\\ell} A_{\\ell i} }{k_i(k_i-1)}\n\n\n\n\nFor example, let us compute the local clustering coefficient of node A in the following network. There are two triangles in the neighborhood of A. The number of possible triangles is 5 \\times 4 / 2 = 10. Thus, the local clustering coefficient of A is 2 / 10 = 0.2.\n\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nA\n\n\n\nB\n\nB\n\n\n\nA--B\n\n\n\n\nC\n\nC\n\n\n\nA--C\n\n\n\n\nD\n\nD\n\n\n\nA--D\n\n\n\n\nE\n\nE\n\n\n\nA--E\n\n\n\n\nF\n\nF\n\n\n\nA--F\n\n\n\n\nB--F\n\n\n\n\nC--E\n\n\n\n\n\n\n\nFigure 3: A network of friends\n\n\n\n\n\n\n\nAverage Local Clustering\nLocal clustering focuses on the clustering of a node’s neighborhood, while the global clustering focuses on the clustering of the entire network. One can adapt the local clustering for measuring the global clustering by taking the average of the local clustering coefficients of all nodes, i.e.,\n\n\\overline {C} = \\frac{1}{N} \\sum_{i=1}^N C_i\n\n\n\nGlobal Clustering\nGlobal clustering, also known as transitivity, measures the overall tendency for triangles to form throughout the entire network. It answers the question: “Across the whole network, how likely is it that two nodes connected to a common neighbor are also connected to each other?”\nThe global clustering coefficient C is defined as:\n\nC = \\frac{3 \\times \\text{number of triangles}}{\\text{number of connected triplets}}\n\nwhere a connected triplet is a set of three nodes connected by at least two edges, forming either a closed triplet (triangle) or an open triplet (wedge) shown below.\n\n\n\n\n\n\n\nG\n\n\n\nA1\n\nA1\n\n\n\nB1\n\nB1\n\n\n\nA1--B1\n\n\n\n\nC1\n\nC1\n\n\n\nB1--C1\n\n\n\n\nC1--A1\n\n\n\n\nA2\n\nA2\n\n\n\nB2\n\nB2\n\n\n\nA2--B2\n\n\n\n\nC2\n\nC2\n\n\n\nB2--C2\n\n\n\n\n\n Closed triplet (left) and open triplet (right) \n\n\n\nIn triplets, the order of the nodes matters. For example, (A_1, B_1, C_1) and (B_1, C_1, A_1) are two different triplets. A triangle pertains to three triplets, i.e., (A_1, B_1, C_1), (B_1, C_1, A_1), and (C_1, A_1, B_1). This is why we multiple three to the number of triangles in the numerator.\n\n\n\n\n\n\nKey difference between average local and global clustering\n\n\n\n\n\nIt is confusing to have two different global clustering measures, but the distinction becomes clearer if we think in terms of micro and macro perspectives:\n\nThe global clustering coefficient C (based on the total number of triangles and triplets in the network) is a micro-level measure. It looks at the prevalence of triangles relative to all possible connected triples in the entire network, essentially aggregating over all small, local patterns (triplets) to get a sense of how likely it is for any three connected nodes to form a closed triangle.\nThe average local clustering coefficient \\overline{C} is a macro-level measure. It first computes the clustering coefficient for each individual node (how clustered each node’s neighborhood is), and then averages these values across all nodes. This gives a sense of the overall tendency for nodes in the network to have tightly knit neighborhoods.\n\nSo the focal scope remains the same: the average local clustering focuses on a node’s neighborhood, while the global clustering focuses on the entire network.\n\n\n\n\n\n\nSmall-world coefficient\nNow let’s define a coefficient to measure the small-world property. Recall that a small-world network has both high clustering and short average path length. A naive approach is to take the ratio between the average local clustering coefficient and the average path length:\n\ns_{\\text{naive}} = \\frac{\\overline{C}}{\\overline{L}}\n\nwhere \\overline{C} is a clustering coefficient and \\overline{L} is the average path length. The original work by Watts and Strogatz used the average local clustering coefficient (Watts and Strogatz 1998) but one can use the global clustering coefficient as well, which leads to different results (Humphries and Gurney 2008).\nA high s_{\\text{naive}} value would seem to indicate a strong small-world property. However, this naive measure has a critical flaw: it can be high for trivial network structures. For example, a fully-connected network has \\overline{L} = 1 (minimum possible) and \\overline{C} = 1 (maximum possible), giving s_{\\text{naive}} = 1. This leads us to normalize against random networks with the same basic properties (Humphries and Gurney 2008).\nTo address this issue, Watts and Strogatz proposed normalizing by equivalent random networks. The small-world index (or small-world coefficient) is defined as:\n\n\\sigma = \\frac{\\overline{C}/\\overline{C}_{\\text{random}}}{\\overline{L}/\\overline{L}_{\\text{random}}} = \\frac{\\overline{C} \\cdot \\overline{L}_{\\text{random}}}{\\overline{L} \\cdot \\overline{C}_{\\text{random}}}\n\nwhere: \\overline{C}_{\\text{random}} and \\overline{L}_{\\text{random}} are the average clustering coefficient and the average path length of an equivalent random network. The “equivalent random network” typically refers to an Erdős–Rényi random graph, where edges are randomly connected with the same number of nodes and edges (or same average degree) as the original network (thus it represents a trivial random network of the same number of nodes and edges).\nA high \\sigma value greater than 1 indicates a strong small-world property. If \\sigma is close to 1, the network is not small-world but comparable to a random network in terms of the small-world property. If \\sigma is less than 1, the network is anti-small-world, i.e., it has a large average path length and low clustering compared to a random counterpart.\nSo how do we compute the reference value of \\overline{C}_{\\text{random}} and \\overline{L}_{\\text{random}}? We can compute them numerically by generating many random networks and computing the average of the clustering coefficient and the path length. For Erdős–Rényi random graph, it has been shown that the reference value of \\overline{C}_{\\text{random}} and \\overline{L}_{\\text{random}} follow on average (Humphries and Gurney 2008) (Newman, Strogatz, and Watts 2001): \n\\begin{aligned}\n\\overline{C}_{\\text{random}} & \\approx \\frac{\\langle k \\rangle}{n-1} \\\\\n\\overline{L}_{\\text{random}} &\\approx \\frac{\\ln n }{\\ln \\langle k \\rangle}\n\\end{aligned}\n\nwhere \\langle k \\rangle is the average degree of the network, and n is the number of nodes.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#watts-strogatz-model",
    "href": "m02-small-world/01-concepts.html#watts-strogatz-model",
    "title": "Core Concepts",
    "section": "6 Watts-Strogatz Model",
    "text": "6 Watts-Strogatz Model\n\n\n\n\n\n\nFigure 4: Watts-Strogatz model.\n\n\n\nWe have a way to measure the small-world property of a network, which reveals that the small-world property is surprisingly common in real-world networks. This leads to a question: what is the underlying mechanism? The Watts-Strogatz model provides a way to generate small-world networks, as we will see in the next section.\n\n\nHere is a nice blog post about the Watts-Strogatz model.\n\n\n“What I cannot create, I do not understand.” - Richard Feynman\n\nThis quote captures the essence of why models like Watts-Strogatz are crucial: by building networks that exhibit small-world properties, we gain deeper insight into how these properties emerge in real systems.\n\n\nWhat is the Watts-Strogatz Model?\nThe Watts-Strogatz model provides one explanation for the small-world phenomenon. The Watts-Strogatz model starts with a ring lattice and introduces randomness through edge rewiring:\nStep 1: Start with a Ring Lattice\n\nCreate a ring of N nodes\nConnect each node to its k nearest neighbors (k/2 on each side)\nThis gives high clustering but long average path length\n\nStep 2: Rewire Edges with Probability p\n\nFor each edge in the lattice:\n\nWith probability p: remove the edge and reconnect one endpoint to a randomly chosen node\nWith probability (1-p): keep the original edge\n\nAvoid self-loops and duplicate edges\n\nAt p = 0, the network is a regular ring lattice (high clustering, long paths); at p = 1, it becomes a random graph (low clustering, short paths). For 0 &lt; p &lt; 1, the network combines high clustering with short path lengths—the hallmark of the small-world property.\n\n\n\n\n\n\ninteractive exploration\n\n\n\nHere is the interactive visualization of the Watts-Strogatz model 😎: .\n\n\n\n\nWhy does the small-world property emerge?\nThe Watts-Strogatz model explains that the small-world property emerges from a small number of long-range connections that connect distant parts of the network, despite the nodes being connected to their local neighbors. While we have focused on social networks, the same explanation applies to different domains, such as biological networks (e.g., neurons are primarily connected locally but have some long-range connections that enable rapid information transmission), and technological networks (e.g., the Internet topology is regional but has some long-range connections that span continents).\n\n\nInteractive Exploration\n\n\nExplore the Watts-Strogatz model interactively by adjusting the rewiring probability and observing how network properties change:\nIn the next section, we will learn how to compute the shortest paths and connected components of a network using a library igraph.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m02-small-world/01-concepts.html#references",
    "href": "m02-small-world/01-concepts.html#references",
    "title": "Core Concepts",
    "section": "7 References",
    "text": "7 References\n\n\nBackstrom, Lars, Paolo Boldi, Marco Rosa, Johan Ugander, and Sebastiano Vigna. 2012. “Four Degrees of Separation.” In Proceedings of the 4th Annual ACM Web Science Conference, 33–42.\n\n\nGoel, Sharad, Roby Muhamad, and Duncan Watts. 2009. “Social Search in\" Small-World\" Experiments.” In Proceedings of the 18th International Conference on World Wide Web, 701–10.\n\n\nHumphries, Mark D., and Kevin Gurney. 2008. “Network ‘Small-World-Ness’: A Quantitative Method for Determining Canonical Network Equivalence.” Edited by Olaf Sporns. PLoS ONE 3 (4): e0002051. https://doi.org/10.1371/journal.pone.0002051.\n\n\nNewman, M. E. J., S. H. Strogatz, and D. J. Watts. 2001. “Random graphs with arbitrary degree distributions and their applications.” Physical Review E 64 (2). https://doi.org/10.1103/physreve.64.026118.\n\n\nWatts, Duncan J, and Steven H Strogatz. 1998. “Collective Dynamics of ‘Small-World’networks.” Nature 393 (6684): 440–42.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m01-euler_tour/04-advanced.html",
    "href": "m01-euler_tour/04-advanced.html",
    "title": "Advanced: Sparse Matrices for Large-Scale Networks",
    "section": "",
    "text": "Modern networks have billions of nodes—far beyond Königsberg’s 4 landmasses. A dense adjacency matrix for Earth’s 8 billion people would require 512 exabytes of memory!\nReal networks are sparse: most node pairs aren’t connected. Edge lists save memory but are inefficient for common operations like finding neighbors or computing degrees.\n\n\nThink about the following operations:\n\nDegree: How many friends does a person have?\nNeighbors: Who are the friends of a person?\n\nThese operations are very common in network analysis. To do so, you need to go through all the edges in the network. This is not efficient, especially for large networks.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Advanced: Sparse Matrices for Large-Scale Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/04-advanced.html#the-scale-problem-from-königsberg-to-global-networks",
    "href": "m01-euler_tour/04-advanced.html#the-scale-problem-from-königsberg-to-global-networks",
    "title": "Advanced: Sparse Matrices for Large-Scale Networks",
    "section": "",
    "text": "Modern networks have billions of nodes—far beyond Königsberg’s 4 landmasses. A dense adjacency matrix for Earth’s 8 billion people would require 512 exabytes of memory!\nReal networks are sparse: most node pairs aren’t connected. Edge lists save memory but are inefficient for common operations like finding neighbors or computing degrees.\n\n\nThink about the following operations:\n\nDegree: How many friends does a person have?\nNeighbors: Who are the friends of a person?\n\nThese operations are very common in network analysis. To do so, you need to go through all the edges in the network. This is not efficient, especially for large networks.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Advanced: Sparse Matrices for Large-Scale Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/04-advanced.html#solution-sparse-matrices",
    "href": "m01-euler_tour/04-advanced.html#solution-sparse-matrices",
    "title": "Advanced: Sparse Matrices for Large-Scale Networks",
    "section": "2 Solution: Sparse Matrices",
    "text": "2 Solution: Sparse Matrices\nWe say a matrix is sparse if the matrix has only a handful of non-zero entries. This is indeed the case for most real-world networks. For such networks, we can use a special type of data type called Compressed Sparse Row (CSR) or Compressed Sparse Column (CSC) to represent the network. This is widely used in many network analysis tools and makes it possible to process large networks in practice.\nTo learn more, here is a very good blog post by Matt Eding about efficient network representations.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Advanced: Sparse Matrices for Large-Scale Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/04-advanced.html#scipys-compressed-sparse-row-csr-format",
    "href": "m01-euler_tour/04-advanced.html#scipys-compressed-sparse-row-csr-format",
    "title": "Advanced: Sparse Matrices for Large-Scale Networks",
    "section": "3 SciPy’s Compressed Sparse Row (CSR) Format",
    "text": "3 SciPy’s Compressed Sparse Row (CSR) Format\n\n\nHere is a short video explaining the CSR format. Good one to watch if you are visual learner.\n\n\n\n\n\n\n\n\nFigure 1: A sparse matrix is a matrix with only a handful of non-zero entries represented with a compressed sparse frmat.\n\n\n\nCSR stores only non-zero matrix entries using three arrays, making it the standard for large-scale network analysis.\n\nUnderstanding CSR Structure\nCSR format uses three arrays to represent a sparse matrix:\n\ndata: Contains all non-zero values\nindices: Column indices of each non-zero value\nindptr: Row pointers indicating where each row starts in the data array\n\n\n\nMemory efficiency: For a sparse matrix with m non-zero entries out of n^2 total entries, CSR uses O(m + n) memory instead of O(n^2). For social networks where m \\ll n^2, this is a massive saving!\n\nimport numpy as np\nfrom scipy import sparse\n\n# Create a small example network\n# Let's represent the same 5-node network from earlier\ndense_matrix = np.array([\n    [0, 1, 1, 0, 0],  # Node 0 connects to nodes 1, 2\n    [1, 0, 1, 1, 0],  # Node 1 connects to nodes 0, 2, 3\n    [1, 1, 0, 0, 1],  # Node 2 connects to nodes 0, 1, 4\n    [0, 1, 0, 0, 1],  # Node 3 connects to nodes 1, 4\n    [0, 0, 1, 1, 0]   # Node 4 connects to nodes 2, 3\n])\n\n# Convert to CSR format\ncsr_matrix = sparse.csr_matrix(dense_matrix)\n\nprint(\"Dense matrix shape:\", dense_matrix.shape)\nprint(\"CSR matrix shape:\", csr_matrix.shape)\nprint(\"Non-zero entries:\", csr_matrix.nnz)\nprint(\"Memory saved: {:.1f}%\".format((1 - csr_matrix.nnz / dense_matrix.size) * 100))\n\nDense matrix shape: (5, 5)\nCSR matrix shape: (5, 5)\nNon-zero entries: 12\nMemory saved: 52.0%\n\n\n\n\nInside the CSR Format\nLet’s examine the internal structure of our CSR matrix:\n\nprint(\"CSR internal arrays:\")\nprint(\"data (non-zero values):\", csr_matrix.data)\nprint(\"indices (column positions):\", csr_matrix.indices)\nprint(\"indptr (row pointers):\", csr_matrix.indptr)\n\n# Let's trace through how CSR works\nprint(\"\\nDecoding CSR structure:\")\nfor i in range(len(csr_matrix.indptr) - 1):\n    start = csr_matrix.indptr[i]\n    end = csr_matrix.indptr[i + 1]\n    row_data = csr_matrix.data[start:end]\n    row_indices = csr_matrix.indices[start:end]\n    print(f\"Row {i}: values {row_data} at columns {row_indices}\")\n\nCSR internal arrays:\ndata (non-zero values): [1 1 1 1 1 1 1 1 1 1 1 1]\nindices (column positions): [1 2 0 2 3 0 1 4 1 4 2 3]\nindptr (row pointers): [ 0  2  5  8 10 12]\n\nDecoding CSR structure:\nRow 0: values [1 1] at columns [1 2]\nRow 1: values [1 1 1] at columns [0 2 3]\nRow 2: values [1 1 1] at columns [0 1 4]\nRow 3: values [1 1] at columns [1 4]\nRow 4: values [1 1] at columns [2 3]\n\n\n\n\n\n\n\n\nHow CSR Works\n\n\n\nFor row i, the non-zero values are stored in data[indptr[i]:indptr[i+1]] with their column positions in indices[indptr[i]:indptr[i+1]].\nFor example, if indptr[0] = 0 and indptr[1] = 2, then row 0 has non-zero values data[0:2] at columns indices[0:2].\n\n\n\n\nCreating CSR Matrices from Edge Lists\nThe most common way to create network CSR matrices is from edge lists:\n\n# Define our network as an edge list\nedges = [\n    (0, 1), (0, 2),  # Node 0 connections\n    (1, 2), (1, 3),  # Node 1 connections\n    (2, 4),          # Node 2 connections\n    (3, 4)           # Node 3 connections\n]\n\n# Extract source and target nodes\nsources = [edge[0] for edge in edges]\ntargets = [edge[1] for edge in edges]\n\n# For undirected graphs, add reverse edges\nall_sources = sources + targets\nall_targets = targets + sources\n\n# Create data array (all ones for unweighted graph)\ndata_values = np.ones(len(all_sources))\n\n# Create CSR matrix directly from edge list\nn_nodes = 5\ncsr_from_edges = sparse.csr_matrix(\n    (data_values, (all_sources, all_targets)),\n    shape=(n_nodes, n_nodes)\n)\n\nprint(\"CSR from edge list:\")\nprint(csr_from_edges.toarray())\n\nCSR from edge list:\n[[0. 1. 1. 0. 0.]\n [1. 0. 1. 1. 0.]\n [1. 1. 0. 0. 1.]\n [0. 1. 0. 0. 1.]\n [0. 0. 1. 1. 0.]]\n\n\n\n\nEfficient Operations with CSR\nCSR format enables efficient network operations that would be slow with dense matrices:\n\n# Node degrees - sum each row\ndegrees = np.array(csr_matrix.sum(axis=1)).flatten()\nprint(\"Node degrees:\", degrees)\n\n# Find neighbors of node 1\nnode_1_neighbors = csr_matrix.indices[csr_matrix.indptr[1]:csr_matrix.indptr[2]]\nprint(\"Node 1 neighbors:\", node_1_neighbors)\n\n# Matrix multiplication for 2-hop paths\ntwo_hop_matrix = csr_matrix @ csr_matrix\nprint(\"Two-hop connections (shows paths of length 2):\")\nprint(two_hop_matrix.toarray())\n\nNode degrees: [2 3 3 2 2]\nNode 1 neighbors: [0 2 3]\nTwo-hop connections (shows paths of length 2):\n[[2 1 1 1 1]\n [1 3 1 0 2]\n [1 1 3 2 0]\n [1 0 2 2 0]\n [1 2 0 0 2]]\n\n\n\n\nMatrix multiplication: @ is the matrix multiplication operator in SciPy and NumPy. It is equivalent to np.dot.\n\n\nMemory Comparison: Dense vs CSR\nLet’s demonstrate the memory efficiency with a larger, sparser network:\n\n# Create a larger sparse network\nn = 1000\ndensity = 0.01  # Only 1% of edges exist\n\n# Generate random sparse matrix\nnp.random.seed(42)\nlarge_dense = sparse.random(n, n, density=density, format='csr')\n\nprint(f\"Network size: {n} × {n} = {n**2:,} potential edges\")\nprint(f\"Actual edges: {large_dense.nnz:,}\")\nprint(f\"Sparsity: {(1 - large_dense.nnz / (n*n)) * 100:.1f}% zeros\")\nprint(f\"CSR memory usage: ~{(large_dense.nnz * 2 + n) * 4 / 1024:.1f} KB\")\nprint(f\"Dense memory usage: ~{n*n * 4 / 1024:.1f} KB\")\nprint(f\"Memory savings: {((n*n * 4) - (large_dense.nnz * 2 + n) * 4) / (n*n * 4) * 100:.1f}%\")\n\nNetwork size: 1000 × 1000 = 1,000,000 potential edges\nActual edges: 10,000\nSparsity: 99.0% zeros\nCSR memory usage: ~82.0 KB\nDense memory usage: ~3906.2 KB\nMemory savings: 97.9%\n\n\n\n\nCSR for Network Analysis Algorithms\nCSR format integrates seamlessly with our previously defined functions:\n\ndef is_walk_sparse(sequence, csr_matrix):\n    \"\"\"\n    Check if a sequence forms a valid walk using sparse CSR matrix.\n    \"\"\"\n    if len(sequence) &lt; 2:\n        return True\n\n    sequence = np.array(sequence)\n    current_nodes = sequence[:-1]\n    next_nodes = sequence[1:]\n\n    # Use CSR matrix indexing - still works with advanced indexing!\n    edges_exist = csr_matrix[(current_nodes, next_nodes)]\n\n    # Convert sparse result to array and check\n    return np.all(edges_exist == 1)\n\n# Test with our CSR matrix\ntest_walk = [0, 1, 2, 4, 3, 1]\nprint(f\"Walk {test_walk} is valid: {is_walk_sparse(test_walk, csr_matrix)}\")\n\nWalk [0, 1, 2, 4, 3, 1] is valid: True\n\n\n\n\n\n\n\n\nBest Practices\n\n\n\nWhen to use CSR: - Sparse matrices - Row-based operations (computing degrees, finding neighbors) - Matrix-vector multiplication\nWhen to use dense matrices: - Small networks - Dense networks - Frequent random access to individual entries\n\n\n\n\nThere are several different sparse matrix formats such as COO, CSC, and LIL. If you are interested in learning more, you can check out this blog post by Matt Eding. The following video is also a good one to watch.\n\n\n\n\nAdvanced CSR Features\n\n# Submatrix extraction - get connections for subset of nodes\nsubset_nodes = [0, 1, 2]\nsubgraph = csr_matrix[subset_nodes][:, subset_nodes]\nprint(\"Subgraph for nodes [0, 1, 2]:\")\nprint(subgraph.toarray())\n\n# Efficient boolean operations\n# Find nodes with degree &gt; 2\nhigh_degree_nodes = np.where(degrees &gt; 2)[0]\nprint(\"High degree nodes (&gt; 2 connections):\", high_degree_nodes)\n\n# Matrix powers for path counting\npaths_3 = csr_matrix ** 3  # Counts 3-step paths\nprint(\"3-step path counts:\")\nprint(paths_3.toarray())\n\nSubgraph for nodes [0, 1, 2]:\n[[0 1 1]\n [1 0 1]\n [1 1 0]]\nHigh degree nodes (&gt; 2 connections): [1 2]\n3-step path counts:\n[[2 4 4 2 2]\n [4 2 6 5 1]\n [4 6 2 1 5]\n [2 5 1 0 4]\n [2 1 5 4 0]]\n\n\nThe CSR format transforms network analysis from impossible to practical for large-scale networks. By storing only the essential information (non-zero connections), we can analyze networks with millions of nodes and billions of edges on standard hardware—something that would require exabytes of memory with dense matrices!",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Advanced: Sparse Matrices for Large-Scale Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html",
    "href": "m01-euler_tour/02-coding.html",
    "title": "Coding Networks in Python",
    "section": "",
    "text": "Now that you understand the conceptual foundation from Euler’s work, let’s explore how to represent and analyze networks computationally. Given a network of any size, our goal is to create a function that can tell us whether the network has an Euler path or not.\nWe’ll work through both general network representations and apply them specifically to the Königsberg bridge problem.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#network-representations-from-pictures-to-data-structures",
    "href": "m01-euler_tour/02-coding.html#network-representations-from-pictures-to-data-structures",
    "title": "Coding Networks in Python",
    "section": "1 Network Representations: From Pictures to Data Structures",
    "text": "1 Network Representations: From Pictures to Data Structures\nConsider this network with 5 nodes and 6 edges:\n\n\n\n\n\n\nFigure 1: A small graph of five nodes and six edges.\n\n\n\nHow do we represent this graph in a format that a computer can understand and manipulate? Just as Euler needed to abstract Königsberg’s bridges, we need data structures that capture the network’s essential connectivity while enabling efficient analysis.\n\n\nThe choice of representation can dramatically affect computational efficiency. For sparse networks (few edges), adjacency lists are memory-efficient. For dense networks or matrix operations, adjacency matrices are preferred.\nLet’s explore three fundamental approaches that form the backbone of all network algorithms.\n\nEdge Table: The Direct Approach\nThe edge table directly lists connections as pairs—the most intuitive way to store network data.\n\n\nEdge tables are also called “edge lists” and are the most common format for storing large-scale network data in files. Social media platforms like Twitter and Facebook store billions of connections this way.\n\n# Each row represents one edge (connection between two nodes)\nedges = [\n    (0, 1),  # Node 0 connects to Node 1\n    (0, 2),  # Node 0 connects to Node 2\n    (1, 2),  # Node 1 connects to Node 2\n    (1, 3),  # Node 1 connects to Node 3\n    (2, 4),  # Node 2 connects to Node 4\n    (3, 4)   # Node 3 connects to Node 4\n]\n\nprint(f\"Network has {len(edges)} edges\")\nprint(\"Edge list:\", edges)\n\nNetwork has 6 edges\nEdge list: [(0, 1), (0, 2), (1, 2), (1, 3), (2, 4), (3, 4)]\n\n\nThis mirrors how we’d naturally describe the network: “Node 0 connects to nodes 1 and 2, node 1 connects to nodes 0, 2, and 3…” It’s the digital equivalent of Euler’s original approach—simply listing which bridges connect which landmasses.\n\n\nAdjacency List: The Neighborhood Map\nThe adjacency list stores each node’s neighbors in a dictionary—like a social network where each person has a list of friends.\n\n\nMost graph algorithms prefer adjacency lists because they allow fast iteration over a node’s neighbors. This is crucial for algorithms like breadth-first search or computing clustering coefficients.\n\n# Define adjacency list directly as a dictionary\nneighbors = {\n    0: [1, 2],     # Node 0 connects to nodes 1 and 2\n    1: [0, 2, 3],  # Node 1 connects to nodes 0, 2, and 3\n    2: [0, 1, 4],  # Node 2 connects to nodes 0, 1, and 4\n    3: [1, 4],     # Node 3 connects to nodes 1 and 4\n    4: [2, 3]      # Node 4 connects to nodes 2 and 3\n}\n\nprint(\"Adjacency list representation:\")\nfor node, neighbor_list in neighbors.items():\n    print(f\"Node {node}: {neighbor_list}\")\n\nAdjacency list representation:\nNode 0: [1, 2]\nNode 1: [0, 2, 3]\nNode 2: [0, 1, 4]\nNode 3: [1, 4]\nNode 4: [2, 3]\n\n\n\n\nAdjacency Matrix\nThe adjacency matrix uses a grid where entry (i,j) = 1 if nodes are connected—the mathematician’s favorite representation.\n\n\nAdjacency matrices enable powerful mathematical operations. Matrix multiplication reveals paths of different lengths, and eigenvalue analysis can uncover community structure. Google’s PageRank algorithm fundamentally relies on matrix operations.\n\n# Define adjacency matrix directly\nimport numpy as np\n\nmatrix = np.array([\n    [0, 1, 1, 0, 0],  # Node 0 connects to nodes 1, 2\n    [1, 0, 1, 1, 0],  # Node 1 connects to nodes 0, 2, 3\n    [1, 1, 0, 0, 1],  # Node 2 connects to nodes 0, 1, 4\n    [0, 1, 0, 0, 1],  # Node 3 connects to nodes 1, 4\n    [0, 0, 1, 1, 0]   # Node 4 connects to nodes 2, 3\n])\n\nprint(\"Adjacency matrix:\")\nprint(matrix)\n\nAdjacency matrix:\n[[0 1 1 0 0]\n [1 0 1 1 0]\n [1 1 0 0 1]\n [0 1 0 0 1]\n [0 0 1 1 0]]\n\n\nNotice the symmetry: if node i connects to node j, then node j connects to node i (for undirected networks). This symmetry disappears in directed networks, where relationships can be one-way.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#node-degrees",
    "href": "m01-euler_tour/02-coding.html#node-degrees",
    "title": "Coding Networks in Python",
    "section": "2 Node Degrees",
    "text": "2 Node Degrees\nThe degree of a node is the number of edges connected to it. This simple concept was central to Euler’s proof—he realized that a valid bridge walk requires each landmass to have an even degree (except possibly the starting and ending points).\n\n\nIn Königsberg, all four landmasses had odd degree, making the bridge walk impossible. This insight—that global properties emerge from local structure—remains fundamental to network analysis today.\nHere’s how to compute degrees using each representation:\n\nFrom Edge Table\nCount how many times each node appears in the edge list.\n\n_degrees = [0] * 5\nfor node1, node2 in edges:\n    _degrees[node1] += 1\n    _degrees[node2] += 1\nprint(\"Degrees from edge list:\", _degrees)\n\nDegrees from edge list: [2, 3, 3, 2, 2]\n\n\n\n\nWe increment the degree counter for both nodes in each edge because every edge contributes to two nodes’ degrees. This is why the total degree always equals twice the number of edges.\n\n\nFrom Adjacency List\nCount the length of each node’s neighbor list—the most direct approach.\n\n_degrees = [len(neighbors[i]) for i in range(5)]\nprint(\"Degrees from adjacency list:\", _degrees)\n\nDegrees from adjacency list: [2, 3, 3, 2, 2]\n\n\n\n\nFrom Adjacency Matrix\nSum each row (or column) of the matrix—leveraging vectorized operations.\n\n_degrees = matrix.sum(axis=1)  # Sum rows\nprint(\"Degrees from adjacency matrix:\", _degrees)\n\nDegrees from adjacency matrix: [2 3 3 2 2]\n\n\n\n\nFor undirected networks, row sums equal column sums. For directed networks, row sums give out-degree (outgoing connections) while column sums give in-degree (incoming connections).",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#checking-for-trails-walks-and-paths",
    "href": "m01-euler_tour/02-coding.html#checking-for-trails-walks-and-paths",
    "title": "Coding Networks in Python",
    "section": "3 Checking for Trails, Walks, and Paths",
    "text": "3 Checking for Trails, Walks, and Paths\nNow that we understand how to represent networks and compute degrees, let’s implement functions to verify whether a sequence of nodes represents a valid walk, trail, path, or cycle. These verification algorithms are essential for network analysis and implementing graph traversal algorithms.\n\nVerifying a Walk\nA walk is the most permissive—we simply need to check that each consecutive pair of nodes is connected by an edge.\n\ndef is_walk(sequence, adjacency_matrix):\n    \"\"\"\n    Check if a sequence of nodes forms a valid walk.\n\n    Args:\n        sequence: List of node indices [v0, v1, v2, ...]\n        adjacency_matrix: 2D numpy array representing the graph\n\n    Returns:\n        bool: True if sequence is a valid walk, False otherwise\n    \"\"\"\n    if len(sequence) &lt; 2:\n        return True  # Single node or empty sequence is trivially a walk\n\n    # Use NumPy vectorized operations for efficient edge checking\n    sequence = np.array(sequence)\n    current_nodes = sequence[:-1]  # All nodes except the last\n    next_nodes = sequence[1:]      # All nodes except the first\n\n    # Simple but slower: for loop version (slower but more explicit)\n    # for i, j in zip(current_nodes, next_nodes):\n    #     if adjacency_matrix[i, j] == 0:\n    #         return False\n    # return True\n\n    # Check all edges at once using advanced indexing\n    edges_exist = adjacency_matrix[current_nodes, next_nodes]\n\n    # All edges must exist (all values must be 1)\n    return np.all(edges_exist == 1)\n\n\n# Test with our sample network\ntest_sequence = [0, 1, 2, 4, 3, 1]\nprint(f\"Sequence {test_sequence} is a valid walk: {is_walk(test_sequence, matrix)}\")\n\n# Test an invalid walk\ninvalid_sequence = [0, 3]  # No direct edge between 0 and 3\nprint(f\"Sequence {invalid_sequence} is a valid walk: {is_walk(invalid_sequence, matrix)}\")\n\nSequence [0, 1, 2, 4, 3, 1] is a valid walk: True\nSequence [0, 3] is a valid walk: False\n\n\n\n\n\n\n\n\nMind the loops!\n\n\n\nFor loops in Python is the notorious source of computational bottlenecks. Avoiding for loops significantly boosts the speed. In is_walk, we use one for loop but you can avoid it by using NumPy’s advanced indexing, i.e., adjacency_matrix[(current_nodes, next_nodes)]. The way to think about this is that (current_nodes, next_nodes) is a tuple of indices, acting as a multi-dimensional index. adjacency_matrix[(current_nodes, next_nodes)] is 1d array of length the same as current_nodes and next_nodes. If the value is 0, then the edge does not exist. We can then check if all the values are not zero.\n\n\n\n\nVerifying a Trail\nA trail requires all edges to be distinct, but nodes can repeat.\n\ndef is_trail(sequence, adjacency_matrix):\n    \"\"\"\n    Check if a sequence of nodes forms a valid trail.\n\n    Args:\n        sequence: List of node indices [v0, v1, v2, ...]\n        adjacency_matrix: 2D numpy array representing the graph\n\n    Returns:\n        bool: True if sequence is a valid trail, False otherwise\n    \"\"\"\n    if not is_walk(sequence, adjacency_matrix):\n        return False  # Must be a valid walk first\n\n    if len(sequence) &lt; 2:\n        return True\n\n    # Convert to numpy for efficient operations\n    sequence = np.array(sequence)\n    current_nodes = sequence[:-1]\n    next_nodes = sequence[1:]\n\n    # Use complex numbers to represent edges!\n    # For undirected graph: smaller_node + 1j * larger_node\n    # This ensures edge (1,2) and (2,1) both become 1+2j\n    edge_starts = np.minimum(current_nodes, next_nodes)  # Real part\n    edge_ends = np.maximum(current_nodes, next_nodes)    # Imaginary part\n    complex_edges = edge_starts + 1j * edge_ends\n\n    # Check uniqueness directly with NumPy\n    return len(complex_edges) == len(np.unique(complex_edges))\n\n    # Alternative: Original for loop version (slower but more explicit)\n    # used_edges = set()\n    # for i in range(len(sequence) - 1):\n    #     current_node = sequence[i]\n    #     next_node = sequence[i + 1]\n    #     # Create edge tuple (smaller index first for undirected graphs)\n    #     edge = (min(current_node, next_node), max(current_node, next_node))\n    #     if edge in used_edges:\n    #         return False  # Edge already used\n    #     used_edges.add(edge)\n    # return True\n\n# Test trail verification\ntrail_sequence = [0, 1, 3, 4, 2]\nprint(f\"Sequence {trail_sequence} is a valid trail: {is_trail(trail_sequence, matrix)}\")\n\n# Test invalid trail (reuses edge 1-2)\ninvalid_trail = [0, 1, 2, 1, 3]\nprint(f\"Sequence {invalid_trail} is a valid trail: {is_trail(invalid_trail, matrix)}\")\n\nSequence [0, 1, 3, 4, 2] is a valid trail: True\nSequence [0, 1, 2, 1, 3] is a valid trail: False\n\n\n\n\nnp.unique is a powerful function that can handle complex numbers natively.\n\n\n\n\n\n\nComplex Numbers for Edge Representation\n\n\n\nWe use complex numbers to represent edges! Each edge becomes smaller_node + 1j * larger_node. For example, edge (1,2) becomes 1+2j, and edge (2,1) also becomes 1+2j (normalized). Think of complex numbers as natural 2D coordinates for representing node pairs.\n\n\n\n\nVerifying a Path\nA path requires all nodes (except possibly start/end for cycles) to be distinct.\n\ndef is_path(sequence, adjacency_matrix):\n    \"\"\"\n    Check if a sequence of nodes forms a valid path.\n\n    Args:\n        sequence: List of node indices [v0, v1, v2, ...]\n        adjacency_matrix: 2D numpy array representing the graph\n        allow_cycle: If True, allows start node = end node (cycle)\n\n    Returns:\n        bool: True if sequence is a valid path, False otherwise\n    \"\"\"\n    if not is_walk(sequence, adjacency_matrix):\n        return False  # Must be a valid walk first\n\n    if len(sequence) &lt; 2:\n        return True\n\n    sequence = np.array(sequence)\n\n    return len(sequence) == len(np.unique(sequence))\n\n# Test path verification\npath_sequence = [0, 1, 3, 4]\nprint(f\"Sequence {path_sequence} is a valid path: {is_path(path_sequence, matrix)}\")\n\n# Test invalid path (repeats node 1)\ninvalid_path = [0, 1, 2, 1, 3]\nprint(f\"Sequence {invalid_path} is a valid path: {is_path(invalid_path, matrix)}\")\n\nSequence [0, 1, 3, 4] is a valid path: True\nSequence [0, 1, 2, 1, 3] is a valid path: False",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#connected-components",
    "href": "m01-euler_tour/02-coding.html#connected-components",
    "title": "Coding Networks in Python",
    "section": "4 Connected Components",
    "text": "4 Connected Components\nConnected components are the maximal sets of nodes where every pair is connected by some path. For Euler path analysis, this is crucial—an Euler path can only exist if the entire graph forms a single connected component (or if we’re only considering the component containing edges).\n\n\nIn Königsberg, all landmasses were connected by bridges, forming one component. If one landmass were isolated, no Euler path could traverse the entire city. This connectivity requirement is the first condition in Euler’s theorem.\n\nThe Algorithm: Depth-First Search\nA simple way to find connected components is to systematically explore from each unvisited node using depth-first search (DFS). This works because DFS can only reach nodes that are connected through some path.\nAlgorithm steps: 1. Mark all nodes as unvisited 2. For each unvisited node: - Start a new component - Use DFS to explore all reachable nodes - Add all reached nodes to this component 3. Return the list of components\n\ndef connected_components(adjacency_matrix):\n    \"\"\"\n    Find connected components in an undirected graph using adjacency matrix.\n\n    Args:\n        adjacency_matrix: 2D numpy array (square)\n\n    Returns:\n        List of lists, each sublist contains node indices in a component\n    \"\"\"\n    import numpy as np\n    n = adjacency_matrix.shape[0]\n    visited = np.zeros(n, dtype=bool)\n    components = []\n\n    def dfs(node, component):\n        \"\"\"Depth-first search to explore a component\"\"\"\n        # Mark the current node as visited and add it to current component\n        visited[node] = True\n        component.append(node)\n        \n        # Find all neighbors of the current node using vectorized operation\n        neighbors = np.where(adjacency_matrix[node] &gt; 0)[0]\n        \n        # Recursively visit unvisited neighbors\n        for neighbor in neighbors:\n            if not visited[neighbor]:\n                dfs(neighbor, component)\n\n    # Main algorithm: iterate through all nodes\n    for v in range(n):\n        if not visited[v]:  # Found a new component\n            component = []\n            dfs(v, component)  # Explore entire component\n            components.append(component)\n    \n    return components\n\n# Test with our original connected graph\nprint(\"Testing with connected graph:\")\ncomponents = connected_components(matrix)\nprint(\"Connected components:\", components)\nprint(f\"Number of components: {len(components)}\")\n\n# Create a disconnected graph to demonstrate multiple components\ndisconnected_matrix = np.array([\n    [0, 1, 0, 0, 0],  # Component 1: nodes 0,1,2\n    [1, 0, 1, 0, 0],  \n    [0, 1, 0, 0, 0],  \n    [0, 0, 0, 0, 1],  # Component 2: nodes 3,4\n    [0, 0, 0, 1, 0]   \n])\n\nprint(\"\\nTesting with disconnected graph:\")\ndisconnected_components = connected_components(disconnected_matrix)\nprint(\"Connected components:\", disconnected_components)\nprint(f\"Number of components: {len(disconnected_components)}\")\n\nTesting with connected graph:\nConnected components: [[0, np.int64(1), np.int64(2), np.int64(4), np.int64(3)]]\nNumber of components: 1\n\nTesting with disconnected graph:\nConnected components: [[0, np.int64(1), np.int64(2)], [3, np.int64(4)]]\nNumber of components: 2\n\n\n\n\nDFS naturally explores as “deep” as possible before backtracking. This makes it perfect for component finding because once we start exploring from a node, we want to find ALL nodes in its component before moving to the next component.\n\n\nImproved Euler Path Checker\nNow we can enhance our Euler path function to include the connectivity requirement:\n\ndef has_euler_path_complete(adjacency_matrix):\n    \"\"\"\n    Complete Euler path checker with connectivity verification.\n    \n    Args:\n        adjacency_matrix: 2D numpy array representing the graph\n    \n    Returns:\n        bool: True if graph has an Euler path, False otherwise\n    \"\"\"\n    # Check if graph is connected (ignoring isolated nodes)\n    components = connected_components(adjacency_matrix)\n    \n    # Find nodes with at least one edge (degree &gt; 0)\n    degrees = adjacency_matrix.sum(axis=1)\n    non_isolated_nodes = np.where(degrees &gt; 0)[0]\n    \n    if len(non_isolated_nodes) == 0:\n        return True  # Empty graph has Euler path trivially\n    \n    # Check if all non-isolated nodes are in the same component\n    component_with_edges = None\n    for component in components:\n        if non_isolated_nodes[0] in component:\n            component_with_edges = set(component)\n            break\n    \n    # All nodes with edges must be in the same component\n    if not all(node in component_with_edges for node in non_isolated_nodes):\n        return False  # Graph is disconnected\n    \n    # Count nodes with odd degrees (among non-isolated nodes)\n    non_isolated_degrees = degrees[non_isolated_nodes]\n    odd_degree_count = np.sum(non_isolated_degrees % 2)\n    \n    # Euler's theorem: exactly 0 or 2 nodes with odd degrees\n    return odd_degree_count == 0 or odd_degree_count == 2\n\n# Test with connected graph\nprint(\"Connected graph has Euler path:\", has_euler_path_complete(matrix))\n\n# Test with disconnected graph\nprint(\"Disconnected graph has Euler path:\", has_euler_path_complete(disconnected_matrix))\n\n# Test the classic Königsberg bridge problem (all odd degrees)\nkonigsberg = np.array([\n    [0, 1, 1, 1],  # Landmass 0 connects to all others (degree 3)\n    [1, 0, 1, 1],  # Landmass 1 connects to all others (degree 3)\n    [1, 1, 0, 1],  # Landmass 2 connects to all others (degree 3)\n    [1, 1, 1, 0]   # Landmass 3 connects to all others (degree 3)\n])\nprint(\"Königsberg bridges have Euler path:\", has_euler_path_complete(konigsberg))\n\nConnected graph has Euler path: True\nDisconnected graph has Euler path: False\nKönigsberg bridges have Euler path: False\n\n\n\n\n\n\n\n\nWhy Connectivity Matters\n\n\n\nEven if a graph has exactly 2 odd-degree nodes, an Euler path cannot exist if those nodes are in different connected components. You cannot traverse from one component to another without existing edges, making a single continuous path impossible.\n\n\n\n\nVisualizing Component Structure\nUnderstanding component structure helps debug complex networks:\n\ndef analyze_graph_structure(adjacency_matrix):\n    \"\"\"Comprehensive analysis of graph structure for Euler path feasibility.\"\"\"\n    n = adjacency_matrix.shape[0]\n    degrees = adjacency_matrix.sum(axis=1)\n    components = connected_components(adjacency_matrix)\n    \n    print(f\"Graph Analysis:\")\n    print(f\"- Total nodes: {n}\")\n    print(f\"- Total edges: {adjacency_matrix.sum() // 2}\")  # Divide by 2 for undirected\n    print(f\"- Connected components: {len(components)}\")\n    \n    # Analyze each component\n    for i, component in enumerate(components):\n        component_degrees = degrees[component]\n        odd_count = np.sum(component_degrees % 2)\n        \n        print(f\"\\nComponent {i}: nodes {component}\")\n        print(f\"  - Size: {len(component)} nodes\")\n        print(f\"  - Node degrees: {dict(zip(component, component_degrees))}\")\n        print(f\"  - Odd degree nodes: {odd_count}\")\n        print(f\"  - Has Euler path: {odd_count == 0 or odd_count == 2}\")\n    \n    # Overall Euler path conclusion\n    non_isolated = np.where(degrees &gt; 0)[0]\n    if len(non_isolated) &gt; 0:\n        # Check if all non-isolated nodes are in same component\n        main_component = None\n        for comp in components:\n            if non_isolated[0] in comp:\n                main_component = set(comp)\n                break\n        \n        connected = all(node in main_component for node in non_isolated)\n        odd_total = np.sum(degrees[non_isolated] % 2)\n        \n        print(f\"\\nOverall Euler Path Analysis:\")\n        print(f\"- All edges connected: {connected}\")\n        print(f\"- Total odd degree nodes: {odd_total}\")\n        print(f\"- Has Euler path: {connected and (odd_total == 0 or odd_total == 2)}\")\n\n# Analyze our example graphs\nprint(\"=== Original Connected Graph ===\")\nanalyze_graph_structure(matrix)\n\nprint(\"\\n=== Disconnected Graph ===\")\nanalyze_graph_structure(disconnected_matrix)\n\nprint(\"\\n=== Königsberg Bridges ===\")\nanalyze_graph_structure(konigsberg)\n\n=== Original Connected Graph ===\nGraph Analysis:\n- Total nodes: 5\n- Total edges: 6\n- Connected components: 1\n\nComponent 0: nodes [0, np.int64(1), np.int64(2), np.int64(4), np.int64(3)]\n  - Size: 5 nodes\n  - Node degrees: {0: np.int64(2), np.int64(1): np.int64(3), np.int64(2): np.int64(3), np.int64(4): np.int64(2), np.int64(3): np.int64(2)}\n  - Odd degree nodes: 2\n  - Has Euler path: True\n\nOverall Euler Path Analysis:\n- All edges connected: True\n- Total odd degree nodes: 2\n- Has Euler path: True\n\n=== Disconnected Graph ===\nGraph Analysis:\n- Total nodes: 5\n- Total edges: 3\n- Connected components: 2\n\nComponent 0: nodes [0, np.int64(1), np.int64(2)]\n  - Size: 3 nodes\n  - Node degrees: {0: np.int64(1), np.int64(1): np.int64(2), np.int64(2): np.int64(1)}\n  - Odd degree nodes: 2\n  - Has Euler path: True\n\nComponent 1: nodes [3, np.int64(4)]\n  - Size: 2 nodes\n  - Node degrees: {3: np.int64(1), np.int64(4): np.int64(1)}\n  - Odd degree nodes: 2\n  - Has Euler path: True\n\nOverall Euler Path Analysis:\n- All edges connected: False\n- Total odd degree nodes: 4\n- Has Euler path: False\n\n=== Königsberg Bridges ===\nGraph Analysis:\n- Total nodes: 4\n- Total edges: 6\n- Connected components: 1\n\nComponent 0: nodes [0, np.int64(1), np.int64(2), np.int64(3)]\n  - Size: 4 nodes\n  - Node degrees: {0: np.int64(3), np.int64(1): np.int64(3), np.int64(2): np.int64(3), np.int64(3): np.int64(3)}\n  - Odd degree nodes: 4\n  - Has Euler path: False\n\nOverall Euler Path Analysis:\n- All edges connected: True\n- Total odd degree nodes: 4\n- Has Euler path: False",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/02-coding.html#summary",
    "href": "m01-euler_tour/02-coding.html#summary",
    "title": "Coding Networks in Python",
    "section": "5 Summary",
    "text": "5 Summary\nYou now understand how to:\n\nRepresent networks using edge lists, adjacency lists, and adjacency matrices—each optimized for different computational tasks\nCompute node degrees efficiently using vectorized operations across all representations\nVerify walks, trails, paths, and cycles with robust algorithms that handle edge cases\nFind connected components using depth-first search to identify disconnected parts of networks\nApply Euler’s theorem completely by checking both degree conditions and connectivity requirements\n\n\n\n\n\n\n\nComputational Complexity\n\n\n\n\nDegree calculation: O(n²) for adjacency matrix, O(E) for edge list, O(1) for adjacency list\nWalk verification: O(k) where k is sequence length\nConnected components: O(n²) for adjacency matrix representation using DFS\nComplete Euler path check: O(n²) dominated by connectivity check\n\n\n\nThese fundamental algorithms form the building blocks for more sophisticated network analysis. Whether you’re analyzing social networks, transportation systems, or molecular structures, these core concepts of connectivity, traversal, and structural analysis remain essential.\nFrom Euler’s original insight about Königsberg’s bridges to modern network science, the mathematical principles you’ve implemented here continue to solve real-world problems—from GPS routing algorithms to understanding brain connectivity patterns.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Coding Networks in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/00-preparation.html",
    "href": "m01-euler_tour/00-preparation.html",
    "title": "From Visual to Computational Thinking",
    "section": "",
    "text": "Take Intro module to set up the environment!",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "From Visual to Computational Thinking"
    ]
  },
  {
    "objectID": "m01-euler_tour/00-preparation.html#preparation",
    "href": "m01-euler_tour/00-preparation.html#preparation",
    "title": "From Visual to Computational Thinking",
    "section": "",
    "text": "Take Intro module to set up the environment!",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "From Visual to Computational Thinking"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to SSIE 641 Advanced Topics on Network Science",
    "section": "",
    "text": "``Don’t think! Feeeeeel’’ is a famous quote by Bruce Lee in the movie Enter the Dragon, and this is my guiding philosophy of learning.\nThis course is designed to help you feel the concepts and tools of network science through pen-and-paper exercises and hands-on coding."
  },
  {
    "objectID": "index.html#list-of-exercises",
    "href": "index.html#list-of-exercises",
    "title": "Welcome to SSIE 641 Advanced Topics on Network Science",
    "section": "1 List of Exercises",
    "text": "1 List of Exercises\n\n\n\nModule\nPen and Paper Exercise\nAssignment\n\n\n\n\nM01: Euler Tour\nThe Koningsberg Bridge\n-\n\n\nM02: Small World\nIt’s a small world!! 6 degrees of separation\nExercise\n\n\nM03: Robustness\nBuild it, Break it, and Build it back!\nExercise\n\n\nM04: Friendship Paradox\nData Visualization\nExercise\n\n\nM05: Clustering\nPerfect vs. Almost Perfect\n-\n\n\nM06: Centrality\nWho’s the Big Cheese in the University Clubs?\n-\n\n\nM07: Random Walks\nRandom Walks on Networks\n-\n\n\nM08: Embedding\nNetwork Embeddings\n-\n\n\nM09: Graph Neural Networks\nGraph Neural Networks\n-"
  },
  {
    "objectID": "index.html#list-of-assignments",
    "href": "index.html#list-of-assignments",
    "title": "Welcome to SSIE 641 Advanced Topics on Network Science",
    "section": "2 List of assignments",
    "text": "2 List of assignments\nNote: For the students taking SSIE 641, the grading will be done through GitHub Classroom, and the following assignments are not linked to GitHub Classroom. Please use the links provided by the instructor. All the links are listed in Brightspace.\n\n\n\nModule\nAssignment\n\n\n\n\nSmall World\nAssignment 1\n\n\nNetwork Centrality\nAssignment 2\n\n\nSmall world networks\nAssignment 3"
  },
  {
    "objectID": "course/minidora-usage.html#getting-started-with-minidora",
    "href": "course/minidora-usage.html#getting-started-with-minidora",
    "title": "Using Minidora",
    "section": "1 Getting Started with Minidora",
    "text": "1 Getting Started with Minidora\nMinidora is your personal AI tutor available 24/7 through Discord to help you master network science concepts. She’s designed to provide personalized learning support, answer questions about course materials, and guide you through challenging topics with patience and clarity. To interact with Minidora, simply use Discord slash commands or mention her directly in any channel or thread where she’s present.\nCheck out the instruction here on how to use Minidora: Minidora Usage",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/minidora-usage.html#asking-questions",
    "href": "course/minidora-usage.html#asking-questions",
    "title": "Using Minidora",
    "section": "2 Asking Questions",
    "text": "2 Asking Questions\nThe most straightforward way to get help is using the /ask command followed by your question. For example, suppose that you want to ask a subject (Euler tour) in module 1.\n\nType /ask then type space.\nType your question (e.g., What is an Euler tour?)\nType space\nYou will be prompted to specify the module id. The id consists of “m”. For example, if it is module 1, you should type m01. Type the module id.\nThen type enter.\n\nMinidora will then read the lecture content and provide an explanation.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/minidora-usage.html#natural-conversations-and-interactive-learning",
    "href": "course/minidora-usage.html#natural-conversations-and-interactive-learning",
    "title": "Using Minidora",
    "section": "3 Natural Conversations and Interactive Learning",
    "text": "3 Natural Conversations and Interactive Learning\nFor a more conversational experience, use the /chat command which allows you to interact with Minidora in a natural, free-flowing manner. You can say things like /chat I'm confused about small-world networks, can you explain them step by step? or /chat Can you help me debug this Python code for computing centrality? Minidora will engage in back-and-forth dialogue, ask clarifying questions, and adapt her explanations based on your responses.\nNote that /chat does not contextualize the Minidora to the course materials. That means that it does not read the lecture content and interact with the students with its build-in knowledge.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/minidora-usage.html#quizzes-and-assessment",
    "href": "course/minidora-usage.html#quizzes-and-assessment",
    "title": "Using Minidora",
    "section": "4 Quizzes and Assessment",
    "text": "4 Quizzes and Assessment\nTo test your understanding and reinforce learning, Minidora offers intelligent quiz features through the /quiz command. She can generate concept-based questions using /concept-quiz m01 multiple-choice for theoretical understanding, or coding challenges with /code-quiz m01 to practice implementation skills. Minidora tracks your progress and adapts quiz difficulty based on your performance, focusing on areas where you need more practice. You can also request quizzes on specific topics by adding subject keywords, such as /quiz m02 clustering algorithms.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/minidora-usage.html#tracking-your-progress",
    "href": "course/minidora-usage.html#tracking-your-progress",
    "title": "Using Minidora",
    "section": "5 Tracking Your Progress",
    "text": "5 Tracking Your Progress\nUse the /status command to monitor your learning journey and see detailed insights about your progress. Minidora provides different status views: /status summary gives you a quick overview of questions asked and concepts mastered, while /status concepts shows which topics you’ve learned and what to study next. The /status profile command reveals your personalized learning profile, including your preferred difficulty level, learning style, and areas where you excel or need additional support. This helps Minidora provide increasingly personalized assistance as you continue learning.",
    "crumbs": [
      "Home",
      "Course Information",
      "Using Minidora"
    ]
  },
  {
    "objectID": "course/setup.html",
    "href": "course/setup.html",
    "title": "Setup",
    "section": "",
    "text": "We’ll use Python to work with data throughout this course. Python is an excellent choice for network science for its rich ecosystem of libraries, readable and intuitive syntax, and well-documented documentation.\nWe strongly recommend using virtual environments to manage your Python packages. Virtual environments create isolated Python installations for each project, avoiding dependency hell and providing several key benefits:\n\n\nDon’t confuse Python virtual environments with virtual machines (VMs). Python virtual environments are lightweight isolation tools that only separate Python packages and dependencies within the same operating system. Virtual machines, on the other hand, create complete isolated operating systems.\n\nReproducibility: Your code will work consistently across different machines and over time\nFlexibility: You can use different versions of packages for different projects without conflicts\nPrevent project interference: Changes to one project won’t break another project’s dependencies\n\n\n\n\n\n\n\nFigure 1: Without virtual environments, you risk dependency hell where package conflicts make your projects unusable.\n\n\n\nWe recommend using mamba and uv. Mamba is a tool for quickly installing Python and other packages, and for creating isolated environments for your projects. uv is a fast Python package and project manager. While we won’t be running uv commands directly in this course, you’ll need uv to properly run Marimo notebooks, which provides a much better development experience. See here for installation instructions.\nFollow the following steps to install mamba, uv, along with the minimum Python packages required for this course.\n\n[Install mamba] (https://github.com/conda-forge/miniforge)\nRun the following command to create a new environment with the minimum Python packages required for this course.\n\nmamba create -n advnetsci python==3.11 matplotlib scipy numpy pandas seaborn uv\n\nActivate the environment.\n\nmamba activate advnetsci\n\nPip install marimo.\n\npip install marimo\n\n\n\n\n\n\nIf you prefer tools other than uv, here are some alternatives:\n\nvenv: The standard library for creating virtual environments;\npyenv: Great for managing multiple Python versions;\nConda: Popular in data science, includes non-Python packages;\nMamba: Faster drop-in replacement for conda;\nMiniforge: Community-driven conda distribution with mamba included;",
    "crumbs": [
      "Home",
      "Course Information",
      "Setup"
    ]
  },
  {
    "objectID": "course/setup.html#python-and-virtual-environments",
    "href": "course/setup.html#python-and-virtual-environments",
    "title": "Setup",
    "section": "",
    "text": "We’ll use Python to work with data throughout this course. Python is an excellent choice for network science for its rich ecosystem of libraries, readable and intuitive syntax, and well-documented documentation.\nWe strongly recommend using virtual environments to manage your Python packages. Virtual environments create isolated Python installations for each project, avoiding dependency hell and providing several key benefits:\n\n\nDon’t confuse Python virtual environments with virtual machines (VMs). Python virtual environments are lightweight isolation tools that only separate Python packages and dependencies within the same operating system. Virtual machines, on the other hand, create complete isolated operating systems.\n\nReproducibility: Your code will work consistently across different machines and over time\nFlexibility: You can use different versions of packages for different projects without conflicts\nPrevent project interference: Changes to one project won’t break another project’s dependencies\n\n\n\n\n\n\n\nFigure 1: Without virtual environments, you risk dependency hell where package conflicts make your projects unusable.\n\n\n\nWe recommend using mamba and uv. Mamba is a tool for quickly installing Python and other packages, and for creating isolated environments for your projects. uv is a fast Python package and project manager. While we won’t be running uv commands directly in this course, you’ll need uv to properly run Marimo notebooks, which provides a much better development experience. See here for installation instructions.\nFollow the following steps to install mamba, uv, along with the minimum Python packages required for this course.\n\n[Install mamba] (https://github.com/conda-forge/miniforge)\nRun the following command to create a new environment with the minimum Python packages required for this course.\n\nmamba create -n advnetsci python==3.11 matplotlib scipy numpy pandas seaborn uv\n\nActivate the environment.\n\nmamba activate advnetsci\n\nPip install marimo.\n\npip install marimo\n\n\n\n\n\n\nIf you prefer tools other than uv, here are some alternatives:\n\nvenv: The standard library for creating virtual environments;\npyenv: Great for managing multiple Python versions;\nConda: Popular in data science, includes non-Python packages;\nMamba: Faster drop-in replacement for conda;\nMiniforge: Community-driven conda distribution with mamba included;",
    "crumbs": [
      "Home",
      "Course Information",
      "Setup"
    ]
  },
  {
    "objectID": "course/setup.html#marimo-notebook",
    "href": "course/setup.html#marimo-notebook",
    "title": "Setup",
    "section": "2 Marimo Notebook",
    "text": "2 Marimo Notebook\nWe’ll use Marimo (GitHub) notebooks for assignments and interactive exercises throughout the course. Marimo is a reactive Python notebook that automatically updates when you change code, making it perfect for exploring network data and seeing results in real-time.\n\n\n\n\nMarimo integrates especially tightly with uv and provides a package sandbox feature that lets you inline dependencies directly in notebook files. This is the easiest way to get started - no prior uv knowledge required.\nCreating a sandboxed notebook:\nuvx marimo edit --sandbox my_notebook.py\nThis command installs marimo in a temporary environment, tracks your dependencies and stores them in the notebook file, and automatically downloads any existing dependencies.\nRunning sandboxed notebooks:\nuv run my_notebook.py\nBenefits: Dependencies are embedded in the notebook file itself, perfect reproducibility, and no need to manage separate dependency files.\n\nAlternative Installation\nIf you’re not using uv, you can install marimo with pip:\npip install marimo\n\n\nRunning Marimo\nTo start a new marimo notebook:\nmarimo edit\nTo open an existing marimo notebook:\nmarimo edit notebook.py",
    "crumbs": [
      "Home",
      "Course Information",
      "Setup"
    ]
  },
  {
    "objectID": "course/setup.html#github-and-github-copilot",
    "href": "course/setup.html#github-and-github-copilot",
    "title": "Setup",
    "section": "3 Github and GitHub Copilot",
    "text": "3 Github and GitHub Copilot\nWe’ll use GitHub for assignment collection and auto-grading in this course.\n\n\n\n\n\nMinimum Requirements\nAt the minimum level, you only need to:\n\nCreate a GitHub account at github.com\nKnow how to upload files to GitHub\n\nDetailed instructions on how to upload your assignments to GitHub will be provided separately - advanced Git features are not required for the course. See this assignment example to get familiar with the format.\n\n\nSubscribing to GitHub Copilot\nWe strongly encourage you to use GitHub Copilot, an AI-powered coding assistant that helps you write code faster and more efficiently. GitHub Copilot is an AI pair programmer that provides intelligent code suggestions, completions, and explanations directly in code editor, including VS Code and Marimo.\nStudents can get free access to GitHub Copilot Pro, which includes enhanced features and priority access. Visit the GitHub Copilot Pro free access page to get started.\nMarimo notebook supports GitHub Copilot out of the box. See the instruction to enable it. If you are using VS Code, you can also install the GitHub Copilot extension to get the same experience.\n\n\nFor Students Interested in Learning More\nUnderstanding Git and GitHub is useful for seamlessly working with assignments and will benefit your programming workflow. Additionally, Git and GitHub integrate nicely with AI tools for productivity improvement, making your development process more efficient.\n\n\nGit(Hub) and AI tools are like a pair of best friends. Git ensures that all edits are tracked and can be reverted. GitHub makes it easy for you to collaborate with (multiple) AI agents with you.\n\n\n\n\n\nGitHub Desktop (Recommended for Beginners)\nIf you want to learn more about version control, start with GitHub Desktop, a user-friendly graphical interface:\n\nGo to desktop.github.com\nDownload for your operating system\nInstall and sign in with your GitHub account\n\n\n\nUnderstanding Git and Version Control\nGit is a version control system that tracks changes in your code over time. Think of it as a sophisticated “save” system that:\n\nKeeps a complete history of all changes to your files\nLets you go back to any previous version\nAllows multiple people to work on the same project simultaneously\nHelps you manage different versions or “branches” of your work\n\nGitHub is a cloud-based platform that hosts Git repositories and adds collaboration features.\n\n\nLearning Resources\nEssential resources to understand Git concepts:\n\nInteractive Git Tutorial - Visual, hands-on learning\nGitHub Desktop Documentation - Official desktop app guide\nAtlassian Git Tutorials - Detailed tutorials with examples",
    "crumbs": [
      "Home",
      "Course Information",
      "Setup"
    ]
  },
  {
    "objectID": "intro/why-networks.html",
    "href": "intro/why-networks.html",
    "title": "Networks",
    "section": "",
    "text": "In 2009, the H1N1 influenza pandemic started in Mexico and spread around the world. Dirk Brockmann and Dirk Helbing tracked how the disease reached different countries and made a surprising discovery that would revolutionize how we understand spreading processes.\nThe most natural way to think about disease spread is through geographic distance. If you looked at a traditional world map, you might expect the disease to spread in expanding circles - first to nearby countries like Guatemala and the United States, then gradually to more distant places. But look at what the data actually shows:\n\n\n\n\n\n\nFigure 1: Geographic distance shows only weak correlation with disease arrival times for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\nDistance does explain the arrival time to some extent - there’s a rough trend where farther places tend to be infected later (C, D, E). But it doesn’t tell the whole story. At the same distances, some cities experienced early arrival while others experienced much later arrival. What explains this variation?\nThis mystery was solved by Dirk Brockmann and his colleagues, who realized that disease spread follows the hidden geometry of mobility networks - not geographic maps. Air travel connections, not physical distance, determined how quickly the pandemic reached different parts of the world.\n\n\n\n\n\n\nFigure 2: Effective distance (based on mobility networks) shows strong correlation with disease arrival times (R² = 0.973) for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\n\n\nSee (Brockmann and Helbing 2013) for more details.\nThe H1N1 example above reveals a fundamental truth: network structure determines how things spread. Geographic distance became irrelevant once we understood the underlying mobility network. This principle extends far beyond disease outbreaks.\nNetworks are everywhere. Look around you: plants depend on pollinators in ecological networks, predators and prey form intricate food webs, your brain operates through neural networks, and modern medicine maps drug interactions. At the molecular level, proteins interact in complex networks that sustain life. Socially, we’re connected through friendship networks, while globally, financial institutions form interconnected webs that can trigger worldwide crises. Every flight you take follows airport networks, every light switch connects to power grids, and every river flows through branching networks to the sea. Even the internet connecting you to this text and the knowledge graphs organizing human understanding - all are networks.\n\n\n\n\n\n\nPlant pollinator network\n\n\n\n\n\n\n\nFood web\n\n\n\n\n\n\n\nBrain network\n\n\n\n\n\n\n\n\n\nMedicine network\n\n\n\n\n\n\n\nProtein-protein interaction\n\n\n\n\n\n\n\nSocial network\n\n\n\n\n\n\n\n\n\nInternational financial network\n\n\n\n\n\n\n\nUS airport network\n\n\n\n\n\n\n\nPower grid network\n\n\n\n\n\n\n\n\n\nRiver network\n\n\n\n\n\n\n\nInternet network\n\n\n\n\n\n\n\nKnowledge graph",
    "crumbs": [
      "Home",
      "Introduction",
      "Networks"
    ]
  },
  {
    "objectID": "intro/why-networks.html#networks-are-everywhere-and-they-matter",
    "href": "intro/why-networks.html#networks-are-everywhere-and-they-matter",
    "title": "Networks",
    "section": "",
    "text": "In 2009, the H1N1 influenza pandemic started in Mexico and spread around the world. Dirk Brockmann and Dirk Helbing tracked how the disease reached different countries and made a surprising discovery that would revolutionize how we understand spreading processes.\nThe most natural way to think about disease spread is through geographic distance. If you looked at a traditional world map, you might expect the disease to spread in expanding circles - first to nearby countries like Guatemala and the United States, then gradually to more distant places. But look at what the data actually shows:\n\n\n\n\n\n\nFigure 1: Geographic distance shows only weak correlation with disease arrival times for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\nDistance does explain the arrival time to some extent - there’s a rough trend where farther places tend to be infected later (C, D, E). But it doesn’t tell the whole story. At the same distances, some cities experienced early arrival while others experienced much later arrival. What explains this variation?\nThis mystery was solved by Dirk Brockmann and his colleagues, who realized that disease spread follows the hidden geometry of mobility networks - not geographic maps. Air travel connections, not physical distance, determined how quickly the pandemic reached different parts of the world.\n\n\n\n\n\n\nFigure 2: Effective distance (based on mobility networks) shows strong correlation with disease arrival times (R² = 0.973) for simulated pandemics (C), H1N1 2009 (D), and SARS 2003 (E).\n\n\n\n\n\nSee (Brockmann and Helbing 2013) for more details.\nThe H1N1 example above reveals a fundamental truth: network structure determines how things spread. Geographic distance became irrelevant once we understood the underlying mobility network. This principle extends far beyond disease outbreaks.\nNetworks are everywhere. Look around you: plants depend on pollinators in ecological networks, predators and prey form intricate food webs, your brain operates through neural networks, and modern medicine maps drug interactions. At the molecular level, proteins interact in complex networks that sustain life. Socially, we’re connected through friendship networks, while globally, financial institutions form interconnected webs that can trigger worldwide crises. Every flight you take follows airport networks, every light switch connects to power grids, and every river flows through branching networks to the sea. Even the internet connecting you to this text and the knowledge graphs organizing human understanding - all are networks.\n\n\n\n\n\n\nPlant pollinator network\n\n\n\n\n\n\n\nFood web\n\n\n\n\n\n\n\nBrain network\n\n\n\n\n\n\n\n\n\nMedicine network\n\n\n\n\n\n\n\nProtein-protein interaction\n\n\n\n\n\n\n\nSocial network\n\n\n\n\n\n\n\n\n\nInternational financial network\n\n\n\n\n\n\n\nUS airport network\n\n\n\n\n\n\n\nPower grid network\n\n\n\n\n\n\n\n\n\nRiver network\n\n\n\n\n\n\n\nInternet network\n\n\n\n\n\n\n\nKnowledge graph",
    "crumbs": [
      "Home",
      "Introduction",
      "Networks"
    ]
  },
  {
    "objectID": "intro/why-networks.html#how-to-represent-a-network",
    "href": "intro/why-networks.html#how-to-represent-a-network",
    "title": "Networks",
    "section": "2 How to represent a network",
    "text": "2 How to represent a network\nAlthough networks come from vastly different fields, we can represent them all using the same universal language 😉. Whether we’re studying brain connections, protein interactions, or social relationships, the mathematical representation remains identical. This abstraction is what makes network science so interdisciplinary.\nA network is simply a collection of nodes connected by edges. Despite this simplicity, it’s one of the most powerful abstractions we have for understanding complex systems.\nWe can represent any network in two equivalent ways. Schematically, we draw them as dots and lines - nodes connected by edges, as shown in this network diagram:\n\n\n\n\n\n\nSchematic network\n\n\n\n\n\n\n\nA network of penguins in the Kyoto Aquarium.\n\n\n\n\n\nWhile the schematic representation is useful, things can get complicated as soon as the network becomes large. Also, we want to represent data quantitatively to obtain a quantitative understanding of network properties and behaviors.\nTables are a natural way to represent networks. The idea is to list the pairs of nodes that are connected by an edge. For example:\n\n\n\nSource\nTarget\n\n\n\n\nNode1\nNode2\n\n\nNode1\nNode3\n\n\nNode2\nNode3\n\n\nNode2\nNode4\n\n\nNode3\nNode5\n\n\n\nThis is called an edge table. Each row represents a connection between two nodes. Once we write down networks in this tabular format, we can apply the same analytical tools regardless of the domain - whether it’s routers, people, neurons, or molecules.",
    "crumbs": [
      "Home",
      "Introduction",
      "Networks"
    ]
  },
  {
    "objectID": "intro/why-networks.html#are-we-done-with-networks",
    "href": "intro/why-networks.html#are-we-done-with-networks",
    "title": "Networks",
    "section": "3 Are we done with networks?",
    "text": "3 Are we done with networks?\nIf we can represent a network in a table—a familiar data format that can be analyzed by statistical methods, machine learning, and other tools—can we just use these tools to analyze networks? Why do we need to learn network science?\nLong story short, a network is not just a collection of nodes and edges. They work in tandem to create a complex system. And this view—that a system is not just a collection of parts—represents a critical shift in science.\nFor centuries, scientists believed in reductionism. If you could create modules that function like duck organs and assemble them together, the machine would eventually behave like a duck. Vaucanson’s 18th century Digesting Duck seemed to prove this approach worked remarkably well: break down complex systems into fundamental components, understand each part, then reassemble them to understand the whole.\n\n\n\n\n\nVaucanson’s Digesting Duck\n\n\nFind more details in Wikipedia\nHowever, scientists began to realize that not all systems can be decomposed into units that provide sufficient understanding of the system as a whole. Networks represent a fundamental challenge to reductionist thinking because their most important properties emerge from the interactions between components, not from the components themselves. You can understand every individual neuron in the brain, but this won’t tell you how consciousness emerges. You can analyze every person in a social movement, but this won’t predict how ideas spread through the population. You can study every computer on the internet, but this won’t explain how global information patterns form.\nThe difficulty lies not in the individual nodes or edges, but in how they combine to create system-level behaviors that are genuinely novel. Scale overwhelms intuition; while you can mentally track relationships between three people, the same intuition fails completely with three million. Small changes can have massive consequences; removing one connection might fragment an entire network, while removing another has no effect at all. This is why network science exists as a distinct field: the traditional reductionist toolkit simply isn’t sufficient for understanding interconnected systems where the connections themselves are the source of complexity!",
    "crumbs": [
      "Home",
      "Introduction",
      "Networks"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html",
    "href": "m01-euler_tour/01-concepts.html",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "",
    "text": "Our story begins not in a lab, but on the streets of an 18th-century Prussian city called Königsberg. It was a city of thinkers—most famously the philosopher Immanuel Kant—but the puzzle that would change mathematics belonged to everyone.\nThe city was built around two islands in the Pregel River, connected to the mainland and each other by seven distinct bridges. During their Sunday strolls, the citizens amused themselves with a challenge:\n\n\n\n\n\n\nThe Königsberg Bridge Problem\n\n\n\nIs it possible to design a walk through the city that crosses each of the seven bridges exactly once and return to the starting point?\n\n\nGo ahead, try it yourself on the map below. Tracing a path with your finger, you’ll soon discover the same frustrating problem the citizens did: you either get stuck, missing a bridge, or you have to cross one twice.\n\n\n\n\n\n\nFigure 1: A map of the seven bridges of Königsberg. Four landmasses are connected by seven bridges over the Pregel River.\n\n\n\nWhat makes this so difficult? No one could find a path, but more importantly, no one could prove it was impossible. The problem eventually reached the brilliant mathematician Leonhard Euler. His goal was not just to find an answer, but to understand the reason behind the answer.\n\n\n\n\n\n\nPause and Think Like a Mathematician\n\n\n\nBefore we reveal Euler’s solution, take a moment to be a mathematician yourself. This is how discovery happens. We strongly recommend working through this pen-and-paper worksheet to experience the discovery process.\nAs you work, ask yourself: - What information is essential? The length of the bridge? The size of the island? - What are the fundamental constraints of the problem? - How can you move from “I can’t find a path” to “A path cannot exist”?",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#what-to-learn-in-this-module",
    "href": "m01-euler_tour/01-concepts.html#what-to-learn-in-this-module",
    "title": "Core Concepts",
    "section": "",
    "text": "In this module, we will explore the historical moment that gave birth to graph theory and modern network science. A simple Sunday stroll puzzle in an 18th-century Prussian city would spark a mathematical revolution that now powers everything from GPS navigation to social media algorithms.\nThrough Euler’s elegant solution, we will learn:\n\nHow to describe a network using mathematical language\nHow mathematical abstraction reveals hidden structure in complex problems\nThe power of degree-based reasoning in network analysis\nKeywords: network, graph, degree, Euler walk, mathematical abstraction\n\n\n\nThis is not just history—Euler’s approach of abstracting complex systems into nodes and edges is the same method we use today to analyze internet routing, brain connectivity, and viral spread patterns.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#the-königsberg-bridge-problem",
    "href": "m01-euler_tour/01-concepts.html#the-königsberg-bridge-problem",
    "title": "Core Concepts",
    "section": "2 The Königsberg Bridge Problem",
    "text": "2 The Königsberg Bridge Problem\n\nA Sunday Stroll That Changed Mathematics\nBack in the 18th century, there was a city called Königsberg situated on the Pregel River in what was then Prussia (now Kaliningrad, Russia). The city was built around two large islands, beautifully connected to each other and the mainland by seven elegant bridges.\n\n\nKönigsberg was a major intellectual center of the Enlightenment. Immanuel Kant spent his entire life there, never traveling more than 10 miles from the city. The university attracted scholars from across Europe.\nDuring their leisurely Sunday walks, the citizens of Königsberg found themselves pondering an intriguing puzzle:\n\n\n\n\n\n\nThe Königsberg Bridge Problem\n\n\n\nIs it possible to take a walk through the city that crosses each bridge exactly once and returns to the starting point?\n\n\n\n\n\n\n\n\nFigure 1: alt text\n\n\n\nThis seemingly innocent recreational question would become one of the most important problems in the history of mathematics. What made it revolutionary wasn’t the answer, but how the answer was found.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#try-it-yourself-first",
    "href": "m01-euler_tour/01-concepts.html#try-it-yourself-first",
    "title": "Core Concepts",
    "section": "3 Try It Yourself First!",
    "text": "3 Try It Yourself First!\nBefore we reveal Euler’s brilliant solution, take some time to think about this problem yourself. This is exactly how mathematical discovery works—by wrestling with puzzles and developing your own insights.\n\n\n\n\n\n\nWork Through It Step by Step\n\n\n\nHighly recommended: Download and work through this excellent pen-and-paper worksheet created by Esteban Moro (Moro 2017). It guides you through Euler’s reasoning step by step, letting you discover the solution yourself.\nQuestions to consider while working:\n\nCan you trace a path that crosses each bridge exactly once?\nWhat patterns do you notice when you try different routes?\nWhat properties of the landmasses seem important?\nHow might you prove that something is impossible, rather than just failing to find it?\n\n\n\nThe beauty of mathematics lies not just in the answers, but in the process of discovery.\n\n\n\n\n\n\n⚠️ Pause Here First!\n\n\n\nBefore reading Euler’s solution below, we strongly encourage you to:\n\nWork through the pen-and-paper worksheet by Esteban Moro\nTry the puzzle yourself - can you find a path that crosses each bridge exactly once?\nThink about what makes this problem difficult - what constraints do you notice?\n\nThe learning experience is much richer when you discover the insights yourself first!\n\n\nOnce you’ve given it some thought, continue reading to see how Euler approached this problem in 1736.\n\n\n🔍 Euler’s Revolutionary Abstraction\nLeonhard Euler approached this puzzle in 1736 with a stroke of genius that would define mathematical thinking for centuries. Instead of getting bogged down in the physical details—the width of the bridges, the size of the islands, the beauty of the architecture—he made a radical simplification.\n\n\nLeonhard Euler (1707-1783) was one of the most prolific mathematicians in history, contributing to nearly every area of mathematics. He lost sight in his right eye in 1738 but continued his work, producing almost half of his total output after becoming completely blind in 1766.\n\nThis was revolutionary thinking for its time. Before Euler, mathematics focused on quantities, measurements, and calculations. Euler showed that sometimes the relationships between objects matter more than the objects themselves.\nEuler realized that for this problem, only one thing mattered: which landmasses connect to which other landmasses. Everything else—the bridge lengths, island shapes, water depths—was irrelevant distraction.\nHe simplified the city into a network of landmasses connected by bridges:\n\n\n\n\n\n\nFigure 2: Euler’s graph of the bridges of Knigsberg. Taken from The Essential Guide to Graph Theory: From an 18th Century Riddle to AI Frameworks\n\n\n\nThis abstraction—reducing a complex physical system to its essential connectivity—was the birth of graph theory. Euler had invented a new mathematical language for describing relationships.\nOnce Euler had his abstract graph, he made another crucial insight. Instead of trying different walking routes (which would take forever), he focused on a fundamental property: how many bridges connect to each landmass?\n\n\nThis shift from “trying all possibilities” to “analyzing constraints” is a hallmark of mathematical thinking. Instead of brute force, Euler used logical reasoning to prove impossibility.\nEuler considered the degree (number of connections) of each node and realized there were only two cases: - a node has an even number of edges, or - a node has an odd number of edges.\nWhen a node has an even number 2k of edges, you can enter and leave the node exactly k times by crossing different edges. Every time you enter through one bridge, you can leave through another. The bridges naturally pair up.\nWhen a node has an odd number 2k+1 of edges, you can enter and leave the node k times, but one edge is left over. The only way to cross this last edge is if your journey starts or ends at this node.\n\n\nThink of it like a dance where everyone needs a partner. In nodes with even degree, every bridge has a “partner” for entering and leaving. Odd-degree nodes always have one “wallflower” bridge that can only be used at the very beginning or end.\nBased on this elegant reasoning, Euler arrived at his famous theorem:\n\n\n\n\n\n\nEuler’s Path Theorem\n\n\n\nA walk that crosses all edges exactly once exists if and only if:\n\nThe graph is connected (you can reach any node from any other node), AND\nEither:\n\nAll nodes have even degree (forms an Euler circuit), OR\nExactly two nodes have odd degree (forms an Euler path)\n\n\n\n\nThis wasn’t just a solution—it was a proof. Euler had shown not just whether such a path exists, but exactly when it’s possible.\n\n\nA good Youtube video explaining the Euler’s story:\n\n\n\n\n⚖️ The Verdict: Königsberg’s Impossible Dream\nApplying Euler’s theorem to the original Königsberg bridges reveals the truth: every landmass has an odd number of bridges. According to Euler’s conditions, this makes the desired walk impossible.\n\n\nIn the original graph: North shore (3 bridges), South shore (3 bridges), Large island (5 bridges), Small island (3 bridges). Four nodes with odd degree—exactly two more than Euler’s theorem allows.\nThe citizens of Königsberg had been attempting the impossible. Their Sunday stroll puzzle had no solution, and Euler had proven it with mathematical certainty.\nThe story takes a sobering turn during World War II. In 1944, Königsberg was heavily bombed by Allied forces, and later captured by the Soviet Union. Two of the seven historic bridges were destroyed in the bombardment.\n\n\n\nAfter WWII bombing, only five bridges remained—finally making an Euler path possible. {#fig-markdown-fig}\n\n\n\n\nThe city was renamed Kaliningrad and became part of Russia. Today, it remains a Russian exclave, separated from the rest of Russia by Lithuania and Poland. The few remaining bridges span a river now in a very different political landscape.\nWith only five bridges remaining, the network finally satisfied Euler’s conditions: exactly two nodes had odd degree. The mathematical puzzle that had stumped citizens for two centuries was “solved” by the tragic circumstances of war.\nThis ironic resolution reminds us that while mathematics reveals timeless truths about structure and possibility, the physical world—and human history—follows much more complex and unpredictable patterns.\n\n\nThe Lasting Legacy\nEuler’s solution to the Königsberg bridge problem did far more than solve a recreational puzzle. It demonstrated that:\n\nAbstract thinking can solve concrete problems\nMathematical proof is more powerful than trial and error\nNetwork structure determines what’s possible in interconnected systems\n\nThese insights now underpin our understanding of everything from internet routing protocols to epidemic spreading models. Every time you use GPS navigation or analyze social network data, you’re applying principles that trace back to Euler’s Sunday stroll through Königsberg.\n\n\nFun trivia:\nLeonhard Euler (1707-1783): Swiss mathematician and physicist, widely regarded as one of the most prolific mathematicians in history. Beyond solving the Königsberg bridge problem, he made fundamental contributions to calculus, topology, number theory, and physics. Despite losing sight in one eye and later becoming completely blind, he continued his mathematical work and produced nearly half of his total output after losing his sight.\nImmanuel Kant (1724-1804): German philosopher and one of the central thinkers of the Enlightenment. Born and died in Königsberg, never traveling more than 10 miles from the city. His systematic works in epistemology, metaphysics, ethics, and aesthetics have made him one of the most influential figures in modern Western philosophy. His regular daily walks were so punctual that neighbors reportedly set their clocks by his daily walks.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#walk-path-and-trail",
    "href": "m01-euler_tour/01-concepts.html#walk-path-and-trail",
    "title": "Core Concepts",
    "section": "4 Walk, Path, and Trail",
    "text": "4 Walk, Path, and Trail\n\n\nHere is a short video explaining the difference between walk, path, and trail. Good one to watch if you are visual learner.\n\n\nWe used the term walk and path in the previous section. But what are they? Let’s define them formally in the following.\nA walk is the most general type of movement through a network. Imagine you’re exploring a city with no restrictions:\n\nYou can visit any vertex (intersection) multiple times\nYou can traverse any edge (street) multiple times\nYou simply move from one connected vertex to another\n\nFormally, a walk is a sequence of nodes where each consecutive node pair is connected by an edge. No teleportation is allowed in a walk on a network.\nA trail is a walk without traversing the same edge twice. You can still visit the same node multiple times though via different edges.\n\n\n\n\n\n\nTrail\n\n\n\nIf edges are directed and two nodes are bidirectionally connected, then an edge from one node to the other is a different edge from the other node to the first node.\n\n\n\n\nA mail carrier’s route through a neighborhood: they might return to the same intersection multiple times but should traverse each street exactly once for efficiency.\nA path is a more restrictive type of walk without revisiting the same node.\n\n\n\nWalk: You can fly from New York to London, then back to New York, then to Paris, possibly using the same flight routes multiple times.\nTrail: You plan a trip where you never take the same flight route twice, but you might visit the same city more than once (e.g., New York \\rightarrow London \\rightarrow Paris \\rightarrow New York \\rightarrow Rome).\nPath: You visit a sequence of cities where you never visit the same city twice (e.g., New York \\rightarrow London \\rightarrow Paris \\rightarrow Rome).\n\nIn airline route maps, a trail means you never repeat a specific flight segment, while a path means you never return to a city you’ve already visited.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#cycle-and-circuit",
    "href": "m01-euler_tour/01-concepts.html#cycle-and-circuit",
    "title": "Core Concepts",
    "section": "5 Cycle and Circuit",
    "text": "5 Cycle and Circuit\nCycle and Circuit are two special types of walks that start and end at the same node—they form closed loops in the network.\nA circuit is a closed trail—a trail that starts and ends at the same vertex. Think of it as making a round trip where you never use the same road twice, but you can pass through the same intersections multiple times.\n\n\nExample: A tourist exploring a city who wants to end up back at their hotel without taking any street twice. They might pass through Times Square multiple times via different streets, but never walk down Broadway twice.\nA cycle is a closed path—a path that starts and ends at the same vertex with no repeated vertices (except for the starting/ending vertex). It’s the most restrictive type of closed walk.\n\n\nExample: A delivery truck route that visits each neighborhood exactly once before returning to the depot. Each stop is unique, forming a perfect loop.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#eulers-special-cases",
    "href": "m01-euler_tour/01-concepts.html#eulers-special-cases",
    "title": "Core Concepts",
    "section": "6 Euler’s Special Cases",
    "text": "6 Euler’s Special Cases\nNow we can precisely define what Euler was looking for in Königsberg:\n\nEuler Trail: A trail that includes every edge in the graph exactly once\nEuler Circuit/Cycle: An Euler trail that starts and ends at the same vertex\n\nThe Königsberg citizens were seeking an Euler circuit—a closed trail that would cross every bridge exactly once and return them home.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#network-connectivity",
    "href": "m01-euler_tour/01-concepts.html#network-connectivity",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "7 Network Connectivity",
    "text": "7 Network Connectivity\nEuler’s theorem only applies if the graph is connected. If you can’t get from one part of the network to another, then a single walk can’t possibly cover all the edges.\n\nA graph is connected if there is a path between any two nodes.\nA disconnected graph is made of two or more separate “islands” of nodes, called connected components.\n\n\n\n\n\n\n\nA graph with three distinct connected components, highlighted in different colors.\n\n\n\n\nFigure 4\n\n\n\n\nConnectivity in Directed Networks\nWhat if edges have a direction, like one-way streets? We call these directed graphs. This introduces two flavors of connectivity:\n\nWeakly Connected: The graph would be connected if you ignored the edge directions. You can get from A to B, but maybe not from B to A.\nStrongly Connected: There is a directed path from every node to every other node. No matter where you start, you can get anywhere else by following the arrows.\n\n\n\n\n\n\n\nA directed graph showing strongly and weakly connected components.\n\n\n\n\nFigure 5",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#references",
    "href": "m01-euler_tour/01-concepts.html#references",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "5 References",
    "text": "5 References",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/03-exercises.html",
    "href": "m01-euler_tour/03-exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Open in molab\n\n\nExercise Notebook",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "Exercises"
    ]
  },
  {
    "objectID": "m02-small-world/00-preparation.html",
    "href": "m02-small-world/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying small-world networks, you should understand these concepts from the Euler Tour module: - Basic graph representations (adjacency matrix, edge lists) - Node degree calculations - Graph connectivity - Path, walks, and trails",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m02-small-world/00-preparation.html#required-knowledge-from-module-1",
    "href": "m02-small-world/00-preparation.html#required-knowledge-from-module-1",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying small-world networks, you should understand these concepts from the Euler Tour module: - Basic graph representations (adjacency matrix, edge lists) - Node degree calculations - Graph connectivity - Path, walks, and trails",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html",
    "href": "m02-small-world/02-coding.html",
    "title": "Efficient Network Representation and Computing Paths",
    "section": "",
    "text": "The Python ecosystem offers several powerful libraries for network analysis, each with distinct strengths:\n\nnetworkx - a beginner-friendly library for network analysis\nigraph - a mature library with a wide range of algorithms\ngraph-tool - specialized for stochastic block models\nscipy - efficient tools for analyzing large networks\n\nThroughout this course, we’ll primarily use igraph, a mature and robust library originally developed for R and later ported to Python. While networkx is by far the most popular library, igraph offers several compelling advantages for serious network analysis: it provides more reliable algorithm implementations (avoiding persistent bugs found in some networkx functions like LFR benchmark and weighted degree assortativity), and its optimized C core delivers the performance needed for large-scale network computations.\n\n\nInstalling igraph\n# Using pip (with plotting support)\npip install igraph cairocffi\n\n# Using conda (recommended)\nconda install -c conda-forge igraph cairocffi\n\n# Alternative plotting backend\npip install igraph pycairo\n\n# For development version\npip install git+https://github.com/igraph/python-igraph.git\nNote: igraph requires compiled C libraries and plotting needs cairocffi or pycairo. Use conda for easier installation.\nFor advanced users comfortable with scipy, the csgraph submodule provides an excellent alternative that leverages one of Python’s most well-tested and optimized libraries. For example, csgraph.shortest_path and csgraph.connected_components offer high-performance implementations.\n\n\n\nLet us create a graph of 4 nodes and 4 edges. Our edge list is given by\n\nedge_list = [(0, 1), (1, 2), (0, 2), (0, 3)]\n\nigraph has an object Graph that stores a graph and provides methods to manipulate and analyze the graph. To create a graph from an edge list, we can use the add_edges method.\n\nimport igraph\n\ng = igraph.Graph() # Create an empty graph\ng.add_vertices(4) # Add 4 vertices\ng.add_edges(edge_list) # Add edges to the graph\n\n# Plot the graph\nigraph.plot(g, bbox=(150, 150), vertex_label=list(range(4)))\n\n\n\n\n\n\n\n\n\n\n\nLet’s compute the paths between nodes 2 and 3.\n\ng.get_all_simple_paths(2, to=3)\n\n[[2, 0, 3], [2, 1, 0, 3]]\n\n\nThis method enumerates all possible simple paths between two nodes. This is OK for small networks but quickly becomes impractical for larger networks, as the number of paths increases exponentially with the size of the network.\nOften, we are interested in the shortest path, which is the path with the smallest number of edges. The shortest path can be computed by using the get_shortest_paths method.\n\ng.get_shortest_paths(2, to=3)\n\n[[2, 0, 3]]\n\n\nNote that there can be multiple shortest paths between two nodes. If we are interested in the “length” instead of the path itself, there is a more efficient function distances.\n\ng.distances(2, 3)\n\n[[2]]\n\n\n\n\n\nIn the simple network above, we can see that for every pair of nodes, we can find a path connecting them. This is the definition of a connected graph. We can check this property for a given graph:\n\ncomponents = g.connected_components()\n\nThe components is a special object called VertexClustering in igraph. It has the following useful functions and attributes:\n\nprint(\"membership: \", components.membership)  # the IDs of the component each node belongs to.\nprint(\"sizes: \", list(components.sizes()))  # the number of nodes in each component.\nprint(\"giant: \", components.giant())  # a subgraph of the largest connected component.\n\nmembership:  [0, 0, 0, 0]\nsizes:  [4]\ngiant:  IGRAPH U--- 4 4 --\n+ edges:\n0--1 1--2 0--2 0--3\n\n\n\n\n\nNow, let us add two nodes that are not connected to the existing graph, and call connected_components again. 🔗➕\nCall get_shortest_paths between the two new nodes in different connected components. 🛣️🔍\nGet the largest connected component. 🌐🏆\n\n\n\n\n\nLet’s extend these ideas about paths and connected components to directed graphs.\n\nedge_list =[(0, 1), (1, 2), (2, 1), (2, 3), (2, 5), (3, 1), (3, 4), (3, 5), (4, 5), (5, 3)]\ng = igraph.Graph(directed=True)\ng.add_vertices(6)\ng.add_edges(edge_list)\nigraph.plot(g, bbox=(250, 250), vertex_label=list(range(6)))\n\n\n\n\n\n\n\n\nIn directed graphs, edges and paths can be one-way. For instance, in our graph, you can go from node 0 to node 3, but not from 3 to 0.\n\nprint(\"From 0 to 3\", g.get_all_simple_paths(0, to=3))\nprint(\"From 3 to 0\", g.get_all_simple_paths(3, to=0))\n\nFrom 0 to 3 [[0, 1, 2, 3], [0, 1, 2, 5, 3]]\nFrom 3 to 0 []\n\n\nThe shortest path from 4 to 1 must take a longer route due to edge directions.\n\ng.get_shortest_paths(4, 1)\n\n[[4, 5, 3, 1]]\n\n\nDirected networks have two kinds of connected components.\n\nStrongly connected components: Strongly connected means that there exists a direct path between every pair of nodes, i.e., that from any node to any other nodes while respecting the edge directionality.\nWeakly connected components: Weakly connected means that there exists a path between every pair of nodes when ignoring the edge directionality.\n\n\nprint(list(g.connected_components(mode=\"strong\")))\nprint(list(g.connected_components(mode=\"weak\")))\n\n[[0], [1, 2, 3, 4, 5]]\n[[0, 1, 2, 3, 4, 5]]",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Efficient Network Representation and Computing Paths"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#convenient-libraries-for-network-analysis",
    "href": "m02-small-world/02-coding.html#convenient-libraries-for-network-analysis",
    "title": "Efficient Network Representation and Computing Paths",
    "section": "",
    "text": "The Python ecosystem offers several powerful libraries for network analysis, each with distinct strengths:\n\nnetworkx - a beginner-friendly library for network analysis\nigraph - a mature library with a wide range of algorithms\ngraph-tool - specialized for stochastic block models\nscipy - efficient tools for analyzing large networks\n\nThroughout this course, we’ll primarily use igraph, a mature and robust library originally developed for R and later ported to Python. While networkx is by far the most popular library, igraph offers several compelling advantages for serious network analysis: it provides more reliable algorithm implementations (avoiding persistent bugs found in some networkx functions like LFR benchmark and weighted degree assortativity), and its optimized C core delivers the performance needed for large-scale network computations.\n\n\nInstalling igraph\n# Using pip (with plotting support)\npip install igraph cairocffi\n\n# Using conda (recommended)\nconda install -c conda-forge igraph cairocffi\n\n# Alternative plotting backend\npip install igraph pycairo\n\n# For development version\npip install git+https://github.com/igraph/python-igraph.git\nNote: igraph requires compiled C libraries and plotting needs cairocffi or pycairo. Use conda for easier installation.\nFor advanced users comfortable with scipy, the csgraph submodule provides an excellent alternative that leverages one of Python’s most well-tested and optimized libraries. For example, csgraph.shortest_path and csgraph.connected_components offer high-performance implementations.\n\n\n\nLet us create a graph of 4 nodes and 4 edges. Our edge list is given by\n\nedge_list = [(0, 1), (1, 2), (0, 2), (0, 3)]\n\nigraph has an object Graph that stores a graph and provides methods to manipulate and analyze the graph. To create a graph from an edge list, we can use the add_edges method.\n\nimport igraph\n\ng = igraph.Graph() # Create an empty graph\ng.add_vertices(4) # Add 4 vertices\ng.add_edges(edge_list) # Add edges to the graph\n\n# Plot the graph\nigraph.plot(g, bbox=(150, 150), vertex_label=list(range(4)))\n\n\n\n\n\n\n\n\n\n\n\nLet’s compute the paths between nodes 2 and 3.\n\ng.get_all_simple_paths(2, to=3)\n\n[[2, 0, 3], [2, 1, 0, 3]]\n\n\nThis method enumerates all possible simple paths between two nodes. This is OK for small networks but quickly becomes impractical for larger networks, as the number of paths increases exponentially with the size of the network.\nOften, we are interested in the shortest path, which is the path with the smallest number of edges. The shortest path can be computed by using the get_shortest_paths method.\n\ng.get_shortest_paths(2, to=3)\n\n[[2, 0, 3]]\n\n\nNote that there can be multiple shortest paths between two nodes. If we are interested in the “length” instead of the path itself, there is a more efficient function distances.\n\ng.distances(2, 3)\n\n[[2]]\n\n\n\n\n\nIn the simple network above, we can see that for every pair of nodes, we can find a path connecting them. This is the definition of a connected graph. We can check this property for a given graph:\n\ncomponents = g.connected_components()\n\nThe components is a special object called VertexClustering in igraph. It has the following useful functions and attributes:\n\nprint(\"membership: \", components.membership)  # the IDs of the component each node belongs to.\nprint(\"sizes: \", list(components.sizes()))  # the number of nodes in each component.\nprint(\"giant: \", components.giant())  # a subgraph of the largest connected component.\n\nmembership:  [0, 0, 0, 0]\nsizes:  [4]\ngiant:  IGRAPH U--- 4 4 --\n+ edges:\n0--1 1--2 0--2 0--3\n\n\n\n\n\nNow, let us add two nodes that are not connected to the existing graph, and call connected_components again. 🔗➕\nCall get_shortest_paths between the two new nodes in different connected components. 🛣️🔍\nGet the largest connected component. 🌐🏆\n\n\n\n\n\nLet’s extend these ideas about paths and connected components to directed graphs.\n\nedge_list =[(0, 1), (1, 2), (2, 1), (2, 3), (2, 5), (3, 1), (3, 4), (3, 5), (4, 5), (5, 3)]\ng = igraph.Graph(directed=True)\ng.add_vertices(6)\ng.add_edges(edge_list)\nigraph.plot(g, bbox=(250, 250), vertex_label=list(range(6)))\n\n\n\n\n\n\n\n\nIn directed graphs, edges and paths can be one-way. For instance, in our graph, you can go from node 0 to node 3, but not from 3 to 0.\n\nprint(\"From 0 to 3\", g.get_all_simple_paths(0, to=3))\nprint(\"From 3 to 0\", g.get_all_simple_paths(3, to=0))\n\nFrom 0 to 3 [[0, 1, 2, 3], [0, 1, 2, 5, 3]]\nFrom 3 to 0 []\n\n\nThe shortest path from 4 to 1 must take a longer route due to edge directions.\n\ng.get_shortest_paths(4, 1)\n\n[[4, 5, 3, 1]]\n\n\nDirected networks have two kinds of connected components.\n\nStrongly connected components: Strongly connected means that there exists a direct path between every pair of nodes, i.e., that from any node to any other nodes while respecting the edge directionality.\nWeakly connected components: Weakly connected means that there exists a path between every pair of nodes when ignoring the edge directionality.\n\n\nprint(list(g.connected_components(mode=\"strong\")))\nprint(list(g.connected_components(mode=\"weak\")))\n\n[[0], [1, 2, 3, 4, 5]]\n[[0, 1, 2, 3, 4, 5]]",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Efficient Network Representation and Computing Paths"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#clustering-coefficients",
    "href": "m02-small-world/02-coding.html#clustering-coefficients",
    "title": "Efficient Network Representation and Computing Paths",
    "section": "2 Clustering Coefficients",
    "text": "2 Clustering Coefficients\nNow let’s see how to compute the clustering coefficients you learned about using igraph.\nLet’s create a more interesting graph to demonstrate clustering:\n\n# Create a graph with some triangles\nedges = [(0, 1), (0, 2), (1, 2),  # Triangle: 0-1-2\n         (0, 3), (3, 4), (3, 5),  # Node 3 with two neighbors (4,5)\n         (4, 5),                  # Triangle: 3-4-5\n         (1, 6), (6, 7)]          # Linear extension\n\ng_cluster = igraph.Graph()\ng_cluster.add_vertices(8)\ng_cluster.add_edges(edges)\n\n# Plot the graph\nigraph.plot(g_cluster, bbox=(300, 200), vertex_label=list(range(8)))\n\n\n\n\n\n\n\n\n\nLocal Clustering Coefficient\nThe transitivity_local_undirected() function computes the local clustering coefficient for each node, returning a list of float values (one per node). It returns NaN for nodes with degree &lt; 2.\n\n# Local clustering coefficient for each node\nlocal_clustering = g_cluster.transitivity_local_undirected()\n\nprint(\"Local clustering coefficients:\")\nfor i, coeff in enumerate(local_clustering):\n    print(f\"Node {i}: {coeff:.3f}\")\n\nLocal clustering coefficients:\nNode 0: 0.333\nNode 1: 0.333\nNode 2: 1.000\nNode 3: 0.333\nNode 4: 1.000\nNode 5: 1.000\nNode 6: 0.000\nNode 7: nan\n\n\n\n\nUnderstanding the values: - 1.0 = All neighbors are connected (perfect local clustering) - 0.0 = No neighbors are connected - NaN = Node has degree &lt; 2 (clustering undefined)\nAnalyze how clustering values relate to actual neighborhood connectivity:\n\n# Analyze clustering for specific nodes\nfor node in range(g_cluster.vcount()):\n    neighbors = g_cluster.neighbors(node)\n    degree = len(neighbors)\n    clustering = local_clustering[node]\n\n    print(f\"Node {node}: degree={degree}, neighbors={neighbors}, clustering={clustering:.3f}\")\n\n    if degree &gt;= 2:\n        # Count actual triangles\n        possible_edges = degree * (degree - 1) // 2\n        actual_edges = 0\n        for i in range(len(neighbors)):\n            for j in range(i + 1, len(neighbors)):\n                if g_cluster.are_adjacent(neighbors[i], neighbors[j]):\n                    actual_edges += 1\n        print(f\"  -&gt; {actual_edges}/{possible_edges} neighbor pairs connected\")\n    print()\n\nNode 0: degree=3, neighbors=[1, 2, 3], clustering=0.333\n  -&gt; 1/3 neighbor pairs connected\n\nNode 1: degree=3, neighbors=[0, 2, 6], clustering=0.333\n  -&gt; 1/3 neighbor pairs connected\n\nNode 2: degree=2, neighbors=[0, 1], clustering=1.000\n  -&gt; 1/1 neighbor pairs connected\n\nNode 3: degree=3, neighbors=[0, 4, 5], clustering=0.333\n  -&gt; 1/3 neighbor pairs connected\n\nNode 4: degree=2, neighbors=[3, 5], clustering=1.000\n  -&gt; 1/1 neighbor pairs connected\n\nNode 5: degree=2, neighbors=[3, 4], clustering=1.000\n  -&gt; 1/1 neighbor pairs connected\n\nNode 6: degree=2, neighbors=[1, 7], clustering=0.000\n  -&gt; 0/1 neighbor pairs connected\n\nNode 7: degree=1, neighbors=[6], clustering=nan\n\n\n\n\n\nAverage Local Clustering\nThe transitivity_avglocal_undirected() function computes the average local clustering coefficient directly, returning a single float value. It automatically ignores NaN values from low-degree nodes.\n\n# Average local clustering (mean of local values)\navg_local_clustering = g_cluster.transitivity_avglocal_undirected()\nprint(f\"Average local clustering: {avg_local_clustering:.3f}\")\n\n# Verify by manual calculation\nimport numpy as np\nmanual_avg = np.nanmean(local_clustering)  # nanmean ignores NaN values\nprint(f\"Manual calculation: {manual_avg:.3f}\")\n\nAverage local clustering: 0.571\nManual calculation: 0.571\n\n\n\n\nGlobal Clustering Coefficient\nThe transitivity_undirected() function computes the global clustering coefficient (transitivity), returning a single float value.\n\n# Global clustering coefficient\nglobal_clustering = g_cluster.transitivity_undirected()\nprint(f\"Global clustering: {global_clustering:.3f}\")\n\n# Let's understand this calculation using supporting functions\n# list_triangles() returns all triangles in the graph\ntriangles_count = len(g_cluster.list_triangles())\nprint(f\"Number of triangles: {triangles_count}\")\nprint(f\"Triangles in graph: {g_cluster.list_triangles()}\")\n\n# Count connected triples (paths of length 2)\n# degree(node) returns the degree of a specific node\ntriples = 0\nfor node in range(g_cluster.vcount()):\n    degree = g_cluster.degree(node)\n    # Each node with degree d contributes d*(d-1)/2 triples\n    if degree &gt;= 2:\n        triples += degree * (degree - 1) // 2\n\nprint(f\"Connected triples: {triples}\")\nprint(f\"Global clustering = 3 * {triangles_count} / {triples} = {3 * triangles_count / triples:.3f}\")\n\nGlobal clustering: 0.462\nNumber of triangles: 2\nTriangles in graph: [(0, 1, 2), (3, 4, 5)]\nConnected triples: 13\nGlobal clustering = 3 * 2 / 13 = 0.462\n\n\n\n\nComparing Different Networks\nWe can use igraph’s built-in network generators: Graph.Full() creates complete graphs, Graph.Erdos_Renyi() creates random graphs, and Graph.Lattice() creates regular lattices.\n\n# Create different network types for comparison\nimport numpy as np\n\n# 1. Complete graph (everyone connected to everyone)\nn_complete = 6\ng_complete = igraph.Graph.Full(n_complete)\n\n# 2. Random graph (Erdős–Rényi)\nn_random = 20\np_random = 0.2\ng_random = igraph.Graph.Erdos_Renyi(n_random, p_random)\n\n# 3. Regular ring lattice (each node connected to k nearest neighbors)\nn_ring = 20\nk_ring = 4\ng_ring = igraph.Graph.Lattice(dim=[n_ring], circular=True, nei=k_ring//2)\n\nnetworks = {\n    \"Complete\": g_complete,\n    \"Random\": g_random,\n    \"Ring Lattice\": g_ring,\n    \"Our Example\": g_cluster\n}\n\nprint(\"Clustering Comparison:\")\nprint(\"-\" * 60)\nprint(f\"{'Network':&lt;15} {'Avg Local':&lt;12} {'Global':&lt;12} {'Nodes':&lt;8} {'Edges':&lt;8}\")\nprint(\"-\" * 60)\n\nfor name, graph in networks.items():\n    avg_local = graph.transitivity_avglocal_undirected()\n    global_clust = graph.transitivity_undirected()\n    nodes = graph.vcount()\n    edges = graph.ecount()\n\n    print(f\"{name:&lt;15} {avg_local:&lt;12.3f} {global_clust:&lt;12.3f} {nodes:&lt;8} {edges:&lt;8}\")\n\nClustering Comparison:\n------------------------------------------------------------\nNetwork         Avg Local    Global       Nodes    Edges   \n------------------------------------------------------------\nComplete        1.000        1.000        6        15      \nRandom          0.178        0.125        20       32      \nRing Lattice    0.500        0.500        20       40      \nOur Example     0.571        0.462        8        9       \n\n\n\n\nSmall-World Network Example\nThe Graph.Watts_Strogatz() function creates small-world networks using the Watts-Strogatz model. The average_path_length() function computes the mean shortest path length across all node pairs.\n\n# Create a small-world network (Watts-Strogatz model)\n# Start with ring lattice, then rewire some edges randomly\nn_ws = 30\nk_ws = 6\np_rewire = 0.1\n\ng_smallworld = igraph.Graph.Watts_Strogatz(dim=1, size=n_ws, nei=k_ws//2, p=p_rewire)\n\nprint(\"Small-World Network Analysis:\")\nprint(f\"Nodes: {g_smallworld.vcount()}, Edges: {g_smallworld.ecount()}\")\nprint(f\"Average local clustering: {g_smallworld.transitivity_avglocal_undirected():.3f}\")\nprint(f\"Global clustering: {g_smallworld.transitivity_undirected():.3f}\")\nprint(f\"Average path length: {g_smallworld.average_path_length():.3f}\")\n\n# Compare with random graph of same size and density\ng_random_compare = igraph.Graph.Erdos_Renyi(n_ws, g_smallworld.ecount() * 2 / (n_ws * (n_ws - 1)))\n\nprint(\"\\nCompared to random graph with same density:\")\nprint(f\"Random avg local clustering: {g_random_compare.transitivity_avglocal_undirected():.3f}\")\nprint(f\"Random global clustering: {g_random_compare.transitivity_undirected():.3f}\")\nprint(f\"Random average path length: {g_random_compare.average_path_length():.3f}\")\n\nSmall-World Network Analysis:\nNodes: 30, Edges: 90\nAverage local clustering: 0.361\nGlobal clustering: 0.319\nAverage path length: 2.149\n\nCompared to random graph with same density:\nRandom avg local clustering: 0.234\nRandom global clustering: 0.202\nRandom average path length: 2.048",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Efficient Network Representation and Computing Paths"
    ]
  },
  {
    "objectID": "m02-small-world/02-coding.html#exercise-02",
    "href": "m02-small-world/02-coding.html#exercise-02",
    "title": "Efficient Network Representation and Computing Paths",
    "section": "3 Exercise 02 🏋️‍♀️💪🧠",
    "text": "3 Exercise 02 🏋️‍♀️💪🧠\nLet’s compute the average path length of a network from pre-existing data and check if how long on average it takes to go from any node to any other node.\n\nSelect a network of your choice from Netzschleuder. For convenience, choose a network of nodes less than 5000.\nDownload the csv version of the data by clicking something like “3KiB” under csv column.\nUnzip the file and find “edges.csv”, open it with a text editor to familiarize yourself with the format.\nLoad the data using pandas.\nGet the source and target nodes from the data to create an edge list.\nConstruct a graph from the edge list, either using igraph or scipy.\nCompute the average path length\n\nHint: Finding all shortest paths is a qubic time operation with respect to the number of nodes, or simply put, it takes a long time to compute. So compute the “estimate” by sampling many pairs of nodes uniformly at random and computing the average path length.",
    "crumbs": [
      "Home",
      "M02: Small World",
      "Efficient Network Representation and Computing Paths"
    ]
  },
  {
    "objectID": "m02-small-world/appendix.html",
    "href": "m02-small-world/appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "CSR format is implemented in scipy. This consists of three arrays called indptr, indices, and data. For example,\n\nimport networkx as nx\nfrom scipy import sparse\n\nG = nx.karate_club_graph()\nA = sparse.csr_matrix(nx.adjacency_matrix(G))\n\nprint(\"A.indices:\", A.indices[:5])\nprint(\"A.indptr:\", A.indptr[:5])\nprint(\"A.data:\", A.data[:5])\n\nWe will walk you through what these arrays mean, how they are generated, and how we can leverage them for efficient computations.\n\n\nLet’s walk you through how to store an example adjacency matrix in Compressed Sparse Row (CSR) format. Our example adjacency matrix is as follows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n1\n\n\n2\n\n1\n\n1\n\n\n\n\n\n\n1\n\n\n3\n\n\n1\n\n1\n1\n1\n\n\n\n\n\n\n4\n\n\n\n1\n\n\n\n1\n\n\n\n\n\n5\n\n\n\n1\n\n\n\n\n\n\n\n\n\n6\n\n\n\n1\n\n\n\n\n1\n1\n\n\n\n7\n\n\n\n\n1\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n9\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n10\n1\n1\n1\n\n\n\n\n\n1\n1\n\n\n\n\n\nWe will first create adjacency list, which is a dictionary consisting of the row IDs and column IDs for the non-zero entries in the adjacency matrix.\n\n\n\\{\\text{Row ID}: (\\text{Column ID}, \\text{Value})\\}\n\n\nConcretely, in Python,\n\nadj_list = {\n  0:[(10,1)],\n  1:[(2,1), (10, 1)],\n  2:[(1,1), (3,1), (10, 1)],\n  3:[(2,1), (4,1), (5,1), (6,1)],\n  #...\n}\n\nCSR format is a concatenation of the keys and values of the adjacency list, respectively. The CSR format has a concatenated array of the values, one for column IDs and one for the values, called indices and data, respectively.\n\nimport numpy as np\n\nindices = np.array([vv[0] for k, v in adj_list.items() for vv in v])\nindices\n\n\ndata = np.array([vv[1] for k, v in adj_list.items() for vv in v])\ndata\n\nAdditionally, the CSR format has another array called indptr, which stores the Row IDs of the non-zero entries in the adjacency matrix. This indptr array has a value such that indptr[i] is the first index of indices that corresponds to the i-th row of the adjacency matrix. This can be generated by\n\nindptr = np.cumsum([0] + [len(adj_list[i]) for i in range(len(adj_list))])\nindptr\n\nwhere we added 0 at the beginning of the array to represent the first non-zero entry in the first row. The first row ends at index len(adj_list[0])-1, and the second row starts at index len(adj_list[0]) and ends at index len(adj_list[0])+len(adj_list[1])-1, and so on.\nNow we have three compressed vectors indptr, indices, and data, that together form the CSR format for the adjacency matrix.\n\n\n\nThe key advantage of the CSR representation is the memory efficiency. But you can leverage the CSR format for more efficient computations, if you know the semantics of indptr, indices, and data arrays.\nFor instance, one can compute the degree of a node by using\n\nnode = 1\ndegree = indptr[node+1] - indptr[node]\ndegree\n\nLet us break down the above code. - indptr[node] is the first index of the indices array that corresponds to the node-th row of the adjacency matrix. - indptr[node+1] is the first index of the indices array that corresponds to the (node+1)-th row of the adjacency matrix. - Thus, indptr[node+1] - indptr[node] is the number of non-zero entries in the node-th row of the adjacency matrix, which is the degree of the node-th node.\nUsing indices, it is easy to identify the neighbors of a given node by using\n\nneighbors = indices[indptr[node]:indptr[node+1]]\nneighbors\n\nwhere indices[indptr[node]:indptr[node+1]] is the corresponding column IDs of the non-zero entries in the node-th row of the adjacency matrix, which corresponds to the node IDs connected to the node-th node.\nThe edge weights to the neighbors can be obtained by using\n\nedge_weights = data[indptr[node]:indptr[node+1]]\nedge_weights"
  },
  {
    "objectID": "m02-small-world/appendix.html#compressed-sparse-row-csr-format",
    "href": "m02-small-world/appendix.html#compressed-sparse-row-csr-format",
    "title": "Appendix",
    "section": "",
    "text": "CSR format is implemented in scipy. This consists of three arrays called indptr, indices, and data. For example,\n\nimport networkx as nx\nfrom scipy import sparse\n\nG = nx.karate_club_graph()\nA = sparse.csr_matrix(nx.adjacency_matrix(G))\n\nprint(\"A.indices:\", A.indices[:5])\nprint(\"A.indptr:\", A.indptr[:5])\nprint(\"A.data:\", A.data[:5])\n\nWe will walk you through what these arrays mean, how they are generated, and how we can leverage them for efficient computations.\n\n\nLet’s walk you through how to store an example adjacency matrix in Compressed Sparse Row (CSR) format. Our example adjacency matrix is as follows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n1\n\n\n2\n\n1\n\n1\n\n\n\n\n\n\n1\n\n\n3\n\n\n1\n\n1\n1\n1\n\n\n\n\n\n\n4\n\n\n\n1\n\n\n\n1\n\n\n\n\n\n5\n\n\n\n1\n\n\n\n\n\n\n\n\n\n6\n\n\n\n1\n\n\n\n\n1\n1\n\n\n\n7\n\n\n\n\n1\n\n\n\n\n\n\n\n\n8\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n9\n\n\n\n\n\n\n1\n\n\n\n1\n\n\n10\n1\n1\n1\n\n\n\n\n\n1\n1\n\n\n\n\n\nWe will first create adjacency list, which is a dictionary consisting of the row IDs and column IDs for the non-zero entries in the adjacency matrix.\n\n\n\\{\\text{Row ID}: (\\text{Column ID}, \\text{Value})\\}\n\n\nConcretely, in Python,\n\nadj_list = {\n  0:[(10,1)],\n  1:[(2,1), (10, 1)],\n  2:[(1,1), (3,1), (10, 1)],\n  3:[(2,1), (4,1), (5,1), (6,1)],\n  #...\n}\n\nCSR format is a concatenation of the keys and values of the adjacency list, respectively. The CSR format has a concatenated array of the values, one for column IDs and one for the values, called indices and data, respectively.\n\nimport numpy as np\n\nindices = np.array([vv[0] for k, v in adj_list.items() for vv in v])\nindices\n\n\ndata = np.array([vv[1] for k, v in adj_list.items() for vv in v])\ndata\n\nAdditionally, the CSR format has another array called indptr, which stores the Row IDs of the non-zero entries in the adjacency matrix. This indptr array has a value such that indptr[i] is the first index of indices that corresponds to the i-th row of the adjacency matrix. This can be generated by\n\nindptr = np.cumsum([0] + [len(adj_list[i]) for i in range(len(adj_list))])\nindptr\n\nwhere we added 0 at the beginning of the array to represent the first non-zero entry in the first row. The first row ends at index len(adj_list[0])-1, and the second row starts at index len(adj_list[0]) and ends at index len(adj_list[0])+len(adj_list[1])-1, and so on.\nNow we have three compressed vectors indptr, indices, and data, that together form the CSR format for the adjacency matrix.\n\n\n\nThe key advantage of the CSR representation is the memory efficiency. But you can leverage the CSR format for more efficient computations, if you know the semantics of indptr, indices, and data arrays.\nFor instance, one can compute the degree of a node by using\n\nnode = 1\ndegree = indptr[node+1] - indptr[node]\ndegree\n\nLet us break down the above code. - indptr[node] is the first index of the indices array that corresponds to the node-th row of the adjacency matrix. - indptr[node+1] is the first index of the indices array that corresponds to the (node+1)-th row of the adjacency matrix. - Thus, indptr[node+1] - indptr[node] is the number of non-zero entries in the node-th row of the adjacency matrix, which is the degree of the node-th node.\nUsing indices, it is easy to identify the neighbors of a given node by using\n\nneighbors = indices[indptr[node]:indptr[node+1]]\nneighbors\n\nwhere indices[indptr[node]:indptr[node+1]] is the corresponding column IDs of the non-zero entries in the node-th row of the adjacency matrix, which corresponds to the node IDs connected to the node-th node.\nThe edge weights to the neighbors can be obtained by using\n\nedge_weights = data[indptr[node]:indptr[node+1]]\nedge_weights"
  },
  {
    "objectID": "m03-robustness/02-coding.html",
    "href": "m03-robustness/02-coding.html",
    "title": "Coding - Network Robustness Analysis",
    "section": "",
    "text": "Network robustness analysis focuses on understanding how networks behave when nodes or edges are removed, whether through random failures or targeted attacks. The Python ecosystem provides powerful tools for analyzing these phenomena:\n\nigraph - comprehensive network analysis with robust algorithms for connectivity analysis\nscipy.sparse.csgraph - efficient connected component algorithms for large networks\nnetworkx - alternative approach with different robustness metrics\n\nThroughout this analysis, we’ll use igraph for its reliable implementations and performance advantages when working with connectivity measures and component analysis.\n\n\nInstalling igraph\n# Using pip (with plotting support)\npip install igraph cairocffi\n\n# Using conda (recommended)\nconda install -c conda-forge igraph cairocffi\n\n# Alternative plotting backend\npip install igraph pycairo\nNote: igraph requires compiled C libraries and plotting needs cairocffi or pycairo. Use conda for easier installation.\nFor advanced users comfortable with scipy, the csgraph submodule provides an excellent alternative that leverages one of Python’s most well-tested and optimized libraries. For example, csgraph.shortest_path and csgraph.connected_components offer high-performance implementations.\n\n\nLet’s start by creating a network using the famous Zachary’s karate club, which provides an excellent testbed for robustness analysis:\n\nimport igraph\n\n# Create the famous Zachary's karate club network\ng = igraph.Graph.Famous('Zachary')\n\n# Visualize the network\nigraph.plot(g, bbox=(300, 200), vertex_size=20, vertex_label=list(range(g.vcount())))\n\n\n\n\n\n\n\n\n\n\nAbout Zachary’s Karate Club\nZachary’s karate club is a famous network of 34 members of a karate club documenting friendships between members. The network is undirected and originally unweighted, making it an excellent testbed for robustness analysis.\n\n\n\nBefore analyzing robustness, let’s understand how to measure network connectivity. In network analysis, we often need to identify connected components:\n\ncomponents = g.connected_components()\nprint(\"Number of components:\", len(components))\nprint(\"Component sizes:\", list(components.sizes()))\nprint(\"Largest component size:\", components.giant().vcount())\n\nNumber of components: 1\nComponent sizes: [34]\nLargest component size: 34\n\n\nThe connectivity of a network is typically measured as the fraction of nodes in the largest connected component:\n\nimport numpy as np\n\ndef network_connectivity(graph, original_size=None):\n    \"\"\"Calculate network connectivity as fraction of nodes in largest component\"\"\"\n    if original_size is None:\n        original_size = graph.vcount()\n\n    if graph.vcount() == 0:\n        return 0.0\n\n    components = graph.connected_components()\n    return max(components.sizes()) / original_size\n\n# Test the function\nconnectivity = network_connectivity(g)\nprint(f\"Current connectivity: {connectivity:.3f}\")\n\nCurrent connectivity: 1.000",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#key-robustness-concepts-in-igraph",
    "href": "m03-robustness/02-coding.html#key-robustness-concepts-in-igraph",
    "title": "Coding - Network Robustness Analysis",
    "section": "",
    "text": "Network robustness analysis focuses on understanding how networks behave when nodes or edges are removed, whether through random failures or targeted attacks. The Python ecosystem provides powerful tools for analyzing these phenomena:\n\nigraph - comprehensive network analysis with robust algorithms for connectivity analysis\nscipy.sparse.csgraph - efficient connected component algorithms for large networks\nnetworkx - alternative approach with different robustness metrics\n\nThroughout this analysis, we’ll use igraph for its reliable implementations and performance advantages when working with connectivity measures and component analysis.\n\n\nInstalling igraph\n# Using pip (with plotting support)\npip install igraph cairocffi\n\n# Using conda (recommended)\nconda install -c conda-forge igraph cairocffi\n\n# Alternative plotting backend\npip install igraph pycairo\nNote: igraph requires compiled C libraries and plotting needs cairocffi or pycairo. Use conda for easier installation.\nFor advanced users comfortable with scipy, the csgraph submodule provides an excellent alternative that leverages one of Python’s most well-tested and optimized libraries. For example, csgraph.shortest_path and csgraph.connected_components offer high-performance implementations.\n\n\nLet’s start by creating a network using the famous Zachary’s karate club, which provides an excellent testbed for robustness analysis:\n\nimport igraph\n\n# Create the famous Zachary's karate club network\ng = igraph.Graph.Famous('Zachary')\n\n# Visualize the network\nigraph.plot(g, bbox=(300, 200), vertex_size=20, vertex_label=list(range(g.vcount())))\n\n\n\n\n\n\n\n\n\n\nAbout Zachary’s Karate Club\nZachary’s karate club is a famous network of 34 members of a karate club documenting friendships between members. The network is undirected and originally unweighted, making it an excellent testbed for robustness analysis.\n\n\n\nBefore analyzing robustness, let’s understand how to measure network connectivity. In network analysis, we often need to identify connected components:\n\ncomponents = g.connected_components()\nprint(\"Number of components:\", len(components))\nprint(\"Component sizes:\", list(components.sizes()))\nprint(\"Largest component size:\", components.giant().vcount())\n\nNumber of components: 1\nComponent sizes: [34]\nLargest component size: 34\n\n\nThe connectivity of a network is typically measured as the fraction of nodes in the largest connected component:\n\nimport numpy as np\n\ndef network_connectivity(graph, original_size=None):\n    \"\"\"Calculate network connectivity as fraction of nodes in largest component\"\"\"\n    if original_size is None:\n        original_size = graph.vcount()\n\n    if graph.vcount() == 0:\n        return 0.0\n\n    components = graph.connected_components()\n    return max(components.sizes()) / original_size\n\n# Test the function\nconnectivity = network_connectivity(g)\nprint(f\"Current connectivity: {connectivity:.3f}\")\n\nCurrent connectivity: 1.000",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#network-robustness-analysis",
    "href": "m03-robustness/02-coding.html#network-robustness-analysis",
    "title": "Coding - Network Robustness Analysis",
    "section": "2 Network Robustness Analysis",
    "text": "2 Network Robustness Analysis\nNow let’s explore how networks behave when nodes fail or are attacked systematically.\n  \n\n# If you are using Google Colab, uncomment the following line to install igraph\n# !sudo apt install libcairo2-dev pkg-config python3-dev\n# !pip install pycairo cairocffi\n# !pip install igraph\n\n\nRandom Attack Simulation\nRandom attacks simulate random failures where nodes are removed with equal probability. Let’s implement a systematic approach:\n\nimport pandas as pd\n\ndef simulate_random_attack(graph):\n    \"\"\"Simulate random node removal and measure connectivity\"\"\"\n    g_test = graph.copy()\n    original_size = g_test.vcount()\n    results = []\n\n    for i in range(original_size - 1):  # Remove all but one node\n        # Randomly select and remove a node\n        node_idx = np.random.choice(g_test.vs.indices)\n        g_test.delete_vertices(node_idx)\n\n        # Measure connectivity\n        connectivity = network_connectivity(g_test, original_size)\n\n        # Store results\n        results.append({\n            \"connectivity\": connectivity,\n            \"frac_nodes_removed\": (i + 1) / original_size,\n        })\n\n    return pd.DataFrame(results)\n\n# Run the simulation\ndf_random = simulate_random_attack(g)\n\nLet’s visualize the robustness profile:\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style='white', font_scale=1.2)\nsns.set_style('ticks')\n\nfig, ax = plt.subplots(figsize=(6, 5))\nax.plot(df_random[\"frac_nodes_removed\"],\n        df_random[\"connectivity\"],\n        'o-', linewidth=2, markersize=4, label=\"Random attack\")\nax.set_xlabel(\"Proportion of nodes removed\")\nax.set_ylabel(\"Connectivity\")\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nsns.despine()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTargeted Attack Simulation\nTargeted attacks remove nodes based on specific criteria, such as degree centrality. High-degree nodes (hubs) often play crucial roles in network connectivity:\n\ndef simulate_targeted_attack(graph, criterion=\"degree\"):\n    \"\"\"Simulate targeted node removal based on specified criterion\"\"\"\n    g_test = graph.copy()\n    original_size = g_test.vcount()\n    results = []\n\n    for i in range(original_size - 1):\n        # Remove node with highest degree\n        if criterion == \"degree\":\n            degrees = g_test.degree()\n            node_idx = g_test.vs.indices[np.argmax(degrees)]\n\n        g_test.delete_vertices(node_idx)\n\n        # Measure connectivity\n        connectivity = network_connectivity(g_test, original_size)\n\n        # Store results\n        results.append({\n            \"connectivity\": connectivity,\n            \"frac_nodes_removed\": (i + 1) / original_size,\n        })\n\n    return pd.DataFrame(results)\n\n# Run targeted attack simulation\ndf_targeted = simulate_targeted_attack(g)\n\nNow let’s compare both attack strategies:\n\nfig, ax = plt.subplots(figsize=(7, 5))\n\nax.plot(df_random[\"frac_nodes_removed\"],\n        df_random[\"connectivity\"],\n        'o-', linewidth=2, markersize=4, label=\"Random attack\", alpha=0.8)\n\nax.plot(df_targeted[\"frac_nodes_removed\"],\n        df_targeted[\"connectivity\"],\n        's-', linewidth=2, markersize=4, label=\"Targeted attack\", alpha=0.8)\n\nax.set_xlabel(\"Proportion of nodes removed\")\nax.set_ylabel(\"Connectivity\")\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nax.legend(frameon=False)\nsns.despine()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe comparison reveals a key insight: while networks are often robust against random failures, they can be vulnerable to targeted attacks on high-degree nodes.\n\nExercise 01 🏋️‍♀️💪🧠\n\nExamine the degree distribution of the Zachary network and identify the nodes with highest degrees. 📊🔍\nCreate a visualization showing which nodes are removed first in the targeted attack. 🎯📈\nTry implementing a targeted attack based on betweenness centrality instead of degree. How does it compare? 🌐⚡",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#minimum-spanning-tree-analysis",
    "href": "m03-robustness/02-coding.html#minimum-spanning-tree-analysis",
    "title": "Coding - Network Robustness Analysis",
    "section": "3 Minimum Spanning Tree Analysis",
    "text": "3 Minimum Spanning Tree Analysis\nUnderstanding network structure through minimum spanning trees can provide insights into network robustness. Let’s explore this concept:\n\nimport random\n\n# Create a weighted version of our network for MST analysis\ng_weighted = g.copy()\ng_weighted.es[\"weight\"] = [random.randint(1, 10) for _ in g_weighted.es]\n\n# Visualize weighted network\nigraph.plot(g_weighted, bbox=(300, 200),\n           edge_width=[w/3 for w in g_weighted.es[\"weight\"]],\n           vertex_label=list(range(g_weighted.vcount())))\n\n\n\n\n\n\n\n\n\nComputing the Minimum Spanning Tree\nThe minimum spanning tree represents the most efficient way to connect all nodes:\n\n# Find minimum spanning tree\nmst = g_weighted.spanning_tree(weights=g_weighted.es[\"weight\"])\n\n# Visualize the MST\nigraph.plot(mst, bbox=(300, 200),\n           edge_width=[w/3 for w in mst.es[\"weight\"]],\n           vertex_label=list(range(mst.vcount())))\n\n\n\n\n\n\n\n\nThe MST identifies the most critical connections for maintaining network connectivity, which relates directly to robustness analysis.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#percolation-theory",
    "href": "m03-robustness/02-coding.html#percolation-theory",
    "title": "Coding - Network Robustness Analysis",
    "section": "4 Percolation Theory",
    "text": "4 Percolation Theory\nNetwork robustness can be viewed as the inverse process of percolation. In percolation theory, we study how connectivity emerges as we randomly add nodes to a network.\n\ndef percolation_simulation(lattice_size=100, p_values=None):\n    \"\"\"Simulate percolation on a 2D lattice\"\"\"\n    if p_values is None:\n        p_values = np.linspace(0, 1, 20)\n\n    # Create 2D lattice\n    g_lattice = igraph.Graph.Lattice([lattice_size, lattice_size],\n                                    nei=1, directed=False,\n                                    mutual=False, circular=False)\n\n    results = []\n    for p in p_values:\n        # Randomly keep nodes with probability p\n        keep_nodes = np.where(np.random.rand(g_lattice.vcount()) &lt; p)[0]\n\n        if len(keep_nodes) &gt; 0:\n            g_sub = g_lattice.subgraph(keep_nodes)\n            largest_size = network_connectivity(g_sub, g_lattice.vcount())\n        else:\n            largest_size = 0\n\n        results.append({\"p\": p, \"largest_component_fraction\": largest_size})\n\n    return pd.DataFrame(results)\n\n# Run percolation simulation\ndf_percolation = percolation_simulation(lattice_size=50)\n\n\nfig, ax = plt.subplots(figsize=(6, 5))\n\nax.plot(df_percolation[\"p\"],\n        df_percolation[\"largest_component_fraction\"],\n        'o-', linewidth=2, markersize=4)\n\n# Mark theoretical critical point for 2D lattice\ncritical_p = 0.593  # Theoretical value for 2D square lattice\nax.axvline(x=critical_p, color='red', linestyle='--', alpha=0.7,\n           label=f'Critical point (p_c ≈ {critical_p})')\n\nax.set_xlabel(\"Probability (p)\")\nax.set_ylabel(\"Fractional largest component size\")\nax.set_title(\"Percolation on 2D Lattice\")\nax.legend(frameon=False)\nsns.despine()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPhase Transition\nThe sharp transition around p_c demonstrates a phase transition - a sudden change from a disconnected to connected state as we cross the critical threshold.\n\nWant to see this in action? 🌟 Check out this interactive simulation.\nPlay around with it and watch how the puddles grow and connect. 🌊\n\n[Bernoulli Percolation Simulation 🌐](https://visualize-it.github.io/bernoulli_percolation/simulation.html) 🔗",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#exercise-02",
    "href": "m03-robustness/02-coding.html#exercise-02",
    "title": "Coding - Network Robustness Analysis",
    "section": "5 Exercise 02 🏋️‍♀️",
    "text": "5 Exercise 02 🏋️‍♀️\nLet’s explore robustness in real-world networks by analyzing data from Netzschleuder.\n\nSelect a network with fewer than 5000 nodes from Netzschleuder\nDownload the CSV version and load it using pandas\nCreate the network using igraph\nCompare random vs. targeted attack robustness profiles\nCalculate theoretical predictions using the Molloy-Reed criterion\n\nHint: For large networks, consider sampling node pairs to estimate average path length rather than computing all pairwise distances.\n\n# Your implementation here",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m03-robustness/02-coding.html#real-world-case-study-airport-network",
    "href": "m03-robustness/02-coding.html#real-world-case-study-airport-network",
    "title": "Coding - Network Robustness Analysis",
    "section": "6 Real-World Case Study: Airport Network",
    "text": "6 Real-World Case Study: Airport Network\nLet’s analyze a more complex real-world network to see robustness principles in action:\n\n# Load airport network data\ndf_airports = pd.read_csv(\"https://raw.githubusercontent.com/skojaku/core-periphery-detection/master/data/edge-table-airport.csv\")\n\n# Process edge data\nedges = df_airports[[\"source\", \"target\"]].to_numpy()\nedges = np.unique(edges.reshape(-1), return_inverse=True)[1]\nedges = edges.reshape(-1, 2)\n\n# Create network\ng_airports = igraph.Graph()\ng_airports.add_vertices(np.max(edges) + 1)\ng_airports.add_edges([tuple(edge) for edge in edges])\n\nprint(f\"Airport network: {g_airports.vcount()} nodes, {g_airports.ecount()} edges\")\n\nAirport network: 2905 nodes, 30442 edges\n\n\n\nTheoretical Prediction using Molloy-Reed Criterion\nThe Molloy-Reed criterion provides a theoretical framework for predicting network robustness:\n\n# Calculate degree statistics\ndegrees = np.array(g_airports.degree())\nk_mean = np.mean(degrees)\nk_squared_mean = np.mean(degrees**2)\n\n# Molloy-Reed criterion: kappa_0 &gt; 2 for giant component\nkappa_0 = k_squared_mean / k_mean\nprint(f\"κ₀ = &lt;k²&gt;/&lt;k&gt; = {kappa_0:.3f}\")\n\n# Critical fraction for network breakdown\nf_c = 1 - 1 / (kappa_0 - 1)\nprint(f\"Predicted critical fraction f_c = {f_c:.3f}\")\n\nκ₀ = &lt;k²&gt;/&lt;k&gt; = 110.937\nPredicted critical fraction f_c = 0.991\n\n\nThe high f_c value indicates the airport network is extremely robust to random failures, maintaining connectivity until almost all nodes are removed.\n\n# Simulate and visualize (using subset for efficiency)\nn_samples = min(500, g_airports.vcount() - 1)  # Sample for computational efficiency\nsample_indices = np.linspace(0, g_airports.vcount() - 2, n_samples, dtype=int)\n\ndf_airport_robustness = simulate_random_attack(g_airports)\ndf_airport_sample = df_airport_robustness.iloc[sample_indices]\n\nfig, ax = plt.subplots(figsize=(6, 5))\nax.plot(df_airport_sample[\"frac_nodes_removed\"],\n        df_airport_sample[\"connectivity\"],\n        'o-', linewidth=2, markersize=3, alpha=0.8)\n\n# Add theoretical prediction\nax.axvline(x=f_c, color='red', linestyle='--', alpha=0.7,\n           label=f'Theoretical f_c = {f_c:.3f}')\n\n# Add diagonal reference line\nax.plot([0, 1], [1, 0], 'gray', linestyle=':', alpha=0.5, label='Linear decline')\n\nax.set_xlabel(\"Proportion of nodes removed\")\nax.set_ylabel(\"Connectivity\")\nax.set_title(\"Airport Network Robustness\")\nax.legend(frameon=False)\nsns.despine()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nKey Design Principles for Robust Networks\nBased on percolation theory and empirical analysis, robust networks share several characteristics:\n\nDegree heterogeneity: Networks with diverse degree distributions (high κ₀) maintain connectivity better\nDistributed hubs: Resilience improves when connectivity doesn’t depend on single critical nodes\nRedundant pathways: Multiple paths between node pairs provide backup routes when primary connections fail\n\nUnderstanding these principles helps in designing resilient infrastructure networks, from transportation systems to communication networks.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Coding - Network Robustness Analysis"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/02-coding.html#visualization-basics",
    "href": "m04-friendship-paradox/02-coding.html#visualization-basics",
    "title": "Advanced Topics in Network Science",
    "section": "1.1 Visualization basics",
    "text": "1.1 Visualization basics\nTo learn the basics of data visualization, please take a pen and paper exercise.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/02-coding.html#coding-exercise",
    "href": "m04-friendship-paradox/02-coding.html#coding-exercise",
    "title": "Advanced Topics in Network Science",
    "section": "1.2 Coding exercise",
    "text": "1.2 Coding exercise\nExercise: Plotting degree distribution\n\nPlotting degree distribution\n(The following content includes the answer to the exercise. So please do the exercise first before reading the following content.)\nWe will first introduce a formal definition of the degree distribution. Then, we will learn how to plot the degree distribution of a network.\nThe degree of a node i, denoted by d_i, is the number of edges connected to it. With the adjacency matrix A, the degree of node i is given by:\n\nk_i = \\sum_{j=1}^N A_{ij}.\n\nLet us compute the degree distribution of a network. We will create a Barabási-Albert network with N=10,000 nodes and m=1 edge per node.\n\nimport igraph\ng = igraph.Graph.Barabasi(n = 10000, m = 1) # Create a Barabási-Albert network\nA = g.get_adjacency() # Get the adjacency matrix\n\nCompute the degree of each node by summing the elements of the adjacency matrix along the rows.\n\nimport numpy as np\ndeg = np.sum(A, axis=1)\ndeg = deg.flatten()\n\nThe degree distribution p(k) can be computed by counting the number of nodes with each degree and dividing by the total number of nodes.\n\np_deg = np.bincount(deg) / len(deg)\n\nLet us plot the degree distribution. This is not as trivial as you might think… 🤔\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\n\nWhile it clearly shows that most nodes have small degree, it does not show the tail of the distribution clearly, and often it is this tail that is of great interest (e.g., hub nodes). To show the tail of the distribution more clearly, we can use a log-log plot.\n\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_ylim(np.min(p_deg[p_deg&gt;0])*0.01, None)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\n\nWe see fluctuations for large degree nodes because of the small number of nodes with large degree. One can use “binning” to smooth the plot. Binning involves grouping the data into bins and calculating the fraction of data within each bin. However, selecting an appropriate bin size can be challenging, and even with a well-chosen bin size, some information may be lost.\nA more convenient way is to use the complementary cumulative distribution function (CCDF). The CCDF at degree k is the probability that a randomly chosen node has degree k' greater than k (k' &gt; k). For a visual comparison of CCDF and PDF, see Figure 3 in {footcite}newman2005power or the arxiv version\n\n\\text{CCDF}(k) = P(k' &gt; k) = \\sum_{k'=k+1}^\\infty p(k')\n\n\nCCDF is a monotonically decreasing function of k.\nCCDF encompasses the full information of p(k), i.e., taking the derivative of CCDF gives p(k).\nCCDF can be plotted as a smooth curve on a log-log scale without binning.\n\n\nccdf_deg = 1 - np.cumsum(p_deg)[:-1] # 1 - CDF (cumulative distribution function).\n# The last element is excluded because it is always 1, resulting in CCDF=0, which cannot be plotted on a log-log scale.\n\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\n\n\n:tags: [remove-cell]\nfrom myst_nb import glue\n\ncdf_deg = np.cumsum(p_deg)\nfig, ax = plt.subplots(figsize=(3,3))\nax = sns.lineplot(x=np.arange(len(cdf_deg)), y=cdf_deg, ax = ax)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CDF')\nglue(\"cdf_fig\", fig, display=False)\n\n\n\n\n\n\n\nNote\n\n\n\nCCDF (complementary cumulative distribution function) is used instead of CDF (cumulative distribution function) because it highlights the tail of the distribution better in a log-log plot. A log scale expands small values and compresses large values. In a CDF, large degree nodes have values close to 1, compressing the tail. In a CCDF, large degree nodes have small values, making the tail more visible. tkoefr cdf_fig :align: center\n\n\nThe slope of the CCDF tells us the heterogeneity of the degree distribution. - Steep slope: more homogeneous degree distribution (similar degrees) - Flat slope: more heterogeneous degree distribution (wide range of degrees)\nThe slope of the CCDF is related to the power-law exponent of the degree distribution. A power-law degree distribution is described by a continuous distribution with the density function (not the probability mass) p(d) given by {footcite}clauset2009power:\n\np(k) = \\frac{\\gamma-1}{k_{\\min}} \\left( \\frac{k}{k_{\\min}} \\right)^{-\\gamma}\n\nwhere: - p(k) is the probability density of a node having degree k - \\gamma is the power-law exponent - k_{\\min} is the minimum degree\n\n\n\n\n\n\nNote\n\n\n\nThe degree distribution is discrete but often approximated by a continuous distribution for mathematical convenience. While generally accurate, caution is needed as the reliability varies depending on the range of the degrees. See {footcite}clauset2009power for more details.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe power-law distribution is ill-defined for d=0, which is why there must be a minimum degree d_{\\min} to avoid this issue.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere has been a long-standing debate in network science as to whether the power-law well represents the real-world networks. Power-law is just one of many possible distributions with a heavy tail (i.e., a long tail on the right side of the distribution), and other distributions may also fit the data well such as log-normal distribution. This discussion is critical as many theories in network science are built on the assumption of the form of the degree distribution. See {footcite}artico2020rare,holme2019rare,voitalov2019scale,barabasi2003scale for the debate.\n\n\nThe CCDF for the power-law distribution is given by:\n\n\\begin{aligned}\n\\text{CCDF}(k) &= 1 - \\int_{k_{\\min}}^k p(x) {\\rm d}x \\\\\n  &= 1 - \\frac{\\gamma -1}{k_{\\min}}\\cdot \\frac{1}{1 - \\gamma} \\left[\n\\left(\\frac{k^{-\\gamma + 1}}{k_{\\min}^{-\\gamma}}\\right) - \\left(\\frac{k_{\\min} ^{-\\gamma + 1}}{k_{\\min} ^{-\n\\gamma}}\\right)\\right] \\\\\n&= \\left( \\frac{k}{k_{\\min}}\\right)^{-\\gamma + 1}\n\\end{aligned}\n\nTaking the logarithm:\n\n\\log \\left[ \\text{CCDF}(k) \\right] = (-\\gamma + 1) \\cdot \\log k + \\text{const.}\n\nThus, the slope of the CCDF in a log-log plot is related to the power-law exponent \\gamma. Specifically, a steeper negative slope (i.e., a more negative value of -\\gamma + 1) corresponds to a larger \\gamma. A larger \\gamma indicates a more homogeneous degree distribution, where the probability of finding nodes with very high degrees decreases more rapidly. Conversely, a flatter slope (i.e., a value of -\\gamma + 1 being closer to zero) corresponds to a smaller \\gamma. A smaller \\gamma indicates a more heterogeneous degree distribution, where there’s a high probability of finding nodes with high degrees compared to that with a large \\gamma value.\nFor students interested in real-world examples of the CCDF plot, refer to Figure 4 in {footcite}newman2005power, or the arxiv version\nIn sum, the CCDF in a log-log plot provides a convenient visual summary of the degree distribution, with the slope of the CCDF providing a measure of the heterogeneity of the degree distribution.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/02-coding.html#degree-distribution-of-a-friend",
    "href": "m04-friendship-paradox/02-coding.html#degree-distribution-of-a-friend",
    "title": "Advanced Topics in Network Science",
    "section": "1.3 Degree distribution of a friend",
    "text": "1.3 Degree distribution of a friend\nContinuing from the previous page, we will now consider the degree distribution of a friend of a node.\nThere are two ways to sample a friend of a node. 1. Sample a node uniformly at random and then sample a friend of the node. 2. Sample a friendship (i.e., edge) uniformly at random and then sample an end node of the edge.\nLet us focus on the second case and leave the first case for interested students as an exercise. In the second case, we sample an edge from the network. This sampling is biased towards nodes with many edges, i.e., a person with d edges is d times more likely to be sampled than someone with 1 edge. Thus, the degree distribution p'(k) of a friend is given by\n\np' (k) = C \\cdot k \\cdot p(k)\n The additional term k reflects the fact that a person with k friends is k times more likely to be sampled than someone with 1 friend. Term C is the normalization constant that ensures the sum of probabilities p'(k) over all k is 1, which can be easily computed as follows:\n\nC = \\frac{1}{\\sum_{k} k \\cdot p(k)} = \\frac{1}{\\langle k \\rangle}\n\nwhere \\langle k \\rangle is the average degree of the network. Substituting C into p'(k), we get:\n\np' (k) = \\frac{k}{\\langle k \\rangle} p(k)\n\nThis is the degree distribution of a friend, and it is easy to verify that the average degree of a friend is given by\n\n\\langle k' \\rangle = \\sum_{k} k \\cdot p'(k) = \\sum_{k} k \\cdot \\frac{k}{\\langle k \\rangle} p(k) = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}\n\nwhich is always larger than \\langle k \\rangle:\n\n\\langle k' \\rangle = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} \\geq \\langle k \\rangle\n\nwith equality only if every node has the same degree. This is a proof of the friendship paradox 😉!\n\n\n\n\n\n\nNote\n\n\n\nThe distribution p'(k) is related to the excess degree distribution given by\n\nq(k) = \\frac{k + 1}{\\langle k \\rangle} p(k+1)\n\nThe term excess comes from the fact that the distribution represents the number of additional connections a randomly chosen friend has, beyond the connection that led to their selection. It excludes the link to the focal node and focuses on the remaining connections of the selected friend.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe friend’s degree, \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}, concides with a term in Molloy-Reed condition:\n$$\n &gt;2\n$$\nwhich is a condition for the existence of a giant component in a network. The Molloy-Reed condition states that the average degree of a node’s friends must be at least 2 (the inequality is strict because the transition from a small component to a giant component is discontinuous). If a friend has only one edge, you and your friend form an isolated component. If a friend has two edges on average, your friend is a friend of someone else, and that someone else is also friend of another someone else and so on, forming a giant component.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/02-coding.html#plotting-degree-distribution-of-a-friend",
    "href": "m04-friendship-paradox/02-coding.html#plotting-degree-distribution-of-a-friend",
    "title": "Advanced Topics in Network Science",
    "section": "1.4 Plotting degree distribution of a friend",
    "text": "1.4 Plotting degree distribution of a friend\nLet us compare the degree distribution of a node and its friend. We first get the edges in the network, from which we sample a friend.\n\nfrom scipy import sparse\nsrc, trg, _ = sparse.find(A)\n\n\nsparse.find(A) returns the source node, target node, and edge weight of the edge.\nsrc is the source node of the edge\ntrg is the target node of the edge\n_ is used to ignore the edge weight values, as we only need the source and target nodes for this analysis.\n\nNow, let us get the degree of each friend\n\ndeg_friend = deg[src]\np_deg_friend = np.bincount(deg_friend) / len(deg_friend)\n\nThe CCDF of the degree distributions of a node and a friend can be computed by:\n\nccdf_deg = 1 - np.cumsum(p_deg)[:-1]\nccdf_deg_friend = 1 - np.cumsum(p_deg_friend)[:-1]\n\nand plotted by:\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg, label='Node')\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg_friend, label='Friend', ax = ax)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\nax.legend(frameon = False)\n\nThe slope of the CCDF of a friend is flatter than that of a node, indicating that the degree distribution of a friend is biased towards higher degrees.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html",
    "href": "m05-clustering/02-coding.html",
    "title": "Clustering Algorithms and Implementation",
    "section": "",
    "text": "Graph cut often provide unbalanced communities, e.g., a community consisting of a single node, and another consisting of all other nodes. For example, if the network has a node with degree one (e.g., one edge), an optimal cut will be to place this node in its own community, resulting in a cut of one.\nRatio cut addresses this issue by introducing a normalization factor to balance the cut. Suppose we cut the network into two communities V_1 and V_2, then the ratio cut is defined as\n\n\\text{Ratio cut}(V_1, V_2) = \\frac{1}{|V_1| \\cdot |V_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|V_1| (or |V_2|) is the number of nodes in the community V_1 (or V_2).\n\nThe normalization factor 1/(|V_1| |V_2|) balances the community sizes. It’s smallest when communities are equal (|V_1| = |V_2|) and largest when one community has only one node (|V_1| = 1 or |V_2| = 1).\n\n:tags: [\"hide-input\"]\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Total number of nodes\ntotal_nodes = 100\n\n# Create an array of possible sizes for V1\nV1_sizes = np.arange(1, total_nodes)\n\n# Calculate corresponding sizes for V2\nV2_sizes = total_nodes - V1_sizes\n\n# Calculate the normalization factor\nnormalization_factor = 1 / (V1_sizes * V2_sizes)\n\n# Create the plot\nfig = plt.figure(figsize=(5, 3))\nplt.plot(V1_sizes, normalization_factor)\nplt.title('Normalization Factor vs. Community Size')\nplt.xlabel('Size of V1')\nplt.ylabel('1 / (|V1| * |V2|)')\nplt.yscale('log')  # Use log scale for y-axis due to large range of values\nplt.grid(True)\n\n\n\n\nNormalized cut{footcite}shi2000normalized balances communities based on edge count, unlike Ratio cut which uses node count. It is defined as:\n\n\\text{Normalized cut}(V_1, V_2) = \\frac{1}{|E_1| \\cdot |E_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|E_1| and |E_2| are the number of edges in the communities V_1 and V_2, respectively.\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCompute the ratio cut and normalized cut for the following network. The red edges should be cut.\n\n\n\n:name: fig-graph-cut\n\n::: {.callout collapse=\"true\"}\n## Click here to reveal the answer\n\nThe graph consists of two cliques, each with 5 nodes ($|V_1| = |V_2| = 5$).\nEach clique has 10 internal edges and 2 edges connecting to the other clique.\nTherefore, $|E_1| = |E_2| = 10 + 2 = 12$.\nWe can now calculate:\n\n- **Ratio cut**: $2 / (5 \\times 5) = 0.08$.\n- **Normalized cut**: $2 / (12 \\times 12) = 0.01388889$.\n\n:::\n\n::: {#eb699019 .cell}\n``` {.python .cell-code}\n:tags: [\"hide-input\", \"remove-output\"]\n\nimport igraph as ig\nimport matplotlib.pyplot as plt\nfrom myst_nb import glue\n\n# Create two cliques of size 5\nG1 = ig.Graph.Full(5)\nG2 = ig.Graph.Full(5)\n\n# Combine the two cliques\nG = G1 + G2\n\n# Add an edge between the two cliques\nG.add_edge(0, 5)\nG.add_edge(1, 6)\n\n# Draw the graph\nlayout = G.layout_fruchterman_reingold()\n\n# Set up the plot\nfig, ax = plt.subplots(figsize=(5, 5))\n\n# Draw the connecting edge in red\nig.plot(\n    G,\n    target=ax,\n    layout=layout,\n    vertex_color='lightblue',\n    vertex_size=20,\n    edge_color='gray',\n    edge_width=1\n)\n\n# Draw the connecting edge in red behind the graph\nax.plot([layout[0][0], layout[5][0]], [layout[0][1], layout[5][1]], color='red', linewidth=2, zorder=0)\nax.plot([layout[1][0], layout[6][0]], [layout[1][1], layout[6][1]], color='red', linewidth=2, zorder=0)\n\nig.plot(\n    G,\n    target=ax,\n    layout=layout,\n    vertex_color='white',\n    vertex_size=20,\n    edge_color='black',\n    edge_width=1\n)\n\n# Add labels to the nodes\nfor i, coords in enumerate(layout):\n    ax.annotate(str(i), coords, ha='center', va='center')\n\nplt.title(\"Two Cliques Connected by One Edge\")\nplt.axis('off')\nplt.tight_layout()\n\nglue(\"fig-graph-cut\", fig, display=False)\n\n\nFigure 1\n\n\n\n\n\n:::\n\n\n\nRatio cut and Normalized cut can be extended to cut into more than two communities. Specifically, we can extend them to cut into k communities, i.e., V_1, V_2, \\dots, V_k by defining\n\n\\begin{align}\n\\text{Ratio cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|V_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right) \\\\\n\\text{Normalized cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|E_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right)\n\\end{align}\n\n\n\n\nFor both ratio and normalized cut, finding the best cut is a NP-hard problem. Yet, there are some heuristics to find a good cut. Interested students are encouraged to refer to Ulrike von Luxburg “A Tutorial on Spectral Clustering” for more details.\n\n\n\nWhile Ratio cut and Normalized cut methods are clever approaches, they do come with a couple of challenges we should be aware of.\nFirstly, these methods ask us to decide upfront how many communities we want to find. This can be tricky because, in real-world networks, we often don’t know this number in advance. It requires us to make a guess on how many different groups of friends we have before actually looking at our social circle.\nSecondly, and perhaps more critically, these methods favor communities of roughly the same size. It’s as if they’re assuming all our friend groups should have about the same number of people. But as we know from real life, that’s not always the case. Some of us might have a large group of college friends and a smaller group of childhood buddies. Research has shown that in many real-world networks, communities can indeed be quite different in size {footcite}palla2005uncovering,clauset2004finding.\nThese limitations don’t mean these methods should not be used, but they do remind us the importance of understanding the underlying assumptions and limitations of methods we use 😉. It’s always good to keep these points in mind when we’re working with network data. 🕸️💡",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html#balanced-cut-approaches",
    "href": "m05-clustering/02-coding.html#balanced-cut-approaches",
    "title": "Clustering Algorithms and Implementation",
    "section": "",
    "text": "Graph cut often provide unbalanced communities, e.g., a community consisting of a single node, and another consisting of all other nodes. For example, if the network has a node with degree one (e.g., one edge), an optimal cut will be to place this node in its own community, resulting in a cut of one.\nRatio cut addresses this issue by introducing a normalization factor to balance the cut. Suppose we cut the network into two communities V_1 and V_2, then the ratio cut is defined as\n\n\\text{Ratio cut}(V_1, V_2) = \\frac{1}{|V_1| \\cdot |V_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|V_1| (or |V_2|) is the number of nodes in the community V_1 (or V_2).\n\nThe normalization factor 1/(|V_1| |V_2|) balances the community sizes. It’s smallest when communities are equal (|V_1| = |V_2|) and largest when one community has only one node (|V_1| = 1 or |V_2| = 1).\n\n:tags: [\"hide-input\"]\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Total number of nodes\ntotal_nodes = 100\n\n# Create an array of possible sizes for V1\nV1_sizes = np.arange(1, total_nodes)\n\n# Calculate corresponding sizes for V2\nV2_sizes = total_nodes - V1_sizes\n\n# Calculate the normalization factor\nnormalization_factor = 1 / (V1_sizes * V2_sizes)\n\n# Create the plot\nfig = plt.figure(figsize=(5, 3))\nplt.plot(V1_sizes, normalization_factor)\nplt.title('Normalization Factor vs. Community Size')\nplt.xlabel('Size of V1')\nplt.ylabel('1 / (|V1| * |V2|)')\nplt.yscale('log')  # Use log scale for y-axis due to large range of values\nplt.grid(True)\n\n\n\n\nNormalized cut{footcite}shi2000normalized balances communities based on edge count, unlike Ratio cut which uses node count. It is defined as:\n\n\\text{Normalized cut}(V_1, V_2) = \\frac{1}{|E_1| \\cdot |E_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|E_1| and |E_2| are the number of edges in the communities V_1 and V_2, respectively.\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCompute the ratio cut and normalized cut for the following network. The red edges should be cut.\n\n\n\n:name: fig-graph-cut\n\n::: {.callout collapse=\"true\"}\n## Click here to reveal the answer\n\nThe graph consists of two cliques, each with 5 nodes ($|V_1| = |V_2| = 5$).\nEach clique has 10 internal edges and 2 edges connecting to the other clique.\nTherefore, $|E_1| = |E_2| = 10 + 2 = 12$.\nWe can now calculate:\n\n- **Ratio cut**: $2 / (5 \\times 5) = 0.08$.\n- **Normalized cut**: $2 / (12 \\times 12) = 0.01388889$.\n\n:::\n\n::: {#eb699019 .cell}\n``` {.python .cell-code}\n:tags: [\"hide-input\", \"remove-output\"]\n\nimport igraph as ig\nimport matplotlib.pyplot as plt\nfrom myst_nb import glue\n\n# Create two cliques of size 5\nG1 = ig.Graph.Full(5)\nG2 = ig.Graph.Full(5)\n\n# Combine the two cliques\nG = G1 + G2\n\n# Add an edge between the two cliques\nG.add_edge(0, 5)\nG.add_edge(1, 6)\n\n# Draw the graph\nlayout = G.layout_fruchterman_reingold()\n\n# Set up the plot\nfig, ax = plt.subplots(figsize=(5, 5))\n\n# Draw the connecting edge in red\nig.plot(\n    G,\n    target=ax,\n    layout=layout,\n    vertex_color='lightblue',\n    vertex_size=20,\n    edge_color='gray',\n    edge_width=1\n)\n\n# Draw the connecting edge in red behind the graph\nax.plot([layout[0][0], layout[5][0]], [layout[0][1], layout[5][1]], color='red', linewidth=2, zorder=0)\nax.plot([layout[1][0], layout[6][0]], [layout[1][1], layout[6][1]], color='red', linewidth=2, zorder=0)\n\nig.plot(\n    G,\n    target=ax,\n    layout=layout,\n    vertex_color='white',\n    vertex_size=20,\n    edge_color='black',\n    edge_width=1\n)\n\n# Add labels to the nodes\nfor i, coords in enumerate(layout):\n    ax.annotate(str(i), coords, ha='center', va='center')\n\nplt.title(\"Two Cliques Connected by One Edge\")\nplt.axis('off')\nplt.tight_layout()\n\nglue(\"fig-graph-cut\", fig, display=False)\n\n\nFigure 1\n\n\n\n\n\n:::\n\n\n\nRatio cut and Normalized cut can be extended to cut into more than two communities. Specifically, we can extend them to cut into k communities, i.e., V_1, V_2, \\dots, V_k by defining\n\n\\begin{align}\n\\text{Ratio cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|V_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right) \\\\\n\\text{Normalized cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|E_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right)\n\\end{align}\n\n\n\n\nFor both ratio and normalized cut, finding the best cut is a NP-hard problem. Yet, there are some heuristics to find a good cut. Interested students are encouraged to refer to Ulrike von Luxburg “A Tutorial on Spectral Clustering” for more details.\n\n\n\nWhile Ratio cut and Normalized cut methods are clever approaches, they do come with a couple of challenges we should be aware of.\nFirstly, these methods ask us to decide upfront how many communities we want to find. This can be tricky because, in real-world networks, we often don’t know this number in advance. It requires us to make a guess on how many different groups of friends we have before actually looking at our social circle.\nSecondly, and perhaps more critically, these methods favor communities of roughly the same size. It’s as if they’re assuming all our friend groups should have about the same number of people. But as we know from real life, that’s not always the case. Some of us might have a large group of college friends and a smaller group of childhood buddies. Research has shown that in many real-world networks, communities can indeed be quite different in size {footcite}palla2005uncovering,clauset2004finding.\nThese limitations don’t mean these methods should not be used, but they do remind us the importance of understanding the underlying assumptions and limitations of methods we use 😉. It’s always good to keep these points in mind when we’re working with network data. 🕸️💡",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html#modularity-implementation",
    "href": "m05-clustering/02-coding.html#modularity-implementation",
    "title": "Clustering Algorithms and Implementation",
    "section": "2 Modularity Implementation",
    "text": "2 Modularity Implementation\n\n\n\nIllustration of how modularity measures assortativity relative to a null model. {#fig-modularity-game}\n\n\nLet’s dive into the modularity formula! To put modularity into math terms, we need a few ingredients: - m: The total number of strings (edges) in our bag - n: The total number of balls (nodes) we have - A_{ij}: This tells us if ball i and ball j are connected by a string - \\delta(c_i,c_j): This is our color-checker. It gives us a 1 if balls i and j are the same color (same community), and 0 if they’re different.\nNow, the probability of pulling out a string out of m string and finding matching colors on both ends is:\n\n\\frac{1}{m} \\sum_{i=1}^n \\sum_{j=i+1}^n A_{ij} \\delta(c_i,c_j) = \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j)\n\nWe set A_{ii} = 0 by assuming our network doesn’t have any “selfie strings” (where a ball is connected to itself). Also, we changed our edge counting a bit. Instead of counting each string once (which gave us m), we’re now counting each string twice (once from each end). That’s why we use 2m in the equation.\nNow, imagine we’ve cut all the strings, and we’re going to draw two balls at random with replacement. Here’s how our new bag looks: - We have 2m balls in total (1 string has 2 balls, and thus m strings have 2m balls in total). - A node with k edges correspond to the k of 2m balls in the bag. - The color of each ball in our bag matches the color (or community) of its node in the network.\nNow, what’s the chance of pulling out two balls of the same color?\n\n\\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\nwhere k_i is the degree (i.e., the number of edges) of node i, and C is the total number of communities (i.e., colors).\nHere’s what it means in simple terms: - We look at each color (c) one by one (the outer sum). - For each color, we figure out how many balls of that color are in our bag (\\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i)). - We divide by 2m to get the probability of drawing a ball of that color. - We then calculate the chance of grabbing that color twice in a row (\\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2). - Finally, we add up these chances for all C colors.\nPutting altogether, the modularity is defined by\n\n\\begin{align}\nQ &=\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n\\end{align}\n\nEquivalently, a standard expression is given by\n\nQ =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)\n\n\nAre the two forms of modularity the same formula? Let's see how we can transform one into the other:\n\n1. We start with our first form of modularity:\n\n   $$\n   Q =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\sum_{c=1}^C \\left( \\frac{1}{2m}\\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2\n   $$\n\n2. First, let's factor out $\\frac{1}{2m}$ from both terms:\n\n   $$\n   Q =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n k_i \\delta(c, c_i) \\right)^2 \\right]\n   $$\n\n3. Now, here's a neat trick: $(\\sum_i a_i)^2 = (\\sum_i a_i)( \\sum_j a_j)$. We can use this to expand the squared term:\n\n   $$\n   Q =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n k_i \\delta(c, c_i) \\right) \\left( \\sum_{j=1}^n k_j \\delta(c, c_j) \\right)\\right]\n   $$\n\n4. And here is another trick $(\\sum_i a_i)( \\sum_j a_j) = \\sum_i a_i \\sum_j a_j = \\sum_i \\sum_j a_ia_j$\n\n   $$\n   Q =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) - \\frac{1}{2m}\\sum_{c=1}^C \\left( \\sum_{i=1}^n \\sum_{j=1}^n k_i k_j  \\delta(c, c_i)  \\delta(c, c_j) \\right)\\right]\n   $$\n\n5. Here's yet another cool trick, $\\delta(c,c_i) \\delta(c, c_j) = \\delta(c_i,c_j)$. This means we can simplify our expression:\n\n   $$\n   Q =\\frac{1}{2m} \\left[ \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta(c_i,c_j) -  \\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n k_i k_j  \\delta(c_i,c_j) \\right]\n   $$\n\n6. Finally, we can factor out the common parts:\n\n   $$\n   Q =\\frac{1}{2m} \\sum_{i=1}^n \\sum_{j=1}^n \\left[ A_{ij} -  \\frac{k_ik_j}{2m} \\right]\\delta(c_i,c_j)\n   $$\n\nModularity Demo\nLet’s learn how the modularity works by playing with a community detection game!\n\n\n\n\n\n\nExercise 1\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (two communities) 🎮\n\n\nOne of the good things about modularity is that it can figure out how many communities there should be all by itself! 🕵️‍♀️ Let’s have some fun with this idea. We’re going to play the same game again, but this time, we’ll start with a different number of communities. See how the modularity score changes as we move things around.\n\n\n\n\n\n\nExercise 2\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) 🎮\n\n\nNow, let’s take our modularity maximization for a real-world example! 🥋 We’re going to use the famous karate club network. This network represents friendships between members of a university karate club. It’s a classic in the world of network science, and it’s perfect for seeing how modularity works in practice.\n\n\n\n\n\n\nExercise 3\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) 🎮\n\n\n\n\nLimitation of Modularity\nLike many other community detection methods, modularity is not a silver bullet. Thanks to extensive research, we know many limitations of modularity. Let’s take a look at a few of them.\n\n\nResolution limit\nThe modularity finds two cliques connected by a single edge as two separate communities. But what if we add another community to this network? Our intuition tells us that, because communities are local structure, the two cliques should remain separated by the modularity. But is this the case?\n\n\n\n\n\n\nExercise 4\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) 🎮\n\n\n\n\n\n\nClick here to see the solution\n\n\n\n\n\nThe best modularity score actually comes from merging our two cliques into one big community. This behavior is what we call the Resolution limit {footcite}fortunato2007resolution. Modularity can’t quite make out communities that are smaller than a certain size!\nThink of it like this: modularity is trying to see the big picture, but it misses the little details. In network terms, the number of edges m_c in a community c has to be bigger than a certain size. This size is related to the total number of edges m in the whole network. We write this mathematically as {\\cal O}(m).\n\n\n\n\nSpurious communities\nWhat if the network does not have any communities at all? Does the modularity find no communities? To find out, let’s run the modularity on a random network, where each pair of nodes is connected randomly with the same probability.\n\n\n\n\n\n\nExercise 5\n\n\n\n:class: tip\nFind communities by maximizing the modularity. Modularity maximization (four communities) 🎮\n\n\n\n\n\n\nClick here to see the solution\n\n\n\n\n\nSurprise, surprise! 😮 Modularity finds communities even in our random network, and with a very high score too! It’s like finding shapes in clouds - sometimes our brains (or algorithms) see patterns where there aren’t any.\nThe wild thing is that the modularity score for this random network is even higher than what we saw for our network with two clear cliques!\nThis teaches us two important lessons: 1. We can’t compare modularity scores between different networks. It’s like comparing apples and oranges! 🍎🍊 2. A high modularity score doesn’t always mean we’ve found communities.\nInterested readers can read more about this in this tweet by Tiago Peixoto and the discussion here.\n\n\nModularity maximization is not a reliable method to find communities in networks. Here's a simple example showing why:1. Generate an Erdős-Rényi random graph with N nodes and average degree &lt;k&gt;.2. Find the maximum modularity partition. pic.twitter.com/MTt5DdFXSX\n\n— Tiago Peixoto ((tiagopeixoto?)) December 2, 2021\n\n\n\n\n\n\n\n\n\nSo should we avoid modularity?\nThe simple answer is no. Modularity is still a powerful tool for finding communities in networks. Like any other method, it has its limitations. And knowing these limitations is crucial for using it effectively. There is “free lunch” in community detection {footcite}peel2017ground.\nWhen these implicit assumptions are met, modularity is in fact a very powerful method for community detection. For example, it is in fact an “optimal” method for a certain class of networks {footcite}nadakuditi2012graph.\nSo, keep modularity in your toolbox. Just remember to use it wisely!\n\n\n3 Stochastic Block Model\nLet’s talk about two ways to look at communities in networks.\nIn modularity maximization, we are given a network and asked to find the best way to group its parts into communities.\nLet’s flip that idea on its head! 🙃 Instead of starting with a network and looking for communities, we start with the communities and ask, “What kind of network would we get if the nodes form these communities?”. This is the idea of the Stochastic Block Model (SBM).\nWhile modularity maximization is about finding hidden patterns, SBM is about imagining what a network would look like based on a given community structure. Two sides of the same coin, each giving us a unique perspective on community detection.\n\nModel\nIn stochastic block model, we describe a network using probabilities given a community structure. Specifically, let us consider two nodes i and j who belong to community c_i and c_j. Then, the probability of an edge between i and j is given by their community membership.\n\nP(A_{ij}=1|c_i, c_j) = p_{c_i,c_j}\n\nwhere p_{c_i,c_j} is the probability of an edge between nodes in community c_i and c_j, respectively. Notice that the edge probability is fully specified by the community membership of the nodes. This means that nodes in a community are connected with the same probability irrespective of the nodes themselves, and the nodes in different two communities are also connected with the same probability. As a result, when plotting the adjacency matrix, we observe “blocks” of different edge densities, which is why we say that SBM is a “block model”.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Plot\nplt.figure(figsize=(8, 8))\nplt.imshow(A, cmap='binary')\nplt.title(\"Adjacency Matrix of Stochastic Block Model\")\nplt.xlabel(\"Node Index\")\nplt.ylabel(\"Node Index\")\nplt.tight_layout()\nplt.show()\n\n\n\nCharacterizing network structures with the SBM\nStochastic Block Model is a flexible model that can be used to describe a wide range of network structures.\nLet’s start with communities where nodes within a community are more likely to be connected to each other than nodes in different communities. We can describe this using SBM by:\n\nP_{c,c'} = \\begin{cases}\n    p_{\\text{in}} & \\text{if } c = c' \\\\\n    p_{\\text{out}} & \\text{if } c \\neq c'\n\\end{cases}\n\n\np_{\\text{in}} is the chance of a connection between nodes in the same community\np_{\\text{out}} is the chance of a connection between nodes in different communities\n\nUsually, we set p_{\\text{in}} &gt; p_{\\text{out}}, because nodes in the same community tend to be more connected.\nBut, there’s more SBM can do:\n\nDisassortative communities: What if we flip things around and set p_{\\text{in}} &lt; p_{\\text{out}}? Now we have communities where nodes prefer to connect with nodes from other communities. This is not in line with the communities we have focused on so far. Yet, it is still a valid model of community structure, and SBM allows for this generalization of community structure easily.\nRandom networks: If we make p_{\\text{in}} = p_{\\text{out}}, we get a completely random network where every node has an equal chance of connecting to any other node. This is what we call an Erdős-Rényi network.\n\nIn sum, SBM has been used as a playground for network scientists. We can use it to create many interesting network structures and study how they behave.\n\n\nGenerating networks with SBM\nIt is easy to generate networks with SBM using igraph. For example, the assortativity communities can be generated as follows.\n\nimport igraph\n\np_in = 0.1\np_out = 0.001\nblock_sizes = [100, 200, 300]\nn = sum(block_sizes)\n\npref_matrix = [\n    [p_in, p_out, p_out],\n    [p_out, p_in, p_out],\n    [p_out, p_out, p_in]\n]\n\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Plot the network\nimport seaborn as sns\npalette = sns.color_palette()\n\ncommunity_colors = sum([[palette[i]] * block_sizes[i] for i in range(len(block_sizes))], [])\nigraph.plot(g, vertex_color=community_colors)\n\n\npref_matrix is the matrix of connection probabilities between communities. Its (i,j)th-element is the probability of a connection between nodes in community i and j.\n\n\n\nDetecting communities with SBM\nImagine you’re a detective trying to figure out how a network was created. You have a hunch about the community structure, and you want to know if it matches the network you see. That’s exactly what we’re going to do to find out communities!\nHere’s how we can describe the probability of seeing a particular network, given a community structure:\n\nP(\\left\\{A_{ij}\\right\\}_{ij}) = \\prod_{i&lt;j} P(A_{ij}=1|c_i, c_j)^{A_{ij}} (1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}\n\nLet’s break this down into simpler terms:\n\nFirst, \\left\\{A_{ij}\\right\\}_{ij} is just a fancy way of saying “all the connections in our network”. Think of it as a big table showing who’s connected to whom.\nWe use \\prod_{i &lt; j} instead of \\prod_{i,j} because we’re dealing with an undirected network. This means if Alice is friends with Bob, Bob is also friends with Alice. We only need to count this friendship once, not twice!\nThe last part, P(A_{ij}=1|c_i, c_j)^A_{ij}(1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}, might look scary, but it’s actually quite clever. It’s a shorthand way of saying “what’s the chance of this connection existing or not existing?” If the connection exists (A_{ij}=1), we use the first part. If it doesn’t (A_{ij}=0), we use the second part. It’s a two-in-one formula.\n\nHere’s a neat trick we can use to make our lives easier. We can take the logarithm of both sides of our equation. This turns our big product (multiplication) into a simpler sum (addition).\n\n{\\cal L}=\\log P(\\left\\{A_{ij}\\right\\}_{ij}) = \\sum_{i&lt;j} A_{ij} \\log P(A_{ij}=1|c_i, c_j) + (1-A_{ij}) \\log (1-P(A_{ij}=1|c_i, c_j))\n\nWe call this the likelihood function. It tells us how likely we are to see this network given our community guess. We can play around with different community assignments and edge probabilities to see which one gives us the highest likelihood. To make this game easier, let’s first figure out the best edge probabilities for a given community assignment.\nOur likelihood function has a special shape - it is a concave function with respect to p_{c,c'}. This means that the likelihood function is a hill with only one peak when we look at it in terms of edge probability p_{c,c'}.\n\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef concave_function(x):\n    return -(x - 0.5)**2 + 0.25\n\nx = np.linspace(0, 1, 100)\ny = concave_function(x)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, 'b-', linewidth=2)\nplt.title('Schematic of Likelihood Function (Concave)')\nplt.xlabel('Edge Probability p_c,c\\'')\nplt.ylabel('Likelihood')\nplt.axvline(x=0.5, color='r', linestyle='--', label='Maximum')\nplt.annotate('Global Maximum', xy=(0.5, 0.25), xytext=(0.6, 0.2),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.legend()\nplt.grid(True)\nplt.show()\n\nSo, what does this mean for us? The top of this hill (our maximum value) is flat, and there’s only one flat spot on the whole hill. So if we can find a spot where the hill isn’t sloping at all (that’s what we mean by “zero gradient”), we’ve found the very top of the hill! 🏔️\nIn math terms, we take the derivative of our likelihood function with respect to p_{c,c'} and set it to zero, i.e., \\partial {\\cal L}  / \\partial p_{cc'} = 0. Here is what we get:\n\n\\begin{aligned}\n\\frac{\\partial {\\cal L}}{\\partial p_{c,c'}} &= 0 \\\\\n\\Rightarrow & \\sum_{i&lt;j} \\left[A_{ij} \\frac{1}{p_{c_i,c_j}} \\delta(c_i,c)\\delta(c_j,c') -(1-A_{ij}) \\frac{1}{1-p_{c_i,c_j}}\\delta(c_i,c')\\delta(c_j,c') \\right] = 0 \\\\\n\\Rightarrow &\n\\frac{m_{cc'}}{p_{c_i,c_j}} - \\frac{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') }{1-p_{c_i,c_j}} = 0 & \\text{if } c \\neq  c' \\\\\n\\Rightarrow & p_{c,c'} = \\frac{m_{cc'}}{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c')}\n\\end{aligned}\n\nLet’s break down these equations:\n\nm_{cc'} is the number of edges between nodes in community c and those in community c'.\nThe derivative \\partial \\log p_{cc} / \\partial p_{cc} is just 1/p_{cc}.\n\nThe denominator \\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') is the total number of pairs of nodes that belong to communities c and c'. It is given by\n\n\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') =\n\\begin{cases}\nn_cn_{c'} & \\text{if } c \\neq c' \\\\\n\\frac{n_c (n_c - 1)}{2} & \\text{if } c = c'\n\\end{cases}\n\nWhy do we have two different equations for p_{c,c'}? It’s because we are counting each pair of nodes only by once. It is easy to verify when looking at the adjacency matrix:\n\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Create the plot\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Plot the adjacency matrix\nax.matshow(A, cmap='binary')\nmask = np.triu(np.ones_like(A, dtype=bool), k=1)\n\n# Highlight the upper triangle with yellow overlay\nax.matshow(np.ma.masked_array(np.ones_like(A), ~mask), cmap='Reds_r', alpha=0.3)\n\n# Add a title\nplt.title(\"Adjacency Matrix with Highlighted Upper Triangle\")\n\nplt.show()\n\nThe upper triangle of the adjacency matrix represents i &lt; j over which we take the sum. When c=c' (the diagonal block), we count only the upper half of the block, resulting in \\frac{n_c (n_c - 1)}{2}. When c \\neq c' (different communities), we count all connections between them, resulting in n_cn_{c'}.\nWe have now obtaind the likelihood function based only on the community assignment. Maximizing {\\cal L} with respect to the community assignment gives us the most likely community assignment for the network.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/02-coding.html#stochastic-block-model",
    "href": "m05-clustering/02-coding.html#stochastic-block-model",
    "title": "Clustering Algorithms and Implementation",
    "section": "3 Stochastic Block Model",
    "text": "3 Stochastic Block Model\nLet’s talk about two ways to look at communities in networks.\nIn modularity maximization, we are given a network and asked to find the best way to group its parts into communities.\nLet’s flip that idea on its head! 🙃 Instead of starting with a network and looking for communities, we start with the communities and ask, “What kind of network would we get if the nodes form these communities?”. This is the idea of the Stochastic Block Model (SBM).\nWhile modularity maximization is about finding hidden patterns, SBM is about imagining what a network would look like based on a given community structure. Two sides of the same coin, each giving us a unique perspective on community detection.\n\nModel\nIn stochastic block model, we describe a network using probabilities given a community structure. Specifically, let us consider two nodes i and j who belong to community c_i and c_j. Then, the probability of an edge between i and j is given by their community membership.\n\nP(A_{ij}=1|c_i, c_j) = p_{c_i,c_j}\n\nwhere p_{c_i,c_j} is the probability of an edge between nodes in community c_i and c_j, respectively. Notice that the edge probability is fully specified by the community membership of the nodes. This means that nodes in a community are connected with the same probability irrespective of the nodes themselves, and the nodes in different two communities are also connected with the same probability. As a result, when plotting the adjacency matrix, we observe “blocks” of different edge densities, which is why we say that SBM is a “block model”.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Plot\nplt.figure(figsize=(8, 8))\nplt.imshow(A, cmap='binary')\nplt.title(\"Adjacency Matrix of Stochastic Block Model\")\nplt.xlabel(\"Node Index\")\nplt.ylabel(\"Node Index\")\nplt.tight_layout()\nplt.show()\n\n\n\nCharacterizing network structures with the SBM\nStochastic Block Model is a flexible model that can be used to describe a wide range of network structures.\nLet’s start with communities where nodes within a community are more likely to be connected to each other than nodes in different communities. We can describe this using SBM by:\n\nP_{c,c'} = \\begin{cases}\n    p_{\\text{in}} & \\text{if } c = c' \\\\\n    p_{\\text{out}} & \\text{if } c \\neq c'\n\\end{cases}\n\n\np_{\\text{in}} is the chance of a connection between nodes in the same community\np_{\\text{out}} is the chance of a connection between nodes in different communities\n\nUsually, we set p_{\\text{in}} &gt; p_{\\text{out}}, because nodes in the same community tend to be more connected.\nBut, there’s more SBM can do:\n\nDisassortative communities: What if we flip things around and set p_{\\text{in}} &lt; p_{\\text{out}}? Now we have communities where nodes prefer to connect with nodes from other communities. This is not in line with the communities we have focused on so far. Yet, it is still a valid model of community structure, and SBM allows for this generalization of community structure easily.\nRandom networks: If we make p_{\\text{in}} = p_{\\text{out}}, we get a completely random network where every node has an equal chance of connecting to any other node. This is what we call an Erdős-Rényi network.\n\nIn sum, SBM has been used as a playground for network scientists. We can use it to create many interesting network structures and study how they behave.\n\n\nGenerating networks with SBM\nIt is easy to generate networks with SBM using igraph. For example, the assortativity communities can be generated as follows.\n\nimport igraph\n\np_in = 0.1\np_out = 0.001\nblock_sizes = [100, 200, 300]\nn = sum(block_sizes)\n\npref_matrix = [\n    [p_in, p_out, p_out],\n    [p_out, p_in, p_out],\n    [p_out, p_out, p_in]\n]\n\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Plot the network\nimport seaborn as sns\npalette = sns.color_palette()\n\ncommunity_colors = sum([[palette[i]] * block_sizes[i] for i in range(len(block_sizes))], [])\nigraph.plot(g, vertex_color=community_colors)\n\n\npref_matrix is the matrix of connection probabilities between communities. Its (i,j)th-element is the probability of a connection between nodes in community i and j.\n\n\n\nDetecting communities with SBM\nImagine you’re a detective trying to figure out how a network was created. You have a hunch about the community structure, and you want to know if it matches the network you see. That’s exactly what we’re going to do to find out communities!\nHere’s how we can describe the probability of seeing a particular network, given a community structure:\n\nP(\\left\\{A_{ij}\\right\\}_{ij}) = \\prod_{i&lt;j} P(A_{ij}=1|c_i, c_j)^{A_{ij}} (1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}\n\nLet’s break this down into simpler terms:\n\nFirst, \\left\\{A_{ij}\\right\\}_{ij} is just a fancy way of saying “all the connections in our network”. Think of it as a big table showing who’s connected to whom.\nWe use \\prod_{i &lt; j} instead of \\prod_{i,j} because we’re dealing with an undirected network. This means if Alice is friends with Bob, Bob is also friends with Alice. We only need to count this friendship once, not twice!\nThe last part, P(A_{ij}=1|c_i, c_j)^A_{ij}(1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}, might look scary, but it’s actually quite clever. It’s a shorthand way of saying “what’s the chance of this connection existing or not existing?” If the connection exists (A_{ij}=1), we use the first part. If it doesn’t (A_{ij}=0), we use the second part. It’s a two-in-one formula.\n\nHere’s a neat trick we can use to make our lives easier. We can take the logarithm of both sides of our equation. This turns our big product (multiplication) into a simpler sum (addition).\n\n{\\cal L}=\\log P(\\left\\{A_{ij}\\right\\}_{ij}) = \\sum_{i&lt;j} A_{ij} \\log P(A_{ij}=1|c_i, c_j) + (1-A_{ij}) \\log (1-P(A_{ij}=1|c_i, c_j))\n\nWe call this the likelihood function. It tells us how likely we are to see this network given our community guess. We can play around with different community assignments and edge probabilities to see which one gives us the highest likelihood. To make this game easier, let’s first figure out the best edge probabilities for a given community assignment.\nOur likelihood function has a special shape - it is a concave function with respect to p_{c,c'}. This means that the likelihood function is a hill with only one peak when we look at it in terms of edge probability p_{c,c'}.\n\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef concave_function(x):\n    return -(x - 0.5)**2 + 0.25\n\nx = np.linspace(0, 1, 100)\ny = concave_function(x)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, 'b-', linewidth=2)\nplt.title('Schematic of Likelihood Function (Concave)')\nplt.xlabel('Edge Probability p_c,c\\'')\nplt.ylabel('Likelihood')\nplt.axvline(x=0.5, color='r', linestyle='--', label='Maximum')\nplt.annotate('Global Maximum', xy=(0.5, 0.25), xytext=(0.6, 0.2),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.legend()\nplt.grid(True)\nplt.show()\n\nSo, what does this mean for us? The top of this hill (our maximum value) is flat, and there’s only one flat spot on the whole hill. So if we can find a spot where the hill isn’t sloping at all (that’s what we mean by “zero gradient”), we’ve found the very top of the hill! 🏔️\nIn math terms, we take the derivative of our likelihood function with respect to p_{c,c'} and set it to zero, i.e., \\partial {\\cal L}  / \\partial p_{cc'} = 0. Here is what we get:\n\n\\begin{aligned}\n\\frac{\\partial {\\cal L}}{\\partial p_{c,c'}} &= 0 \\\\\n\\Rightarrow & \\sum_{i&lt;j} \\left[A_{ij} \\frac{1}{p_{c_i,c_j}} \\delta(c_i,c)\\delta(c_j,c') -(1-A_{ij}) \\frac{1}{1-p_{c_i,c_j}}\\delta(c_i,c')\\delta(c_j,c') \\right] = 0 \\\\\n\\Rightarrow &\n\\frac{m_{cc'}}{p_{c_i,c_j}} - \\frac{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') }{1-p_{c_i,c_j}} = 0 & \\text{if } c \\neq  c' \\\\\n\\Rightarrow & p_{c,c'} = \\frac{m_{cc'}}{\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c')}\n\\end{aligned}\n\nLet’s break down these equations:\n\nm_{cc'} is the number of edges between nodes in community c and those in community c'.\nThe derivative \\partial \\log p_{cc} / \\partial p_{cc} is just 1/p_{cc}.\n\nThe denominator \\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') is the total number of pairs of nodes that belong to communities c and c'. It is given by\n\n\\sum_{i &lt; j} \\delta(c_i,c)\\delta(c_j,c') =\n\\begin{cases}\nn_cn_{c'} & \\text{if } c \\neq c' \\\\\n\\frac{n_c (n_c - 1)}{2} & \\text{if } c = c'\n\\end{cases}\n\nWhy do we have two different equations for p_{c,c'}? It’s because we are counting each pair of nodes only by once. It is easy to verify when looking at the adjacency matrix:\n\n:tags: [remove-input]\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport igraph\n\n# Generate SBM\nn, k = 900, 3\n\n# Create block sizes (equal for simplicity)\nblock_sizes = [n // k] * k\n\n# Create diverse pref matrix\npref_matrix = [\n    [0.3, 0.05, 0.1],\n    [0.05, 0.4, 0.02],\n    [0.1, 0.02, 0.35]\n]\n\n# Generate SBM using igraph\ng = igraph.Graph.SBM(n, pref_matrix, block_sizes)\n\n# Convert to adjacency matrix for visualization\nA = np.array(g.get_adjacency().data)\n\n# Create the plot\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Plot the adjacency matrix\nax.matshow(A, cmap='binary')\nmask = np.triu(np.ones_like(A, dtype=bool), k=1)\n\n# Highlight the upper triangle with yellow overlay\nax.matshow(np.ma.masked_array(np.ones_like(A), ~mask), cmap='Reds_r', alpha=0.3)\n\n# Add a title\nplt.title(\"Adjacency Matrix with Highlighted Upper Triangle\")\n\nplt.show()\n\nThe upper triangle of the adjacency matrix represents i &lt; j over which we take the sum. When c=c' (the diagonal block), we count only the upper half of the block, resulting in \\frac{n_c (n_c - 1)}{2}. When c \\neq c' (different communities), we count all connections between them, resulting in n_cn_{c'}.\nWe have now obtaind the likelihood function based only on the community assignment. Maximizing {\\cal L} with respect to the community assignment gives us the most likely community assignment for the network.",
    "crumbs": [
      "Home",
      "M05: Clustering",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m05-clustering/graph-cut.html",
    "href": "m05-clustering/graph-cut.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Graph cut\nAnother approach from computer science is to treat a community detection problem as an optimization problem. An early example is the graph cut problem, which asks to find the minimum number of edges to cut the graph into two disconnected components.\nSpecifically, let us consider cutting the network into two communities. Let V_1 and V_2 be the set of nodes in the two communities. Then, the cut is the number of edges between the two communities, which is given by\n\n\\begin{align}\n\\text{Cut}(V_1, V_2) = \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\\end{align}\n\nNow, the community detection problem is translated into an optimization problem, with the goal of finding a cut V_1, V_2 that minimizes \\text{Cut}(V_1, V_2).\nThe description of this problem is not complete 😈. Let’s find out what is missing by playing with the optimization problem.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCan you identify what is missing in the description of the graph cut problem? Without this, the best cut is trivial. {{ “Graph Cut Problem 🎮”.replace(‘BASE_URL’, base_url) }}\n\n\n\n\n\n\nClick to reveal the answer!\n\n\n\n\n\nThe missing element is a constraint: each community must contain at least one node. Without this, the trivial solution of placing all nodes in a single community would always yield a cut of zero.\n\n\n\n:::{#quarto-navigation-envelope .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyLXRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXItdGl0bGU=\"}\n[Course Information]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMQ==\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvd2VsY29tZS5odG1sV2VsY29tZQ==\"}\n[About us]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvYWJvdXQuaHRtbEFib3V0LXVz\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvZGlzY29yZC5odG1sRGlzY29yZA==\"}\n[Using Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvbWluaWRvcmEtdXNhZ2UuaHRtbFVzaW5nLU1pbmlkb3Jh\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvc2V0dXAuaHRtbFNldHVw\"}\n[Introduction]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMg==\"}\n[Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9pbnRyby93aHktbmV0d29ya3MuaHRtbE5ldHdvcmtz\"}\n[M01: Euler Path]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMw==\"}\n[From Visual to Computational Thinking]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMC1wcmVwYXJhdGlvbi5odG1sRnJvbS1WaXN1YWwtdG8tQ29tcHV0YXRpb25hbC1UaGlua2luZw==\"}\n[Euler Path Concepts - The Birth of Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMS1jb25jZXB0cy5odG1sRXVsZXItUGF0aC1Db25jZXB0cy0tLVRoZS1CaXJ0aC1vZi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Coding Networks in Python]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMi1jb2RpbmcuaHRtbENvZGluZy1OZXR3b3Jrcy1pbi1QeXRob24=\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcw==\"}\n[Advanced: Sparse Matrices for Large-Scale Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wNC1hZHZhbmNlZC5odG1sQWR2YW5jZWQ6LVNwYXJzZS1NYXRyaWNlcy1mb3ItTGFyZ2UtU2NhbGUtTmV0d29ya3M=\"}\n[M02: Small World]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNA==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDAtcHJlcGFyYXRpb24uaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Small-World Networks: Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDEtY29uY2VwdHMuaHRtbFNtYWxsLVdvcmxkLU5ldHdvcmtzOi1Db3JlLUNvbmNlcHRz\"}\n[Efficient Network Representation and Computing Paths]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDItY29kaW5nLmh0bWxFZmZpY2llbnQtTmV0d29yay1SZXByZXNlbnRhdGlvbi1hbmQtQ29tcHV0aW5nLVBhdGhz\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDMtZXhlcmNpc2VzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Appendix - Brief Introduction to igraph]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDQtYXBwZW5kaXguaHRtbEFwcGVuZGl4LS0tQnJpZWYtSW50cm9kdWN0aW9uLXRvLWlncmFwaA==\"}\n[M03: Robustness]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNQ==\"}\n[Preparation]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMC1wcmVwYXJhdGlvbi5odG1sUHJlcGFyYXRpb24=\"}\n[Network Robustness: Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMS1jb25jZXB0cy5odG1sTmV0d29yay1Sb2J1c3RuZXNzOi1Db3JlLUNvbmNlcHRz\"}\n[Coding - Network Robustness Analysis]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMi1jb2RpbmcuaHRtbENvZGluZy0tLU5ldHdvcmstUm9idXN0bmVzcy1BbmFseXNpcw==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wNC1hcHBlbmRpeC5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M04: Friendship Paradox]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNg==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M05: Clustering]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNw==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMC1wcmVwYXJhdGlvbi5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMS1jb25jZXB0cy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMi1jb2RpbmcuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[M06: Centrality]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOA==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMC1wcmVwYXJhdGlvbi5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMS1jb25jZXB0cy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMi1jb2RpbmcuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[M07: Random Walks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M08: Embedding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTA=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[M09: Graph Neural Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTE=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Home]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SG9tZQ==\"}\n[/index.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2luZGV4Lmh0bWw=\"}\n[Course]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q291cnNl\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2VsY29tZQ==\"}\n[/course/welcome.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS93ZWxjb21lLmh0bWw=\"}\n[About]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWJvdXQ=\"}\n[/course/about.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9hYm91dC5odG1s\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RGlzY29yZA==\"}\n[/course/discord.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9kaXNjb3JkLmh0bWw=\"}\n[Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6TWluaWRvcmE=\"}\n[/course/minidora-usage.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9taW5pZG9yYS11c2FnZS5odG1s\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6U2V0dXA=\"}\n[/course/setup.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9zZXR1cC5odG1s\"}\n[Intro]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SW50cm8=\"}\n[Why Networks?]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2h5IE5ldHdvcmtzPw==\"}\n[/intro/why-networks.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2ludHJvL3doeS1uZXR3b3Jrcy5odG1s\"}\n[Foundations]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Rm91bmRhdGlvbnM=\"}\n[─── M01: Euler Path ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMTogRXVsZXIgUGF0aCDilIDilIDilIA=\"}\n[Preparation]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6UHJlcGFyYXRpb24=\"}\n[/m01-euler_tour/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29uY2VwdHM=\"}\n[/m01-euler_tour/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[Coding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29kaW5n\"}\n[/m01-euler_tour/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAyLWNvZGluZy5odG1s\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RXhlcmNpc2Vz\"}\n[/m01-euler_tour/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQ=\"}\n[/m01-euler_tour/04-advanced.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzA0LWFkdmFuY2VkLmh0bWw=\"}\n[─── M02: Small World ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMjogU21hbGwgV29ybGQg4pSA4pSA4pSA\"}\n[/m02-small-world/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMC1wcmVwYXJhdGlvbi5odG1s\"}\n[/m02-small-world/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMS1jb25jZXB0cy5odG1s\"}\n[/m02-small-world/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMi1jb2RpbmcuaHRtbA==\"}\n[/m02-small-world/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMy1leGVyY2lzZXMuaHRtbA==\"}\n[Appendix]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QXBwZW5kaXg=\"}\n[/m02-small-world/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wNC1hcHBlbmRpeC5odG1s\"}\n[─── M03: Robustness ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMzogUm9idXN0bmVzcyDilIDilIDilIA=\"}\n[/m03-robustness/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m03-robustness/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m03-robustness/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAyLWNvZGluZy5odG1s\"}\n[/m03-robustness/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[/m03-robustness/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzA0LWFwcGVuZGl4Lmh0bWw=\"}\n[Core Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29yZSBUb3BpY3M=\"}\n[─── M04: Friendship Paradox ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNDogRnJpZW5kc2hpcCBQYXJhZG94IOKUgOKUgOKUgA==\"}\n[/m04-friendship-paradox/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m04-friendship-paradox/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m04-friendship-paradox/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDItY29kaW5nLmh0bWw=\"}\n[/m04-friendship-paradox/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[─── M05: Clustering ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNTogQ2x1c3RlcmluZyDilIDilIDilIA=\"}\n[/m05-clustering/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m05-clustering/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m05-clustering/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAyLWNvZGluZy5odG1s\"}\n[/m05-clustering/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[─── M06: Centrality ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNjogQ2VudHJhbGl0eSDilIDilIDilIA=\"}\n[/m06-centrality/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m06-centrality/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m06-centrality/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAyLWNvZGluZy5odG1s\"}\n[/m06-centrality/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQgVG9waWNz\"}\n[─── M07: Random Walks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNzogUmFuZG9tIFdhbGtzIOKUgOKUgOKUgA==\"}\n[/m07-random-walks/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m07-random-walks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m07-random-walks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDItY29kaW5nLmh0bWw=\"}\n[/m07-random-walks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[─── M08: Embedding ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wODogRW1iZWRkaW5nIOKUgOKUgOKUgA==\"}\n[/m08-embedding/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m08-embedding/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m08-embedding/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDItY29kaW5nLmh0bWw=\"}\n[/m08-embedding/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m08-embedding/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDQtYXBwZW5kaXguaHRtbA==\"}\n[─── M09: Graph Neural Networks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wOTogR3JhcGggTmV1cmFsIE5ldHdvcmtzIOKUgOKUgOKUgA==\"}\n[/m09-graph-neural-networks/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m09-graph-neural-networks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m09-graph-neural-networks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDItY29kaW5nLmh0bWw=\"}\n[/m09-graph-neural-networks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m09-graph-neural-networks/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDQtYXBwZW5kaXguaHRtbA==\"}\n\n:::{.hidden .quarto-markdown-envelope-contents render-id=\"Zm9vdGVyLWxlZnQ=\"}\nCopyright 2024, Sadamori Kojaku\n:::\n\n:::\n\n\n\n:::{#quarto-meta-markdown .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGF0aXRsZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkdGl0bGU=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZHRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGFzaXRlbmFtZQ==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkZGVzYw==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZGRkZXNj\"}\n:::\n\n\n\n\n&lt;!-- --&gt;\n\n::: {.quarto-embedded-source-code}\n```````````````````{.markdown shortcodes=\"false\"}\n# Graph cut\n\nAnother approach from computer science is to treat a community detection problem as an *optimization* problem.\nAn early example is the **graph cut** problem, which asks to find the minimum number of edges to cut the graph into two disconnected components.\n\nSpecifically, let us consider cutting the network into two communities. Let $V_1$ and $V_2$ be the set of nodes in the two communities.\nThen, the cut is the number of edges between the two communities, which is given by\n\n$$\n\\begin{align}\n\\text{Cut}(V_1, V_2) = \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\\end{align}\n$$\n\nNow, the community detection problem is translated into **an optimization problem**, with the goal of finding a cut $V_1, V_2$ that minimizes $\\text{Cut}(V_1, V_2)$.\n\nThe description of this problem is not complete 😈. Let's find out what is missing by playing with the optimization problem.\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nCan you identify what is missing in the description of the graph cut problem? Without this, the best cut is trivial. {{ \"&lt;a href='BASE_URL/vis/community-detection/index.html?scoreType=graphcut&numCommunities=2&randomness=1&dataFile=two-cliques.json'&gt;Graph Cut Problem 🎮&lt;/a&gt;\".replace('BASE_URL', base_url) }}\n\n::: {.callout collapse=\"true\"}\n## Click to reveal the answer!\n\nThe missing element is a constraint: each community must contain at least one node. Without this, the trivial solution of placing all nodes in a single community would always yield a cut of zero.\n```````````````````"
  },
  {
    "objectID": "m05-clustering/modularity.html",
    "href": "m05-clustering/modularity.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Modularity is by far the most widely used method for community detection. Modularity can be derived in many ways, but we will follow the one derived from assortativity.\n\n\nAssortativity is a measure of the tendency of nodes to connect with nodes of the same attribute. The attribute, in our case, is the community that the node belongs to, and we say that a network is assortative if nodes of the same community are more likely to connect with each other than nodes of different communities.\nLet’s think about assortativity by using color balls and strings! 🎨🧵\nImagine we’re playing a game as follows:\n\nPicture each connection in our network as two colored balls joined by a piece of string. 🔴🟢–🔵🟡\nThe color of each ball shows which community it belongs to.\nNow, let’s toss all these ball-and-string pairs into a big bag.\nWe’ll keep pulling out strings with replacement and checking if the balls on each end match colors.\n\nThe more color matches we find, the more assortative our network is. But, there’s a catch! What if we got lots of matches just by luck? For example, if all our balls were the same color, we’d always get a match. But that doesn’t tell us much about our communities. So, to be extra clever, we compare our results to a “random” version (null model):\n\nWe snip all the strings and mix up all the balls.\nThen we draw pairs of balls at random with replacement and see how often the colors match.\n\nBy comparing our original network to this mixed-up version, we can see if our communities are really sticking together more than we’d expect by chance. This comparison against the random version is the heart of modularity. Unlike graph cut methods that aim to maximize assortativity directly, modularity measures assortativity relative to a null model.\n\n\n\n\n\n\nFigure 1: Illustration of how modularity measures assortativity relative to a null model.\n\n\n\n\n\n\nNow, let’s put on our math hats and make this colorful game a bit more precise.\nLet’s introduce some helpful symbols to describe our network: - N: This is our total number of nodes (or balls in our game) - M: The number of edges (or strings) connecting our nodes - A_{ij}: Adjacency matrix. If A_{ij} = 1, it means node i and node j are connected. If A_{ij} = 0, they’re not connected. - k_i: Degree of node i, i.e., how many edges a node has. - c_i: Community of node i, i.e., which community a node belongs to. - \\delta(c_i, c_j): Kronecker delta function. It gives us 1 if nodes i and j are the same color, and 0 if they’re different.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nWhat is the probability of color matches for a given network? Derive the probability by using \\sum, M, A_{ij}, \\delta(c_i, c_j).\n\n\n\n\n\n\nHint\n\n\n\n\n\nLet’s think about our colorful bag of balls and strings! 🎨🧵 First, ask yourself: 1. How many strings do we have in total? (This is our M!) 2. Now, out of all these strings, how many are the same color on both ends?\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nWhat is the probability of color matches for the random version? Derive the probability by using $\\sum, M, \\delta(c_i, c_j), k_i,k_j$.\n\n::: {.callout collapse=\"true\"}\n## Hint\n1. Imagine a big bag full of colorful balls, but this time without any strings. 🔴🟢🔵🟡\n2. Now, think about picking one ball out of the bag. What are the chances of picking a specific color?\n3. Then, put that ball back and pick another one. What are the odds this second ball matches the color of the first one?\n\nThe full modularity formula is on the next page 😉.\n\n\n\n\n\n:::\n:::"
  },
  {
    "objectID": "m05-clustering/modularity.html#assortativity",
    "href": "m05-clustering/modularity.html#assortativity",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Assortativity is a measure of the tendency of nodes to connect with nodes of the same attribute. The attribute, in our case, is the community that the node belongs to, and we say that a network is assortative if nodes of the same community are more likely to connect with each other than nodes of different communities.\nLet’s think about assortativity by using color balls and strings! 🎨🧵\nImagine we’re playing a game as follows:\n\nPicture each connection in our network as two colored balls joined by a piece of string. 🔴🟢–🔵🟡\nThe color of each ball shows which community it belongs to.\nNow, let’s toss all these ball-and-string pairs into a big bag.\nWe’ll keep pulling out strings with replacement and checking if the balls on each end match colors.\n\nThe more color matches we find, the more assortative our network is. But, there’s a catch! What if we got lots of matches just by luck? For example, if all our balls were the same color, we’d always get a match. But that doesn’t tell us much about our communities. So, to be extra clever, we compare our results to a “random” version (null model):\n\nWe snip all the strings and mix up all the balls.\nThen we draw pairs of balls at random with replacement and see how often the colors match.\n\nBy comparing our original network to this mixed-up version, we can see if our communities are really sticking together more than we’d expect by chance. This comparison against the random version is the heart of modularity. Unlike graph cut methods that aim to maximize assortativity directly, modularity measures assortativity relative to a null model.\n\n\n\n\n\n\nFigure 1: Illustration of how modularity measures assortativity relative to a null model."
  },
  {
    "objectID": "m05-clustering/modularity.html#deriving-modularity",
    "href": "m05-clustering/modularity.html#deriving-modularity",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Now, let’s put on our math hats and make this colorful game a bit more precise.\nLet’s introduce some helpful symbols to describe our network: - N: This is our total number of nodes (or balls in our game) - M: The number of edges (or strings) connecting our nodes - A_{ij}: Adjacency matrix. If A_{ij} = 1, it means node i and node j are connected. If A_{ij} = 0, they’re not connected. - k_i: Degree of node i, i.e., how many edges a node has. - c_i: Community of node i, i.e., which community a node belongs to. - \\delta(c_i, c_j): Kronecker delta function. It gives us 1 if nodes i and j are the same color, and 0 if they’re different.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nWhat is the probability of color matches for a given network? Derive the probability by using \\sum, M, A_{ij}, \\delta(c_i, c_j).\n\n\n\n\n\n\nHint\n\n\n\n\n\nLet’s think about our colorful bag of balls and strings! 🎨🧵 First, ask yourself: 1. How many strings do we have in total? (This is our M!) 2. Now, out of all these strings, how many are the same color on both ends?\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nWhat is the probability of color matches for the random version? Derive the probability by using $\\sum, M, \\delta(c_i, c_j), k_i,k_j$.\n\n::: {.callout collapse=\"true\"}\n## Hint\n1. Imagine a big bag full of colorful balls, but this time without any strings. 🔴🟢🔵🟡\n2. Now, think about picking one ball out of the bag. What are the chances of picking a specific color?\n3. Then, put that ball back and pick another one. What are the odds this second ball matches the color of the first one?\n\nThe full modularity formula is on the next page 😉.\n\n\n\n\n\n:::\n:::"
  },
  {
    "objectID": "m05-clustering/ratio-normalized-cut.html",
    "href": "m05-clustering/ratio-normalized-cut.html",
    "title": "Balanced cut",
    "section": "",
    "text": "Graph cut often provide unbalanced communities, e.g., a community consisting of a single node, and another consisting of all other nodes. For example, if the network has a node with degree one (e.g., one edge), an optimal cut will be to place this node in its own community, resulting in a cut of one.\nRatio cut addresses this issue by introducing a normalization factor to balance the cut. Suppose we cut the network into two communities V_1 and V_2, then the ratio cut is defined as\n\n\\text{Ratio cut}(V_1, V_2) = \\frac{1}{|V_1| \\cdot |V_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|V_1| (or |V_2|) is the number of nodes in the community V_1 (or V_2).\n\nThe normalization factor 1/(|V_1| |V_2|) balances the community sizes. It’s smallest when communities are equal (|V_1| = |V_2|) and largest when one community has only one node (|V_1| = 1 or |V_2| = 1).\n\n:tags: [\"hide-input\"]\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Total number of nodes\ntotal_nodes = 100\n\n# Create an array of possible sizes for V1\nV1_sizes = np.arange(1, total_nodes)\n\n# Calculate corresponding sizes for V2\nV2_sizes = total_nodes - V1_sizes\n\n# Calculate the normalization factor\nnormalization_factor = 1 / (V1_sizes * V2_sizes)\n\n# Create the plot\nfig = plt.figure(figsize=(5, 3))\nplt.plot(V1_sizes, normalization_factor)\nplt.title('Normalization Factor vs. Community Size')\nplt.xlabel('Size of V1')\nplt.ylabel('1 / (|V1| * |V2|)')\nplt.yscale('log')  # Use log scale for y-axis due to large range of values\nplt.grid(True)"
  },
  {
    "objectID": "m05-clustering/ratio-normalized-cut.html#ratio-cut",
    "href": "m05-clustering/ratio-normalized-cut.html#ratio-cut",
    "title": "Balanced cut",
    "section": "",
    "text": "Graph cut often provide unbalanced communities, e.g., a community consisting of a single node, and another consisting of all other nodes. For example, if the network has a node with degree one (e.g., one edge), an optimal cut will be to place this node in its own community, resulting in a cut of one.\nRatio cut addresses this issue by introducing a normalization factor to balance the cut. Suppose we cut the network into two communities V_1 and V_2, then the ratio cut is defined as\n\n\\text{Ratio cut}(V_1, V_2) = \\frac{1}{|V_1| \\cdot |V_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|V_1| (or |V_2|) is the number of nodes in the community V_1 (or V_2).\n\nThe normalization factor 1/(|V_1| |V_2|) balances the community sizes. It’s smallest when communities are equal (|V_1| = |V_2|) and largest when one community has only one node (|V_1| = 1 or |V_2| = 1).\n\n:tags: [\"hide-input\"]\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Total number of nodes\ntotal_nodes = 100\n\n# Create an array of possible sizes for V1\nV1_sizes = np.arange(1, total_nodes)\n\n# Calculate corresponding sizes for V2\nV2_sizes = total_nodes - V1_sizes\n\n# Calculate the normalization factor\nnormalization_factor = 1 / (V1_sizes * V2_sizes)\n\n# Create the plot\nfig = plt.figure(figsize=(5, 3))\nplt.plot(V1_sizes, normalization_factor)\nplt.title('Normalization Factor vs. Community Size')\nplt.xlabel('Size of V1')\nplt.ylabel('1 / (|V1| * |V2|)')\nplt.yscale('log')  # Use log scale for y-axis due to large range of values\nplt.grid(True)"
  },
  {
    "objectID": "m05-clustering/ratio-normalized-cut.html#normalized-cut",
    "href": "m05-clustering/ratio-normalized-cut.html#normalized-cut",
    "title": "Balanced cut",
    "section": "2 Normalized cut",
    "text": "2 Normalized cut\nNormalized cut{footcite}shi2000normalized balances communities based on edge count, unlike Ratio cut which uses node count. It is defined as:\n\n\\text{Normalized cut}(V_1, V_2) = \\frac{1}{|E_1| \\cdot |E_2|} \\sum_{i \\in V_1} \\sum_{j \\in V_2} A_{ij}\n\n\n|E_1| and |E_2| are the number of edges in the communities V_1 and V_2, respectively.\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCompute the ratio cut and normalized cut for the following network. The red edges should be cut.\n\n\n\n:name: fig-graph-cut\n\n::: {.callout collapse=\"true\"}\n## Click here to reveal the answer\n\nThe graph consists of two cliques, each with 5 nodes ($|V_1| = |V_2| = 5$).\nEach clique has 10 internal edges and 2 edges connecting to the other clique.\nTherefore, $|E_1| = |E_2| = 10 + 2 = 12$.\nWe can now calculate:\n\n- **Ratio cut**: $2 / (5 \\times 5) = 0.08$.\n- **Normalized cut**: $2 / (12 \\times 12) = 0.01388889$.\n\n:::\n\n::: {#bae7d7ee .cell}\n``` {.python .cell-code}\n:tags: [\"hide-input\", \"remove-output\"]\n\nimport igraph as ig\nimport matplotlib.pyplot as plt\nfrom myst_nb import glue\n\n# Create two cliques of size 5\nG1 = ig.Graph.Full(5)\nG2 = ig.Graph.Full(5)\n\n# Combine the two cliques\nG = G1 + G2\n\n# Add an edge between the two cliques\nG.add_edge(0, 5)\nG.add_edge(1, 6)\n\n# Draw the graph\nlayout = G.layout_fruchterman_reingold()\n\n# Set up the plot\nfig, ax = plt.subplots(figsize=(5, 5))\n\n# Draw the connecting edge in red\nig.plot(\n    G,\n    target=ax,\n    layout=layout,\n    vertex_color='lightblue',\n    vertex_size=20,\n    edge_color='gray',\n    edge_width=1\n)\n\n# Draw the connecting edge in red behind the graph\nax.plot([layout[0][0], layout[5][0]], [layout[0][1], layout[5][1]], color='red', linewidth=2, zorder=0)\nax.plot([layout[1][0], layout[6][0]], [layout[1][1], layout[6][1]], color='red', linewidth=2, zorder=0)\n\nig.plot(\n    G,\n    target=ax,\n    layout=layout,\n    vertex_color='white',\n    vertex_size=20,\n    edge_color='black',\n    edge_width=1\n)\n\n# Add labels to the nodes\nfor i, coords in enumerate(layout):\n    ax.annotate(str(i), coords, ha='center', va='center')\n\nplt.title(\"Two Cliques Connected by One Edge\")\nplt.axis('off')\nplt.tight_layout()\n\nglue(\"fig-graph-cut\", fig, display=False)\n\n\nFigure 1\n\n\n\n\n\n:::"
  },
  {
    "objectID": "m05-clustering/ratio-normalized-cut.html#cut-into-more-than-two-communities",
    "href": "m05-clustering/ratio-normalized-cut.html#cut-into-more-than-two-communities",
    "title": "Balanced cut",
    "section": "3 Cut into more than two communities",
    "text": "3 Cut into more than two communities\nRatio cut and Normalized cut can be extended to cut into more than two communities. Specifically, we can extend them to cut into k communities, i.e., V_1, V_2, \\dots, V_k by defining\n\n\\begin{align}\n\\text{Ratio cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|V_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right) \\\\\n\\text{Normalized cut}(V_1, V_2, \\dots, V_k) &= \\sum_{k=1}^K \\frac{1}{|E_k|} \\left(\\sum_{i \\in V_k} \\sum_{j \\notin V_{k}} A_{ij} \\right)\n\\end{align}"
  },
  {
    "objectID": "m05-clustering/ratio-normalized-cut.html#algorithms-to-find-the-best-cut",
    "href": "m05-clustering/ratio-normalized-cut.html#algorithms-to-find-the-best-cut",
    "title": "Balanced cut",
    "section": "4 Algorithms to find the best cut",
    "text": "4 Algorithms to find the best cut\nFor both ratio and normalized cut, finding the best cut is a NP-hard problem. Yet, there are some heuristics to find a good cut. Interested students are encouraged to refer to Ulrike von Luxburg “A Tutorial on Spectral Clustering” for more details."
  },
  {
    "objectID": "m05-clustering/ratio-normalized-cut.html#issue-of-ratio-cut-and-normalized-cut",
    "href": "m05-clustering/ratio-normalized-cut.html#issue-of-ratio-cut-and-normalized-cut",
    "title": "Balanced cut",
    "section": "5 Issue of Ratio cut and Normalized cut",
    "text": "5 Issue of Ratio cut and Normalized cut\nWhile Ratio cut and Normalized cut methods are clever approaches, they do come with a couple of challenges we should be aware of.\nFirstly, these methods ask us to decide upfront how many communities we want to find. This can be tricky because, in real-world networks, we often don’t know this number in advance. It requires us to make a guess on how many different groups of friends we have before actually looking at our social circle.\nSecondly, and perhaps more critically, these methods favor communities of roughly the same size. It’s as if they’re assuming all our friend groups should have about the same number of people. But as we know from real life, that’s not always the case. Some of us might have a large group of college friends and a smaller group of childhood buddies. Research has shown that in many real-world networks, communities can indeed be quite different in size {footcite}palla2005uncovering,clauset2004finding.\nThese limitations don’t mean these methods should not be used, but they do remind us the importance of understanding the underlying assumptions and limitations of methods we use 😉. It’s always good to keep these points in mind when we’re working with network data. 🕸️💡"
  },
  {
    "objectID": "m06-centrality/01-concepts.html",
    "href": "m06-centrality/01-concepts.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn centrality, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is centrality in networks? - How to operationalize centrality? - How to find centrality in networks? - Limitations of centrality - Keywords: degree centrality, closeness centrality, betweenness centrality, eigenvector centrality, PageRank, Katz centrality, HITS, random walk\n\n\n\nHave you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone’s talking about right now? These questions are all about finding out what’s important in a network of people, ideas, or things. In network science, we call this centrality.\nCentrality or importance is a question of how important a node is in a network. But the notion of importance is somewhat vague. In what sense we say a node is important? Answering this question needs a specific context, and there are many contexts in which the importance is defined.\n\n\n\n\nThe simplest approach to measuring centrality is to count the connections of each node. This gives us degree centrality, which considers a node important if it has many direct connections.\nDegree centrality is just the count of the number of edges connected to a node (i.e., the number of neighbors, or degree in network science terminology). The most important node is thus the one with the highest degree.\n\nc_i = d_i = \\sum_{j} A_{ij}\n\nwhere A_{ij} is the adjacency matrix of the network, and d_i is the degree of node i.\n\n\n\n\nLet’s talk about an ancient Roman monument called the Milliarium Aureum, also known as the Golden Milestone. It was the starting point for measuring distances on all major roads in the Roman Empire. Emperor Augustus built it when Rome changed from a republic to an empire. The monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire. Perhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define centrality in networks.\nThis family of centrality measures is based on shortest path distances between nodes. They consider a node important if it has short distances to other nodes or if it lies on many shortest paths.\nCloseness centrality measures how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N - 1, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n\n\n\nHarmonic centrality adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can’t reach others, making their distance infinite. This causes all centrality values to become zero, which isn’t very helpful! To fix this, Beauchamp {footcite:p}beauchamp1965improved came up with a clever solution called harmonic centrality. It works even when the network is disconnected.\n\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n\nEccentricity centrality is based on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\nBetweenness centrality considers that a node is important if it lies on many shortest paths between other nodes.\n\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n\nwhere \\sigma_{jk} is the number of shortest paths between nodes j and k, and \\sigma_{jk}(i) is the number of shortest paths between nodes j and k that pass through node i.\n\n\n“A man is known by the company he keeps” is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire. It suggests that a person’s character is reflected by the people this person is friends with. This idea can be applied to define the centrality of a node in a network.\nThis family of centrality measures considers that a node is important if it is connected to other important nodes, or if it receives many “walks” or “votes” from other nodes in the network. These measures often use recursive definitions and are computed using linear algebra techniques.\nEigenvector centrality considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here’s the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet’s think about it for a moment. We want our centrality measure to be positive. It wouldn’t make much sense to have negative importance! So, we’re looking for an eigenvector where all the elements are positive. And a good news is that there’s a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associated with the largest eigenvalue always has all positive elements.\nHyperlink-Induced Topic Search (HITS) centrality\nextends eigenvector centrality to directed networks. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet’s put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbf{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree d_j of the authority, namely\n\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting x_i = d_i.\n\n\nKatz centrality addresses a limitation of eigenvector centrality, which tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. The solution is to add a little bit of score to all nodes.\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nDerive the solution of the Katz centrality.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe equation can be solved by\n\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n\nwhere \\mathbf{1} is the vector of ones. By rewriting the equation, we get\n\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n\nBy taking the inverse of \\mathbf{I} - \\lambda \\mathbf{A}, we get\n\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n\n\n\n\nPageRank is the celebrated idea behind Google Search and can be seen as a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In the Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers.\n\n\n\nSchool exercises",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#what-to-learn-in-this-module",
    "href": "m06-centrality/01-concepts.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn centrality, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is centrality in networks? - How to operationalize centrality? - How to find centrality in networks? - Limitations of centrality - Keywords: degree centrality, closeness centrality, betweenness centrality, eigenvector centrality, PageRank, Katz centrality, HITS, random walk",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#what-is-centrality",
    "href": "m06-centrality/01-concepts.html#what-is-centrality",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Have you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone’s talking about right now? These questions are all about finding out what’s important in a network of people, ideas, or things. In network science, we call this centrality.\nCentrality or importance is a question of how important a node is in a network. But the notion of importance is somewhat vague. In what sense we say a node is important? Answering this question needs a specific context, and there are many contexts in which the importance is defined.",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#degree-based-centrality",
    "href": "m06-centrality/01-concepts.html#degree-based-centrality",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The simplest approach to measuring centrality is to count the connections of each node. This gives us degree centrality, which considers a node important if it has many direct connections.\nDegree centrality is just the count of the number of edges connected to a node (i.e., the number of neighbors, or degree in network science terminology). The most important node is thus the one with the highest degree.\n\nc_i = d_i = \\sum_{j} A_{ij}\n\nwhere A_{ij} is the adjacency matrix of the network, and d_i is the degree of node i.",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#distance-based-centrality",
    "href": "m06-centrality/01-concepts.html#distance-based-centrality",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Let’s talk about an ancient Roman monument called the Milliarium Aureum, also known as the Golden Milestone. It was the starting point for measuring distances on all major roads in the Roman Empire. Emperor Augustus built it when Rome changed from a republic to an empire. The monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire. Perhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define centrality in networks.\nThis family of centrality measures is based on shortest path distances between nodes. They consider a node important if it has short distances to other nodes or if it lies on many shortest paths.\nCloseness centrality measures how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N - 1, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n\n\n\nHarmonic centrality adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can’t reach others, making their distance infinite. This causes all centrality values to become zero, which isn’t very helpful! To fix this, Beauchamp {footcite:p}beauchamp1965improved came up with a clever solution called harmonic centrality. It works even when the network is disconnected.\n\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n\nEccentricity centrality is based on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\nBetweenness centrality considers that a node is important if it lies on many shortest paths between other nodes.\n\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n\nwhere \\sigma_{jk} is the number of shortest paths between nodes j and k, and \\sigma_{jk}(i) is the number of shortest paths between nodes j and k that pass through node i.\n\n\n“A man is known by the company he keeps” is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire. It suggests that a person’s character is reflected by the people this person is friends with. This idea can be applied to define the centrality of a node in a network.\nThis family of centrality measures considers that a node is important if it is connected to other important nodes, or if it receives many “walks” or “votes” from other nodes in the network. These measures often use recursive definitions and are computed using linear algebra techniques.\nEigenvector centrality considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here’s the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet’s think about it for a moment. We want our centrality measure to be positive. It wouldn’t make much sense to have negative importance! So, we’re looking for an eigenvector where all the elements are positive. And a good news is that there’s a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associated with the largest eigenvalue always has all positive elements.\nHyperlink-Induced Topic Search (HITS) centrality\nextends eigenvector centrality to directed networks. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet’s put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbf{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree d_j of the authority, namely\n\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting x_i = d_i.\n\n\nKatz centrality addresses a limitation of eigenvector centrality, which tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. The solution is to add a little bit of score to all nodes.\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nDerive the solution of the Katz centrality.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe equation can be solved by\n\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n\nwhere \\mathbf{1} is the vector of ones. By rewriting the equation, we get\n\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n\nBy taking the inverse of \\mathbf{I} - \\lambda \\mathbf{A}, we get\n\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n\n\n\n\nPageRank is the celebrated idea behind Google Search and can be seen as a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In the Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers.\n\n\n\nSchool exercises",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#walk-based-centrality",
    "href": "m06-centrality/01-concepts.html#walk-based-centrality",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "“A man is known by the company he keeps” is a quote from Aesop who lived in the ancient Greece, a further back in time from the Roman Empire. It suggests that a person’s character is reflected by the people this person is friends with. This idea can be applied to define the centrality of a node in a network.\nThis family of centrality measures considers that a node is important if it is connected to other important nodes, or if it receives many “walks” or “votes” from other nodes in the network. These measures often use recursive definitions and are computed using linear algebra techniques.\nEigenvector centrality considers that a node is important if it is connected to other important nodes. Yes, it sounds like circular! But it is actually computable! Let us define it more precisely by the following equation.\n\nc_i = \\lambda \\sum_{j} A_{ij} c_j\n\nwhere \\lambda is a constant. It suggests that the centrality of a node (c_i) is the sum of the centralities of its neighbors (A_{ij} c_j; note that A_{ij}=1 if j is a neighbor, and otherwise A_{ij}=0), normalized by \\lambda. Using vector notation, we can rewrite the equation as\n\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix} = \\lambda\n\\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1n} \\\\\nA_{21} & A_{22} & \\cdots & A_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\\nc_2 \\\\\n\\vdots \\\\\nc_n\n\\end{bmatrix}\n\nor equivalently,\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nOkay, but how do we solve this? Well, this is actually the eigenvector equation! And the solution to this equation is the eigenvector of the adjacency matrix, \\mathbf{A}. But here’s the tricky part - there are multiple eigenvectors. So which one should we choose?\nLet’s think about it for a moment. We want our centrality measure to be positive. It wouldn’t make much sense to have negative importance! So, we’re looking for an eigenvector where all the elements are positive. And a good news is that there’s a special eigenvector that fits the bill perfectly. Perron-Frobenius theorem guarantees that the eigenvector associated with the largest eigenvalue always has all positive elements.\nHyperlink-Induced Topic Search (HITS) centrality\nextends eigenvector centrality to directed networks. It introduces two notions of importance: hub and authority. A node is an important hub if it points to many important authorities. A node is an important authority if it is pointed by many important hubs.\nLet’s put on a math hat to concretely define the hub and authority centralities. We introduce two vectors, x_i and y_i, to denote the hub and authority centralities of node i, respectively. Following the idea of eigenvector centrality, we can define the hub and authority centralities as follows:\n\nx_i = \\lambda_x \\sum_j A_{ji} y_j, \\quad y_i = \\lambda_y \\sum_j A_{ij} x_j\n\nOr equivalently,\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{y}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x}\n\nSubstituting \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{x} into the first equation and similar for \\mathbf{x}, we get\n\n\\mathbf{x} = \\lambda_x \\mathbf{A}^T \\mathbf{A} \\mathbf{x}, \\quad \\mathbf{y} = \\lambda_y \\mathbf{A} \\mathbf{A}^T \\mathbf{y}\n\nAgain, we obtain the eigenvector equations whose solutions are the eigenvectors of \\mathbf{A}^T \\mathbf{A} and \\mathbf{A} \\mathbf{A}^T for \\mathbf{x} and \\mathbf{y}, respectively.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nIf the graph is undirected, the hub and authority centralities are equivalent. And the solution is given by the eigenvector of \\mathbf{A} \\mathbf{A}^T. Now, let us consider the eigenvector equation for the adjacency matrix \\mathbf{A}.\n\n\\mathbf{c} = \\lambda \\mathbf{A} \\mathbf{c}\n\nBy multiplying \\mathbf{A} on the both sides, we get\n\n\\begin{aligned}\n\\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A} \\mathbf{A} \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda \\mathbf{A}^\\top \\mathbf{c} \\\\\n\\iff \\mathbf{A}^\\top \\mathbf{A} \\mathbf{c} &= \\lambda^2 \\mathbf{c}\n\\end{aligned}\n\nwhere we used the fact that \\mathbf{A} is symmetric. It suggests that the eigenvector of \\mathbf{A}^\\top \\mathbf{A} is the same as that of \\mathbf{A}, and that the eigenvalue of \\mathbf{A}^\\top \\mathbf{A} is the square of that of \\mathbf{A}. Thus, the eigenvector centrality is equivalent to the HITS centrality if the network is undirected.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree d_j of the authority, namely\n\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n\nThen we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting x_i = d_i.\n\n\nKatz centrality addresses a limitation of eigenvector centrality, which tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. The solution is to add a little bit of score to all nodes.\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nDerive the solution of the Katz centrality.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe equation can be solved by\n\n\\mathbf{c} = \\beta \\mathbf{1} + \\lambda \\mathbf{A} \\mathbf{c}\n\nwhere \\mathbf{1} is the vector of ones. By rewriting the equation, we get\n\n\\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right) \\mathbf{c} = \\beta \\mathbf{1}\n\nBy taking the inverse of \\mathbf{I} - \\lambda \\mathbf{A}, we get\n\n\\mathbf{c} = \\beta \\left( \\mathbf{I} - \\lambda \\mathbf{A} \\right)^{-1} \\mathbf{1}\n\n\n\n\nPageRank is the celebrated idea behind Google Search and can be seen as a cousin of Katz centrality.\n\nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nwhere d^{\\text{out}}_j is the out-degree of node j (the number of edges pointing out from node j). The term c_j/d^{\\text{out}}_j represents that the score of node j is divided by the number of nodes to which node j points. In the Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers.\n\n\n\nSchool exercises",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/01-concepts.html#pen-and-paper-exercises",
    "href": "m06-centrality/01-concepts.html#pen-and-paper-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "School exercises",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/degree-distance-based-centrality.html",
    "href": "m06-centrality/degree-distance-based-centrality.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Have you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone’s talking about right now? These questions are all about finding out what’s important in a network of people, ideas, or things. In network science, we call this centrality.\nCentrality or importance is a question of how important a node is in a network. But the notion of importance is somewhat vague. In what sense we say a node is important? Answering this question needs a specific context, and there are many contexts in which the importance is defined.\n\n\n\nHere we will focus on several popular centrality measures. Let us denote by c_i the centrality of node i throughout this section. Here is a preview of the centrality measures we will cover in this section\n\n\n\n\n\n\n\n\nCentrality\nCategory\nDescription\n\n\n\n\nDegree Centrality\nDegree\nCounts the number of edges connected to a node.\n\n\nCloseness Centrality\nShortest Path\nMeasures how close a node is to all other nodes in the network.\n\n\nEccentricity Centrality\nShortest Path\nBased on the maximum shortest path distance from a node to any other node.\n\n\nHarmonic Centrality\nShortest Path\nAdjusts closeness centrality to work even in disconnected networks.\n\n\nBetweenness Centrality\nShortest Path\nMeasures the extent to which a node lies on paths between other nodes.\n\n\nEigenvector Centrality\nWalk\nMeasures a node’s influence based on the influence of its neighbors.\n\n\nHITS (Hub and Authority) Centrality\nWalk\nMeasures the importance of nodes as hubs and authorities in a network.\n\n\nKatz Centrality\nWalk\nConsiders the total number of walks between nodes, with a damping factor.\n\n\nPageRank\nWalk\nMeasures the importance of nodes based on the structure of incoming links.\n\n\n\n\n\nPerhaps the simplest form of cnetrality is degree centrality. It is just the count of the number of edges connected to a node (i.e., the number of neighbors, or degree in network science terminology). The most important node is thus the one with the highest degree.\n\nc_i = d_i = \\sum_{j} A_{ij}\n\nwhere A_{ij} is the adjacency matrix of the network, and d_i is the degree of node i.\n\n\n\n\nLet’s talk about an ancient Roman monument called the Milliarium Aureum, also known as the Golden Milestone. It was the starting point for measuring distances on all major roads in the Roman Empire. Emperor Augustus built it when Rome changed from a republic to an empire. The monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire. Perhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define centrality in networks.\n\n\n\nClosenes centrality is a measure of how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N - 1, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n\n\n### Harmonic centrality\n\n**Harmonic Centrality** is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can't reach others, making their distance infinite. This causes all centrality values to become zero, which isn't very helpful!\n\nTo fix this, Beauchamp {footcite:p}`beauchamp1965improved` came up with a clever solution called *harmonic centrality*. It works even when the network is disconnected.\n\n$$\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n$$\n\n### Eccentricity centrality\n\n**Eccentricity centrality** is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n\nThese centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.\n\nA central node should be close to all other nodes.\n\nCloseness centrality captures the notion of \"centrality\" in the network. Namely, a node is *central* if it is close to all other nodes.\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\nwhere $N$ is the number of nodes in the network. The numerator, $N$, is the normalization factor to make the centrality to have the maximum value of 1.\n\n\n### Eccentricity centrality\n\nEccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the *maximum* distance as opposed to the average distance like in the closeness centrality.\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n\n### Betweenness centrality\n\nAnother notion of centrality is *betweenness centrality*. It considers that a node is important if it lies on many shortest paths between other nodes.\n\n$$\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n$$\n\nwhere $\\sigma_{jk}$ is the number of shortest paths between nodes $j$ and $k$, and $\\sigma_{jk}(i)$ is the number of shortest paths between nodes $j$ and $k$ that pass through node $i$.\n\n\n\n\n\n:::{#quarto-navigation-envelope .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyLXRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXItdGl0bGU=\"}\n[Course Information]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMQ==\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvd2VsY29tZS5odG1sV2VsY29tZQ==\"}\n[About us]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvYWJvdXQuaHRtbEFib3V0LXVz\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvZGlzY29yZC5odG1sRGlzY29yZA==\"}\n[Using Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvbWluaWRvcmEtdXNhZ2UuaHRtbFVzaW5nLU1pbmlkb3Jh\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvc2V0dXAuaHRtbFNldHVw\"}\n[Introduction]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMg==\"}\n[Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9pbnRyby93aHktbmV0d29ya3MuaHRtbE5ldHdvcmtz\"}\n[M01: Euler Path]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMw==\"}\n[From Visual to Computational Thinking]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMC1wcmVwYXJhdGlvbi5odG1sRnJvbS1WaXN1YWwtdG8tQ29tcHV0YXRpb25hbC1UaGlua2luZw==\"}\n[Euler Path Concepts - The Birth of Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMS1jb25jZXB0cy5odG1sRXVsZXItUGF0aC1Db25jZXB0cy0tLVRoZS1CaXJ0aC1vZi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Coding Networks in Python]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMi1jb2RpbmcuaHRtbENvZGluZy1OZXR3b3Jrcy1pbi1QeXRob24=\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcw==\"}\n[Advanced: Sparse Matrices for Large-Scale Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wNC1hZHZhbmNlZC5odG1sQWR2YW5jZWQ6LVNwYXJzZS1NYXRyaWNlcy1mb3ItTGFyZ2UtU2NhbGUtTmV0d29ya3M=\"}\n[M02: Small World]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNA==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDAtcHJlcGFyYXRpb24uaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Small-World Networks: Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDEtY29uY2VwdHMuaHRtbFNtYWxsLVdvcmxkLU5ldHdvcmtzOi1Db3JlLUNvbmNlcHRz\"}\n[Efficient Network Representation and Computing Paths]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDItY29kaW5nLmh0bWxFZmZpY2llbnQtTmV0d29yay1SZXByZXNlbnRhdGlvbi1hbmQtQ29tcHV0aW5nLVBhdGhz\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDMtZXhlcmNpc2VzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Appendix - Brief Introduction to igraph]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDQtYXBwZW5kaXguaHRtbEFwcGVuZGl4LS0tQnJpZWYtSW50cm9kdWN0aW9uLXRvLWlncmFwaA==\"}\n[M03: Robustness]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNQ==\"}\n[Preparation]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMC1wcmVwYXJhdGlvbi5odG1sUHJlcGFyYXRpb24=\"}\n[Network Robustness: Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMS1jb25jZXB0cy5odG1sTmV0d29yay1Sb2J1c3RuZXNzOi1Db3JlLUNvbmNlcHRz\"}\n[Coding - Network Robustness Analysis]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMi1jb2RpbmcuaHRtbENvZGluZy0tLU5ldHdvcmstUm9idXN0bmVzcy1BbmFseXNpcw==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wNC1hcHBlbmRpeC5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M04: Friendship Paradox]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNg==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M05: Clustering]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNw==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMC1wcmVwYXJhdGlvbi5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMS1jb25jZXB0cy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMi1jb2RpbmcuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[M06: Centrality]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOA==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMC1wcmVwYXJhdGlvbi5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMS1jb25jZXB0cy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMi1jb2RpbmcuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[M07: Random Walks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M08: Embedding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTA=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[M09: Graph Neural Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTE=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Home]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SG9tZQ==\"}\n[/index.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2luZGV4Lmh0bWw=\"}\n[Course]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q291cnNl\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2VsY29tZQ==\"}\n[/course/welcome.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS93ZWxjb21lLmh0bWw=\"}\n[About]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWJvdXQ=\"}\n[/course/about.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9hYm91dC5odG1s\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RGlzY29yZA==\"}\n[/course/discord.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9kaXNjb3JkLmh0bWw=\"}\n[Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6TWluaWRvcmE=\"}\n[/course/minidora-usage.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9taW5pZG9yYS11c2FnZS5odG1s\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6U2V0dXA=\"}\n[/course/setup.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9zZXR1cC5odG1s\"}\n[Intro]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SW50cm8=\"}\n[Why Networks?]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2h5IE5ldHdvcmtzPw==\"}\n[/intro/why-networks.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2ludHJvL3doeS1uZXR3b3Jrcy5odG1s\"}\n[Foundations]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Rm91bmRhdGlvbnM=\"}\n[─── M01: Euler Path ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMTogRXVsZXIgUGF0aCDilIDilIDilIA=\"}\n[Preparation]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6UHJlcGFyYXRpb24=\"}\n[/m01-euler_tour/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29uY2VwdHM=\"}\n[/m01-euler_tour/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[Coding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29kaW5n\"}\n[/m01-euler_tour/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAyLWNvZGluZy5odG1s\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RXhlcmNpc2Vz\"}\n[/m01-euler_tour/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQ=\"}\n[/m01-euler_tour/04-advanced.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzA0LWFkdmFuY2VkLmh0bWw=\"}\n[─── M02: Small World ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMjogU21hbGwgV29ybGQg4pSA4pSA4pSA\"}\n[/m02-small-world/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMC1wcmVwYXJhdGlvbi5odG1s\"}\n[/m02-small-world/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMS1jb25jZXB0cy5odG1s\"}\n[/m02-small-world/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMi1jb2RpbmcuaHRtbA==\"}\n[/m02-small-world/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMy1leGVyY2lzZXMuaHRtbA==\"}\n[Appendix]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QXBwZW5kaXg=\"}\n[/m02-small-world/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wNC1hcHBlbmRpeC5odG1s\"}\n[─── M03: Robustness ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMzogUm9idXN0bmVzcyDilIDilIDilIA=\"}\n[/m03-robustness/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m03-robustness/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m03-robustness/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAyLWNvZGluZy5odG1s\"}\n[/m03-robustness/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[/m03-robustness/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzA0LWFwcGVuZGl4Lmh0bWw=\"}\n[Core Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29yZSBUb3BpY3M=\"}\n[─── M04: Friendship Paradox ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNDogRnJpZW5kc2hpcCBQYXJhZG94IOKUgOKUgOKUgA==\"}\n[/m04-friendship-paradox/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m04-friendship-paradox/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m04-friendship-paradox/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDItY29kaW5nLmh0bWw=\"}\n[/m04-friendship-paradox/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[─── M05: Clustering ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNTogQ2x1c3RlcmluZyDilIDilIDilIA=\"}\n[/m05-clustering/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m05-clustering/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m05-clustering/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAyLWNvZGluZy5odG1s\"}\n[/m05-clustering/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[─── M06: Centrality ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNjogQ2VudHJhbGl0eSDilIDilIDilIA=\"}\n[/m06-centrality/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m06-centrality/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m06-centrality/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAyLWNvZGluZy5odG1s\"}\n[/m06-centrality/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQgVG9waWNz\"}\n[─── M07: Random Walks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNzogUmFuZG9tIFdhbGtzIOKUgOKUgOKUgA==\"}\n[/m07-random-walks/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m07-random-walks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m07-random-walks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDItY29kaW5nLmh0bWw=\"}\n[/m07-random-walks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[─── M08: Embedding ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wODogRW1iZWRkaW5nIOKUgOKUgOKUgA==\"}\n[/m08-embedding/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m08-embedding/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m08-embedding/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDItY29kaW5nLmh0bWw=\"}\n[/m08-embedding/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m08-embedding/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDQtYXBwZW5kaXguaHRtbA==\"}\n[─── M09: Graph Neural Networks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wOTogR3JhcGggTmV1cmFsIE5ldHdvcmtzIOKUgOKUgOKUgA==\"}\n[/m09-graph-neural-networks/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m09-graph-neural-networks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m09-graph-neural-networks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDItY29kaW5nLmh0bWw=\"}\n[/m09-graph-neural-networks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m09-graph-neural-networks/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDQtYXBwZW5kaXguaHRtbA==\"}\n\n:::{.hidden .quarto-markdown-envelope-contents render-id=\"Zm9vdGVyLWxlZnQ=\"}\nCopyright 2024, Sadamori Kojaku\n:::\n\n:::\n\n\n\n:::{#quarto-meta-markdown .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGF0aXRsZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkdGl0bGU=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZHRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGFzaXRlbmFtZQ==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkZGVzYw==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZGRkZXNj\"}\n:::\n\n\n\n\n&lt;!-- --&gt;\n\n::: {.quarto-embedded-source-code}\n```````````````````{.markdown shortcodes=\"false\"}\n# What is centrality?\n\nHave you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone's talking about right now?\nThese questions are all about finding out what's important in a network of people, ideas, or things. In network science, we call this *centrality.*\n\nCentrality or *importance* is a question of how important a node is in a network.\nBut the notion of *importance* is somewhat vague.\nIn what sense we say a node is important?\nAnswering this question needs a specific *context*, and there are many contexts in which the *importance* is defined.\n\n![](../figs/centrality.jpg)\n\n## Different centrality measures\n\nHere we will focus on several popular centrality measures. Let us denote by $c_i$ the centrality of node $i$ throughout this section.\nHere is a preview of the centrality measures we will cover in this section\n\n| Centrality          | Category            | Description                                                                 |\n|-------------------------|---------------------|-----------------------------------------------------------------------------|\n| Degree Centrality       | Degree              | Counts the number of edges connected to a node.                             |\n| Closeness Centrality    | Shortest Path  | Measures how close a node is to all other nodes in the network.             |\n| Eccentricity Centrality | Shortest Path  | Based on the maximum shortest path distance from a node to any other node.  |\n| Harmonic Centrality     | Shortest Path  | Adjusts closeness centrality to work even in disconnected networks.         |\n| Betweenness Centrality  | Shortest Path  | Measures the extent to which a node lies on paths between other nodes.      |\n| Eigenvector Centrality  | Walk           | Measures a node's influence based on the influence of its neighbors.        |\n| HITS (Hub and Authority) Centrality | Walk  | Measures the importance of nodes as hubs and authorities in a network.      |\n| Katz Centrality         | Walk           | Considers the total number of walks between nodes, with a damping factor.   |\n| PageRank                | Walk           | Measures the importance of nodes based on the structure of incoming links.  |\n\n\n### Degree centrality\n\nPerhaps the simplest form of cnetrality is *degree centrality*. It is just the count of the number of edges connected to a node (i.e., the number of neighbors, or *degree* in network science terminology). The most important node is thus the one with the highest degree.\n\n$$\nc_i = d_i = \\sum_{j} A_{ij}\n$$\n\nwhere $A_{ij}$ is the adjacency matrix of the network, and $d_i$ is the degree of node $i$.\n\n### Centrality based on shortest path\n\n\n&lt;img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Milliarium_Aureum_op_het_Forum_Romanum_te_Rome_Columna_Miliaria_in_Foro_Romano_%28titel_op_object%29_Antieke_monumenten_%28serietitel%29_Antiquae_Urbis_Splendor_%28serietitel%29%2C_RP-P-2016-345-28-1.jpg/1546px-thumbnail.jpg?20191217151048\" alt=\"Roma Foro Romano Miliarium Aureum\" width=\"80%\" style=\"display: block; margin-left: auto; margin-right: auto;\"&gt;\n\n\nLet's talk about an ancient Roman monument called the *Milliarium Aureum*, also known as the *Golden Milestone*.\nIt was the starting point for measuring distances on all major roads in the Roman Empire.\nEmperor Augustus built it when Rome changed from a republic to an empire.\nThe monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire.\nPerhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define *centrality* in networks.\n\n### Closeness centrality\n**Closenes centrality** is a measure of how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\nwhere $N$ is the number of nodes in the network. The numerator, $N - 1$, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n&lt;img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Star_network_7.svg/1920px-Star_network_7.svg.png\" alt=\"Star graph S7\" width=\"50%\" style=\"display: block; margin-left: auto; margin-right: auto;\"&gt;\n\n\n\nHarmonic Centrality is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can’t reach others, making their distance infinite. This causes all centrality values to become zero, which isn’t very helpful!\nTo fix this, Beauchamp {footcite:p}beauchamp1965improved came up with a clever solution called harmonic centrality. It works even when the network is disconnected.\n\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n\n\n\n\nEccentricity centrality is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\nThese centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.\nA central node should be close to all other nodes.\nCloseness centrality captures the notion of “centrality” in the network. Namely, a node is central if it is close to all other nodes.\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N, is the normalization factor to make the centrality to have the maximum value of 1.\n\n\n\nEccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the maximum distance as opposed to the average distance like in the closeness centrality.\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\n\n\n\nAnother notion of centrality is betweenness centrality. It considers that a node is important if it lies on many shortest paths between other nodes.\n\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n\nwhere \\sigma_{jk} is the number of shortest paths between nodes j and k, and \\sigma_{jk}(i) is the number of shortest paths between nodes j and k that pass through node i.\n```````````````````"
  },
  {
    "objectID": "m06-centrality/degree-distance-based-centrality.html#different-centrality-measures",
    "href": "m06-centrality/degree-distance-based-centrality.html#different-centrality-measures",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Here we will focus on several popular centrality measures. Let us denote by c_i the centrality of node i throughout this section. Here is a preview of the centrality measures we will cover in this section\n\n\n\n\n\n\n\n\nCentrality\nCategory\nDescription\n\n\n\n\nDegree Centrality\nDegree\nCounts the number of edges connected to a node.\n\n\nCloseness Centrality\nShortest Path\nMeasures how close a node is to all other nodes in the network.\n\n\nEccentricity Centrality\nShortest Path\nBased on the maximum shortest path distance from a node to any other node.\n\n\nHarmonic Centrality\nShortest Path\nAdjusts closeness centrality to work even in disconnected networks.\n\n\nBetweenness Centrality\nShortest Path\nMeasures the extent to which a node lies on paths between other nodes.\n\n\nEigenvector Centrality\nWalk\nMeasures a node’s influence based on the influence of its neighbors.\n\n\nHITS (Hub and Authority) Centrality\nWalk\nMeasures the importance of nodes as hubs and authorities in a network.\n\n\nKatz Centrality\nWalk\nConsiders the total number of walks between nodes, with a damping factor.\n\n\nPageRank\nWalk\nMeasures the importance of nodes based on the structure of incoming links.\n\n\n\n\n\nPerhaps the simplest form of cnetrality is degree centrality. It is just the count of the number of edges connected to a node (i.e., the number of neighbors, or degree in network science terminology). The most important node is thus the one with the highest degree.\n\nc_i = d_i = \\sum_{j} A_{ij}\n\nwhere A_{ij} is the adjacency matrix of the network, and d_i is the degree of node i.\n\n\n\n\nLet’s talk about an ancient Roman monument called the Milliarium Aureum, also known as the Golden Milestone. It was the starting point for measuring distances on all major roads in the Roman Empire. Emperor Augustus built it when Rome changed from a republic to an empire. The monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire. Perhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define centrality in networks.\n\n\n\nClosenes centrality is a measure of how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N - 1, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n\n\n\n\nExercise\n\n\n\n:class: tip\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n\n\n\n\nClick to see the answer\n\n\n\n\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n\n\n### Harmonic centrality\n\n**Harmonic Centrality** is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can't reach others, making their distance infinite. This causes all centrality values to become zero, which isn't very helpful!\n\nTo fix this, Beauchamp {footcite:p}`beauchamp1965improved` came up with a clever solution called *harmonic centrality*. It works even when the network is disconnected.\n\n$$\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n$$\n\n### Eccentricity centrality\n\n**Eccentricity centrality** is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n\nThese centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.\n\nA central node should be close to all other nodes.\n\nCloseness centrality captures the notion of \"centrality\" in the network. Namely, a node is *central* if it is close to all other nodes.\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\nwhere $N$ is the number of nodes in the network. The numerator, $N$, is the normalization factor to make the centrality to have the maximum value of 1.\n\n\n### Eccentricity centrality\n\nEccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the *maximum* distance as opposed to the average distance like in the closeness centrality.\n\n$$\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n$$\n\n\n### Betweenness centrality\n\nAnother notion of centrality is *betweenness centrality*. It considers that a node is important if it lies on many shortest paths between other nodes.\n\n$$\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n$$\n\nwhere $\\sigma_{jk}$ is the number of shortest paths between nodes $j$ and $k$, and $\\sigma_{jk}(i)$ is the number of shortest paths between nodes $j$ and $k$ that pass through node $i$.\n\n\n\n\n\n:::{#quarto-navigation-envelope .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyLXRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXItdGl0bGU=\"}\n[Course Information]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMQ==\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvd2VsY29tZS5odG1sV2VsY29tZQ==\"}\n[About us]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvYWJvdXQuaHRtbEFib3V0LXVz\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvZGlzY29yZC5odG1sRGlzY29yZA==\"}\n[Using Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2UvbWluaWRvcmEtdXNhZ2UuaHRtbFVzaW5nLU1pbmlkb3Jh\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9jb3Vyc2Uvc2V0dXAuaHRtbFNldHVw\"}\n[Introduction]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMg==\"}\n[Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9pbnRyby93aHktbmV0d29ya3MuaHRtbE5ldHdvcmtz\"}\n[M01: Euler Path]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMw==\"}\n[From Visual to Computational Thinking]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMC1wcmVwYXJhdGlvbi5odG1sRnJvbS1WaXN1YWwtdG8tQ29tcHV0YXRpb25hbC1UaGlua2luZw==\"}\n[Euler Path Concepts - The Birth of Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMS1jb25jZXB0cy5odG1sRXVsZXItUGF0aC1Db25jZXB0cy0tLVRoZS1CaXJ0aC1vZi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Coding Networks in Python]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMi1jb2RpbmcuaHRtbENvZGluZy1OZXR3b3Jrcy1pbi1QeXRob24=\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wMy1leGVyY2lzZXMuaHRtbEV4ZXJjaXNlcw==\"}\n[Advanced: Sparse Matrices for Large-Scale Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDEtZXVsZXJfdG91ci8wNC1hZHZhbmNlZC5odG1sQWR2YW5jZWQ6LVNwYXJzZS1NYXRyaWNlcy1mb3ItTGFyZ2UtU2NhbGUtTmV0d29ya3M=\"}\n[M02: Small World]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNA==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDAtcHJlcGFyYXRpb24uaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Small-World Networks: Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDEtY29uY2VwdHMuaHRtbFNtYWxsLVdvcmxkLU5ldHdvcmtzOi1Db3JlLUNvbmNlcHRz\"}\n[Efficient Network Representation and Computing Paths]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDItY29kaW5nLmh0bWxFZmZpY2llbnQtTmV0d29yay1SZXByZXNlbnRhdGlvbi1hbmQtQ29tcHV0aW5nLVBhdGhz\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDMtZXhlcmNpc2VzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Appendix - Brief Introduction to igraph]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDItc21hbGwtd29ybGQvMDQtYXBwZW5kaXguaHRtbEFwcGVuZGl4LS0tQnJpZWYtSW50cm9kdWN0aW9uLXRvLWlncmFwaA==\"}\n[M03: Robustness]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNQ==\"}\n[Preparation]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMC1wcmVwYXJhdGlvbi5odG1sUHJlcGFyYXRpb24=\"}\n[Network Robustness: Core Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMS1jb25jZXB0cy5odG1sTmV0d29yay1Sb2J1c3RuZXNzOi1Db3JlLUNvbmNlcHRz\"}\n[Coding - Network Robustness Analysis]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMi1jb2RpbmcuaHRtbENvZGluZy0tLU5ldHdvcmstUm9idXN0bmVzcy1BbmFseXNpcw==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDMtcm9idXN0bmVzcy8wNC1hcHBlbmRpeC5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M04: Friendship Paradox]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNg==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDQtZnJpZW5kc2hpcC1wYXJhZG94LzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M05: Clustering]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tNw==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMC1wcmVwYXJhdGlvbi5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMS1jb25jZXB0cy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMi1jb2RpbmcuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDUtY2x1c3RlcmluZy8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[M06: Centrality]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOA==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMC1wcmVwYXJhdGlvbi5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMS1jb25jZXB0cy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMi1jb2RpbmcuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDYtY2VudHJhbGl0eS8wMy1leGVyY2lzZXMuaHRtbEFkdmFuY2VkLVRvcGljcy1pbi1OZXR3b3JrLVNjaWVuY2U=\"}\n[M07: Random Walks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tOQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDctcmFuZG9tLXdhbGtzLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[M08: Embedding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTA=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDgtZW1iZWRkaW5nLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[M09: Graph Neural Networks]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOnF1YXJ0by1zaWRlYmFyLXNlY3Rpb24tMTE=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAwLXByZXBhcmF0aW9uLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAxLWNvbmNlcHRzLmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAyLWNvZGluZy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzAzLWV4ZXJjaXNlcy5odG1sQWR2YW5jZWQtVG9waWNzLWluLU5ldHdvcmstU2NpZW5jZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1zaWRlYmFyOi9tMDktZ3JhcGgtbmV1cmFsLW5ldHdvcmtzLzA0LWFwcGVuZGl4Lmh0bWxBZHZhbmNlZC1Ub3BpY3MtaW4tTmV0d29yay1TY2llbmNl\"}\n[Home]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SG9tZQ==\"}\n[/index.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2luZGV4Lmh0bWw=\"}\n[Course]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q291cnNl\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2VsY29tZQ==\"}\n[/course/welcome.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS93ZWxjb21lLmh0bWw=\"}\n[About]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWJvdXQ=\"}\n[/course/about.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9hYm91dC5odG1s\"}\n[Discord]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RGlzY29yZA==\"}\n[/course/discord.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9kaXNjb3JkLmh0bWw=\"}\n[Minidora]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6TWluaWRvcmE=\"}\n[/course/minidora-usage.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9taW5pZG9yYS11c2FnZS5odG1s\"}\n[Setup]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6U2V0dXA=\"}\n[/course/setup.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2NvdXJzZS9zZXR1cC5odG1s\"}\n[Intro]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6SW50cm8=\"}\n[Why Networks?]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6V2h5IE5ldHdvcmtzPw==\"}\n[/intro/why-networks.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2ludHJvL3doeS1uZXR3b3Jrcy5odG1s\"}\n[Foundations]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Rm91bmRhdGlvbnM=\"}\n[─── M01: Euler Path ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMTogRXVsZXIgUGF0aCDilIDilIDilIA=\"}\n[Preparation]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6UHJlcGFyYXRpb24=\"}\n[/m01-euler_tour/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[Concepts]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29uY2VwdHM=\"}\n[/m01-euler_tour/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[Coding]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29kaW5n\"}\n[/m01-euler_tour/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAyLWNvZGluZy5odG1s\"}\n[Exercises]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6RXhlcmNpc2Vz\"}\n[/m01-euler_tour/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQ=\"}\n[/m01-euler_tour/04-advanced.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMS1ldWxlcl90b3VyLzA0LWFkdmFuY2VkLmh0bWw=\"}\n[─── M02: Small World ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMjogU21hbGwgV29ybGQg4pSA4pSA4pSA\"}\n[/m02-small-world/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMC1wcmVwYXJhdGlvbi5odG1s\"}\n[/m02-small-world/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMS1jb25jZXB0cy5odG1s\"}\n[/m02-small-world/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMi1jb2RpbmcuaHRtbA==\"}\n[/m02-small-world/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wMy1leGVyY2lzZXMuaHRtbA==\"}\n[Appendix]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QXBwZW5kaXg=\"}\n[/m02-small-world/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMi1zbWFsbC13b3JsZC8wNC1hcHBlbmRpeC5odG1s\"}\n[─── M03: Robustness ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wMzogUm9idXN0bmVzcyDilIDilIDilIA=\"}\n[/m03-robustness/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m03-robustness/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m03-robustness/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAyLWNvZGluZy5odG1s\"}\n[/m03-robustness/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[/m03-robustness/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wMy1yb2J1c3RuZXNzLzA0LWFwcGVuZGl4Lmh0bWw=\"}\n[Core Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6Q29yZSBUb3BpY3M=\"}\n[─── M04: Friendship Paradox ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNDogRnJpZW5kc2hpcCBQYXJhZG94IOKUgOKUgOKUgA==\"}\n[/m04-friendship-paradox/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m04-friendship-paradox/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m04-friendship-paradox/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDItY29kaW5nLmh0bWw=\"}\n[/m04-friendship-paradox/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNC1mcmllbmRzaGlwLXBhcmFkb3gvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[─── M05: Clustering ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNTogQ2x1c3RlcmluZyDilIDilIDilIA=\"}\n[/m05-clustering/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m05-clustering/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m05-clustering/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAyLWNvZGluZy5odG1s\"}\n[/m05-clustering/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNS1jbHVzdGVyaW5nLzAzLWV4ZXJjaXNlcy5odG1s\"}\n[─── M06: Centrality ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNjogQ2VudHJhbGl0eSDilIDilIDilIA=\"}\n[/m06-centrality/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAwLXByZXBhcmF0aW9uLmh0bWw=\"}\n[/m06-centrality/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAxLWNvbmNlcHRzLmh0bWw=\"}\n[/m06-centrality/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAyLWNvZGluZy5odG1s\"}\n[/m06-centrality/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNi1jZW50cmFsaXR5LzAzLWV4ZXJjaXNlcy5odG1s\"}\n[Advanced Topics]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWR2YW5jZWQgVG9waWNz\"}\n[─── M07: Random Walks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wNzogUmFuZG9tIFdhbGtzIOKUgOKUgOKUgA==\"}\n[/m07-random-walks/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m07-random-walks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m07-random-walks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDItY29kaW5nLmh0bWw=\"}\n[/m07-random-walks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wNy1yYW5kb20td2Fsa3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[─── M08: Embedding ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wODogRW1iZWRkaW5nIOKUgOKUgOKUgA==\"}\n[/m08-embedding/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m08-embedding/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m08-embedding/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDItY29kaW5nLmh0bWw=\"}\n[/m08-embedding/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m08-embedding/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOC1lbWJlZGRpbmcvMDQtYXBwZW5kaXguaHRtbA==\"}\n[─── M09: Graph Neural Networks ───]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI64pSA4pSA4pSAIE0wOTogR3JhcGggTmV1cmFsIE5ldHdvcmtzIOKUgOKUgOKUgA==\"}\n[/m09-graph-neural-networks/00-preparation.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDAtcHJlcGFyYXRpb24uaHRtbA==\"}\n[/m09-graph-neural-networks/01-concepts.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDEtY29uY2VwdHMuaHRtbA==\"}\n[/m09-graph-neural-networks/02-coding.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDItY29kaW5nLmh0bWw=\"}\n[/m09-graph-neural-networks/03-exercises.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDMtZXhlcmNpc2VzLmh0bWw=\"}\n[/m09-graph-neural-networks/04-appendix.html]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLWludC1uYXZiYXI6L20wOS1ncmFwaC1uZXVyYWwtbmV0d29ya3MvMDQtYXBwZW5kaXguaHRtbA==\"}\n\n:::{.hidden .quarto-markdown-envelope-contents render-id=\"Zm9vdGVyLWxlZnQ=\"}\nCopyright 2024, Sadamori Kojaku\n:::\n\n:::\n\n\n\n:::{#quarto-meta-markdown .hidden}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGF0aXRsZQ==\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkdGl0bGU=\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZHRpdGxl\"}\n[Advanced Topics in Network Science]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW1ldGFzaXRlbmFtZQ==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkZGVzYw==\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"cXVhcnRvLW9nY2FyZGRkZXNj\"}\n:::\n\n\n\n\n&lt;!-- --&gt;\n\n::: {.quarto-embedded-source-code}\n```````````````````{.markdown shortcodes=\"false\"}\n# What is centrality?\n\nHave you ever wondered who the most popular person in your school is? Or which idea is the most important in a subject? Or maybe which movie everyone's talking about right now?\nThese questions are all about finding out what's important in a network of people, ideas, or things. In network science, we call this *centrality.*\n\nCentrality or *importance* is a question of how important a node is in a network.\nBut the notion of *importance* is somewhat vague.\nIn what sense we say a node is important?\nAnswering this question needs a specific *context*, and there are many contexts in which the *importance* is defined.\n\n![](../figs/centrality.jpg)\n\n## Different centrality measures\n\nHere we will focus on several popular centrality measures. Let us denote by $c_i$ the centrality of node $i$ throughout this section.\nHere is a preview of the centrality measures we will cover in this section\n\n| Centrality          | Category            | Description                                                                 |\n|-------------------------|---------------------|-----------------------------------------------------------------------------|\n| Degree Centrality       | Degree              | Counts the number of edges connected to a node.                             |\n| Closeness Centrality    | Shortest Path  | Measures how close a node is to all other nodes in the network.             |\n| Eccentricity Centrality | Shortest Path  | Based on the maximum shortest path distance from a node to any other node.  |\n| Harmonic Centrality     | Shortest Path  | Adjusts closeness centrality to work even in disconnected networks.         |\n| Betweenness Centrality  | Shortest Path  | Measures the extent to which a node lies on paths between other nodes.      |\n| Eigenvector Centrality  | Walk           | Measures a node's influence based on the influence of its neighbors.        |\n| HITS (Hub and Authority) Centrality | Walk  | Measures the importance of nodes as hubs and authorities in a network.      |\n| Katz Centrality         | Walk           | Considers the total number of walks between nodes, with a damping factor.   |\n| PageRank                | Walk           | Measures the importance of nodes based on the structure of incoming links.  |\n\n\n### Degree centrality\n\nPerhaps the simplest form of cnetrality is *degree centrality*. It is just the count of the number of edges connected to a node (i.e., the number of neighbors, or *degree* in network science terminology). The most important node is thus the one with the highest degree.\n\n$$\nc_i = d_i = \\sum_{j} A_{ij}\n$$\n\nwhere $A_{ij}$ is the adjacency matrix of the network, and $d_i$ is the degree of node $i$.\n\n### Centrality based on shortest path\n\n\n&lt;img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Milliarium_Aureum_op_het_Forum_Romanum_te_Rome_Columna_Miliaria_in_Foro_Romano_%28titel_op_object%29_Antieke_monumenten_%28serietitel%29_Antiquae_Urbis_Splendor_%28serietitel%29%2C_RP-P-2016-345-28-1.jpg/1546px-thumbnail.jpg?20191217151048\" alt=\"Roma Foro Romano Miliarium Aureum\" width=\"80%\" style=\"display: block; margin-left: auto; margin-right: auto;\"&gt;\n\n\nLet's talk about an ancient Roman monument called the *Milliarium Aureum*, also known as the *Golden Milestone*.\nIt was the starting point for measuring distances on all major roads in the Roman Empire.\nEmperor Augustus built it when Rome changed from a republic to an empire.\nThe monument not only marked the distances but also represent a centralization of power, where Rome transitioned from a Republic to an Empire.\nPerhaps the Romans understood the importance of being central in terms of distance, and this concept can be applied to define *centrality* in networks.\n\n### Closeness centrality\n**Closenes centrality** is a measure of how close a node is to all other nodes in the network. A node is central if it is close to all other nodes, which is operationally defined as\n\n$$\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n$$\n\nwhere $N$ is the number of nodes in the network. The numerator, $N - 1$, is the normalization factor to make the centrality have a maximum value of 1.\n\n\n::: {.callout-note title=\"Exercise\"}\n:class: tip\n\nCreate a graph where a node has the maximum closeness centrality of value 1.\n\n\n::: {.callout collapse=\"true\"}\n## Click to see the answer\n\nThe simplest example is a star graph, where one node is connected to all other nodes. The node at the center has the highest closeness centrality.\n\n&lt;img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Star_network_7.svg/1920px-Star_network_7.svg.png\" alt=\"Star graph S7\" width=\"50%\" style=\"display: block; margin-left: auto; margin-right: auto;\"&gt;\n\n\n\nHarmonic Centrality is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can’t reach others, making their distance infinite. This causes all centrality values to become zero, which isn’t very helpful!\nTo fix this, Beauchamp {footcite:p}beauchamp1965improved came up with a clever solution called harmonic centrality. It works even when the network is disconnected.\n\nc_i = \\sum_{j\\neq i} \\frac{1}{\\text{shortest path length from } j \\text{ to } i}\n\n\n\n\nEccentricity centrality is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\nThese centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.\nA central node should be close to all other nodes.\nCloseness centrality captures the notion of “centrality” in the network. Namely, a node is central if it is close to all other nodes.\n\nc_i = \\frac{N - 1}{\\sum_{j = 1}^N \\text{shortest path length from } j \\text{ to } i}\n\nwhere N is the number of nodes in the network. The numerator, N, is the normalization factor to make the centrality to have the maximum value of 1.\n\n\n\nEccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the maximum distance as opposed to the average distance like in the closeness centrality.\n\nc_i = \\frac{1}{\\max_{j} \\text{shortest path length from } i \\text{ to } j}\n\n\n\n\nAnother notion of centrality is betweenness centrality. It considers that a node is important if it lies on many shortest paths between other nodes.\n\nc_i = \\sum_{j &lt; k} \\frac{\\sigma_{jk}(i)}{\\sigma_{jk}}\n\nwhere \\sigma_{jk} is the number of shortest paths between nodes j and k, and \\sigma_{jk}(i) is the number of shortest paths between nodes j and k that pass through node i.\n```````````````````"
  },
  {
    "objectID": "m07-random-walks/01-concepts.html",
    "href": "m07-random-walks/01-concepts.html",
    "title": "Random Walks: Core Concepts",
    "section": "",
    "text": "In this module, we will learn random walks, one of the most fundamental techniques in network analysis. We’ll explore what random walks are, how to simulate them on networks, their behavior patterns, and their connections to community detection and network centralities.\nTo make these concepts tangible, let’s start with a fun game that perfectly illustrates random walk principles:\n\n\n\n\n\n\nLadder Lottery\n\n\n\n:class: tip\nLadder Lottery is a fun East Asian game, also known as “鬼腳圖” (Guijiaotu) in Chinese, “阿弥陀籤” (Amida-kuzi) in Japanese, “사다리타기” (Sadaritagi) in Korean, and “Ladder Lottery” in English. The game is played as follows: 1. A player is given a board with a set of vertical lines. 2. The player chooses a line and starts to move along the line 3. When hitting a horizontal line, the player must move along the horizontal line and then continue to move along the next vertical line. 4. The player wins if the player can hit a marked line at the bottom of the board. 5. You cannot see the horizontal lines in advance!\nPlay the {{ ‘Ladder Lottery Game! 🎮✨’.replace(‘BASE_URL’, base_url) }} and try to answer the following questions:\n\nIs there a strategy to maximize the probability of winning?\nHow does the probability of winning change as the number of horizontal lines increases?\n\n\n\n\nThe Ladder Lottery game is actually a perfect introduction to random walks! In this game, states are the vertical lines, transitions happen when you encounter horizontal connections, randomness comes from not knowing where the horizontal lines are placed, and long-term behavior determines your probability of winning. This simple game illustrates many key concepts we’ll explore in random walks on networks.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#introduction-through-games-ladder-lottery",
    "href": "m07-random-walks/01-concepts.html#introduction-through-games-ladder-lottery",
    "title": "Random Walks: Core Concepts",
    "section": "",
    "text": "In this module, we will learn random walks, one of the most fundamental techniques in network analysis. We’ll explore what random walks are, how to simulate them on networks, their behavior patterns, and their connections to community detection and network centralities.\nTo make these concepts tangible, let’s start with a fun game that perfectly illustrates random walk principles:\n\n\n\n\n\n\nLadder Lottery\n\n\n\n:class: tip\nLadder Lottery is a fun East Asian game, also known as “鬼腳圖” (Guijiaotu) in Chinese, “阿弥陀籤” (Amida-kuzi) in Japanese, “사다리타기” (Sadaritagi) in Korean, and “Ladder Lottery” in English. The game is played as follows: 1. A player is given a board with a set of vertical lines. 2. The player chooses a line and starts to move along the line 3. When hitting a horizontal line, the player must move along the horizontal line and then continue to move along the next vertical line. 4. The player wins if the player can hit a marked line at the bottom of the board. 5. You cannot see the horizontal lines in advance!\nPlay the {{ ‘Ladder Lottery Game! 🎮✨’.replace(‘BASE_URL’, base_url) }} and try to answer the following questions:\n\nIs there a strategy to maximize the probability of winning?\nHow does the probability of winning change as the number of horizontal lines increases?\n\n\n\n\nThe Ladder Lottery game is actually a perfect introduction to random walks! In this game, states are the vertical lines, transitions happen when you encounter horizontal connections, randomness comes from not knowing where the horizontal lines are placed, and long-term behavior determines your probability of winning. This simple game illustrates many key concepts we’ll explore in random walks on networks.",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#understanding-random-walks",
    "href": "m07-random-walks/01-concepts.html#understanding-random-walks",
    "title": "Random Walks: Core Concepts",
    "section": "2 Understanding Random Walks",
    "text": "2 Understanding Random Walks\nSuppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network.\nMore formally, a random walk in undirected networks follows this process: 1. Start at a node i 2. Randomly choose an edge to traverse to a neighbor node j 3. Repeat step 2 until you have taken T steps\nIn directed networks, a random walker can only move along the edge direction, and it can be that the random walker is stuck in a so-called \"dead end\" that does not have any outgoing edges.\nWhen studying random walks, we want to understand several key aspects: short-term behavior (where does the walker go in the first few steps?), long-term behavior (after many steps, where does the walker spend most of its time?), structural insights (what does the walker’s behavior tell us about the network?), and applications (how can we use random walks for centrality and community detection?).",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#pen-and-paper-exercises",
    "href": "m07-random-walks/01-concepts.html#pen-and-paper-exercises",
    "title": "Random Walks: Core Concepts",
    "section": "3 Pen and Paper Exercises",
    "text": "3 Pen and Paper Exercises\nBefore diving into the mathematical details and coding, it’s important to work through some fundamental concepts by hand.\n\n✍️ Pen and paper exercises\n\nThese exercises will help you: - Understand the basic mechanics of random walks - Calculate transition probabilities manually - Explore simple examples of stationary distributions - Connect random walk concepts to network properties",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/01-concepts.html#preview-whats-coming-next",
    "href": "m07-random-walks/01-concepts.html#preview-whats-coming-next",
    "title": "Random Walks: Core Concepts",
    "section": "4 Preview: What’s Coming Next",
    "text": "4 Preview: What’s Coming Next\nIn the following sections, we will: 1. Dive into the mathematics behind random walks and their connection to Markov chains 2. Implement random walks in code and visualize their behavior on real networks 3. Explore applications including centrality measures and community detection 4. Work through practical exercises to solidify your understanding\nThe journey from this simple concept to powerful network analysis tools is both fascinating and practical!",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html",
    "href": "m07-random-walks/03-exercises.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "This section contains all the exercises from the Random Walks module, organized by topic and difficulty level.\n\n\n\n\nWrite the following function to simulate the random walk for a given number of steps and return the position for each step.\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass\nHints: - Initialize the walker at a random starting position - Use the transition probability matrix P = A / k (where k is the degree vector) - For each step, randomly choose the next node based on transition probabilities - Store the position at each step\n\n\n\nWrite a function to compute the expected position of the walker at time t using the formula \\mathbb{E}[x(t)] = x(0) P^t:\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The expected position distribution at time t.\n    \"\"\"\n    # Your code here\n    pass\nHints: - Compute the transition matrix P from adjacency matrix A - Use matrix power P^t to get multi-step transition probabilities - Apply the initial distribution x_0 to get the expected position\n\n\n\nPlot each element of x(t) as a function of t for t=0,1,2,\\ldots, 1000. Try different initial positions and compare the results!\nSteps: 1. Define the initial position of the walker 2. Compute the expected position of the walker at time t using the function from Exercise 02 3. Draw a line for each element of x(t), totaling 5 lines for a 5-node network 4. Create multiple such plots for different initial positions and compare them\nQuestions to explore: - Do all initial positions converge to the same stationary distribution? - How long does it take to converge? - What does the stationary distribution tell us about the network structure?\n\n\n\n\nStochastic Block Model Analysis:\n\nGenerate a network of 100 nodes with 4 communities using a stochastic block model\nSet inter-community edge probability to 0.05 and intra-community edge probability to 0.2\nCompute the expected position of the walker starting from node zero after x steps\nPlot the results for x = 0, 5, 10, 1000\n\nParameter Sensitivity:\n\nIncrease the inter-community edge probability to 0.15 and repeat the simulation\nCompare the results with the previous simulation\nWhat happens to community detection when communities become more connected?\n\n\nImplementation hints:\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nimport networkx as nx\n\n# Example stochastic block model generation\ndef generate_sbm(n_nodes_per_community, p_within, p_between):\n    \"\"\"Generate a stochastic block model network\"\"\"\n    # Your implementation here\n    pass\n\n\n\n\n\n\nIf the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\nSolution Framework: - Consider the HITS equations for undirected networks - Compare with eigenvector centrality equation - Use the symmetry property of undirected networks - Show the mathematical relationship between the two measures\n\n\n\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree d_j of the authority:\n\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n\nShow that the hub centrality becomes equivalent to the degree centrality by substituting x_i = d_i.\nSteps to verify: 1. Substitute x_i = d_i into the first equation 2. Show that this satisfies the system of equations 3. Interpret the result in terms of network centrality\n\n\n\n\n\n\nDerive the solution of the Katz centrality equation:\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\nSolution steps: - Write the equation in matrix form - Rearrange to isolate the centrality vector - Find the matrix inverse solution - Verify the solution satisfies the original equation\n\n\n\nShow that PageRank can be written as the stationary distribution of a modified random walk with teleportation.\nStarting equation: \nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nTasks: 1. Identify the transition probabilities in this equation 2. Show that this represents a Markov chain 3. Prove that the solution is a stationary distribution 4. Interpret the teleportation parameter \\beta\n\n\n\n\n\n\n\n✍️ Pen and paper exercises\n\nThese exercises include: - Hand calculation of transition matrices for small networks - Manual computation of stationary distributions - Step-by-step random walk simulations - Eigenvalue calculations for simple graphs\n\n\n\n\n\n\nUsing the Ladder Lottery Game! 🎮✨, explore:\n\nStrategy Development:\n\nIs there a strategy to maximize the probability of winning?\nHow does the starting position affect winning probability?\n\nParameter Effects:\n\nHow does the probability of winning change as the number of horizontal lines increases?\nWhat happens with different numbers of vertical lines?\n\nConnection to Random Walks:\n\nHow does this game relate to random walks on networks?\nWhat type of transition matrix would represent this game?\n\n\n\n\n\nUsing the Random Walk Simulator! 🎮✨, investigate:\n\nShort-term vs. Long-term behavior:\n\nWhen the random walker makes many steps, where does it tend to visit most frequently?\nWhen the walker makes only a few steps, where does it tend to visit?\n\nNetwork Structure Analysis:\n\nDoes the behavior of the walker inform us about centrality of the nodes?\nDoes the behavior of the walker inform us about communities in the network?\n\nParameter Exploration:\n\nTry different network topologies (star, ring, complete graph)\nObserve how network structure affects random walk behavior\n\n\n\n\n\n\n\n\n\nTheoretical Calculation:\n\nFor a given network, compute the second-largest eigenvalue\nCalculate the theoretical mixing time bound\nCompare with empirical convergence time\n\nNetwork Comparison:\n\nCompare mixing times across different network types\nHow does community structure affect mixing time?\nWhat about scale-free vs. random networks?\n\n\n\n\n\n\nDerivation Verification:\n\nVerify the random walk interpretation of modularity step by step\nShow that high modularity corresponds to slow mixing between communities\n\nEmpirical Validation:\n\nGenerate networks with known community structure\nCompute modularity using both traditional and random walk approaches\nCompare the results and interpretation\n\n\n\n\n\nDesign your own centrality measure based on random walks:\n\nDesign Phase:\n\nChoose a specific aspect of random walk behavior to capture\nDefine your measure mathematically\nJustify why it captures important network properties\n\nImplementation:\n\nImplement your measure in Python\nTest on various network types\nCompare with existing centrality measures\n\nValidation:\n\nEvaluate on networks where you know the “ground truth”\nAnalyze computational complexity\nDiscuss practical applications\n\n\n\n\n\n\n\n\nExtend random walks to multi-layer networks:\n\nModel Development:\n\nHow would you define transition probabilities between layers?\nWhat does the stationary distribution represent?\n\nImplementation:\n\nCode a multi-layer random walk simulator\nAnalyze convergence properties\nCompare with single-layer results\n\n\n\n\n\nConsider random walks on time-varying networks:\n\nTheoretical Framework:\n\nHow do you handle changing adjacency matrices?\nWhat is the appropriate notion of stationary distribution?\n\nSimulation Study:\n\nImplement random walks on temporal networks\nStudy how network dynamics affect walker behavior\nDevelop time-dependent centrality measures\n\n\n\n\n\n\n\n\nBeginner Level (Exercises 1-6): - Focus on understanding basic concepts - Emphasize coding implementation - Check mathematical derivations step-by-step\nIntermediate Level (Exercises 7-11): - Require deeper mathematical understanding - Expect connections between theory and practice - Look for creative interpretations\nAdvanced Level (Exercises 12-16): - Demand original thinking and research - Expect novel implementations - Require critical analysis and comparison\n\n\n\nCode Quality (40%): - Correctness of implementation - Efficiency and elegance - Documentation and comments\nMathematical Understanding (30%): - Correct derivations - Clear explanations - Proper use of notation\nAnalysis and Interpretation (30%): - Insightful discussion of results - Connections to network science concepts - Critical thinking about limitations and extensions\n\n\n\n\n\nDatasets: Use networks from SNAP, NetworkX, or create synthetic ones\nVisualization: Consider using NetworkX, igraph, or D3.js for interactive plots\nFurther Reading: Consult papers on spectral graph theory and Markov chain analysis\nSoftware: Explore specialized tools like graph-tool or GTNA for large-scale analysis",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#coding-exercises",
    "href": "m07-random-walks/03-exercises.html#coding-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Write the following function to simulate the random walk for a given number of steps and return the position for each step.\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass\nHints: - Initialize the walker at a random starting position - Use the transition probability matrix P = A / k (where k is the degree vector) - For each step, randomly choose the next node based on transition probabilities - Store the position at each step\n\n\n\nWrite a function to compute the expected position of the walker at time t using the formula \\mathbb{E}[x(t)] = x(0) P^t:\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The expected position distribution at time t.\n    \"\"\"\n    # Your code here\n    pass\nHints: - Compute the transition matrix P from adjacency matrix A - Use matrix power P^t to get multi-step transition probabilities - Apply the initial distribution x_0 to get the expected position\n\n\n\nPlot each element of x(t) as a function of t for t=0,1,2,\\ldots, 1000. Try different initial positions and compare the results!\nSteps: 1. Define the initial position of the walker 2. Compute the expected position of the walker at time t using the function from Exercise 02 3. Draw a line for each element of x(t), totaling 5 lines for a 5-node network 4. Create multiple such plots for different initial positions and compare them\nQuestions to explore: - Do all initial positions converge to the same stationary distribution? - How long does it take to converge? - What does the stationary distribution tell us about the network structure?\n\n\n\n\nStochastic Block Model Analysis:\n\nGenerate a network of 100 nodes with 4 communities using a stochastic block model\nSet inter-community edge probability to 0.05 and intra-community edge probability to 0.2\nCompute the expected position of the walker starting from node zero after x steps\nPlot the results for x = 0, 5, 10, 1000\n\nParameter Sensitivity:\n\nIncrease the inter-community edge probability to 0.15 and repeat the simulation\nCompare the results with the previous simulation\nWhat happens to community detection when communities become more connected?\n\n\nImplementation hints:\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nimport networkx as nx\n\n# Example stochastic block model generation\ndef generate_sbm(n_nodes_per_community, p_within, p_between):\n    \"\"\"Generate a stochastic block model network\"\"\"\n    # Your implementation here\n    pass",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#theoretical-exercises",
    "href": "m07-random-walks/03-exercises.html#theoretical-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "If the original network is undirected, is the HITS centrality equivalent to the eigenvector centrality? If so or not, explain why.\nSolution Framework: - Consider the HITS equations for undirected networks - Compare with eigenvector centrality equation - Use the symmetry property of undirected networks - Show the mathematical relationship between the two measures\n\n\n\nConsider the case where the graph is undirected and we normalize the hub centrality by the degree d_j of the authority:\n\nx_i = \\sum_j \\frac{A_{ji}}{d_j} y_j,\\quad y_i = \\sum_j A_{ij} x_j\n\nShow that the hub centrality becomes equivalent to the degree centrality by substituting x_i = d_i.\nSteps to verify: 1. Substitute x_i = d_i into the first equation 2. Show that this satisfies the system of equations 3. Interpret the result in terms of network centrality",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#mathematical-derivation-exercises",
    "href": "m07-random-walks/03-exercises.html#mathematical-derivation-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Derive the solution of the Katz centrality equation:\n\nc_i = \\beta + \\lambda \\sum_{j} A_{ij} c_j\n\nSolution steps: - Write the equation in matrix form - Rearrange to isolate the centrality vector - Find the matrix inverse solution - Verify the solution satisfies the original equation\n\n\n\nShow that PageRank can be written as the stationary distribution of a modified random walk with teleportation.\nStarting equation: \nc_i = (1-\\beta) \\sum_j A_{ji}\\frac{c_j}{d^{\\text{out}}_j} + \\beta \\cdot \\frac{1}{N}\n\nTasks: 1. Identify the transition probabilities in this equation 2. Show that this represents a Markov chain 3. Prove that the solution is a stationary distribution 4. Interpret the teleportation parameter \\beta",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#pen-and-paper-exercises",
    "href": "m07-random-walks/03-exercises.html#pen-and-paper-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\nThese exercises include: - Hand calculation of transition matrices for small networks - Manual computation of stationary distributions - Step-by-step random walk simulations - Eigenvalue calculations for simple graphs",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#interactive-exercises",
    "href": "m07-random-walks/03-exercises.html#interactive-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Using the Ladder Lottery Game! 🎮✨, explore:\n\nStrategy Development:\n\nIs there a strategy to maximize the probability of winning?\nHow does the starting position affect winning probability?\n\nParameter Effects:\n\nHow does the probability of winning change as the number of horizontal lines increases?\nWhat happens with different numbers of vertical lines?\n\nConnection to Random Walks:\n\nHow does this game relate to random walks on networks?\nWhat type of transition matrix would represent this game?\n\n\n\n\n\nUsing the Random Walk Simulator! 🎮✨, investigate:\n\nShort-term vs. Long-term behavior:\n\nWhen the random walker makes many steps, where does it tend to visit most frequently?\nWhen the walker makes only a few steps, where does it tend to visit?\n\nNetwork Structure Analysis:\n\nDoes the behavior of the walker inform us about centrality of the nodes?\nDoes the behavior of the walker inform us about communities in the network?\n\nParameter Exploration:\n\nTry different network topologies (star, ring, complete graph)\nObserve how network structure affects random walk behavior",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#advanced-exercises",
    "href": "m07-random-walks/03-exercises.html#advanced-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Theoretical Calculation:\n\nFor a given network, compute the second-largest eigenvalue\nCalculate the theoretical mixing time bound\nCompare with empirical convergence time\n\nNetwork Comparison:\n\nCompare mixing times across different network types\nHow does community structure affect mixing time?\nWhat about scale-free vs. random networks?\n\n\n\n\n\n\nDerivation Verification:\n\nVerify the random walk interpretation of modularity step by step\nShow that high modularity corresponds to slow mixing between communities\n\nEmpirical Validation:\n\nGenerate networks with known community structure\nCompute modularity using both traditional and random walk approaches\nCompare the results and interpretation\n\n\n\n\n\nDesign your own centrality measure based on random walks:\n\nDesign Phase:\n\nChoose a specific aspect of random walk behavior to capture\nDefine your measure mathematically\nJustify why it captures important network properties\n\nImplementation:\n\nImplement your measure in Python\nTest on various network types\nCompare with existing centrality measures\n\nValidation:\n\nEvaluate on networks where you know the “ground truth”\nAnalyze computational complexity\nDiscuss practical applications",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#challenge-problems",
    "href": "m07-random-walks/03-exercises.html#challenge-problems",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Extend random walks to multi-layer networks:\n\nModel Development:\n\nHow would you define transition probabilities between layers?\nWhat does the stationary distribution represent?\n\nImplementation:\n\nCode a multi-layer random walk simulator\nAnalyze convergence properties\nCompare with single-layer results\n\n\n\n\n\nConsider random walks on time-varying networks:\n\nTheoretical Framework:\n\nHow do you handle changing adjacency matrices?\nWhat is the appropriate notion of stationary distribution?\n\nSimulation Study:\n\nImplement random walks on temporal networks\nStudy how network dynamics affect walker behavior\nDevelop time-dependent centrality measures",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#assessment-guidelines",
    "href": "m07-random-walks/03-exercises.html#assessment-guidelines",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Beginner Level (Exercises 1-6): - Focus on understanding basic concepts - Emphasize coding implementation - Check mathematical derivations step-by-step\nIntermediate Level (Exercises 7-11): - Require deeper mathematical understanding - Expect connections between theory and practice - Look for creative interpretations\nAdvanced Level (Exercises 12-16): - Demand original thinking and research - Expect novel implementations - Require critical analysis and comparison\n\n\n\nCode Quality (40%): - Correctness of implementation - Efficiency and elegance - Documentation and comments\nMathematical Understanding (30%): - Correct derivations - Clear explanations - Proper use of notation\nAnalysis and Interpretation (30%): - Insightful discussion of results - Connections to network science concepts - Critical thinking about limitations and extensions",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/03-exercises.html#additional-resources",
    "href": "m07-random-walks/03-exercises.html#additional-resources",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Datasets: Use networks from SNAP, NetworkX, or create synthetic ones\nVisualization: Consider using NetworkX, igraph, or D3.js for interactive plots\nFurther Reading: Consult papers on spectral graph theory and Markov chain analysis\nSoftware: Explore specialized tools like graph-tool or GTNA for large-scale analysis",
    "crumbs": [
      "Home",
      "M07: Random Walks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html",
    "href": "m07-random-walks/random-walks-code.html",
    "title": "Random Walks in Python",
    "section": "",
    "text": "We will simulate random walks on a simple graph of five nodes as follows.\n\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n\nA random walk is characterized by the transition probabilities between nodes.\n\nP_{ij} = \\frac{A_{ij}}{k_i}\n\nLet us first compute the transition probabilities and store them in a matrix, \\mathbf{P}.\n\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] &gt; 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i-&gt;ij\", A, 1 / k)\n\n\nprint(\"Transition probability matrix:\\n\", P)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n\nEach row and column of \\mathbf{P} corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\nNow, let us simulate a random walk on this graph. We represent a position of the walker by a vector, \\mathbf{x}, with five elements, each of which represents a node. We mark the node that the walker is currently at by 1 and others as 0.\n\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n\nThis vector representation is convenient to get the probabilities of transitions to other nodes from the current node:\n\n\\mathbf{x} \\mathbf{P}\n\nwhich is translated into the following code:\n\nprobs = x @ P\nprint(\"Position of the walker after one step:\\n\", probs)\n\nWe can then draw the next node based on the probabilities\n\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position of the walker after one step:\\n\", x)\n\nBy repeating this process, we can simulate the random walk.\n\n\nWrite the following function to simulate the random walk for a given number of steps and return the x for each step.\n\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x (np.ndarray): The initial position of the walker.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass"
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html#simulating-random-walks",
    "href": "m07-random-walks/random-walks-code.html#simulating-random-walks",
    "title": "Random Walks in Python",
    "section": "",
    "text": "We will simulate random walks on a simple graph of five nodes as follows.\n\nimport numpy as np\nimport igraph\n\ng = igraph.Graph()\n\ng.add_vertices([0, 1, 2, 3, 4])\ng.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])\nigraph.plot(g, vertex_size=20, vertex_label=g.vs[\"name\"])\n\nA random walk is characterized by the transition probabilities between nodes.\n\nP_{ij} = \\frac{A_{ij}}{k_i}\n\nLet us first compute the transition probabilities and store them in a matrix, \\mathbf{P}.\n\nA = g.get_adjacency_sparse().toarray()\nk = np.array(g.degree())\nn_nodes = g.vcount()\n\n# A simple but inefficient way to compute P\nP = np.zeros((n_nodes, n_nodes))\nfor i in range(n_nodes):\n    for j in range(n_nodes):\n        if k[i] &gt; 0:\n            P[i, j] = A[i, j] / k[i]\n        else:\n            P[i, j] = 0\n\n# Alternative, more efficient way to compute P\nP = A / k[:, np.newaxis]\n\n# or even more efficiently\nP = np.einsum(\"ij,i-&gt;ij\", A, 1 / k)\n\n\nprint(\"Transition probability matrix:\\n\", P)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(P, annot=True, cmap=\"YlGnBu\")\nplt.show()\n\nEach row and column of \\mathbf{P} corresponds to a node, with entries representing the transition probabilities from the row node to the column node.\nNow, let us simulate a random walk on this graph. We represent a position of the walker by a vector, \\mathbf{x}, with five elements, each of which represents a node. We mark the node that the walker is currently at by 1 and others as 0.\n\nx = np.array([0, 0, 0, 0, 0])\nx[0] = 1\nprint(\"Initial position of the walker:\\n\", x)\n\nThis vector representation is convenient to get the probabilities of transitions to other nodes from the current node:\n\n\\mathbf{x} \\mathbf{P}\n\nwhich is translated into the following code:\n\nprobs = x @ P\nprint(\"Position of the walker after one step:\\n\", probs)\n\nWe can then draw the next node based on the probabilities\n\nnext_node = np.random.choice(n_nodes, p=probs)\nx[:] = 0 # zero out the vector\nx[next_node] = 1 # set the next node to 1\nprint(\"Position of the walker after one step:\\n\", x)\n\nBy repeating this process, we can simulate the random walk.\n\n\nWrite the following function to simulate the random walk for a given number of steps and return the x for each step.\n\ndef random_walk(A, n_steps):\n    \"\"\"\n    Simulate the random walk on a graph with adjacency matrix A.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x (np.ndarray): The initial position of the walker.\n        n_steps (int): The number of steps to simulate.\n\n    Returns:\n        np.ndarray: The position of the walker after each step.\n    \"\"\"\n    # Your code here\n    pass"
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html#expected-behavior-of-random-walks",
    "href": "m07-random-walks/random-walks-code.html#expected-behavior-of-random-walks",
    "title": "Random Walks in Python",
    "section": "2 Expected behavior of random walks",
    "text": "2 Expected behavior of random walks\nWhat is the expected position of the walker after multiple steps? It is easy to compute the expected position of the walker after one step from initial position x(0):\n\n\\mathbb{E}[x(1)] = x(0) P\n\nwhere x(t) is the probability distribution of the walker at time t. In Python, the expected position of the walker at time t=1 is given by\n\nx_0 = np.array([1, 0, 0, 0, 0])\nx_1 = x_0 @ P\nprint(\"Expected position of the walker after one step:\\n\", x_1)\n\nFor the second step, the expected position of the walker is given by\n\n\\mathbb{E}[x(2)] = \\mathbb{E}[x(1) P] = \\mathbb{E}[x(0) P] P = x(0) P^2\n\nIn other words,\n\nx_2 = x_1 @ P\nprint(\"Expected position of the walker after two steps:\\n\", x_2)\n\nFollowing the same argument, the expected position of the walker at time t is given by\n\n\\mathbb{E}[x(t)] = x(0) P^t\n\n\nExercise 02\nWrite a function to compute the expected position of the walker at time t using the above formula:\n\ndef expected_position(A, x_0, t):\n    \"\"\"\n    Compute the expected position of the walker at time t.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        x_0 (np.ndarray): The initial position of the walker.\n        t (int): The number of steps to simulate.\n    \"\"\"\n    # Your code here\n    pass\n\n\n\nExercise 03\nPlot each element of x(t) as a function of t for t=0,1,2,\\ldots, 1000. Try different initial positions and compare the results!\nSteps: 1. Define the initial position of the walker. 2. Compute the expected position of the walker at time t using the function you wrote above. 3. Draw a line for each element of x(t), totalling 5 lines. 4. Create multiple such plots for different initial positions and compare them."
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html#community-structure",
    "href": "m07-random-walks/random-walks-code.html#community-structure",
    "title": "Random Walks in Python",
    "section": "3 Community structure",
    "text": "3 Community structure\nRandom walks can capture community structure of a network. To see this, let us consider a network of a ring of cliques.\n\nimport networkx as nx\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nn_cliques = 3\nn_nodes_per_clique = 5\n\nG = nx.ring_of_cliques(n_cliques, n_nodes_per_clique)\ng = igraph.Graph().Adjacency(nx.to_numpy_array(G).tolist()).as_undirected()\nmembership = np.repeat(np.arange(n_cliques), n_nodes_per_clique)\n\ncolor_map = [sns.color_palette()[i] for i in membership]\nigraph.plot(g, vertex_size=20, vertex_color=color_map)\n\nLet us compute the expected position of the walker after 1 to 10 steps.\nCompute the transition matrix:\n\n:tags: [hide-cell]\nfrom scipy import sparse\n\n# Get the adjacency matrix and degree\nA = g.get_adjacency_sparse()\nk = np.array(g.degree())\n\n# This is an efficient way to compute the transition matrix\n# using scipy.sparse\nP = sparse.diags(1 / k) @ A\n\nCompute the expected position of the walker after 1 to 300 steps:\n\n:tags: [hide-cell]\n\nx_t = np.zeros(g.vcount())\nx_t[2] = 1\nx_list = [x_t]\nfor t in range(300):\n    x_t = x_t @ P\n    x_list.append(x_t)\nx_list = np.array(x_list)\n\nPlot the expected position of the walker at each step:\n\n:tags: [hide-input]\n\ncmap = sns.color_palette(\"viridis\", as_cmap=True)\n\nsns.set_style('white')\nsns.set(font_scale=1.2)\nsns.set_style('ticks')\n\nfig, axes = plt.subplots(figsize=(15,10), ncols = 3, nrows = 2)\n\nt_list = [0, 1, 3, 5, 10, 299]\nfor i, t in enumerate(t_list):\n    igraph.plot(g, vertex_size=20, vertex_color=[cmap(x_list[t][j] / np.max(x_list[t])) for j in range(g.vcount())], target = axes[i//3][i%3])\n    axes[i//3][i%3].set_title(f\"$t$ = {t}\", fontsize = 25)\n\nwhere the color of each node represents the probability of the walker being at that node.\nAn important observation is that the walker spends more time in the clique that it started from and then diffuse to others. Thus, the position of the walker before reaching the steady state tells us the community structure of the network."
  },
  {
    "objectID": "m07-random-walks/random-walks-code.html#exercise-04",
    "href": "m07-random-walks/random-walks-code.html#exercise-04",
    "title": "Random Walks in Python",
    "section": "4 Exercise 04",
    "text": "4 Exercise 04\n\nGenerate a network of 100 nodes with 4 communities using a stochastic block model, with inter-community edge probability 0.05 and intra-community edge probability 0.2. Then, compute the expected position of the walker starting from node zero after x steps. Plot the results for x = 0, 5, 10, 1000.\nIncrease the inter-community edge probability to 0.15 and repeat the simulation. Compare the results with the previous simulation."
  },
  {
    "objectID": "m07-random-walks/random-walks.html",
    "href": "m07-random-walks/random-walks.html",
    "title": "Random Walks",
    "section": "",
    "text": "Suppose you walk in a city. You are drunk and your feet have no idea where to go. You just take a step wherever your feet take you. At every intersection, you make a random decision and take a step. This is the core idea of a random walk.\nWhile your feet are taking you to a random street, after making many steps and looking back, you will realize that you have been to certain places more frequently than others. If you were to map the frequency of your visits to each street, you will end up with a distribution that tells you about salient structure of the street network. It is surprising that this seemingly random, brainless behavior can tell us something deep about the structure of the city."
  },
  {
    "objectID": "m07-random-walks/random-walks.html#random-walks-in-a-network",
    "href": "m07-random-walks/random-walks.html#random-walks-in-a-network",
    "title": "Random Walks",
    "section": "1 Random walks in a network",
    "text": "1 Random walks in a network\nA random walk in undirected networks is the following process: 1. Start at a node i 2. Randomly choose an edge to traverse to a neighbor node j 3. Repeat step 2 until you have taken T steps.\nIn case of directed networks, a random walker can only move along the edge direction, and it can be that the random walker is stuck in a so-called ``dead end'' that does not have any outgoing edges.\nHow does this simple process tell us something about the network structure? To get some insights, let us play with a simple interactive visualization.\n\n\n\n\n\n\nRandom Walk Simulation\n\n\n\n:class: tip\nPlay with the Random Walk Simulator! 🎮✨ and try to answer the following questions:\n\nWhen the random walker makes many steps, where does it tend to visit most frequently?\nWhen the walker makes only a few steps, where does it tend to visit?\nDoes the behavior of the walker inform us about centrality of the nodes?\nDoes the behavior of the walker inform us about communities in the network?"
  },
  {
    "objectID": "m08-embedding/02-coding.html",
    "href": "m08-embedding/02-coding.html",
    "title": "Embedding Methods: Implementation and Practice",
    "section": "",
    "text": "Networks are a high-dimensional discrete data that can be difficult to analyze with traditional machine learning methods that assume continuous and smooth data. Spectral embedding is a technique to embed networks into low-dimensional spaces.\nLet us approach the spectral embedding from the perspective of network compression. Suppose we have an adjacency matrix \\mathbf{A} of a network. The adjacency matrix is a high-dimensional data, i.e., a matrix has size N \\times N for a network of N nodes. We want to compress it into a lower-dimensional matrix \\mathbf{U} of size N \\times d for a user-defined small integer d &lt; N. A good \\mathbf{U} should preserve the network structure and thus can reconstruct the original data \\mathbf{A} as closely as possible. This leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nwhere:\n\n\\mathbf{U}\\mathbf{U}^\\top is the outer product of \\mathbf{U} and represents the reconstructed network.\n\\|\\cdot\\|_F is the Frobenius norm, which is the sum of the squares of the elements in the matrix.\nJ(\\mathbf{U}) is the loss function that measures the difference between the original network \\mathbf{A} and the reconstructed network \\mathbf{U}\\mathbf{U}^\\top.\n\nBy minimizing the Frobenius norm with respect to \\mathbf{U}, we obtain the best low-dimensional embedding of the network.\n\n\n\nLet us first understand the solution intuitively. Consider the spectral decomposition of \\mathbf{A}:\n\n\\mathbf{A} = \\sum_{i=1}^N \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top\n\nwhere \\lambda_i are weights and \\mathbf{u}_i are column vectors. Each term \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top is a rank-one matrix that captures a part of the network’s structure. The larger the weight \\lambda_i, the more important that term is in describing the network.\nTo compress the network, we can select the d terms with the largest weights \\lambda_i. By combining the corresponding \\mathbf{u}_i vectors into a matrix \\mathbf{U}, we obtain a good low-dimensional embedding of the network.\n\nFor a formal proof, please refer to the Appendix section.\n\n\n\nLet us demonstrate the results with a simple example as follows.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a small example network\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).toarray()\nlabels = np.unique([d[1]['club'] for d in G.nodes(data=True)], return_inverse=True)[1]\ncmap = sns.color_palette()\nnx.draw(G, with_labels=False, node_color=[cmap[i] for i in labels])\n\n\n:tags: [hide-input]\n\n# Compute the spectral decomposition\neigvals, eigvecs = np.linalg.eig(A)\n\n# Find the top d eigenvectors\nd = 2\nsorted_indices = np.argsort(eigvals)[::-1][:d]\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n# Plot the results\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Spectral Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nInterestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes. The second eigenvector captures the community structure of the network, clearly separating the two communities in the network.\n\n\n\nIn a similar vein, we can use the modularity matrix to generate a low-dimensional embedding of the network. Namely, let us define the modularity matrix \\mathbf{Q} as follows:\n\nQ_{ij} = \\frac{1}{2m}A_{ij} - \\frac{k_i k_j}{4m^2}\n\nwhere k_i is the degree of node i, and m is the number of edges in the network.\nWe then compute the eigenvectors of \\mathbf{Q} and use them to embed the network into a low-dimensional space just as we did for the adjacency matrix.\n\n:tags: [hide-input]\n\ndeg = np.sum(A, axis=1)\nm = np.sum(deg) / 2\nQ = A - np.outer(deg, deg) / (2 * m)\nQ/= 2*m\n\neigvals, eigvecs = np.linalg.eig(Q)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(-eigvals)[:d]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Modularity Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nThe modularity embedding can be used to bipartition the network into two communities using a simple algorithm: group nodes with the same sign of the second eigenvector {footcite}`newman2006modularity`.\n\n\n\nLaplacian Eigenmap {footcite}belkin2003laplacian is another approach to compress a network into a low-dimensional space. The fundamental idea behind this method is to position connected nodes close to each other in the low-dimensional space. This approach leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J_{LE}(\\mathbf{U}),\\quad J_{LE}(\\mathbf{U}) = \\frac{1}{2}\\sum_{i,j} A_{ij} \\| u_i - u_j \\|^2\n\nIn this equation, \\| u_i - u_j \\|^2 represents the squared distance between nodes i and j in the low-dimensional space. The goal is to minimize this distance for connected nodes (where A_{ij} = 1). The factor \\frac{1}{2} is included for mathematical convenience in later calculations.\nTo solve this optimization problem, we rewrite J_{LE}(\\mathbf{U}) as follows:\n\n\\begin{aligned}\nJ_{LE}(\\mathbf{U}) &= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\| u_i - u_j \\|^2 \\\\\n&= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\left( \\| u_i \\|^2 - 2 u_i^\\top u_j + \\| u_j \\|^2 \\right) \\\\\n&= \\sum_{i}\\sum_{j} A_{ij} \\| u_i \\|^2 - \\sum_{i}\\sum_{j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i} k_i \\| u_i \\|^2 - \\sum_{i,j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i,j} L_{ij} u_i^\\top u_j\n\\end{aligned}\n\nwhere\n\nL_{ij} = \\begin{cases}\nk_i & \\text{if } i = j \\\\\n-A_{ij} & \\text{if } i \\neq j\n\\end{cases}\n\nThe minimization problem can be rewritten as:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nwhere\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\mathbf{u}_1 ^\\top \\\\\n\\mathbf{u}_2 ^\\top \\\\\n\\vdots \\\\\n\\mathbf{u}_N ^\\top \\\\\n\\end{bmatrix}\n\nSee the Appendix section for the detailed derivation.\nBy taking the derivative of J_{LE}(\\mathbf{U}) with respect to \\mathbf{U} and set it to zero, we obtain the following equation:\n\n\\frac{\\partial J_{LE}}{\\partial \\mathbf{U}} = 0 \\implies \\mathbf{L} \\mathbf{U} = \\lambda \\mathbf{U}\n\nThe solution is the d eigenvectors associated with the d smallest eigenvalues of \\mathbf{L}.\nIt is important to note that the eigenvector corresponding to the smallest eigenvalue (which is always zero for connected graphs) is trivial - it’s the all-one vector. Therefore, in practice, we typically compute the d+1 smallest eigenvectors and discard the one corresponding to the zero eigenvalue.\n\n\n\nLet us first compute the Laplacian matrix and its eigenvectors.\n\n:tags: [hide-input]\n\nD = np.diag(np.sum(A, axis=1))\nL = D - A\n\neigvals, eigvecs = np.linalg.eig(L)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(eigvals)[1:d+1]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nThe eigenvectors corresponding to the d smallest eigenvalues are:\n\n:tags: [hide-input]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Laplacian Eigenmap')\nax.set_xlabel('Eigenvector 2')\nax.set_ylabel('Eigenvector 3')\nplt.show()",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#spectral-embedding",
    "href": "m08-embedding/02-coding.html#spectral-embedding",
    "title": "Embedding Methods: Implementation and Practice",
    "section": "",
    "text": "Networks are a high-dimensional discrete data that can be difficult to analyze with traditional machine learning methods that assume continuous and smooth data. Spectral embedding is a technique to embed networks into low-dimensional spaces.\nLet us approach the spectral embedding from the perspective of network compression. Suppose we have an adjacency matrix \\mathbf{A} of a network. The adjacency matrix is a high-dimensional data, i.e., a matrix has size N \\times N for a network of N nodes. We want to compress it into a lower-dimensional matrix \\mathbf{U} of size N \\times d for a user-defined small integer d &lt; N. A good \\mathbf{U} should preserve the network structure and thus can reconstruct the original data \\mathbf{A} as closely as possible. This leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nwhere:\n\n\\mathbf{U}\\mathbf{U}^\\top is the outer product of \\mathbf{U} and represents the reconstructed network.\n\\|\\cdot\\|_F is the Frobenius norm, which is the sum of the squares of the elements in the matrix.\nJ(\\mathbf{U}) is the loss function that measures the difference between the original network \\mathbf{A} and the reconstructed network \\mathbf{U}\\mathbf{U}^\\top.\n\nBy minimizing the Frobenius norm with respect to \\mathbf{U}, we obtain the best low-dimensional embedding of the network.\n\n\n\nLet us first understand the solution intuitively. Consider the spectral decomposition of \\mathbf{A}:\n\n\\mathbf{A} = \\sum_{i=1}^N \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top\n\nwhere \\lambda_i are weights and \\mathbf{u}_i are column vectors. Each term \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top is a rank-one matrix that captures a part of the network’s structure. The larger the weight \\lambda_i, the more important that term is in describing the network.\nTo compress the network, we can select the d terms with the largest weights \\lambda_i. By combining the corresponding \\mathbf{u}_i vectors into a matrix \\mathbf{U}, we obtain a good low-dimensional embedding of the network.\n\nFor a formal proof, please refer to the Appendix section.\n\n\n\nLet us demonstrate the results with a simple example as follows.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a small example network\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).toarray()\nlabels = np.unique([d[1]['club'] for d in G.nodes(data=True)], return_inverse=True)[1]\ncmap = sns.color_palette()\nnx.draw(G, with_labels=False, node_color=[cmap[i] for i in labels])\n\n\n:tags: [hide-input]\n\n# Compute the spectral decomposition\neigvals, eigvecs = np.linalg.eig(A)\n\n# Find the top d eigenvectors\nd = 2\nsorted_indices = np.argsort(eigvals)[::-1][:d]\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n# Plot the results\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Spectral Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nInterestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes. The second eigenvector captures the community structure of the network, clearly separating the two communities in the network.\n\n\n\nIn a similar vein, we can use the modularity matrix to generate a low-dimensional embedding of the network. Namely, let us define the modularity matrix \\mathbf{Q} as follows:\n\nQ_{ij} = \\frac{1}{2m}A_{ij} - \\frac{k_i k_j}{4m^2}\n\nwhere k_i is the degree of node i, and m is the number of edges in the network.\nWe then compute the eigenvectors of \\mathbf{Q} and use them to embed the network into a low-dimensional space just as we did for the adjacency matrix.\n\n:tags: [hide-input]\n\ndeg = np.sum(A, axis=1)\nm = np.sum(deg) / 2\nQ = A - np.outer(deg, deg) / (2 * m)\nQ/= 2*m\n\neigvals, eigvecs = np.linalg.eig(Q)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(-eigvals)[:d]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Modularity Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nThe modularity embedding can be used to bipartition the network into two communities using a simple algorithm: group nodes with the same sign of the second eigenvector {footcite}`newman2006modularity`.\n\n\n\nLaplacian Eigenmap {footcite}belkin2003laplacian is another approach to compress a network into a low-dimensional space. The fundamental idea behind this method is to position connected nodes close to each other in the low-dimensional space. This approach leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J_{LE}(\\mathbf{U}),\\quad J_{LE}(\\mathbf{U}) = \\frac{1}{2}\\sum_{i,j} A_{ij} \\| u_i - u_j \\|^2\n\nIn this equation, \\| u_i - u_j \\|^2 represents the squared distance between nodes i and j in the low-dimensional space. The goal is to minimize this distance for connected nodes (where A_{ij} = 1). The factor \\frac{1}{2} is included for mathematical convenience in later calculations.\nTo solve this optimization problem, we rewrite J_{LE}(\\mathbf{U}) as follows:\n\n\\begin{aligned}\nJ_{LE}(\\mathbf{U}) &= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\| u_i - u_j \\|^2 \\\\\n&= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\left( \\| u_i \\|^2 - 2 u_i^\\top u_j + \\| u_j \\|^2 \\right) \\\\\n&= \\sum_{i}\\sum_{j} A_{ij} \\| u_i \\|^2 - \\sum_{i}\\sum_{j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i} k_i \\| u_i \\|^2 - \\sum_{i,j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i,j} L_{ij} u_i^\\top u_j\n\\end{aligned}\n\nwhere\n\nL_{ij} = \\begin{cases}\nk_i & \\text{if } i = j \\\\\n-A_{ij} & \\text{if } i \\neq j\n\\end{cases}\n\nThe minimization problem can be rewritten as:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nwhere\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\mathbf{u}_1 ^\\top \\\\\n\\mathbf{u}_2 ^\\top \\\\\n\\vdots \\\\\n\\mathbf{u}_N ^\\top \\\\\n\\end{bmatrix}\n\nSee the Appendix section for the detailed derivation.\nBy taking the derivative of J_{LE}(\\mathbf{U}) with respect to \\mathbf{U} and set it to zero, we obtain the following equation:\n\n\\frac{\\partial J_{LE}}{\\partial \\mathbf{U}} = 0 \\implies \\mathbf{L} \\mathbf{U} = \\lambda \\mathbf{U}\n\nThe solution is the d eigenvectors associated with the d smallest eigenvalues of \\mathbf{L}.\nIt is important to note that the eigenvector corresponding to the smallest eigenvalue (which is always zero for connected graphs) is trivial - it’s the all-one vector. Therefore, in practice, we typically compute the d+1 smallest eigenvectors and discard the one corresponding to the zero eigenvalue.\n\n\n\nLet us first compute the Laplacian matrix and its eigenvectors.\n\n:tags: [hide-input]\n\nD = np.diag(np.sum(A, axis=1))\nL = D - A\n\neigvals, eigvecs = np.linalg.eig(L)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(eigvals)[1:d+1]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nThe eigenvectors corresponding to the d smallest eigenvalues are:\n\n:tags: [hide-input]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Laplacian Eigenmap')\nax.set_xlabel('Eigenvector 2')\nax.set_ylabel('Eigenvector 3')\nplt.show()",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#neural-embedding-with-word2vec",
    "href": "m08-embedding/02-coding.html#neural-embedding-with-word2vec",
    "title": "Embedding Methods: Implementation and Practice",
    "section": "2 Neural Embedding with word2vec",
    "text": "2 Neural Embedding with word2vec\n\nIntroduction to word2vec\nIn this section, we will introduce word2vec, a powerful technique for learning word embeddings. word2vec is a neural network model that learns words embeddings in a continuous vector space. It was introduced by Tomas Mikolov and his colleagues at Google in 2013 {footcite}mikolov2013distributed.\n\n\nHow it works\n“You shall know a word by the company it keeps” {footcite}church1988word is a famous quote in linguistics. It means that you can understand the meaning of a word by looking at the words that appear in the same context. word2vec operates on the same principle. word2vec identifies a word’s context by examining the words within a fixed window around it. For example, in the sentence:\n\nThe quick brown fox jumps over a lazy dog\n\nThe context of the word fox includes quick, brown, jumps, over, and lazy. word2vec is trained to predict which words are likely to appear as the context of an input word.\nThere are two main architectures for word2vec:\n1. **Continuous Bag of Words (CBOW)**: Predicts the target word (center word) from the context words (surrounding words).\n2. **Skip-gram**: Predicts the context words (surrounding words) from the target word (center word).\nSo how are word embeddings learned? word2vec is a neural network model that looks like a bow tie. It has two layers of the vocabulary size coupled with a much smaller hidden layer.\n\n\nInput layer: The input layer consists of N neurons, where N is the size of the vocabulary (i.e., the number of unique words in the corpus). Each neuron corresponds to a unique word in the vocabulary. When a word is inputted, its corresponding neuron is activated and the other neurons are inhibited. Thus, the input layer is essentially a lookup mechanism that transforms the input word into a corresponding one-hot vector.\nOutput layer: The output layer also consists of N neurons, each corresponding to a unique word in the vocabulary. Unlike the input layer, multiple neurons can be activated for a single input. The strength of the activation of each neuron (with a normalization by the softmax function) represents the probability of the corresponding word being the input word’s context.\nHidden layer: The hidden layer is much smaller than the input and output layers. Multiple neurons in the hidden layer can be activated for a single input, and this activation pattern represents the word’s embedding.\n\nWe can consider word2vec as a dimensionality reduction technique that reduces the dimensionality of the input layer to the hidden layer based on the co-occurrence of words within a short distance. The distance is named the window size, which is a user-defined hyperparameter.\n\n\nWhat’s special about word2vec?\nWith word2vec, words are represented as dense vectors, enabling us to explore their relationships using simple linear algebra. This is in contrast to traditional natural language processing (NLP) methods, such as bag-of-words and topic modeling, which represent words as discrete units or high-dimensional vectors.\n\nTo showcase the effectiveness of word2vec, let’s walk through an example using the gensim library.\n\nimport gensim\nimport gensim.downloader\nfrom gensim.models import Word2Vec\n\n# Load pre-trained word2vec model from Google News\nmodel = gensim.downloader.load('word2vec-google-news-300')\n\nOur first example is to find the words most similar to king.\n\n# Example usage\nword = \"king\"\nsimilar_words = model.most_similar(word)\nprint(f\"Words most similar to '{word}':\")\nfor similar_word, similarity in similar_words:\n    print(f\"{similar_word}: {similarity:.4f}\")\n\nA cool (yet controversial) application of word embeddings is analogy solving. Let us consider the following puzzle:\n\nman is to woman as king is to ___ ?\n\nWe can use word embeddings to solve this puzzle.\n\n# We solve the puzzle by\n#\n#  vec(king) - vec(man) + vec(woman)\n#\n# To solve this, we use the model.most_similar function, with positive words being \"king\" and \"woman\" (additive), and negative words being \"man\" (subtractive).\n#\nmodel.most_similar(positive=['woman', \"king\"], negative=['man'], topn=5)\n\nThe last example is to visualize the word embeddings.\n\n:tags: [hide-input]\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ncountries = ['Germany', 'France', 'Italy', 'Spain', 'Portugal', 'Greece']\ncapital_words = ['Berlin', 'Paris', 'Rome', 'Madrid', 'Lisbon', 'Athens']\n\n# Get the word embeddings for the countries and capitals\ncountry_embeddings = np.array([model[country] for country in countries])\ncapital_embeddings = np.array([model[capital] for capital in capital_words])\n\n# Compute the PCA\npca = PCA(n_components=2)\nembeddings = np.vstack([country_embeddings, capital_embeddings])\nembeddings_pca = pca.fit_transform(embeddings)\n\n# Create a DataFrame for seaborn\ndf = pd.DataFrame(embeddings_pca, columns=['PC1', 'PC2'])\ndf['Label'] = countries + capital_words\ndf['Type'] = ['Country'] * len(countries) + ['Capital'] * len(capital_words)\n\n# Plot the data\nplt.figure(figsize=(12, 10))\n\n# Create a scatter plot with seaborn\nscatter_plot = sns.scatterplot(data=df, x='PC1', y='PC2', hue='Type', style='Type', s=200, palette='deep', markers=['o', 's'])\n\n# Annotate the points\nfor i in range(len(df)):\n    plt.text(df['PC1'][i], df['PC2'][i] + 0.08, df['Label'][i], fontsize=12, ha='center', va='bottom',\n             bbox=dict(facecolor='white', edgecolor='none', alpha=0.8))\n\n# Draw arrows between countries and capitals\nfor i in range(len(countries)):\n    plt.arrow(df['PC1'][i], df['PC2'][i], df['PC1'][i + len(countries)] - df['PC1'][i], df['PC2'][i + len(countries)] - df['PC2'][i],\n              color='gray', alpha=0.6, linewidth=1.5, head_width=0.02, head_length=0.03)\n\nplt.legend(title='Type', title_fontsize='13', fontsize='11')\nplt.title('PCA of Country and Capital Word Embeddings', fontsize=16)\nplt.xlabel('Principal Component 1', fontsize=14)\nplt.ylabel('Principal Component 2', fontsize=14)\nax = plt.gca()\nax.set_axis_off()\n\nWe can see that word2vec places the words representing countries close to each other and so do the words representing their capitals. The country-capital relationship is also roughly preserved, e.g., Germany-Berlin vector is roughly parallel to France-Paris vector.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/02-coding.html#graph-embedding-with-word2vec",
    "href": "m08-embedding/02-coding.html#graph-embedding-with-word2vec",
    "title": "Embedding Methods: Implementation and Practice",
    "section": "3 Graph Embedding with word2vec",
    "text": "3 Graph Embedding with word2vec\nHow can we apply word2vec to graph data? There is a critical challenge: word2vec takes sequence of words as input, while graph data are discrete and unordered. A solution to fill this gap is random walk, which transforms graph data into a sequence of nodes. Once we have a sequence of nodes, we can treat it as a sequence of words and apply word2vec.\n\nDeepWalk\n\nDeepWalk is one of the pioneering works to apply word2vec to graph data {footcite}perozzi2014deepwalk. It views the nodes as words and the nodes random walks on the graph as sentences, and applies word2vec to learn the node embeddings.\nMore specifically, the method contains the following steps:\n\nSample multiple random walks from the graph.\nTreat the random walks as sentences and feed them to word2vev to learn the node embeddings.\n\nThere are some technical details that we need to be aware of, which we will learn by implementing DeepWalk in the following exercise.\n\n\nExercise 01: Implement DeepWalk\nIn this exercise, we implement DeepWalk step by step.\n\nStep 1: Data preparation\nWe will use the karate club network as an example.\nLoad the data\n\n:tags: [hide-input]\n\nimport igraph\nimport networkx as nx\nimport numpy as np\nimport seaborn as sns\n\ng = igraph.Graph.Famous(\"Zachary\")\nA = g.get_adjacency_sparse()\n\n# Add the community labels to the nodes for visualization\ng.vs[\"label\"] = np.unique([d[1]['club'] for d in nx.karate_club_graph().nodes(data=True)], return_inverse=True)[1]\n\npalette = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[palette[label] for label in g.vs[\"label\"]], bbox=(300, 300))\n\n\n\nStep 2: Generate random walks\nNext, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network. Let us first implement a function to sample random walks from a given network.\n\ndef random_walk(net, start_node, walk_length):\n    # Initialize the walk with the starting node\n    walk = [start_node]\n\n    # Continue the walk until the desired length is reached\n    while len(walk) &lt; walk_length:\n        # Get the current node (the last node in the walk)\n        cur = walk[-1]\n\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n\n        # If the current node has neighbors, randomly choose one and add it to the walk\n        if len(cur_nbrs) &gt; 0:\n            walk.append(np.random.choice(cur_nbrs))\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    # Return the generated walk\n    return walk\n\nGenerate 10 random walks of length 50 starting from each node.\n\nn_nodes = g.vcount()\nn_walkers_per_node = 10\nwalk_length = 50\nwalks = []\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(random_walk(A, i, walk_length))\n\n\n\nStep 3: Train the word2vec model\nThen, we feed the random walks to the word2vec model.\n\nfrom gensim.models import Word2Vec\n\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\nHere,\n\nvector_size is the dimension of the embedding vectors.\nwindow indicates the maximum distance between a word and its context words. For example, in the random walk [0, 1, 2, 3, 4, 5, 6, 7], the context words of node 2 are [0, 1, 3, 4, 5] when window=3.\nmin_count is the minimum number of times a word must appear in the training data to be included in the vocabulary.\n\nTwo parameters sg=1 and hs=1 indicate that we are using the skip-gram model with negative sampling. Let us understand what they mean in detail as follows.\n\nSkip-gram model: it trains word2vec by predicting context words given a target word. For example, given the sentence “The quick brown fox jumps over the lazy dog”, in the skip-gram model, given the target word “fox”, the model will try to predict the context words “quick”, “brown”, “jumps”, and “over”. If sg=0, the input and output are swapped: the model will predict the target word from the context words, e.g., given the context words “quick”, “brown”, “jumps”, and “over”, the model will predict the target word “fox”.\nHierarchical softmax: To understand hierarchical softmax better, let’s break down how the word2vec model works. The goal of word2vec is to predict context words given a target word. For example, if our target word is w_t and our context word is w_c, we want to find the probability of w_c given w_t. This probability is calculated using the softmax function:\n\n  P(w_c | w_t) = \\frac{\\exp(\\mathbf{v}_{w_c} \\cdot \\mathbf{v}_{w_t})}{\\sum_{w \\in V} \\exp(\\mathbf{v}_w \\cdot \\mathbf{u}_{w_t})}\n\nHere, \\mathbf{v}_w and \\mathbf{u}_w represent the vector for word w as context and target respectively, and V is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!\nHierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.\n\n\nBy using the skip-gram model with hierarchical softmax, we can efficiently learn high-quality word embeddings even when dealing with large vocabularies.\nNow, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the wv attribute. The embedding of node i is given by model.wv[i].\n\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\nembedding is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.\nPrint the first 3 nodes\n\n:tags: [hide-input]\n\nembedding[:3]\n\nLet’s visualize the node embeddings using UMAP.\n\n:tags: [hide-input]\nimport umap\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource, HoverTool\n\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nshow(p)\n\n\n\nStep 4: Clustering\nOne of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as K-means and Gaussian mixture model. Let’s see what we can get from the node embeddings.\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Determine the optimal number of clusters using the silhouette score\ndef Kmeans_with_silhouette(embedding, n_clusters_range=(2, 10)):\n    silhouette_scores = []\n\n    # Iterate over a range of cluster numbers from 2 to 9\n    for n_clusters in range(*n_clusters_range):\n        # Create a KMeans object with the current number of clusters\n        kmeans = KMeans(n_clusters=n_clusters)\n\n        # Fit the KMeans model to the embedding data\n        kmeans.fit(embedding)\n\n        # Calculate the silhouette score for the current clustering\n        score = silhouette_score(embedding, kmeans.labels_)\n\n        # Append the number of clusters and its corresponding silhouette score to the list\n        silhouette_scores.append((n_clusters, score))\n\n    # Find the number of clusters that has the highest silhouette score\n    optimal_n_clusters = max(silhouette_scores, key=lambda x: x[1])[0]\n\n    # Create a KMeans object with the optimal number of clusters\n    kmeans = KMeans(n_clusters=optimal_n_clusters)\n\n    # Fit the KMeans model to the embedding data with the optimal number of clusters\n    kmeans.fit(embedding)\n\n    # Return the labels (cluster assignments) for each data point\n    return kmeans.labels_\n\n\nimport seaborn as sns\nlabels = Kmeans_with_silhouette(embedding)\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500))\n\n\n\n\nnode2vec\nnode2vec is a sibling of DeepWalk proposed by {footcite}grover2016node2vec. Both use word2vec trained on random walks on networks. So, it appears that they are very similar. However, the following two components make them very different.\n\nBiased random walk: node2vec uses biased random walks that can move in different directions. The bias walk is parameterized by two parameters, p and q:\n\n  P(v_{t+1} = x | v_t = v, v_{t-1} = t) \\propto\n  \\begin{cases}\n  \\frac{1}{p} & \\text{if } d(v,t) = 0 \\\\\n  1 & \\text{if } d(v,t) = 1 \\\\\n  \\frac{1}{q} & \\text{if } d(v,t) = 2 \\\\\n  \\end{cases}\n  \nwhere d(v,x) is the shortest path distance between node v and x. A smaller p leads to more biased towards the previous node, v_{t-1} = t. A smaller q leads to more biased towards the nodes that are further away from the previous node, v_{t-1} = t.\nBy adjusting the parameters p and q, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).\n\nBreadth-First Sampling (BFS): This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.\nDepth-First Sampling (DFS): This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.\n\n\nThe embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.\n\nNegative sampling: node2vec uses negative sampling, instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to {footcite}kojaku2021neurips and {footcite}dyer2014notes for more details.\n\n\n\nExercise 02: Implement node2vec\nLet’s implement the biased random walk for node2vec\n\ndef node2vec_random_walk(net, start_node, walk_length, p, q):\n    \"\"\"\n    Sample a random walk starting from start_node.\n    \"\"\"\n    # Initialize the walk with the start_node\n    walk = [start_node]\n\n    # Continue the walk until it reaches the desired length\n    while len(walk) &lt; walk_length:\n        # Get the current node in the walk\n        cur = walk[-1]\n        # Get the neighbors of the current node\n        cur_nbrs = list(net[cur].indices)\n        # Check if the current node has any neighbors\n        if len(cur_nbrs) &gt; 0:\n            # If the walk has just started, randomly choose the next node from the neighbors\n            if len(walk) == 1:\n                walk.append(np.random.choice(cur_nbrs))\n            else:\n                # Get the previous node in the walk\n                prev = walk[-2]\n                # Use the alias sampling method to choose the next node based on the bias parameters p and q\n                next_node = alias_sample(net, cur_nbrs, prev, p, q)\n                # Append the chosen next node to the walk\n                walk.append(next_node)\n        else:\n            # If the current node has no neighbors, terminate the walk\n            break\n\n    return walk\n\ndef alias_sample(net, neighbors, prev, p, q):\n    \"\"\"\n    Helper function to sample the next node in the walk.\n    \"\"\"\n    # Implement the logic to sample the next node based on the bias parameters p and q\n    # You can use the formula provided in the instructions to calculate the probabilities\n    # and then sample the next node accordingly.\n    # Initialize an empty list to store the unnormalized probabilities for each neighbor\n    unnormalized_probs = []\n\n    # Iterate over each neighbor of the current node\n    for neighbor in neighbors:\n        # If the neighbor is the same as the previous node in the walk\n        if neighbor == prev:\n            # Append the probability 1/p to the unnormalized probabilities list\n            unnormalized_probs.append(1 / p)\n        # If the neighbor is connected to the previous node in the walk\n        elif neighbor in net[prev].indices:\n            # Append the probability 1 to the unnormalized probabilities list\n            unnormalized_probs.append(1)\n        # If the neighbor is not connected to the previous node in the walk\n        else:\n            # Append the probability 1/q to the unnormalized probabilities list\n            unnormalized_probs.append(1 / q)\n\n    # Calculate the normalization constant by summing all unnormalized probabilities\n    norm_const = sum(unnormalized_probs)\n\n    # Normalize the probabilities by dividing each unnormalized probability by the normalization constant\n    normalized_probs = [float(prob) / norm_const for prob in unnormalized_probs]\n\n    # Randomly choose the next node from the neighbors based on the normalized probabilities\n    next_node = np.random.choice(neighbors, size=1, p=normalized_probs)[0]\n\n    # Return the chosen next node\n    return next_node\n\nNow, let’s set up the word2vec model for node2vec.\n\nwalks = []\np = 1\nq = 0.1\nfor i in range(n_nodes):\n    for _ in range(n_walkers_per_node):\n        walks.append(node2vec_random_walk(A, i, walk_length, p, q))\nmodel = Word2Vec(walks, vector_size=32, window=3, min_count=1, sg=1, hs = 1)\n\nwhere hs=0 indicates that we are using negative sampling. Notice that we set sg=1 and hs=1 instead of sg=1 and hs=0 in DeepWalk. This is because node2vec uses the skip-gram model with negative sampling.\nNow, we extract the node embeddings from the word2vec model.\n\nembedding = []\nfor i in range(n_nodes):\n    embedding.append(model.wv[i])\nembedding = np.array(embedding)\n\nLet’s visualize the node embeddings from node2vec.\n\n:tags: [hide-input]\n\nreducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, metric=\"cosine\")\nxy = reducer.fit_transform(embedding)\n\noutput_notebook()\n\n# Calculate the degree of each node\ndegrees = A.sum(axis=1).A1\n\nsource = ColumnDataSource(data=dict(\n    x=xy[:, 0],\n    y=xy[:, 1],\n    size=np.sqrt(degrees / np.max(degrees)) * 30,\n    community=[palette[label] for label in g.vs[\"label\"]],\n    name = [str(i) for i in range(n_nodes)]\n))\n\np = figure(title=\"Node Embeddings from Word2Vec\", x_axis_label=\"X\", y_axis_label=\"Y\")\n\np.scatter('x', 'y', size='size', source=source, line_color=\"black\", color=\"community\")\n\nhover = HoverTool()\nhover.tooltips = [\n    (\"Name\", \"@name\"),\n    (\"Community\", \"@community\")\n]\np.add_tools(hover)\n\nshow(p)\n\nThe results for clustering are as follows:\n\nimport seaborn as sns\n\nlabels = Kmeans_with_silhouette(embedding)\n\n\ncmap = sns.color_palette().as_hex()\nigraph.plot(g, vertex_color=[cmap[label] for label in labels], bbox=(500, 500), vertex_label=[\"%d\" %  d for d in  np.arange(n_nodes)])\n\n\n\nLINE\nLINE {footcite}tang2015line is another pioneering work to learn node embeddings by directly optimizing the graph structure. It is equivalent to node2vec with p=1, q=1, and window size 1.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/spectral-embedding.html",
    "href": "m08-embedding/spectral-embedding.html",
    "title": "Spectral Embedding",
    "section": "",
    "text": "Networks are a high-dimensional discrete data that can be difficult to analyze with traditional machine learning methods that assume continuous and smooth data. Spectral embedding is a technique to embed networks into low-dimensional spaces.\nLet us approach the spectral embedding from the perspective of network compression. Suppose we have an adjacency matrix \\mathbf{A} of a network. The adjacency matrix is a high-dimensional data, i.e., a matrix has size N \\times N for a network of N nodes. We want to compress it into a lower-dimensional matrix \\mathbf{U} of size N \\times d for a user-defined small integer d &lt; N. A good \\mathbf{U} should preserve the network structure and thus can reconstruct the original data \\mathbf{A} as closely as possible. This leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nwhere:\n\n\\mathbf{U}\\mathbf{U}^\\top is the outer product of \\mathbf{U} and represents the reconstructed network.\n\\|\\cdot\\|_F is the Frobenius norm, which is the sum of the squares of the elements in the matrix.\nJ(\\mathbf{U}) is the loss function that measures the difference between the original network \\mathbf{A} and the reconstructed network \\mathbf{U}\\mathbf{U}^\\top.\n\nBy minimizing the Frobenius norm with respect to \\mathbf{U}, we obtain the best low-dimensional embedding of the network.\n\n\nLet us first understand the solution intuitively. Consider the spectral decomposition of \\mathbf{A}:\n\n\\mathbf{A} = \\sum_{i=1}^N \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top\n\nwhere \\lambda_i are weights and \\mathbf{u}_i are column vectors. Each term \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top is a rank-one matrix that captures a part of the network’s structure. The larger the weight \\lambda_i, the more important that term is in describing the network.\nTo compress the network, we can select the d terms with the largest weights \\lambda_i. By combining the corresponding \\mathbf{u}_i vectors into a matrix \\mathbf{U}, we obtain a good low-dimensional embedding of the network.\n\nFor a formal proof, please refer to the Appendix section.\n\n\n\nLet us demonstrate the results with a simple example as follows.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a small example network\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).toarray()\nlabels = np.unique([d[1]['club'] for d in G.nodes(data=True)], return_inverse=True)[1]\ncmap = sns.color_palette()\nnx.draw(G, with_labels=False, node_color=[cmap[i] for i in labels])\n\n\n:tags: [hide-input]\n\n# Compute the spectral decomposition\neigvals, eigvecs = np.linalg.eig(A)\n\n# Find the top d eigenvectors\nd = 2\nsorted_indices = np.argsort(eigvals)[::-1][:d]\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n# Plot the results\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Spectral Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nInterestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes. The second eigenvector captures the community structure of the network, clearly separating the two communities in the network."
  },
  {
    "objectID": "m08-embedding/spectral-embedding.html#network-compression",
    "href": "m08-embedding/spectral-embedding.html#network-compression",
    "title": "Spectral Embedding",
    "section": "",
    "text": "Networks are a high-dimensional discrete data that can be difficult to analyze with traditional machine learning methods that assume continuous and smooth data. Spectral embedding is a technique to embed networks into low-dimensional spaces.\nLet us approach the spectral embedding from the perspective of network compression. Suppose we have an adjacency matrix \\mathbf{A} of a network. The adjacency matrix is a high-dimensional data, i.e., a matrix has size N \\times N for a network of N nodes. We want to compress it into a lower-dimensional matrix \\mathbf{U} of size N \\times d for a user-defined small integer d &lt; N. A good \\mathbf{U} should preserve the network structure and thus can reconstruct the original data \\mathbf{A} as closely as possible. This leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J(\\mathbf{U}),\\quad J(\\mathbf{U}) = \\| \\mathbf{A} - \\mathbf{U}\\mathbf{U}^\\top \\|_F^2\n\nwhere:\n\n\\mathbf{U}\\mathbf{U}^\\top is the outer product of \\mathbf{U} and represents the reconstructed network.\n\\|\\cdot\\|_F is the Frobenius norm, which is the sum of the squares of the elements in the matrix.\nJ(\\mathbf{U}) is the loss function that measures the difference between the original network \\mathbf{A} and the reconstructed network \\mathbf{U}\\mathbf{U}^\\top.\n\nBy minimizing the Frobenius norm with respect to \\mathbf{U}, we obtain the best low-dimensional embedding of the network.\n\n\nLet us first understand the solution intuitively. Consider the spectral decomposition of \\mathbf{A}:\n\n\\mathbf{A} = \\sum_{i=1}^N \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top\n\nwhere \\lambda_i are weights and \\mathbf{u}_i are column vectors. Each term \\lambda_i \\mathbf{u}_i \\mathbf{u}_i^\\top is a rank-one matrix that captures a part of the network’s structure. The larger the weight \\lambda_i, the more important that term is in describing the network.\nTo compress the network, we can select the d terms with the largest weights \\lambda_i. By combining the corresponding \\mathbf{u}_i vectors into a matrix \\mathbf{U}, we obtain a good low-dimensional embedding of the network.\n\nFor a formal proof, please refer to the Appendix section.\n\n\n\nLet us demonstrate the results with a simple example as follows.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a small example network\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).toarray()\nlabels = np.unique([d[1]['club'] for d in G.nodes(data=True)], return_inverse=True)[1]\ncmap = sns.color_palette()\nnx.draw(G, with_labels=False, node_color=[cmap[i] for i in labels])\n\n\n:tags: [hide-input]\n\n# Compute the spectral decomposition\neigvals, eigvecs = np.linalg.eig(A)\n\n# Find the top d eigenvectors\nd = 2\nsorted_indices = np.argsort(eigvals)[::-1][:d]\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\n# Plot the results\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Spectral Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nInterestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes. The second eigenvector captures the community structure of the network, clearly separating the two communities in the network."
  },
  {
    "objectID": "m08-embedding/spectral-embedding.html#modularity-embedding",
    "href": "m08-embedding/spectral-embedding.html#modularity-embedding",
    "title": "Spectral Embedding",
    "section": "2 Modularity embedding",
    "text": "2 Modularity embedding\nIn a similar vein, we can use the modularity matrix to generate a low-dimensional embedding of the network. Namely, let us define the modularity matrix \\mathbf{Q} as follows:\n\nQ_{ij} = \\frac{1}{2m}A_{ij} - \\frac{k_i k_j}{4m^2}\n\nwhere k_i is the degree of node i, and m is the number of edges in the network.\nWe then compute the eigenvectors of \\mathbf{Q} and use them to embed the network into a low-dimensional space just as we did for the adjacency matrix.\n\n:tags: [hide-input]\n\ndeg = np.sum(A, axis=1)\nm = np.sum(deg) / 2\nQ = A - np.outer(deg, deg) / (2 * m)\nQ/= 2*m\n\neigvals, eigvecs = np.linalg.eig(Q)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(-eigvals)[:d]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Modularity Embedding')\nax.set_xlabel('Eigenvector 1')\nax.set_ylabel('Eigenvector 2')\nplt.show()\n\nThe modularity embedding can be used to bipartition the network into two communities using a simple algorithm: group nodes with the same sign of the second eigenvector {footcite}`newman2006modularity`."
  },
  {
    "objectID": "m08-embedding/spectral-embedding.html#laplacian-eigenmap",
    "href": "m08-embedding/spectral-embedding.html#laplacian-eigenmap",
    "title": "Spectral Embedding",
    "section": "3 Laplacian Eigenmap",
    "text": "3 Laplacian Eigenmap\nLaplacian Eigenmap {footcite}belkin2003laplacian is another approach to compress a network into a low-dimensional space. The fundamental idea behind this method is to position connected nodes close to each other in the low-dimensional space. This approach leads to the following optimization problem:\n\n\\min_{\\mathbf{U}} J_{LE}(\\mathbf{U}),\\quad J_{LE}(\\mathbf{U}) = \\frac{1}{2}\\sum_{i,j} A_{ij} \\| u_i - u_j \\|^2\n\nIn this equation, \\| u_i - u_j \\|^2 represents the squared distance between nodes i and j in the low-dimensional space. The goal is to minimize this distance for connected nodes (where A_{ij} = 1). The factor \\frac{1}{2} is included for mathematical convenience in later calculations.\nTo solve this optimization problem, we rewrite J_{LE}(\\mathbf{U}) as follows:\n\n\\begin{aligned}\nJ_{LE}(\\mathbf{U}) &= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\| u_i - u_j \\|^2 \\\\\n&= \\frac{1}{2}\\sum_{i}\\sum_{j} A_{ij} \\left( \\| u_i \\|^2 - 2 u_i^\\top u_j + \\| u_j \\|^2 \\right) \\\\\n&= \\sum_{i}\\sum_{j} A_{ij} \\| u_i \\|^2 - \\sum_{i}\\sum_{j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i} k_i \\| u_i \\|^2 - \\sum_{i,j} A_{ij} u_i^\\top u_j\\\\\n&= \\sum_{i,j} L_{ij} u_i^\\top u_j\n\\end{aligned}\n\nwhere\n\nL_{ij} = \\begin{cases}\nk_i & \\text{if } i = j \\\\\n-A_{ij} & \\text{if } i \\neq j\n\\end{cases}\n\nLet us go through the derivation step by step.\n\nIn the first step (i.e., the second line), we expand the squared norm using the vector identity \\|a-b\\|^2 = \\|a\\|^2 - 2a^\\top b + \\|b\\|^2.\nIn the second step (i.e., the third line), we distribute the sum and the factor \\frac{1}{2}. The middle term gets a factor of 1 because it appears twice in the expansion (once for i,j and once for j,i), canceling out the \\frac{1}{2}. Note that the term A_{ij} is symmetric, i.e., A_{ij} = A_{ji}.\nIn the third step (i.e., the fourth line), we recognize that \\sum_j A_{ij} is the degree of node i, which we denote as k_i.\nFinally, we combine the terms by using the Laplacian matrix \\mathbf{L}.\n\nThe minimization problem can be rewritten as:\n\nJ_{LE}(\\mathbf{U}) = \\text{Tr}(\\mathbf{U}^\\top \\mathbf{L} \\mathbf{U})\n\nwhere\n\n\\mathbf{U} =\n\\begin{bmatrix}\n\\mathbf{u}_1 ^\\top \\\\\n\\mathbf{u}_2 ^\\top \\\\\n\\vdots \\\\\n\\mathbf{u}_N ^\\top \\\\\n\\end{bmatrix}\n\nSee the Appendix section for the detailed derivation.\nBy taking the derivative of J_{LE}(\\mathbf{U}) with respect to \\mathbf{U} and set it to zero, we obtain the following equation:\n\n\\frac{\\partial J_{LE}}{\\partial \\mathbf{U}} = 0 \\implies \\mathbf{L} \\mathbf{U} = \\lambda \\mathbf{U}\n\nThe solution is the d eigenvectors associated with the d smallest eigenvalues of \\mathbf{L}.\nIt is important to note that the eigenvector corresponding to the smallest eigenvalue (which is always zero for connected graphs) is trivial - it’s the all-one vector. Therefore, in practice, we typically compute the d+1 smallest eigenvectors and discard the one corresponding to the zero eigenvalue.\n\nAn example for the Laplacian Eigenmap\nLet us first compute the Laplacian matrix and its eigenvectors.\n\n:tags: [hide-input]\n\nD = np.diag(np.sum(A, axis=1))\nL = D - A\n\neigvals, eigvecs = np.linalg.eig(L)\n\n# Sort the eigenvalues and eigenvectors\nsorted_indices = np.argsort(eigvals)[1:d+1]  # Exclude the first eigenvector\neigvals = eigvals[sorted_indices]\neigvecs = eigvecs[:, sorted_indices]\n\nThe eigenvectors corresponding to the d smallest eigenvalues are:\n\n:tags: [hide-input]\n\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.scatterplot(x = eigvecs[:, 0], y = eigvecs[:, 1], hue=labels, ax=ax)\nax.set_title('Laplacian Eigenmap')\nax.set_xlabel('Eigenvector 2')\nax.set_ylabel('Eigenvector 3')\nplt.show()"
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html",
    "href": "m09-graph-neural-networks/02-coding.html",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "",
    "text": "Graph Neural Networks are a type of neural network for graph data. node2vec and deepwalk stem from the idea of language modeling. In this module, we will focus on another branch of graph neural networks that stem from image processing.\n\n\nEdge detection is a classical problem in image processing. The goal is to identify the boundaries of objects in an image.\n\nTo approach the problem, let us first remind that an image is a matrix of pixels. Each pixel has RGB values, each of which represents the intensity of red, green, and blue color. To simplify the problem, we focus on grayscale images, in which each pixel has only one value representing the brightness. In this case, an image can be represented as a 2D matrix, where each element in the matrix represents the brightness of a pixel.\n\n\n\n\nHuman eyes are very sensitive to brightness changes. An edge in an image appears when there is a significant brightness change between adjacent pixels. To be more concrete, let’s consider a small example consisting of 6x6 pixels, with a vertical line from the top to the bottom, where the brightness is higher than the neighboring pixels. This is an edge we want to detect.\n\nX = \\begin{bmatrix}\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10\n\\end{bmatrix}\n\nLet’s zoom on the pixel at (3, 3) and its surrounding pixels.\n\nZ = \\begin{bmatrix}\n10 & 80 & 10 \\\\\n\\textcolor{blue}{10} & \\textcolor{red}{80} & \\textcolor{purple}{10} \\\\\n10 & 80 & 10\n\\end{bmatrix}\n\nwhere the central pixel is highlighted in red. Since we are interested in the edge which is a sudden change in brightness along the horizontal direction, we take a derivative at the central pixel by\n\n\\nabla Z_{22} = \\textcolor{blue}{Z_{2,1}} - \\textcolor{purple}{Z_{2,3}}\n\nFollowing the same process, we can compute the derivative at all pixels, which gives us the (horizontal) derivative of the image.\n\n\\begin{bmatrix}\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & -\n\\end{bmatrix}\n\nThe symbol - indicates that the derivative is not defined because one of the neighboring pixels is out of the image boundary. We observe that the derivative is high at the edge and low elsewhere. This is a simple but effective way to detect edges in an image.\nWe can consider a derivative operator along the vertical direction that computes the difference between the vertical neighboring pixels.\n\n\\nabla Z_{22} = Z_{1,2} - Z_{3,2}\n\nAnd, when applied to the entire image, the result is\n\n\\begin{bmatrix}\n- & - & - & - & -  & - \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n- & - & - & - & - & -\n\\end{bmatrix}\n\nThe all entries are zero, meaning that there is no edge in the vertical direction.\nWe can combine the horizontal and vertical derivatives to get the gradient of the image. For example,\n\n\\nabla Z_{22} = Z_{12} - Z_{32} + Z_{21} - Z_{23}\n\nWhen applied to the entire image, the result is the same as the horizontal derivative.\n\n\n\nWe observe that there is a repeated pattern in the derivative computation: we are taking addition and subtraction of neighbiring pixels. This motivates us to generalize the operation to a more general form.\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j}\n\nwhere K is a 3 \\times 3 matrix, and w=h=3 represent the width and height of the kernel.\n\nK_{\\text{horizontal}} = \\begin{bmatrix}\n0 & 0 & 0 \\\\\n-1 & 0 & 1 \\\\\n0 & 0 & 0\n\\end{bmatrix},\\quad\nK_{\\text{vertical}} = \\begin{bmatrix}\n0 & -1 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{bmatrix}\n\nThe operation of K on the image is called convolution, and K is called the kernel or filter. More generally, the convolution of a kernel K and an image X is defined as\n\nY_{ij} = \\sum_{p}\\sum_{q} K_{pq} X_{i+p-\\frac{h+1}{2}, j+q-\\frac{w+1}{2}}\n\nwhere h and w are the height and width of the kernel, respectively.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#preliminaries-image-processing",
    "href": "m09-graph-neural-networks/02-coding.html#preliminaries-image-processing",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "",
    "text": "Graph Neural Networks are a type of neural network for graph data. node2vec and deepwalk stem from the idea of language modeling. In this module, we will focus on another branch of graph neural networks that stem from image processing.\n\n\nEdge detection is a classical problem in image processing. The goal is to identify the boundaries of objects in an image.\n\nTo approach the problem, let us first remind that an image is a matrix of pixels. Each pixel has RGB values, each of which represents the intensity of red, green, and blue color. To simplify the problem, we focus on grayscale images, in which each pixel has only one value representing the brightness. In this case, an image can be represented as a 2D matrix, where each element in the matrix represents the brightness of a pixel.\n\n\n\n\nHuman eyes are very sensitive to brightness changes. An edge in an image appears when there is a significant brightness change between adjacent pixels. To be more concrete, let’s consider a small example consisting of 6x6 pixels, with a vertical line from the top to the bottom, where the brightness is higher than the neighboring pixels. This is an edge we want to detect.\n\nX = \\begin{bmatrix}\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10 \\\\\n10 & 10 & 80 & 10 & 10 & 10\n\\end{bmatrix}\n\nLet’s zoom on the pixel at (3, 3) and its surrounding pixels.\n\nZ = \\begin{bmatrix}\n10 & 80 & 10 \\\\\n\\textcolor{blue}{10} & \\textcolor{red}{80} & \\textcolor{purple}{10} \\\\\n10 & 80 & 10\n\\end{bmatrix}\n\nwhere the central pixel is highlighted in red. Since we are interested in the edge which is a sudden change in brightness along the horizontal direction, we take a derivative at the central pixel by\n\n\\nabla Z_{22} = \\textcolor{blue}{Z_{2,1}} - \\textcolor{purple}{Z_{2,3}}\n\nFollowing the same process, we can compute the derivative at all pixels, which gives us the (horizontal) derivative of the image.\n\n\\begin{bmatrix}\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & - \\\\\n- & -70 & 0 & 70 & 0 & -\n\\end{bmatrix}\n\nThe symbol - indicates that the derivative is not defined because one of the neighboring pixels is out of the image boundary. We observe that the derivative is high at the edge and low elsewhere. This is a simple but effective way to detect edges in an image.\nWe can consider a derivative operator along the vertical direction that computes the difference between the vertical neighboring pixels.\n\n\\nabla Z_{22} = Z_{1,2} - Z_{3,2}\n\nAnd, when applied to the entire image, the result is\n\n\\begin{bmatrix}\n- & - & - & - & -  & - \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n- & - & - & - & - & -\n\\end{bmatrix}\n\nThe all entries are zero, meaning that there is no edge in the vertical direction.\nWe can combine the horizontal and vertical derivatives to get the gradient of the image. For example,\n\n\\nabla Z_{22} = Z_{12} - Z_{32} + Z_{21} - Z_{23}\n\nWhen applied to the entire image, the result is the same as the horizontal derivative.\n\n\n\nWe observe that there is a repeated pattern in the derivative computation: we are taking addition and subtraction of neighbiring pixels. This motivates us to generalize the operation to a more general form.\n\n\\nabla Z_{22} = \\sum_{i=-1}^1 \\sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j}\n\nwhere K is a 3 \\times 3 matrix, and w=h=3 represent the width and height of the kernel.\n\nK_{\\text{horizontal}} = \\begin{bmatrix}\n0 & 0 & 0 \\\\\n-1 & 0 & 1 \\\\\n0 & 0 & 0\n\\end{bmatrix},\\quad\nK_{\\text{vertical}} = \\begin{bmatrix}\n0 & -1 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{bmatrix}\n\nThe operation of K on the image is called convolution, and K is called the kernel or filter. More generally, the convolution of a kernel K and an image X is defined as\n\nY_{ij} = \\sum_{p}\\sum_{q} K_{pq} X_{i+p-\\frac{h+1}{2}, j+q-\\frac{w+1}{2}}\n\nwhere h and w are the height and width of the kernel, respectively.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#from-image-to-graph",
    "href": "m09-graph-neural-networks/02-coding.html#from-image-to-graph",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "2 From Image to Graph",
    "text": "2 From Image to Graph\n\nAnalogy between image and graph data\nWe can think of a convolution of an image from the perspective of networks. In the convolution of an image, a pixel is convolved with its neighbors. We can regard each pixel as a node, and each node is connected to its neighboring nodes (pixels) that are involved in the convolution.\n\nBuilding on this analogy, we can extend the idea of convolution to general graph data. Each node has a pixel value(s) (e.g., feature vector), which is convolved with the values of its neighbors in the graph. This is the key idea of graph convolutional networks. But, there is a key difference: while the number of neighbors for an image is homogeneous, the number of neighbors for a node in a graph can be heterogeneous. Each pixel has the same number of neighbors (except for the boundary pixels), but nodes in a graph can have very different numbers of neighbors. This makes it non-trivial to define the “kernel” for graph convolution.\n\n\nSpectral filter on graphs\nJust like we can define a convolution on images in the frequency domain, we can also define a ‘’frequency domain’’ for graphs.\nConsider a network of N nodes, where each node has a feature variable {\\mathbf x}_i \\in \\mathbb{R}. We are interested in:\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2,\n\nwhere A_{ij} is the adjacency matrix of the graph. The quantity J represents the total variation of x between connected nodes; a small J means that connected nodes have similar x (low variation; low frequency), while a large J means that connected nodes have very different x (high variation; high frequency).\nWe can rewrite J as\n\nJ = \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 = {\\bf x}^\\top {\\bf L} {\\bf x},\n\nwhere {\\bf L} is the Laplacian matrix of the graph given by\n\nL_{ij} = \\begin{cases}\n-1 & \\text{if } i \\text{ and } j \\text{ are connected} \\\\\nk_i & \\text{if } i = j \\\\\n0 & \\text{otherwise}\n\\end{cases}.\n\nand {\\bf x} = [x_1,x_2,\\ldots, x_N]^\\top is a column vector of feature variables.\n\n\n\n\n\n\nDetailed derivation\n\n\n\n:tag: note :class: dropdown\nThe above derivation shows that the total variation of x between connected nodes is proportional to {\\bf x}^\\top {\\bf L} {\\bf x}.\n\n\\begin{aligned}\nJ &= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}(x_i - x_j)^2 \\\\\n&= \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\underbrace{A_{ij}\\left( x_i^2 +x_j^2\\right)}_{\\text{symmetric}} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2\\underbrace{\\sum_{j=1}^N A_{ij}}_{\\text{degree of node } i, k_i} - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\sum_{i=1}^Nx_i^2 k_i - \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}x_ix_j \\\\\n&= \\underbrace{[x_1,x_2,\\ldots, x_N]}_{{\\bf x}} \\underbrace{\\begin{bmatrix} k_1 & 0 & \\cdots & 0 \\\\ 0 & k_2 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & k_N \\end{bmatrix}}_{{\\bf D}} \\underbrace{\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N \\end{bmatrix}}_{{\\bf x}} - 2\\underbrace{\\sum_{i=1}^N\\sum_{j=1}^N A_{ij}}_{{\\bf x}^\\top {\\mathbf A} {\\bf x}} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf D} {\\bf x} - {\\bf x}^\\top {\\mathbf A} {\\bf x} \\\\\n&= {\\bf x}^\\top {\\bf L} {\\bf x},\n\\end{aligned}\n\n\n\nLet us showcase the analogy between the Fourier transform and the Laplacian matrix. In the Fourier transform, a signal is decomposed into sinusoidal basis functions. Similarly, for a graph, we can decompose the variation J into eigenvector bases.\n\nJ = \\sum_{i=1}^N \\lambda_i  {\\bf x}^\\top {\\mathbf u}_i {\\mathbf u}_i^\\top {\\bf x} = \\sum_{i=1}^N \\lambda_i  ||{\\bf x}^\\top {\\mathbf u}_i||^2.\n\nwhere {\\mathbf u}_i is the eigenvector corresponding to the eigenvalue \\lambda_i. - The term ({\\bf x}^\\top {\\mathbf u}_i) is a dot-product between the feature vector {\\bf x} and the eigenvector {\\mathbf u}_i, which measures how much {\\bf x} coheres with eigenvector {\\mathbf u}_i, similar to how Fourier coefficients measure coherency with sinusoids. - Each ||{\\bf x}^\\top {\\mathbf u}_i||^2 is the ‘’strength’’ of {\\bf x} with respect to the eigenvector {\\mathbf u}_i, and the total variation J is a weighted sum of these strengths.\nSome eigenvectors correspond to low-frequency components, while others correspond to high-frequency components. For example, the total variation J for an eigenvector {\\mathbf u}_i is given by\n\nJ = \\frac{1}{2} \\sum_{j}\\sum_{\\ell} A_{j\\ell}(u_{ij} - u_{i\\ell})^2 = {\\mathbf u}_i^\\top {\\mathbf L} {\\mathbf u}_i = \\lambda_i.\n\nThis equation provides key insight into the meaning of eigenvalues:\n\nFor an eigenvector {\\mathbf u}_i, its eigenvalue \\lambda_i measures the total variation for {\\mathbf u}_i.\nLarge eigenvalues mean large differences between neighbors (high frequency), while small eigenvalues mean small differences (low frequency).\n\nThus, if {\\bf x} aligns well with {\\mathbf u}_i with a large \\lambda_i, then {\\bf x} has a strong high-frequency component; if {\\bf x} aligns well with {\\mathbf u}_i with a small \\lambda_i, then {\\bf x} has strong low-frequency component.\n\n\nSpectral Filtering\nEigenvalues \\lambda_i can be thought of as a filter that controls which frequency components pass through. Instead of using the filter associated with the Laplacian matrix, we can design a filter h(\\lambda_i) to control which frequency components pass through. This leads to the idea of spectral filtering. Two common filters are:\n\nLow-pass Filter: h_{\\text{low}}(\\lambda) = \\frac{1}{1 + \\alpha\\lambda}\n\nPreserves low frequencies (small λ)\nSuppresses high frequencies (large λ)\nResults in smoother signals\n\nHigh-pass Filter: h_{\\text{high}}(\\lambda) = \\frac{\\alpha\\lambda}{1 + \\alpha\\lambda}\n\nPreserves high frequencies\nSuppresses low frequencies\nEmphasizes differences between neighbors\n\n\n\n:tags: [remove-input]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context(\"talk\")\n\nalpha = 1\nlambdas = np.linspace(0, 10, 100)\nh_low = 1 / (1 + alpha * lambdas)\nh_high = (alpha * lambdas) / (1 + alpha * lambdas)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\nsns.lineplot(x=lambdas, y=h_low, label=\"Low-pass filter\", ax=axes[0])\naxes[0].legend(frameon=False).remove()\nsns.lineplot(x=lambdas, y=h_high, label=\"High-pass filter\", ax=axes[1])\naxes[1].legend(frameon=False).remove()\naxes[0].set_title(\"Low-pass filter\")\naxes[1].set_title(\"High-pass filter\")\nfig.text(0.5, 0.01, \"Eigenvalue $\\lambda$\", ha=\"center\")\naxes[0].set_ylabel(\"Filter response $h(\\lambda)$\")\nsns.despine()\nplt.tight_layout()\n\n\n\nExample\nLet us showcase the idea of spectral filtering with a simple example with the karate club network.\n\n:tags: [remove-input]\nimport igraph as ig\nimport numpy as np\nfrom scipy import sparse\nimport matplotlib as mpl\n\nG = ig.Graph.Famous(\"Zachary\")\nA = G.get_adjacency_sparse()\n\nWe will first compute the laplacian matrix and its eigendecomposition.\n\n# Compute Laplacian matrix\ndeg = np.array(A.sum(axis=1)).reshape(-1)\nD = sparse.diags(deg)\nL = D - A\n\n# Compute eigendecomposition\nevals, evecs = np.linalg.eigh(L.toarray())\n\n# Sort eigenvalues and eigenvectors\norder = np.argsort(evals)\nevals = evals[order]\nevecs = evecs[:, order]\n\nNow, let’s create a low-pass and high-pass filter.\n\nalpha = 2\nL_low = evecs @ np.diag(1 / (1 + alpha * evals)) @ evecs.T\nL_high = evecs @ np.diag(alpha * evals / (1 + alpha * evals)) @ evecs.T\n\nprint(\"Size of low-pass filter:\", L_low.shape)\nprint(\"Size of high-pass filter:\", L_high.shape)\n\nNotice that the high-pass filter and low-pass filter are matrices of the same size as the adjacency matrix A, which defines a ‘convolution’ on the graph as follows:\n\n{\\bf x}' = {\\bf L}_{\\text{low}} {\\bf x} \\quad \\text{or} \\quad {\\bf x}' = {\\bf L}_{\\text{high}} {\\bf x}.\n\nwhere {\\bf L}_{\\text{low}} and {\\bf L}_{\\text{high}} are the low-pass and high-pass filters, respectively, and {\\bf x}' is the convolved feature vector.\nNow, let’s see how these filters work. Our first example is a random feature vector.\n\n# Random feature vector\nx = np.random.randn(A.shape[0], 1)\n\n# Convolve with low-pass filter\nx_low = L_low @ x\n\n# Convolve with high-pass filter\nx_high = L_high @ x\n\nLet us visualize the results.\n\n:tags: [hide-input]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\nnorm = mpl.colors.Normalize(vmin=-0.3, vmax=0.3)\n\n# Original\nvalues = x.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\n# Low-pass filter applied\nvalues = L_low @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\n# High-pass filter applied\nvalues = L_high @ x\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\nWe observe that the low-pass filter results in smoother {\\bf x} between connected nodes (i.e., neighboring nodes have similar {\\bf x}). The original {\\bf x} and {\\bf x}'_{\\text{low}} are very similar because random variables are high-frequency components. In contrast, when we apply the high-pass filter, {\\bf x}'_{\\text{high}} is similar to {\\bf x} because the high-frequency components are not filtered.\nLet’s now use an eigenvector as our feature vector {\\bf x}.\n\n:tags: [hide-input]\neigen_centrality = np.array(G.eigenvector_centrality()).reshape(-1, 1)\nlow_pass_eigen = L_low @ eigen_centrality\nhigh_pass_eigen = L_high @ eigen_centrality\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\npalette = sns.color_palette(\"viridis\", as_cmap=True)\n\nnorm = mpl.colors.Normalize(vmin=-0, vmax=0.3)\nvalues = eigen_centrality.reshape(-1)# high_pass_random.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[0])\naxes[0].set_title(\"Original\")\n\nvalues = low_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nvalues = values.reshape(-1)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[1])\naxes[1].set_title(\"Low-pass filter\")\n\nvalues = high_pass_eigen.reshape(-1)\nvalues /= np.linalg.norm(values)\nig.plot(G, vertex_color=[palette(norm(x)) for x in values], bbox=(0, 0, 500, 500), vertex_size=20, target=axes[2])\naxes[2].set_title(\"High-pass filter\")\nfig.tight_layout()\n\nThe high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#graph-convolutional-networks",
    "href": "m09-graph-neural-networks/02-coding.html#graph-convolutional-networks",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "3 Graph Convolutional Networks",
    "text": "3 Graph Convolutional Networks\nWe have seen that spectral filters give us a principled way to think about “convolution” on irregular graph structures, and controlling the frequency components brings out different aspects of the data. We now go one step further: instead of designing filters by hand, we can learn them from data for specific tasks.\n\nSpectral Graph Convolutional Networks\nA simplest form of learnable spectral filter is given by\n\n{\\bf L}_{\\text{learn}} = \\sum_{k=1}^K \\theta_k {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\nwhere {\\mathbf u}_k are the eigenvectors and \\theta_k are the learnable parameters. The variable K is the number of eigenvectors used (i.e., the rank of the filter). The weight \\theta_k is learned to maximize the performance of the task at hand.\nBuilding on this idea, {footcite}bruna2014spectral added a nonlinearity to the filter and proposed a spectral convolutional neural network (GCN) by\n\n{\\bf x}^{(\\ell+1)} = h\\left( L_{\\text{learn}} {\\bf x}^{(\\ell)}\\right),\n\nwhere h is an activation function, and {\\bf x}^{(\\ell)} is the feature vector of the \\ell-th convolution. They further extend this idea to convolve on multidimensional feature vectors, {\\bf X} \\in \\mathbb{R}^{N \\times f_{\\text{in}}} to produce new feature vectors of different dimensionality, {\\bf X}' \\in \\mathbb{R}^{N \\times f_{\\text{out}}}.\n\n\\begin{aligned}\n{\\bf X}^{(\\ell+1)}_i &= h\\left( \\sum_j L_{\\text{learn}}^{(i,j)} {\\bf X}^{(\\ell)}_j\\right),\\quad \\text{where} \\quad L^{(i,j)}_{\\text{learn}} = \\sum_{k=1}^K \\theta_{k, (i,j)} {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\\end{aligned}\n\nNotice that the learnable filter L_{\\text{learn}}^{(i,j)} is defined for each pair of input i and output j dimensions.\nMany GCNs simple when it comes to implementation despite the complicated formula. And this is one of my ways to learn GNNs. Check out the [Appendix for the Python implementation](appendix.md).\n\n\n\nFrom Spectral to Spatial\nSpectral GCNs are mathematically elegant but have two main limitations: 1. Computational Limitation: Computing the spectra of the Laplacian is expensive {\\cal O}(N^3) and prohibitive for large graphs 2. Spatial Locality: The learned filters are not spatially localized. A node can be influenced by all other nodes in the graph.\nThese two limitations motivate the development of spatial GCNs.\n\n\nChebNet\nChebNet {footcite}defferrard2016convolutional is one of the earliest spatial GCNs that bridges the gap between spectral and spatial domains. The key idea is to leverage Chebyshev polynomials to approximate {\\bf L}_{\\text{learn}} by\n\n{\\bf L}_{\\text{learn}} \\approx \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}), \\quad \\text{where} \\quad \\tilde{{\\bf L}} = \\frac{2}{\\lambda_{\\text{max}}}{\\bf L} - {\\bf I},\n\nwhere \\tilde{{\\bf L}} is the scaled and normalized Laplacian matrix in order to have eigenvalues in the range of [-1,1]. The Chebyshev polynomials T_k(\\tilde{{\\bf L}}) transforms the eigenvalues \\tilde{{\\bf L}} to the following recursively:\n\n\\begin{aligned}\nT_0(\\tilde{{\\bf L}}) &= {\\bf I} \\\\\nT_1(\\tilde{{\\bf L}}) &= \\tilde{{\\bf L}} \\\\\nT_k(\\tilde{{\\bf L}}) &= 2\\tilde{{\\bf L}} T_{k-1}(\\tilde{{\\bf L}}) - T_{k-2}(\\tilde{{\\bf L}})\n\\end{aligned}\n\nWe then replace {\\bf L}_{\\text{learn}} in the original spectral GCN with the Chebyshev polynomial approximation:\n\n{\\bf x}^{(\\ell+1)} = h\\left( \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}){\\bf x}^{(\\ell)}\\right),\n\nwhere: - T_k(\\tilde{{\\bf L}}) applies the k-th Chebyshev polynomial to the scaled Laplacian matrix - \\theta_k are the learnable parameters - K is the order of the polynomial (typically small, e.g., K=3)\n\n\nGraph Convolutional Networks by Kipf and Welling\nWhile ChebNet offers a principled way to approximate spectral convolutions, Kipf and Welling (2017) {footcite}kipf2017semi proposed an even simpler and highly effective variant called Graph Convolutional Networks (GCN).\n\nFirst-order Approximation\nThe key departure is to use the first-order approximation of the Chebyshev polynomials.\n\ng_{\\theta'} * x \\approx \\theta'_0x + \\theta'_1(L - I_N)x = \\theta'_0x - \\theta'_1D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}x\n\nThis is crude approximation but it leads to a much simpler form, leaving only two learnable parameters, instead of K parameters in the original ChebNet.\nAdditionally, they further simplify the formula by using the same \\theta for both remaining parameters (i.e., \\theta_0 = \\theta and \\theta_1 = -\\theta). The result is the following convolutional filter:\n\ng_{\\theta} * x \\approx \\theta(I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}})x\n\nWhile this is a very simple filter, one can stack multiple layers of convolutions to perform high-order graph convolutions.\n\n\nDeep GCNs can suffer from over-smoothing\nGCN models can be deep, and when they are too deep, they start suffering from an ill-posed problem called gradient vanishing/exploding, where the gradients of the loss function becomes too small or too large to update the model parameters. It is a common problem in deep learning.\nTo facilitate the training of deep GCNs, the authors introduce a very simple trick called renormalization. The idea is to add self-connections to the graph:\n\n\\tilde{A} = A + I_N, \\quad \\text{and} \\quad \\tilde{D}_{ii} = \\sum_j \\tilde{A}_{ij}\n\nAnd use \\tilde{A} and \\tilde{D} to form the convolutional filter.\nAltogether, this leads to the following layer-wise propagation rule:\nX^{(\\ell+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}X^{(\\ell)}W^{(\\ell)})\nwhere: - X^{(\\ell)} is the matrix of node features at layer \\ell - W^{(\\ell)} is the layer’s trainable weight matrix - \\sigma is a nonlinear activation function (e.g., ReLU)\nThese simplifications offer several advantages: - Efficiency: Linear complexity in number of edges - Localization: Each layer only aggregates information from immediate neighbors - Depth: Fewer parameters allow building deeper models - Performance: Despite (or perhaps due to) its simplicity, it often outperforms more complex models\n\n\n\n\n\n\nExercise\n\n\n\n:class: note\nLet’s implement a simple GCN model for node classification. Coding Exercise",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/02-coding.html#popular-graph-neural-networks",
    "href": "m09-graph-neural-networks/02-coding.html#popular-graph-neural-networks",
    "title": "Coding: Graph Neural Networks Implementation",
    "section": "4 Popular Graph Neural Networks",
    "text": "4 Popular Graph Neural Networks\nIn this section, we will introduce three popular GNNs: GraphSAGE, Graph Attention Networks (GAT), and Graph Isomorphism Network (GIN).\n\nGraphSAGE: Sample and Aggregate\nGraphSAGE {footcite}hamilton2017graphsage introduced a different GCN that can be generalized to unseen nodes (they called it “inductive”). While previous approaches like ChebNet and GCN operate on the entire graph, GraphSAGE proposes an inductive framework that generates embeddings by sampling and aggregating features from a node’s neighborhood.\n\n\n\nKey Ideas\nGraphSAGE involves two key ideas: (1) sampling and (2) aggregation.\n\nNeighborhood Sampling\nThe key idea is the neighborhood sampling. Instead of using all neighbors, GraphSAGE samples a fixed-size set of neighbors for each node. This controls memory complexity, a key limitation of the previous GNNs.\nAnother key advantage of neighborhood sampling is that it enables GraphSAGE to handle dynamic, growing networks. Consider a citation network where new papers (nodes) are continuously added. Traditional GCNs would need to recompute filters for the entire network with each new addition. In contrast, GraphSAGE can immediately generate embeddings for new nodes by simply sampling their neighbors, without any retraining or recomputation.\n\n\nAggregation\nAnother key idea is the aggregation. GraphSAGE makes a distinction between self-information and neighborhood information. While previous GNNs treat them equally and aggregate them, GraphSAGE treats them differently. Specifically, GraphSAGE introduces an additional step: it concatenates the self-information and the neighborhood information as the input of the convolution.\n\nZ_v = \\text{CONCAT}(X_v, X_{\\mathcal{N}(v)})\n\nwhere X_v is the feature of the node itself and X_{\\mathcal{N}(v)} is the aggregation of the features of its neighbors. GraphSAGE introduces different ways to aggregate information from neighbors:\nX_{\\mathcal{N}(v)} = \\text{AGGREGATE}_k(\\{X_u, \\forall u \\in \\mathcal{N}(v)\\})\nCommon aggregation functions include: - Mean aggregator: \\text{AGGREGATE} = \\text{mean}(\\{h_u, \\forall u \\in \\mathcal{N}(v)\\}) - Max-pooling: \\text{AGGREGATE} = \\max(\\{\\sigma(W_{\\text{pool}}h_u + b), \\forall u \\in \\mathcal{N}(v)\\}) - LSTM aggregator: Apply LSTM to randomly permuted neighbors\nThe concatenated feature Z_v is normalized by the L2 norm.\n\n\\hat{Z}_v = \\frac{Z_v}{\\|Z_v\\|_2}\n\nand then fed into the convolution.\n\nX_v^k = \\sigma(W^k \\hat{Z}_v + b^k)\n\n\n\n\nGraph Attention Networks (GAT): Differentiate Individual Neighbors\nA key innovation of GraphSAGE is to treat the self and neighborhood information differently. But should all neighbors be treated equally? Graph Attention Networks (GAT) address this by letting the model learn which neighbors to pay attention to.\n\n\nAttention Mechanism\n\nThe core idea is beautifully simple: instead of using fixed weights like GCN, let’s learn attention weights \\alpha_{ij} that determine how much node i should attend to node j. These weights are computed dynamically based on node features:\n\n\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik})}\n\nwhere e_{ij} represents the importance of the edge between node i and node j. Variable e_{ij} is a learnable parameter and can be negative, and the exponential function is applied to transform it to a non-negative value, with the normalization term \\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik}) to ensure the weights sum to 1.\nHow to compute e_{ij}? One simple choice is to use a neural network with a shared weight matrix W and a LeakyReLU activation function. Specifically:\n\nLet’s focus on computing e_{ij} for node i and its neighbor j.\nWe use a shared weight matrix W to transform the features of node i and j. \n\\mathbf{\\tilde h}_i  = \\mathbf{h}_i, \\quad \\mathbf{\\tilde h}_j  = W\\mathbf{h}_j\n\nWe concatenate the transformed features and apply a LeakyReLU activation function.\n\n\ne_{ij} = \\text{LeakyReLU}(\\mathbf{a}^T[\\mathbf{\\tilde h}_i, \\mathbf{\\tilde h}_j])\n\nwhere \\mathbf{a} is a trainable parameter vector that sums the two transformed features.\nOnce we have these attention weights, the node update is straightforward - just a weighted sum of neighbor features:\n\\mathbf{h}'_i = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}{\\bf W}_{\\text{feature}}\\mathbf{h}_j\\right)\nwhere {\\bf W}_{\\text{feature}} is a trainable weight matrix. To stabilize training, GAT uses multiple attention heads and concatenates their outputs:\n\\mathbf{h}'_i = \\parallel_{k=1}^K \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}^k{\\bf W}^k_{\\text{feature}}\\mathbf{h}_j\\right)\n\n\nGraph Isomorphism Network (GIN): Differentiate the Aggregation\nGraph Isomorphism Networks (GIN) is another popular GNN that born out of a question: what is the maximum discriminative power achievable by Graph Neural Networks? The answer lies in its theoretical connection to the Weisfeiler-Lehman (WL) test, a powerful algorithm for graph isomorphism testing.\n\n\nWeisfeiler-Lehman Test\nAre two graphs structurally identical? Graph isomorphism testing determines if two graphs are structurally identical, with applications in graph classification, clustering, and other tasks.\n\nWhile the general problem has no known polynomial-time solution, the WL test is an efficient heuristic that works well in practice. The WL test iteratively refines node labels by hashing the multiset of neighboring labels\n\nThe WL test works as follows:\n\nAssign all nodes the same initial label.\nFor each node, collect the labels of all its neighbors and aggregate them into a hash (e.g., new label). For example, the top node gets {0} from its neighbors, resulting in a collection {0,0}. A new label is created via a hash function h that maps {0, {0, 0}} to a new label 1.\nRepeat the process for a fixed number of iterations or until convergence.\n\nHere is the implementation of the WL test in Python:\n\n:tags: [hide-input]\n\nimport numpy as np\nfrom scipy import sparse\n\ndef weisfeiler_lehman_test(A, num_iterations):\n    n_nodes = A.shape[0]\n    labels = np.zeros(n_nodes, dtype=int)\n    color_map = {}\n    hash_fn = lambda x: color_map.setdefault(x, len(color_map))\n    for _ in range(num_iterations):\n\n        # Go through each node\n        labels_old = labels.copy()\n        for i in range(n_nodes):\n\n            # Collect the labels of all neighbors\n            neighbors = A[i].nonzero()[1]\n            neighbor_labels = labels_old[neighbors]\n\n            # Count the frequency of each label\n            unique, counts = np.unique(neighbor_labels, return_counts=True)\n\n            # Create a hash key by converting the frequency dictionary to a string\n            hash_key = str({unique[j]: counts[j] for j in range(len(unique))})\n\n            # Create a new label by hashing the frequency dictionary\n            label = hash_fn(hash_key)\n            labels[i] = label\n\n        # Check convergence\n        unique, counts = np.unique(labels, return_counts=True)\n        unique_old, counts_old = np.unique(labels_old, return_counts=True)\n        if np.array_equal(np.sort(counts), np.sort(counts_old)):\n            break\n    return labels\n\n\nedge_list = [(0, 1), (1, 2), (2, 0), (3, 4), (4, 5), (5, 3)]\n\nA = sparse.csr_matrix(\n    ([1] * len(edge_list), ([e[0] for e in edge_list], [e[1] for e in edge_list])),\n    shape=(6, 6),\n)\nA = A + A.T\nA.sort_indices()\n\nweisfeiler_lehman_test(A, A.shape[0])\n\nAfter these iterations: - Nodes with the same label are structurally identical, meaning that they are indistinguishable unless we label them differently. - Two graphs are structurally identical if and only if they have the same node labels after the WL test.\nThe WL test is a heuristic and can fail on some graphs. For example, it cannot distinguish regular graphs with the same number of nodes and edges.\nThe WL test above is called the 1-WL test. There are higher-order WL tests that can distinguish more graphs, which are the basis of advanced GNNs.\nCheck out [this note](https://www.moldesk.net/blog/weisfeiler-lehman-isomorphism-test/)\n\n\nGIN\nGIN {footcite}xu2018how is a GNN that is based on the WL test. The key idea is to focus on the parallel between the WL test and the GNN update rule. - In the WL test, we iteratively collect the labels of neighbors and aggregate them through a hash function. - In the GraphSAGE and GAT, the labels are the nodes’ features, and the aggregation is some arithmetic operations such as mean or max.\nThe key difference is that the hash function in the WL test always distinguishes different sets of neighbors’ labels, while the aggregation in GraphSAGE and GAT does not always do so. For example, if all nodes have the same feature (e.g., all 1), the aggregation by the mean or max will result in the same value for all nodes, whereas the hash function in the WL test can still distinguish different sets of neighbors’ labels by the count of each label.\nThe resulting convolution update rule is:\n\nh_v^{(k+1)} = \\text{MLP}^{(k)}\\left((1 + \\epsilon^{(k)}) \\cdot h_v^{(k)} + \\sum_{u \\in \\mathcal{N}(v)} h_u^{(k)}\\right)\n\nwhere \\text{MLP}^{(k)} is a multi-layer perceptron (MLP) with k layers, and \\epsilon^{(k)} is a fixed or trainable parameter.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/04-appendix.html",
    "href": "m09-graph-neural-networks/04-appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Let’s first implement Bruna’s spectral GCN.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport scipy.sparse as sp\nimport torch\nimport torch.nn as nn\nimport scipy.sparse.linalg as slinalg\n\nclass BrunaGraphConv(nn.Module):\n    \"\"\"\n    Bruna's Spectral Graph Convolution Layer\n\n    This implementation follows the original formulation by Joan Bruna et al.,\n    using the eigendecomposition of the graph Laplacian for spectral convolution.\n    \"\"\"\n\n    def __init__(self, in_features, out_features, n_nodes):\n        \"\"\"\n        Initialize the Bruna Graph Convolution layer\n\n        Args:\n            in_features (int): Number of input features\n            out_features (int): Number of output features\n        \"\"\"\n        super(BrunaGraphConv, self).__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        # Learnable spectral filter parameters\n        self.weight = nn.Parameter(\n            torch.FloatTensor(in_features, out_features, n_nodes-1)\n        )\n\n        # Initialize parameters\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        \"\"\"Initialize weights using Glorot initialization\"\"\"\n        nn.init.xavier_uniform_(self.weight)\n\n\n    @staticmethod\n    def get_laplacian_eigenvectors(adj):\n        \"\"\"\n        Compute eigendecomposition of the normalized graph Laplacian\n\n        Args:\n            adj: Adjacency matrix\n\n        Returns:\n            eigenvalues, eigenvectors of the normalized Laplacian\n        \"\"\"\n        # Compute normalized Laplacian\n        # Add self-loops\n        adj = adj + sp.eye(adj.shape[0])\n\n        # Compute degree matrix\n        deg = np.array(adj.sum(axis=1))\n        Dsqrt_inv = sp.diags(1.0 / np.sqrt(deg).flatten())\n\n        # Compute normalized Laplacian: D^(-1/2) A D^(-1/2)\n        laplacian = sp.eye(adj.shape[0]) - Dsqrt_inv @ adj @ Dsqrt_inv\n\n        # Compute eigendecomposition\n        # Using k=adj.shape[0]-1 to get all non-zero eigenvalues\n        eigenvals, eigenvecs = slinalg.eigsh(laplacian.tocsc(), k=adj.shape[0]-1,which='SM', tol=1e-6)\n\n        return torch.FloatTensor(eigenvals), torch.FloatTensor(eigenvecs)\n\n    def forward(self, x, eigenvecs):\n        \"\"\"\n        Forward pass implementing Bruna's spectral convolution\n\n        Args:\n            x: Input features [num_nodes, in_features]\n            eigenvecs: Eigenvectors of the graph Laplacian [num_nodes, num_nodes-1]\n\n        Returns:\n            Output features [num_nodes, out_features]\n        \"\"\"\n        # Transform to spectral domain\n        x_spectral = torch.matmul(eigenvecs.t(), x)  # [num_nodes-1, in_features]\n\n        # Initialize output tensor\n        out = torch.zeros(x.size(0), self.out_features, device=x.device)\n\n        # For each input-output feature pair\n        for i in range(self.in_features):\n            for j in range(self.out_features):\n                # Element-wise multiplication in spectral domain\n                # This is the actual spectral filtering operation\n                filtered = x_spectral[:, i] * self.weight[i, j, :]  # [num_spectrum]\n\n                # Transform back to spatial domain and accumulate\n                out[:, j] += torch.matmul(eigenvecs, filtered)\n\n        return out\n\nNext, we will train the model on the karate club network to predict the given node labels indicating nodes’ community memberships. We load the data by\n\n:tags: [hide-input]\n\nimport networkx as nx\nimport torch\nimport matplotlib.pyplot as plt\n\n# Load karate club network\nG = nx.karate_club_graph()\nadj = nx.to_scipy_sparse_array(G)\nfeatures = torch.eye(G.number_of_nodes())\nlabels = torch.tensor([G.nodes[i]['club'] == 'Officer' for i in G.nodes()], dtype=torch.long)\n\nWe apply the convolution twice with ReLu activation in between. This can be implemented by preparing two independent BrunaGraphConv layers, applying them consecutively, and adding a ReLu activation in between.\n\n:tags: [hide-input]\n\n# Define a simple GCN model\nclass SimpleGCN(nn.Module):\n    def __init__(self, in_features, out_features, hidden_features, n_nodes):\n        super(SimpleGCN, self).__init__()\n        self.conv1 = BrunaGraphConv(in_features, hidden_features, n_nodes)\n        self.relu = nn.ReLU()\n        self.conv2 = BrunaGraphConv(hidden_features, out_features, n_nodes)\n\n    def forward(self, x, eigenvecs):\n        x = self.conv1(x, eigenvecs)\n        x = self.relu(x)\n        x = self.conv2(x, eigenvecs)\n        return x\n\nWe then train the model by\n\n:tags: [hide-input]\n\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Get eigenvectors of the Laplacian\neigenvals, eigenvecs = BrunaGraphConv.get_laplacian_eigenvectors(adj)\n\n# Initialize the model\nhidden_features = 10\ninput_features = features.shape[1]\noutput_features = 2\nn_nodes = G.number_of_nodes()\nmodel = SimpleGCN(input_features, output_features, hidden_features, n_nodes)\n\n# Train the model\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Split the data into training and testing sets\ntrain_idx, test_idx = train_test_split(np.arange(G.number_of_nodes()), test_size=0.2, random_state=42)\ntrain_features = features[train_idx]\ntrain_labels = labels[train_idx]\ntest_features = features[test_idx]\ntest_labels = labels[test_idx]\n\n\nn_train = 100\nfor epoch in range(n_train):\n    model.train()\n    optimizer.zero_grad()\n    output = model(train_features, eigenvecs[train_idx, :])\n    loss = criterion(output, train_labels)\n    loss.backward()\n    optimizer.step()\n\n    # Evaluate the model\n    if epoch == 0 or (epoch+1) % 25 == 0:\n        model.eval()\n        with torch.no_grad():\n            output = model(test_features, eigenvecs[test_idx, :])\n            _, predicted = torch.max(output, 1)\n            accuracy = (predicted == test_labels).float().mean()\n            print(f'Epoch {epoch+1}/{n_train}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}')\n\nObserve that the accuracy increases as the training progresses. We can use the model to predict the labels. The model has a hidden layer, and let’s visualize the data in the hidden space.\n\n:tags: [hide-input]\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\n# Visualize the learned embeddings\nembeddings = model.conv1(features, eigenvecs).detach().numpy()\n\nxy = TSNE(n_components=2).fit_transform(embeddings)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.scatterplot(x = xy[:, 0].reshape(-1), y = xy[:, 1].reshape(-1), hue=labels.numpy(), palette='tab10', ax = ax)\nax.set_title(\"Learned Node Embeddings\")\nplt.show()",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/04-appendix.html#brunas-spectral-gcn",
    "href": "m09-graph-neural-networks/04-appendix.html#brunas-spectral-gcn",
    "title": "Appendix",
    "section": "",
    "text": "Let’s first implement Bruna’s spectral GCN.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport scipy.sparse as sp\nimport torch\nimport torch.nn as nn\nimport scipy.sparse.linalg as slinalg\n\nclass BrunaGraphConv(nn.Module):\n    \"\"\"\n    Bruna's Spectral Graph Convolution Layer\n\n    This implementation follows the original formulation by Joan Bruna et al.,\n    using the eigendecomposition of the graph Laplacian for spectral convolution.\n    \"\"\"\n\n    def __init__(self, in_features, out_features, n_nodes):\n        \"\"\"\n        Initialize the Bruna Graph Convolution layer\n\n        Args:\n            in_features (int): Number of input features\n            out_features (int): Number of output features\n        \"\"\"\n        super(BrunaGraphConv, self).__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        # Learnable spectral filter parameters\n        self.weight = nn.Parameter(\n            torch.FloatTensor(in_features, out_features, n_nodes-1)\n        )\n\n        # Initialize parameters\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        \"\"\"Initialize weights using Glorot initialization\"\"\"\n        nn.init.xavier_uniform_(self.weight)\n\n\n    @staticmethod\n    def get_laplacian_eigenvectors(adj):\n        \"\"\"\n        Compute eigendecomposition of the normalized graph Laplacian\n\n        Args:\n            adj: Adjacency matrix\n\n        Returns:\n            eigenvalues, eigenvectors of the normalized Laplacian\n        \"\"\"\n        # Compute normalized Laplacian\n        # Add self-loops\n        adj = adj + sp.eye(adj.shape[0])\n\n        # Compute degree matrix\n        deg = np.array(adj.sum(axis=1))\n        Dsqrt_inv = sp.diags(1.0 / np.sqrt(deg).flatten())\n\n        # Compute normalized Laplacian: D^(-1/2) A D^(-1/2)\n        laplacian = sp.eye(adj.shape[0]) - Dsqrt_inv @ adj @ Dsqrt_inv\n\n        # Compute eigendecomposition\n        # Using k=adj.shape[0]-1 to get all non-zero eigenvalues\n        eigenvals, eigenvecs = slinalg.eigsh(laplacian.tocsc(), k=adj.shape[0]-1,which='SM', tol=1e-6)\n\n        return torch.FloatTensor(eigenvals), torch.FloatTensor(eigenvecs)\n\n    def forward(self, x, eigenvecs):\n        \"\"\"\n        Forward pass implementing Bruna's spectral convolution\n\n        Args:\n            x: Input features [num_nodes, in_features]\n            eigenvecs: Eigenvectors of the graph Laplacian [num_nodes, num_nodes-1]\n\n        Returns:\n            Output features [num_nodes, out_features]\n        \"\"\"\n        # Transform to spectral domain\n        x_spectral = torch.matmul(eigenvecs.t(), x)  # [num_nodes-1, in_features]\n\n        # Initialize output tensor\n        out = torch.zeros(x.size(0), self.out_features, device=x.device)\n\n        # For each input-output feature pair\n        for i in range(self.in_features):\n            for j in range(self.out_features):\n                # Element-wise multiplication in spectral domain\n                # This is the actual spectral filtering operation\n                filtered = x_spectral[:, i] * self.weight[i, j, :]  # [num_spectrum]\n\n                # Transform back to spatial domain and accumulate\n                out[:, j] += torch.matmul(eigenvecs, filtered)\n\n        return out\n\nNext, we will train the model on the karate club network to predict the given node labels indicating nodes’ community memberships. We load the data by\n\n:tags: [hide-input]\n\nimport networkx as nx\nimport torch\nimport matplotlib.pyplot as plt\n\n# Load karate club network\nG = nx.karate_club_graph()\nadj = nx.to_scipy_sparse_array(G)\nfeatures = torch.eye(G.number_of_nodes())\nlabels = torch.tensor([G.nodes[i]['club'] == 'Officer' for i in G.nodes()], dtype=torch.long)\n\nWe apply the convolution twice with ReLu activation in between. This can be implemented by preparing two independent BrunaGraphConv layers, applying them consecutively, and adding a ReLu activation in between.\n\n:tags: [hide-input]\n\n# Define a simple GCN model\nclass SimpleGCN(nn.Module):\n    def __init__(self, in_features, out_features, hidden_features, n_nodes):\n        super(SimpleGCN, self).__init__()\n        self.conv1 = BrunaGraphConv(in_features, hidden_features, n_nodes)\n        self.relu = nn.ReLU()\n        self.conv2 = BrunaGraphConv(hidden_features, out_features, n_nodes)\n\n    def forward(self, x, eigenvecs):\n        x = self.conv1(x, eigenvecs)\n        x = self.relu(x)\n        x = self.conv2(x, eigenvecs)\n        return x\n\nWe then train the model by\n\n:tags: [hide-input]\n\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Get eigenvectors of the Laplacian\neigenvals, eigenvecs = BrunaGraphConv.get_laplacian_eigenvectors(adj)\n\n# Initialize the model\nhidden_features = 10\ninput_features = features.shape[1]\noutput_features = 2\nn_nodes = G.number_of_nodes()\nmodel = SimpleGCN(input_features, output_features, hidden_features, n_nodes)\n\n# Train the model\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Split the data into training and testing sets\ntrain_idx, test_idx = train_test_split(np.arange(G.number_of_nodes()), test_size=0.2, random_state=42)\ntrain_features = features[train_idx]\ntrain_labels = labels[train_idx]\ntest_features = features[test_idx]\ntest_labels = labels[test_idx]\n\n\nn_train = 100\nfor epoch in range(n_train):\n    model.train()\n    optimizer.zero_grad()\n    output = model(train_features, eigenvecs[train_idx, :])\n    loss = criterion(output, train_labels)\n    loss.backward()\n    optimizer.step()\n\n    # Evaluate the model\n    if epoch == 0 or (epoch+1) % 25 == 0:\n        model.eval()\n        with torch.no_grad():\n            output = model(test_features, eigenvecs[test_idx, :])\n            _, predicted = torch.max(output, 1)\n            accuracy = (predicted == test_labels).float().mean()\n            print(f'Epoch {epoch+1}/{n_train}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}')\n\nObserve that the accuracy increases as the training progresses. We can use the model to predict the labels. The model has a hidden layer, and let’s visualize the data in the hidden space.\n\n:tags: [hide-input]\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\n# Visualize the learned embeddings\nembeddings = model.conv1(features, eigenvecs).detach().numpy()\n\nxy = TSNE(n_components=2).fit_transform(embeddings)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.scatterplot(x = xy[:, 0].reshape(-1), y = xy[:, 1].reshape(-1), hue=labels.numpy(), palette='tab10', ax = ax)\nax.set_title(\"Learned Node Embeddings\")\nplt.show()",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/04-appendix.html#chebnet",
    "href": "m09-graph-neural-networks/04-appendix.html#chebnet",
    "title": "Appendix",
    "section": "2 ChebNet",
    "text": "2 ChebNet\nLet’s implement the ChebNet layer.\n\n:tags: [hide-input]\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport scipy.sparse as sp\nfrom typing import Optional\n\n\ndef sparse_mx_to_torch_sparse(sparse_mx):\n    \"\"\"Convert scipy sparse matrix to torch sparse tensor.\"\"\"\n    sparse_mx = sparse_mx.tocoo()\n    indices = torch.from_numpy(\n        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n    )\n    values = torch.from_numpy(sparse_mx.data.astype(np.float32))\n    shape = torch.Size(sparse_mx.shape)\n    return torch.sparse_coo_tensor(indices, values, shape)\n\n\nclass ChebConv(nn.Module):\n    \"\"\"\n    Chebyshev Spectral Graph Convolutional Layer\n    \"\"\"\n\n    def __init__(self, in_channels: int, out_channels: int, K: int, bias: bool = True):\n        super(ChebConv, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.K = K\n\n        # Trainable parameters\n        self.weight = nn.Parameter(torch.Tensor(K, in_channels, out_channels))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(out_channels))\n        else:\n            self.register_parameter(\"bias\", None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        \"\"\"Initialize parameters.\"\"\"\n        nn.init.xavier_uniform_(self.weight)\n        if self.bias is not None:\n            nn.init.zeros_(self.bias)\n\n    def _normalize_laplacian(self, adj_matrix):\n        \"\"\"\n        Compute normalized Laplacian L = I - D^(-1/2)AD^(-1/2)\n        \"\"\"\n        # Convert to scipy if it's not already\n        if not sp.isspmatrix(adj_matrix):\n            adj_matrix = sp.csr_matrix(adj_matrix)\n\n        adj_matrix = adj_matrix.astype(float)\n\n        # Compute degree matrix D\n        rowsum = np.array(adj_matrix.sum(1)).flatten()\n        d_inv_sqrt = np.power(rowsum, -0.5)\n        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.0\n        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n\n        # Compute L = I - D^(-1/2)AD^(-1/2)\n        n = adj_matrix.shape[0]\n        L = sp.eye(n) - d_mat_inv_sqrt @ adj_matrix @ d_mat_inv_sqrt\n        return L\n\n    def _scale_laplacian(self, L):\n        \"\"\"\n        Scale Laplacian eigenvalues to [-1, 1] interval\n        L_scaled = 2L/lambda_max - I\n        \"\"\"\n        try:\n            # Compute largest eigenvalue\n            eigenval, _ = sp.linalg.eigsh(L, k=1, which=\"LM\", return_eigenvectors=False)\n            lambda_max = eigenval[0]\n        except:\n            # Approximate lambda_max = 2 if eigenvalue computation fails\n            lambda_max = 2.0\n\n        n = L.shape[0]\n        L_scaled = (2.0 / lambda_max) * L - sp.eye(n)\n        return L_scaled\n\n    def chebyshev_basis(self, L_sparse: torch.sparse.Tensor, X: torch.Tensor):\n        \"\"\"\n        Compute Chebyshev polynomials basis up to order K.\n        \"\"\"\n        # List to store Chebyshev polynomials\n        cheb_polynomials = []\n\n        # T_0(L) = I\n        cheb_polynomials.append(X)\n\n        if self.K &gt; 1:\n            # T_1(L) = L\n            X_1 = torch.sparse.mm(L_sparse, X)\n            cheb_polynomials.append(X_1)\n\n        # Recurrence T_k(L) = 2L·T_{k-1}(L) - T_{k-2}(L)\n        for k in range(2, self.K):\n            X_k = (\n                2 * torch.sparse.mm(L_sparse, cheb_polynomials[k - 1])\n                - cheb_polynomials[k - 2]\n            )\n            cheb_polynomials.append(X_k)\n\n        return torch.stack(cheb_polynomials, dim=0)  # [K, num_nodes, in_channels]\n\n    def forward(self, X: torch.Tensor, adj_matrix: sp.spmatrix):\n        \"\"\"\n        Forward pass.\n\n        Args:\n            X: Node features tensor of shape [num_nodes, in_channels]\n            adj_matrix: Adjacency matrix in scipy sparse format\n\n        Returns:\n            Output tensor of shape [num_nodes, out_channels]\n        \"\"\"\n        # Compute normalized and scaled Laplacian\n        L_norm = self._normalize_laplacian(adj_matrix)\n        L_scaled = self._scale_laplacian(L_norm)\n\n        # Convert to torch sparse tensor\n        L_scaled = sparse_mx_to_torch_sparse(L_scaled).to(X.device)\n\n        # Compute Chebyshev polynomials basis\n        Tx = self.chebyshev_basis(L_scaled, X)  # [K, num_nodes, in_channels]\n\n        # Perform convolution using learned weights\n        out = torch.einsum(\"kni,kio-&gt;no\", Tx, self.weight)\n\n        if self.bias is not None:\n            out += self.bias\n\n        return out\n\nWe stack the layers to form a simple GCN model.\n\n:tags: [hide-input]\n\nclass ChebNet(nn.Module):\n    \"\"\"\n    ChebNet model for node classification\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        hidden_channels: int,\n        out_channels: int,\n        K: int,\n        num_layers: int,\n        dropout: float = 0.5,\n    ):\n        super(ChebNet, self).__init__()\n\n        self.convs = nn.ModuleList()\n\n        # First layer\n        self.convs.append(ChebConv(in_channels, hidden_channels, K))\n\n        # Hidden layers\n        for _ in range(num_layers - 2):\n            self.convs.append(ChebConv(hidden_channels, hidden_channels, K))\n\n        # Output layer\n        self.convs.append(ChebConv(hidden_channels, out_channels, K))\n\n        self.dropout = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, X: torch.Tensor, adj_matrix: sp.spmatrix):\n        \"\"\"\n        Forward pass through all layers\n        \"\"\"\n        for i, conv in enumerate(self.convs[:-1]):\n            X = conv(X, adj_matrix)\n            X = self.activation(X)\n            X = self.dropout(X)\n\n        # Output layer\n        X = self.convs[-1](X, adj_matrix)\n        return X\n\nLet’s train the model on the karate club network.\n\n:tags: [hide-input]\n\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\nimport networkx as nx\nimport torch\nimport matplotlib.pyplot as plt\n\n# Load karate club network\nG = nx.karate_club_graph()\nadj = nx.to_scipy_sparse_array(G)\nfeatures = torch.eye(G.number_of_nodes())\nlabels = torch.tensor(\n    [G.nodes[i][\"club\"] == \"Officer\" for i in G.nodes()], dtype=torch.long\n)\n\n# Initialize the model\nhidden_features = 10\ninput_features = features.shape[1]\noutput_features = 2\nn_nodes = G.number_of_nodes()\nK = 3\nnum_layers = 2\ndropout = 0.5\n\nmodel = ChebNet(\n    input_features, hidden_features, output_features, K, num_layers, dropout\n)\n\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Train the model\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Split the data into training and testing sets\ntrain_idx, test_idx = train_test_split(\n    np.arange(G.number_of_nodes()), test_size=0.2, random_state=42\n)\ntrain_features = features[train_idx]\ntrain_labels = labels[train_idx]\ntest_features = features[test_idx]\ntest_labels = labels[test_idx]\n\n\nn_train = 100\nfor epoch in range(n_train):\n    model.train()\n    optimizer.zero_grad()\n    output = model(features, adj)\n    loss = criterion(output[train_idx], train_labels)\n    loss.backward()\n    optimizer.step()\n\n    # Evaluate the model\n    if epoch == 0 or (epoch + 1) % 25 == 0:\n        model.eval()\n        with torch.no_grad():\n            output = model(features, adj)\n            _, predicted = torch.max(output[test_idx], 1)\n            accuracy = (predicted == test_labels).float().mean()\n            print(\n                f\"Epoch {epoch+1}/{n_train}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}\"\n            )\n\nLet’s visualize the learned embeddings.\n\n:tags: [hide-input]\n\nmodel.eval()\nwith torch.no_grad():\n    # Get embeddings from the last hidden layer\n    X_hidden = features\n    for conv in model.convs[:-1]:\n        X_hidden = conv(X_hidden, adj)\n        X_hidden = model.activation(X_hidden)\n\n# Reduce dimensionality for visualization\nxy = TSNE(n_components=2).fit_transform(X_hidden.numpy())\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.scatterplot(\n    x=xy[:, 0].reshape(-1),\n    y=xy[:, 1].reshape(-1),\n    hue=labels.numpy(),\n    palette=\"tab10\",\n    ax=ax,\n)\nax.set_title(\"Learned Node Embeddings\")\nplt.show()",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/graph-convolutional-network.html",
    "href": "m09-graph-neural-networks/graph-convolutional-network.html",
    "title": "Graph Convolutional Networks",
    "section": "",
    "text": "We have seen that spectral filters give us a principled way to think about “convolution” on irregular graph structures, and controlling the frequency components brings out different aspects of the data. We now go one step further: instead of designing filters by hand, we can learn them from data for specific tasks."
  },
  {
    "objectID": "m09-graph-neural-networks/graph-convolutional-network.html#spectral-graph-convolutional-networks",
    "href": "m09-graph-neural-networks/graph-convolutional-network.html#spectral-graph-convolutional-networks",
    "title": "Graph Convolutional Networks",
    "section": "1 Spectral Graph Convolutional Networks",
    "text": "1 Spectral Graph Convolutional Networks\nA simplest form of learnable spectral filter is given by\n\n{\\bf L}_{\\text{learn}} = \\sum_{k=1}^K \\theta_k {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\nwhere {\\mathbf u}_k are the eigenvectors and \\theta_k are the learnable parameters. The variable K is the number of eigenvectors used (i.e., the rank of the filter). The weight \\theta_k is learned to maximize the performance of the task at hand.\nBuilding on this idea, {footcite}bruna2014spectral added a nonlinearity to the filter and proposed a spectral convolutional neural network (GCN) by\n\n{\\bf x}^{(\\ell+1)} = h\\left( L_{\\text{learn}} {\\bf x}^{(\\ell)}\\right),\n\nwhere h is an activation function, and {\\bf x}^{(\\ell)} is the feature vector of the \\ell-th convolution. They further extend this idea to convolve on multidimensional feature vectors, {\\bf X} \\in \\mathbb{R}^{N \\times f_{\\text{in}}} to produce new feature vectors of different dimensionality, {\\bf X}' \\in \\mathbb{R}^{N \\times f_{\\text{out}}}.\n\n\\begin{aligned}\n{\\bf X}^{(\\ell+1)}_i &= h\\left( \\sum_j L_{\\text{learn}}^{(i,j)} {\\bf X}^{(\\ell)}_j\\right),\\quad \\text{where} \\quad L^{(i,j)}_{\\text{learn}} = \\sum_{k=1}^K \\theta_{k, (i,j)} {\\mathbf u}_k {\\mathbf u}_k^\\top,\n\\end{aligned}\n\nNotice that the learnable filter L_{\\text{learn}}^{(i,j)} is defined for each pair of input i and output j dimensions.\nMany GCNs simple when it comes to implementation despite the complicated formula. And this is one of my ways to learn GNNs. Check out the [Appendix for the Python implementation](appendix.md)."
  },
  {
    "objectID": "m09-graph-neural-networks/graph-convolutional-network.html#from-spectral-to-spatial",
    "href": "m09-graph-neural-networks/graph-convolutional-network.html#from-spectral-to-spatial",
    "title": "Graph Convolutional Networks",
    "section": "2 From Spectral to Spatial",
    "text": "2 From Spectral to Spatial\nSpectral GCNs are mathematically elegant but have two main limitations: 1. Computational Limitation: Computing the spectra of the Laplacian is expensive {\\cal O}(N^3) and prohibitive for large graphs 2. Spatial Locality: The learned filters are not spatially localized. A node can be influenced by all other nodes in the graph.\nThese two limitations motivate the development of spatial GCNs.\n\nChebNet\nChebNet {footcite}defferrard2016convolutional is one of the earliest spatial GCNs that bridges the gap between spectral and spatial domains. The key idea is to leverage Chebyshev polynomials to approximate {\\bf L}_{\\text{learn}} by\n\n{\\bf L}_{\\text{learn}} \\approx \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}), \\quad \\text{where} \\quad \\tilde{{\\bf L}} = \\frac{2}{\\lambda_{\\text{max}}}{\\bf L} - {\\bf I},\n\nwhere \\tilde{{\\bf L}} is the scaled and normalized Laplacian matrix in order to have eigenvalues in the range of [-1,1]. The Chebyshev polynomials T_k(\\tilde{{\\bf L}}) transforms the eigenvalues \\tilde{{\\bf L}} to the following recursively:\n\n\\begin{aligned}\nT_0(\\tilde{{\\bf L}}) &= {\\bf I} \\\\\nT_1(\\tilde{{\\bf L}}) &= \\tilde{{\\bf L}} \\\\\nT_k(\\tilde{{\\bf L}}) &= 2\\tilde{{\\bf L}} T_{k-1}(\\tilde{{\\bf L}}) - T_{k-2}(\\tilde{{\\bf L}})\n\\end{aligned}\n\nWe then replace {\\bf L}_{\\text{learn}} in the original spectral GCN with the Chebyshev polynomial approximation:\n\n{\\bf x}^{(\\ell+1)} = h\\left( \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{{\\bf L}}){\\bf x}^{(\\ell)}\\right),\n\nwhere: - T_k(\\tilde{{\\bf L}}) applies the k-th Chebyshev polynomial to the scaled Laplacian matrix - \\theta_k are the learnable parameters - K is the order of the polynomial (typically small, e.g., K=3)\n\n\nGraph Convolutional Networks by Kipf and Welling\nWhile ChebNet offers a principled way to approximate spectral convolutions, Kipf and Welling (2017) {footcite}kipf2017semi proposed an even simpler and highly effective variant called Graph Convolutional Networks (GCN).\n\n\nFirst-order Approximation\nThe key departure is to use the first-order approximation of the Chebyshev polynomials.\n\ng_{\\theta'} * x \\approx \\theta'_0x + \\theta'_1(L - I_N)x = \\theta'_0x - \\theta'_1D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}x\n\nThis is crude approximation but it leads to a much simpler form, leaving only two learnable parameters, instead of K parameters in the original ChebNet.\nAdditionally, they further simplify the formula by using the same \\theta for both remaining parameters (i.e., \\theta_0 = \\theta and \\theta_1 = -\\theta). The result is the following convolutional filter:\n\ng_{\\theta} * x \\approx \\theta(I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}})x\n\nWhile this is a very simple filter, one can stack multiple layers of convolutions to perform high-order graph convolutions.\n\n\nDeep GCNs can suffer from over-smoothing\nGCN models can be deep, and when they are too deep, they start suffering from an ill-posed problem called gradient vanishing/exploding, where the gradients of the loss function becomes too small or too large to update the model parameters. It is a common problem in deep learning.\nTo facilitate the training of deep GCNs, the authors introduce a very simple trick called renormalization. The idea is to add self-connections to the graph:\n\n\\tilde{A} = A + I_N, \\quad \\text{and} \\quad \\tilde{D}_{ii} = \\sum_j \\tilde{A}_{ij}\n\nAnd use \\tilde{A} and \\tilde{D} to form the convolutional filter.\nAltogether, this leads to the following layer-wise propagation rule:\nX^{(\\ell+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}X^{(\\ell)}W^{(\\ell)})\nwhere: - X^{(\\ell)} is the matrix of node features at layer \\ell - W^{(\\ell)} is the layer’s trainable weight matrix - \\sigma is a nonlinear activation function (e.g., ReLU)\nThese simplifications offer several advantages: - Efficiency: Linear complexity in number of edges - Localization: Each layer only aggregates information from immediate neighbors - Depth: Fewer parameters allow building deeper models - Performance: Despite (or perhaps due to) its simplicity, it often outperforms more complex models\n\n\n\n\n\n\nExercise\n\n\n\n:class: note\nLet’s implement a simple GCN model for node classification. Coding Exercise"
  },
  {
    "objectID": "m09-graph-neural-networks/popular-gnn.html",
    "href": "m09-graph-neural-networks/popular-gnn.html",
    "title": "Popular Graph Neural Networks",
    "section": "",
    "text": "In this note, we will introduce three popular GNNs: GraphSAGE, Graph Attention Networks (GAT), and Graph Isomorphism Network (GIN)."
  },
  {
    "objectID": "m09-graph-neural-networks/popular-gnn.html#graphsage-sample-and-aggregate",
    "href": "m09-graph-neural-networks/popular-gnn.html#graphsage-sample-and-aggregate",
    "title": "Popular Graph Neural Networks",
    "section": "1 GraphSAGE: Sample and Aggregate",
    "text": "1 GraphSAGE: Sample and Aggregate\nGraphSAGE {footcite}hamilton2017graphsage introduced a different GCN that can be generalized to unseen nodes (they called it “inductive”). While previous approaches like ChebNet and GCN operate on the entire graph, GraphSAGE proposes an inductive framework that generates embeddings by sampling and aggregating features from a node’s neighborhood.\n\n\nKey Ideas\nGraphSAGE involves two key ideas: (1) sampling and (2) aggregation.\n\n\nNeighborhood Sampling\nThe key idea is the neighborhood sampling. Instead of using all neighbors, GraphSAGE samples a fixed-size set of neighbors for each node. This controls memory complexity, a key limitation of the previous GNNs.\nAnother key advantage of neighborhood sampling is that it enables GraphSAGE to handle dynamic, growing networks. Consider a citation network where new papers (nodes) are continuously added. Traditional GCNs would need to recompute filters for the entire network with each new addition. In contrast, GraphSAGE can immediately generate embeddings for new nodes by simply sampling their neighbors, without any retraining or recomputation.\n\n\nAggregation\nAnother key idea is the aggregation. GraphSAGE makes a distinction between self-information and neighborhood information. While previous GNNs treat them equally and aggregate them, GraphSAGE treats them differently. Specifically, GraphSAGE introduces an additional step: it concatenates the self-information and the neighborhood information as the input of the convolution.\n\nZ_v = \\text{CONCAT}(X_v, X_{\\mathcal{N}(v)})\n\nwhere X_v is the feature of the node itself and X_{\\mathcal{N}(v)} is the aggregation of the features of its neighbors. GraphSAGE introduces different ways to aggregate information from neighbors:\nX_{\\mathcal{N}(v)} = \\text{AGGREGATE}_k(\\{X_u, \\forall u \\in \\mathcal{N}(v)\\})\nCommon aggregation functions include: - Mean aggregator: \\text{AGGREGATE} = \\text{mean}(\\{h_u, \\forall u \\in \\mathcal{N}(v)\\}) - Max-pooling: \\text{AGGREGATE} = \\max(\\{\\sigma(W_{\\text{pool}}h_u + b), \\forall u \\in \\mathcal{N}(v)\\}) - LSTM aggregator: Apply LSTM to randomly permuted neighbors\nThe concatenated feature Z_v is normalized by the L2 norm.\n\n\\hat{Z}_v = \\frac{Z_v}{\\|Z_v\\|_2}\n\nand then fed into the convolution.\n\nX_v^k = \\sigma(W^k \\hat{Z}_v + b^k)"
  },
  {
    "objectID": "m09-graph-neural-networks/popular-gnn.html#graph-attention-networks-gat-differentiate-individual-neighbors",
    "href": "m09-graph-neural-networks/popular-gnn.html#graph-attention-networks-gat-differentiate-individual-neighbors",
    "title": "Popular Graph Neural Networks",
    "section": "2 Graph Attention Networks (GAT): Differentiate Individual Neighbors",
    "text": "2 Graph Attention Networks (GAT): Differentiate Individual Neighbors\nA key innovation of GraphSAGE is to treat the self and neighborhood information differently. But should all neighbors be treated equally? Graph Attention Networks (GAT) address this by letting the model learn which neighbors to pay attention to.\n\nAttention Mechanism\n\nThe core idea is beautifully simple: instead of using fixed weights like GCN, let’s learn attention weights \\alpha_{ij} that determine how much node i should attend to node j. These weights are computed dynamically based on node features:\n\n\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik})}\n\nwhere e_{ij} represents the importance of the edge between node i and node j. Variable e_{ij} is a learnable parameter and can be negative, and the exponential function is applied to transform it to a non-negative value, with the normalization term \\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik}) to ensure the weights sum to 1.\nHow to compute e_{ij}? One simple choice is to use a neural network with a shared weight matrix W and a LeakyReLU activation function. Specifically:\n\nLet’s focus on computing e_{ij} for node i and its neighbor j.\nWe use a shared weight matrix W to transform the features of node i and j. \n\\mathbf{\\tilde h}_i  = \\mathbf{h}_i, \\quad \\mathbf{\\tilde h}_j  = W\\mathbf{h}_j\n\nWe concatenate the transformed features and apply a LeakyReLU activation function.\n\n\ne_{ij} = \\text{LeakyReLU}(\\mathbf{a}^T[\\mathbf{\\tilde h}_i, \\mathbf{\\tilde h}_j])\n\nwhere \\mathbf{a} is a trainable parameter vector that sums the two transformed features.\nOnce we have these attention weights, the node update is straightforward - just a weighted sum of neighbor features:\n\\mathbf{h}'_i = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}{\\bf W}_{\\text{feature}}\\mathbf{h}_j\\right)\nwhere {\\bf W}_{\\text{feature}} is a trainable weight matrix. To stabilize training, GAT uses multiple attention heads and concatenates their outputs:\n\\mathbf{h}'_i = \\parallel_{k=1}^K \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij}^k{\\bf W}^k_{\\text{feature}}\\mathbf{h}_j\\right)"
  },
  {
    "objectID": "m09-graph-neural-networks/popular-gnn.html#graph-isomorphism-network-gin-differentiate-the-aggregation",
    "href": "m09-graph-neural-networks/popular-gnn.html#graph-isomorphism-network-gin-differentiate-the-aggregation",
    "title": "Popular Graph Neural Networks",
    "section": "3 Graph Isomorphism Network (GIN): Differentiate the Aggregation",
    "text": "3 Graph Isomorphism Network (GIN): Differentiate the Aggregation\nGraph Isomorphism Networks (GIN) is another popular GNN that born out of a question: what is the maximum discriminative power achievable by Graph Neural Networks? The answer lies in its theoretical connection to the Weisfeiler-Lehman (WL) test, a powerful algorithm for graph isomorphism testing.\n\nWeisfeiler-Lehman Test\nAre two graphs structurally identical? Graph isomorphism testing determines if two graphs are structurally identical, with applications in graph classification, clustering, and other tasks.\n\nWhile the general problem has no known polynomial-time solution, the WL test is an efficient heuristic that works well in practice. The WL test iteratively refines node labels by hashing the multiset of neighboring labels\n\nThe WL test works as follows:\n\nAssign all nodes the same initial label.\nFor each node, collect the labels of all its neighbors and aggregate them into a hash (e.g., new label). For example, the top node gets {0} from its neighbors, resulting in a collection {0,0}. A new label is created via a hash function h that maps {0, {0, 0}} to a new label 1.\nRepeat the process for a fixed number of iterations or until convergence.\n\nHere is the implementation of the WL test in Python:\n\n:tags: [hide-input]\n\nimport numpy as np\nfrom scipy import sparse\n\ndef weisfeiler_lehman_test(A, num_iterations):\n    n_nodes = A.shape[0]\n    labels = np.zeros(n_nodes, dtype=int)\n    color_map = {}\n    hash_fn = lambda x: color_map.setdefault(x, len(color_map))\n    for _ in range(num_iterations):\n\n        # Go through each node\n        labels_old = labels.copy()\n        for i in range(n_nodes):\n\n            # Collect the labels of all neighbors\n            neighbors = A[i].nonzero()[1]\n            neighbor_labels = labels_old[neighbors]\n\n            # Count the frequency of each label\n            unique, counts = np.unique(neighbor_labels, return_counts=True)\n\n            # Create a hash key by converting the frequency dictionary to a string\n            hash_key = str({unique[j]: counts[j] for j in range(len(unique))})\n\n            # Create a new label by hashing the frequency dictionary\n            label = hash_fn(hash_key)\n            labels[i] = label\n\n        # Check convergence\n        unique, counts = np.unique(labels, return_counts=True)\n        unique_old, counts_old = np.unique(labels_old, return_counts=True)\n        if np.array_equal(np.sort(counts), np.sort(counts_old)):\n            break\n    return labels\n\n\nedge_list = [(0, 1), (1, 2), (2, 0), (3, 4), (4, 5), (5, 3)]\n\nA = sparse.csr_matrix(\n    ([1] * len(edge_list), ([e[0] for e in edge_list], [e[1] for e in edge_list])),\n    shape=(6, 6),\n)\nA = A + A.T\nA.sort_indices()\n\nweisfeiler_lehman_test(A, A.shape[0])\n\nAfter these iterations: - Nodes with the same label are structurally identical, meaning that they are indistinguishable unless we label them differently. - Two graphs are structurally identical if and only if they have the same node labels after the WL test.\nThe WL test is a heuristic and can fail on some graphs. For example, it cannot distinguish regular graphs with the same number of nodes and edges.\nThe WL test above is called the 1-WL test. There are higher-order WL tests that can distinguish more graphs, which are the basis of advanced GNNs.\nCheck out [this note](https://www.moldesk.net/blog/weisfeiler-lehman-isomorphism-test/)\n\n\nGIN\nGIN {footcite}xu2018how is a GNN that is based on the WL test. The key idea is to focus on the parallel between the WL test and the GNN update rule. - In the WL test, we iteratively collect the labels of neighbors and aggregate them through a hash function. - In the GraphSAGE and GAT, the labels are the nodes’ features, and the aggregation is some arithmetic operations such as mean or max.\nThe key difference is that the hash function in the WL test always distinguishes different sets of neighbors’ labels, while the aggregation in GraphSAGE and GAT does not always do so. For example, if all nodes have the same feature (e.g., all 1), the aggregation by the mean or max will result in the same value for all nodes, whereas the hash function in the WL test can still distinguish different sets of neighbors’ labels by the count of each label.\nThe resulting convolution update rule is:\n\nh_v^{(k+1)} = \\text{MLP}^{(k)}\\left((1 + \\epsilon^{(k)}) \\cdot h_v^{(k)} + \\sum_{u \\in \\mathcal{N}(v)} h_u^{(k)}\\right)\n\nwhere \\text{MLP}^{(k)} is a multi-layer perceptron (MLP) with k layers, and \\epsilon^{(k)} is a fixed or trainable parameter."
  },
  {
    "objectID": "course/activities.html",
    "href": "course/activities.html",
    "title": "Learning activities",
    "section": "",
    "text": "Quiz: Each lecture begins with a short paper‑based quiz reviewing the previous week’s material, graded immediately when possible, followed by a discussion of common mistakes at the end of the lecture.\nPen‑and‑Paper Exercise: Before the lecture, students complete a brief exercise to practice key concepts, then discuss solutions in class while the instructor synthesizes the answers.\nLecture: In class lectures are delivered by the instructor.\nNetwork of the Week: Weekly, a student or group presents a 10‑minute paper on a network‑related topic of their choice.\nCoding: Each module includes a Python coding exercise (using Marimo notebooks) to apply the concepts to real data."
  },
  {
    "objectID": "course/activities.html#in-class-activities",
    "href": "course/activities.html#in-class-activities",
    "title": "Learning activities",
    "section": "",
    "text": "Quiz: Each lecture begins with a short paper‑based quiz reviewing the previous week’s material, graded immediately when possible, followed by a discussion of common mistakes at the end of the lecture.\nPen‑and‑Paper Exercise: Before the lecture, students complete a brief exercise to practice key concepts, then discuss solutions in class while the instructor synthesizes the answers.\nLecture: In class lectures are delivered by the instructor.\nNetwork of the Week: Weekly, a student or group presents a 10‑minute paper on a network‑related topic of their choice.\nCoding: Each module includes a Python coding exercise (using Marimo notebooks) to apply the concepts to real data."
  },
  {
    "objectID": "course/activities.html#homework",
    "href": "course/activities.html#homework",
    "title": "Learning activities",
    "section": "2 Homework",
    "text": "2 Homework\n\nCoding assignment: Every module comes with a coding assignment. The assignment will be distributed via GitHub Classroom. Students will submit their solutions to the assignment via GitHub and get automatic grading.\nLLM Quiz Challenge: Every assignment also includes a task of formulating two quiz questions and correct answers. These quiz questions will be taken by a large language model that learns the course content without seeing the correct answers. The students pass the test if they can generate questions that LLM fails to answer correctly."
  },
  {
    "objectID": "course/activities.html#project",
    "href": "course/activities.html#project",
    "title": "Learning activities",
    "section": "3 Project",
    "text": "3 Project\n\nProject Proposal: The students will submit a project proposal on the course content.\nProject Paper: The students will submit a project paper on the course content.\nProject Presentation: The students will present their project."
  },
  {
    "objectID": "course/activities.html#exam",
    "href": "course/activities.html#exam",
    "title": "Learning activities",
    "section": "4 Exam",
    "text": "4 Exam\nA final exam will be given at the end of the course during the exam period. This exam will be a take-home exam, and will be distributed via Brightspace."
  },
  {
    "objectID": "course/activities.html#resources",
    "href": "course/activities.html#resources",
    "title": "Learning activities",
    "section": "5 Resources",
    "text": "5 Resources\n\nMark Newman, Networks (Second Edition), Oxford University Press, 2018\nFilippo Menczer, Santo Fortunato, and Clayton A. Davis, A First Course in Network Science, Cambridge University Press, 2020\nJames Bagrow and Yong-Yeol Ahn, Working with Network Data: A Data Science Perspective, Cambridge University Press, 2024"
  },
  {
    "objectID": "course/welcome.html",
    "href": "course/welcome.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to the course! In this class, we will explore the fascinating world of networks—from the social connections that shape our lives to the complex systems that power the internet, biology, and beyond.\nThis course is designed to provide you with both a theoretical foundation and hands-on experience in network science. You will learn how to analyze, model, and interpret network data using Python, and apply these skills to real-world problems.\n\n\n\nEngaging Lectures: Each week, we’ll dive into key concepts in network science, supported by interactive discussions and in-class activities.\nHands-on Coding: You’ll work with real network data using Python and modern data science tools.\nCollaborative Learning: Participate in group activities, discussions, and our dedicated Discord server for Q&A and support.\nProjects and Assignments: Apply your knowledge through coding assignments, quizzes, and a final project.\nSupport: Get help from the instructor, TA, and our AI tutor, Minidora.\n\n\n\n\n\nRead the About Us page to meet your instructor, TA, and Minidora.\nJoin the Discord server for announcements, help, and community.\nSet up your Python environment by following the Setup Guide.\nCheck out the Learning Activities to understand how the course is structured.",
    "crumbs": [
      "Home",
      "Course Information",
      "Welcome"
    ]
  },
  {
    "objectID": "course/welcome.html#what-to-expect",
    "href": "course/welcome.html#what-to-expect",
    "title": "Welcome",
    "section": "",
    "text": "Engaging Lectures: Each week, we’ll dive into key concepts in network science, supported by interactive discussions and in-class activities.\nHands-on Coding: You’ll work with real network data using Python and modern data science tools.\nCollaborative Learning: Participate in group activities, discussions, and our dedicated Discord server for Q&A and support.\nProjects and Assignments: Apply your knowledge through coding assignments, quizzes, and a final project.\nSupport: Get help from the instructor, TA, and our AI tutor, Minidora.",
    "crumbs": [
      "Home",
      "Course Information",
      "Welcome"
    ]
  },
  {
    "objectID": "course/welcome.html#how-to-get-started",
    "href": "course/welcome.html#how-to-get-started",
    "title": "Welcome",
    "section": "",
    "text": "Read the About Us page to meet your instructor, TA, and Minidora.\nJoin the Discord server for announcements, help, and community.\nSet up your Python environment by following the Setup Guide.\nCheck out the Learning Activities to understand how the course is structured.",
    "crumbs": [
      "Home",
      "Course Information",
      "Welcome"
    ]
  },
  {
    "objectID": "m02-small-world/pen-and-paper.html",
    "href": "m02-small-world/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Why is our social network small world?\n\n✍️ It’s a small world!! 6 degrees of separation {footcite}esteban-moro-worksheet"
  },
  {
    "objectID": "m03-robustness/04-appendix.html",
    "href": "m03-robustness/04-appendix.html",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "We will compute the average path length of a network of scientists. The network is constructed from {footcite:p}sinatra2016quantifying, where each node represents a scientist and two scientists are connected if they have co-authored a paper in Physical Review Journals from American Physical Society.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html#overview",
    "href": "m03-robustness/04-appendix.html#overview",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "This appendix provides a comprehensive treatment of network robustness, covering both the theoretical foundations and practical applications. We examine how networks respond to various types of failures and attacks, using both classical percolation theory and modern generating function approaches.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html#theoretical-foundations",
    "href": "m03-robustness/04-appendix.html#theoretical-foundations",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Molloy and Reed derived the following criterion for the existence of a giant component in a network with an arbitrary degree distribution {footcite}molloy1995critical. It is based on a simple heuristic argument: the network has a giant component when a random node i with neighbor j has, on average, more than one other connection.\nThe condition is expressed as:\n\n\\langle k_i \\vert i \\leftrightarrow j \\rangle = \\sum_{k} k P(k \\vert i \\leftrightarrow j) &gt; 2\n\nwhere \\langle k_i \\vert i \\leftrightarrow j \\rangle is the conditional average degree of node i given that it is connected to node j.\nFrom Bayes’ theorem:\n\nP(k_i \\vert i \\leftrightarrow j) = \\frac{P(i \\leftrightarrow j \\vert k_i) P(k_i)}{P(i \\leftrightarrow j)}\n\nAssuming the network is uncorrelated and sparse (neglecting loops), we have P(i \\leftrightarrow j \\vert k_i) = k_i / (N-1) and P(i \\leftrightarrow j) = \\langle k \\rangle / (N-1). Substituting these:\n\nP(k_i \\vert i \\leftrightarrow j) = \\frac{k_i P(k_i)}{\\langle k \\rangle}\n\nThus, the Molloy-Reed criterion for giant component existence is:\n\n\\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} &gt; 2\n\nThis fundamental result connects network structure (degree distribution moments) to global connectivity properties.\n\n\n\nGenerating functions provide a powerful mathematical framework for analyzing network properties and attack effects.\nDegree Generating Function: G(x) = \\sum_{k=0}^{\\infty} p_k x^k\nExcess Degree Generating Function: Q(x) = \\sum_{k=0}^{\\infty} q_k x^k = \\frac{G'(x)}{G'(1)}\nThe excess degree distribution describes the remaining degrees of nodes reached by following random edges, which is crucial for understanding percolation processes.\nKey Parameters: - Mean degree: z = G'(1) - Mean excess degree: q = Q'(1)\nThe mean excess degree q is particularly important as it determines the percolation threshold: q &gt; 1 implies the existence of a giant component.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html#random-attacks-and-percolation",
    "href": "m03-robustness/04-appendix.html#random-attacks-and-percolation",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Consider random node removal where a fraction p of nodes is removed independently. The degree of remaining nodes follows a binomial distribution:\n\nP(k \\vert k_0, p) = \\binom{k_0}{k} (1-p)^k p^{k_0-k}\n\nThe new degree distribution becomes:\n\nP'(k) = \\sum_{k_0 = k}^{\\infty} P(k_0) \\binom{k_0}{k} (1-p)^k p^{k_0-k}\n\nMoment Analysis:\nThe first moment (mean degree) after attack: \n\\langle k \\rangle' = \\langle k_0 \\rangle (1-p)\n\nThe second moment: \n\\langle k^2 \\rangle' = \\langle k_0^2 \\rangle (1-p)^2 + \\langle k_0 \\rangle p (1-p)\n\nApplying the Molloy-Reed criterion:\n\n\\frac{\\langle k^2 \\rangle'}{\\langle k \\rangle'} = \\frac{\\langle k_0^2 \\rangle (1-p) + \\langle k_0 \\rangle p}{\\langle k_0 \\rangle} &gt; 2\n\nSolving for the percolation threshold:\n\n1-p &lt; \\frac{1}{\\langle k_0^2 \\rangle / \\langle k_0 \\rangle - 1}\n\n\n\n\n\n\nFor random link removal with survival probability c and removal probability r = 1-c, we define an “attack” generating function:\nA(x) = r + cx\nThe network’s response is captured by function composition: - New degree distribution: G_a(x) = G(A(x)) - New excess degree distribution: Q_a(x) = Q(A(x))\nKey Result: The mean excess degree after link attack is: q_a = q \\cdot c\nThis elegant result shows that random link removal simply scales the mean excess degree by the survival probability.\n\n\n\nRandom node removal creates a two-step process: 1. Node removal: A fraction r of nodes is removed 2. Stub removal: Dangling edges to removed nodes are eliminated\nCritical Insight: The stub removal process is mathematically equivalent to random link removal with probability r.\n\n\n\nBoth link and node percolation yield identical effects on connectivity metrics:\n\n\n\nProperty\nBefore Attack\nAfter Random Attack\n\n\n\n\nMean Degree\nz\ncz\n\n\nMean Excess Degree\nq\ncq\n\n\nDegree Gen. Func.\nG(x)\nG(A(x))\n\n\nExcess Degree Gen. Func.\nQ(x)\nQ(A(x))\n\n\n\nwhere c = 1-r is the survival probability.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html#network-structure-and-resilience",
    "href": "m03-robustness/04-appendix.html#network-structure-and-resilience",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Random Failure: Nodes or links fail uniformly at random (natural disasters, random component failures)\nTargeted Attack: Strategic removal of specific nodes/links (cyber attacks, coordinated failures)\n\n\n\n\n\n\nCharacteristics: Low degree variance, q \\approx z-1\nBehavior: “Hard but Brittle”\n\nExtremely robust to small perturbations\nSharp percolation transition at critical threshold\nRapid complete failure once threshold exceeded\n\n\nExample: 4-regular grid with random link failures - Initial: z = 4, q = 3 - 20% link failure: q_a = 3 \\times 0.8 = 2.4 &gt; 1 → Network survives - Sharp transition near 67% failure rate\n\n\n\n\nCharacteristics: High degree variance, large hubs, q \\gg z-1\nBehavior: “Soft but Resilient”\n\nGradual degradation under random attack\nNo sharp transition point\nExtremely difficult to destroy completely\nHubs maintain global connectivity\n\n\n\n\n\n\nConsider a urban road grid (4-regular network) under storm damage: - Model: z = 4, q = 3 - Attack: 20% of roads blocked randomly - Analysis: q_a = 3 \\times 0.8 = 2.4 &gt; 1 - Conclusion: Giant connected component survives; city remains navigable",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html#implications-and-applications",
    "href": "m03-robustness/04-appendix.html#implications-and-applications",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Redundancy vs. Efficiency: Homogeneous networks are efficient but vulnerable\nHub Protection: In heterogeneous networks, protecting high-degree nodes is crucial\nGraceful Degradation: Scale-free topologies provide better fault tolerance\n\n\n\n\n\nInternet Resilience: Router and link failures\nEpidemic Spreading: Vaccination strategies and quarantine\nInfrastructure: Power grids, transportation networks\nSocial Networks: Information diffusion and community fragmentation",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/04-appendix.html#conclusion",
    "href": "m03-robustness/04-appendix.html#conclusion",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The mathematical framework connecting degree distributions, generating functions, and percolation theory provides deep insights into network robustness. Key findings include:\n\nUniversal Scaling: Random attacks reduce mean excess degree by survival probability factor\nStructure Matters: Network heterogeneity fundamentally alters failure patterns\n\nThreshold Phenomena: Molloy-Reed criterion determines critical attack intensity\nDesign Trade-offs: Efficiency vs. robustness considerations in network architecture\n\nThese results have profound implications for understanding and designing resilient systems across domains from infrastructure to biology to social systems.\nLooking Forward: While random failures follow predictable patterns, targeted attacks that exploit network structure pose greater threats, requiring advanced defensive strategies and adaptive network designs.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html",
    "href": "m04-friendship-paradox/01-concepts.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn about the friendship paradox. Specifically: - Friendship paradox: what is it, why it’s important, and what are the consequences? - Keywords: friendship paradox, degree bias\n\n\n\n“Your friends have more friends than you” is a well-known phenomenon in social networks. It appears everywhere from physical social networks to online social networks, and even random networks! OK. Let’s do not “think” but “feeeeel” this paradox through the following in-class experiment.\n\n\n\nMaterials: - 📇 Friendship card - 🖊️ Pen\nFriendship Network Experiment:\n┌─────────────────────────────────────────────────────────────┐\n\n   1. [📇] Receive Your Card\n      Get a card with a unique letter\n\n   2. [🤝] Meet and Greet (5 mins)\n      Move around, exchange cards with at least one friend\n\n   3. [🧮] Count Connections (2 mins)\n      Count received cards, write number, return cards\n\n   4. [📈] Calculate Average (2 mins)\n      Calculate average 'friend count' of your friends\n\n   5. [📝] Fill Form\n      Write your average and your own friend count\n      in a separate sheet\n\n└─────────────────────────────────────────────────────────────┘\n\n❗ Important Notes:\n  • This is a fun experiment, not a popularity contest\n  • Be respectful and inclusive during the meet and greet\n  • If you finish early, wait patiently for further instructions\n\n\n\n\n\n\nThe paradox arises not because of the way we form friendships. It’s about measurement! For example a person with 100 friends generates 100 cards, while a person with 1 friend generates only 1 card. If we average friend counts over the cards, popular people are counted more. This is where the friendship paradox comes from.\nIn network terms, cards represent edges and people represent nodes. The friendship paradox arises because we measure at different levels: nodes or edges. The average friend count at the node level is lower than at the edge level because popular people are counted more often at the edge level.\n\n\n\n\n🎉 Fun Challenge: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this Friendship Paradox Game! 🎮✨\nQuestion: Can you create a network where the friendship paradox is absent? In other words, can you create a graph, where your friends have the same number of friends as you?\n\n\n\n\nBeyond an interesting trivia, the friendship paradox has many practical utilities.\n\n\n\nThe friendship paradox has important implications for public health strategies. By understanding that highly connected individuals are more likely to be selected through their connections, we can develop more effective vaccination strategies.\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this Vaccination Game! 🎮✨\n\n\n\n\nWhen we vaccinate people chosen through the friendship paradox principle: 1. We’re more likely to vaccinate highly connected individuals 2. Highly connected people are more likely to spread diseases 3. Vaccinating them creates a disproportionate impact on disease spread 4. This strategy is more effective than random vaccination\n\n\n\nThe friendship paradox can be understood through the concept of degree bias:\n\nNode sampling: Selecting people randomly gives equal weight to everyone\nEdge sampling: Selecting people through their connections gives higher weight to popular people\nResult: Edge sampling systematically overrepresents high-degree nodes\n\nThis mathematical insight has applications beyond friendships, including: - Social network analysis - Epidemiology and disease control - Marketing and influence strategies - Network robustness and vulnerability assessment",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#what-we-learn-in-this-module",
    "href": "m04-friendship-paradox/01-concepts.html#what-we-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn about the friendship paradox. Specifically: - Friendship paradox: what is it, why it’s important, and what are the consequences? - Keywords: friendship paradox, degree bias",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#in-class-experiment",
    "href": "m04-friendship-paradox/01-concepts.html#in-class-experiment",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "“Your friends have more friends than you” is a well-known phenomenon in social networks. It appears everywhere from physical social networks to online social networks, and even random networks! OK. Let’s do not “think” but “feeeeel” this paradox through the following in-class experiment.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#experiment-materials-and-procedure",
    "href": "m04-friendship-paradox/01-concepts.html#experiment-materials-and-procedure",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Materials: - 📇 Friendship card - 🖊️ Pen\nFriendship Network Experiment:\n┌─────────────────────────────────────────────────────────────┐\n\n   1. [📇] Receive Your Card\n      Get a card with a unique letter\n\n   2. [🤝] Meet and Greet (5 mins)\n      Move around, exchange cards with at least one friend\n\n   3. [🧮] Count Connections (2 mins)\n      Count received cards, write number, return cards\n\n   4. [📈] Calculate Average (2 mins)\n      Calculate average 'friend count' of your friends\n\n   5. [📝] Fill Form\n      Write your average and your own friend count\n      in a separate sheet\n\n└─────────────────────────────────────────────────────────────┘\n\n❗ Important Notes:\n  • This is a fun experiment, not a popularity contest\n  • Be respectful and inclusive during the meet and greet\n  • If you finish early, wait patiently for further instructions",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#the-origin-of-the-friendship-paradox",
    "href": "m04-friendship-paradox/01-concepts.html#the-origin-of-the-friendship-paradox",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The paradox arises not because of the way we form friendships. It’s about measurement! For example a person with 100 friends generates 100 cards, while a person with 1 friend generates only 1 card. If we average friend counts over the cards, popular people are counted more. This is where the friendship paradox comes from.\nIn network terms, cards represent edges and people represent nodes. The friendship paradox arises because we measure at different levels: nodes or edges. The average friend count at the node level is lower than at the edge level because popular people are counted more often at the edge level.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#key-questions-to-consider",
    "href": "m04-friendship-paradox/01-concepts.html#key-questions-to-consider",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "🎉 Fun Challenge: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this Friendship Paradox Game! 🎮✨\nQuestion: Can you create a network where the friendship paradox is absent? In other words, can you create a graph, where your friends have the same number of friends as you?",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#practical-applications-vaccination-game",
    "href": "m04-friendship-paradox/01-concepts.html#practical-applications-vaccination-game",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Beyond an interesting trivia, the friendship paradox has many practical utilities.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#strategic-vaccination",
    "href": "m04-friendship-paradox/01-concepts.html#strategic-vaccination",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The friendship paradox has important implications for public health strategies. By understanding that highly connected individuals are more likely to be selected through their connections, we can develop more effective vaccination strategies.\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this Vaccination Game! 🎮✨",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#why-vaccination-strategy-works",
    "href": "m04-friendship-paradox/01-concepts.html#why-vaccination-strategy-works",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "When we vaccinate people chosen through the friendship paradox principle: 1. We’re more likely to vaccinate highly connected individuals 2. Highly connected people are more likely to spread diseases 3. Vaccinating them creates a disproportionate impact on disease spread 4. This strategy is more effective than random vaccination",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/01-concepts.html#mathematical-foundation",
    "href": "m04-friendship-paradox/01-concepts.html#mathematical-foundation",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "The friendship paradox can be understood through the concept of degree bias:\n\nNode sampling: Selecting people randomly gives equal weight to everyone\nEdge sampling: Selecting people through their connections gives higher weight to popular people\nResult: Edge sampling systematically overrepresents high-degree nodes\n\nThis mathematical insight has applications beyond friendships, including: - Social network analysis - Epidemiology and disease control - Marketing and influence strategies - Network robustness and vulnerability assessment",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-friendship-paradox/what-to-learn.html",
    "href": "m04-friendship-paradox/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn about the friendship paradox. Specifically, - Friendship paradox: what is it, why it’s important, and what are the consequences? - Keywords: friendship paradox, degree bias"
  },
  {
    "objectID": "m04-friendship-paradox/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m04-friendship-paradox/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn about the friendship paradox. Specifically, - Friendship paradox: what is it, why it’s important, and what are the consequences? - Keywords: friendship paradox, degree bias"
  },
  {
    "objectID": "m05-clustering/pen-and-paper.html",
    "href": "m05-clustering/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and Paper\n✍️ Pen and Paper Exercise 🚢"
  },
  {
    "objectID": "m05-clustering/what-to-learn.html",
    "href": "m05-clustering/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn community detection, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is community structure in networks? - How to operationalize community structure? - How to find communities in networks? - Limitations of community detection - Keywords: community detection, assortativity, modularity, resolution limit, rugged landscape, random graph, label switching algorithm, Louvain algorithm, stochastic block model, the configuration model."
  },
  {
    "objectID": "m05-clustering/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m05-clustering/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn community detection, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is community structure in networks? - How to operationalize community structure? - How to find communities in networks? - Limitations of community detection - Keywords: community detection, assortativity, modularity, resolution limit, rugged landscape, random graph, label switching algorithm, Louvain algorithm, stochastic block model, the configuration model."
  },
  {
    "objectID": "m06-centrality/03-exercises.html",
    "href": "m06-centrality/03-exercises.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Assignment\nWe will compute the various centrality measures for airport networks.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "Home",
      "M06: Centrality",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m06-centrality/what-to-learn.html",
    "href": "m06-centrality/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn centrality, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is centrality in networks? - How to operationalize centrality? - How to find centrality in networks? - Limitations of centrality - Keywords: degree centrality, closeness centrality, betweenness centrality, eigenvector centrality, PageRank, Katz centrality, HITS, random walk"
  },
  {
    "objectID": "m06-centrality/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m06-centrality/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn centrality, one of the most widely-used yet controversial techniques in network analysis. We will learn: - What is centrality in networks? - How to operationalize centrality? - How to find centrality in networks? - Limitations of centrality - Keywords: degree centrality, closeness centrality, betweenness centrality, eigenvector centrality, PageRank, Katz centrality, HITS, random walk"
  },
  {
    "objectID": "m07-random-walks/pen-and-paper.html",
    "href": "m07-random-walks/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and paper exercises\n\n✍️ Pen and paper exercises"
  },
  {
    "objectID": "m08-embedding/00-preparation.html",
    "href": "m08-embedding/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying network embedding, ensure you understand: - From M01-M07: Network representations, linear algebra, eigenvalue theory, and Markov chain concepts - From M07: Stationary distributions and spectral properties of random walks\n\n\n\n\n\nEssential decomposition for dimensionality reduction: - Definition: For matrix A: A = U \\Sigma V^T - Components: U (left singular vectors), \\Sigma (singular values), V (right singular vectors) - Properties: Provides optimal low-rank approximation in Frobenius norm - Truncated SVD: Using only top-k singular values/vectors for compression\n\n\n\nMathematical foundation for embedding: - Frobenius norm: ||A||_F = \\sqrt{\\sum_{ij} A_{ij}^2} - Optimal approximation: SVD minimizes ||A - A_k||_F for rank-k matrix A_k - Information preservation: How much structure is retained in low dimensions\n\n\n\nClassical dimensionality reduction technique: - Objective: Find directions of maximum variance - Covariance matrix: C = \\frac{1}{n-1}X^TX for centered data matrix X - Solution: Eigenvectors of covariance matrix - Connection to SVD: PCA eigenvectors are SVD right singular vectors\n\n\n\n\n\n\nUnderstanding what we optimize in embedding: - Reconstruction error: How well embeddings recreate original data - Preservation metrics: Maintaining distances, similarities, or other properties - Regularization: Preventing overfitting and ensuring generalization\n\n\n\nEssential for neural embedding methods: - Gradient descent: \\theta_{t+1} = \\theta_t - \\alpha \\nabla_\\theta L(\\theta_t) - Stochastic gradient descent: Using random samples for efficiency - Learning rate scheduling: Adaptive step sizes - Convergence criteria: When to stop optimization\n\n\n\nFor embedding problems with constraints: - Orthogonality constraints: When embedding vectors must be orthogonal - Norm constraints: Limiting embedding vector magnitudes - Lagrange multipliers: Mathematical tool for handling constraints\n\n\n\n\n\n\nUnderstanding what makes a good distance measure: - Non-negativity: d(x,y) \\geq 0 - Symmetry: d(x,y) = d(y,x) - Triangle inequality: d(x,z) \\leq d(x,y) + d(y,z) - Identity: d(x,y) = 0 if and only if x = y\n\n\n\n\nEuclidean distance: ||x - y||_2\nCosine similarity: \\frac{x \\cdot y}{||x|| ||y||}\nManhattan distance: ||x - y||_1\nJaccard similarity: For set-based comparisons\n\n\n\n\nHow to evaluate if embeddings preserve important properties: - Distance preservation: Do similar nodes remain close? - Neighborhood preservation: Are local structures maintained? - Global structure: Are long-range relationships captured?\n\n\n\n\n\n\nUnderstanding challenges with high-dimensional spaces: - Distance concentration: All points become equidistant in high dimensions - Sparsity: High-dimensional spaces are mostly empty - Visualization challenges: Difficulty interpreting high-dimensional data\n\n\n\nAssumption underlying many embedding methods: - Manifold hypothesis: High-dimensional data lies on lower-dimensional manifolds - Local linearity: Small neighborhoods can be approximated linearly - Intrinsic dimensionality: True degrees of freedom in the data\n\n\n\n\n\n\nChallenges with large networks: - Matrix operations: O(n³) complexity for eigenvalue decomposition - Memory requirements: Storing large adjacency matrices - Approximation methods: Trading accuracy for computational efficiency\n\n\n\nEssential for large network analysis: - Sparse storage: Only storing non-zero entries - Iterative methods: Lanczos algorithm for eigenvalues - Random sampling: Approximating matrix operations\nThese mathematical foundations provide the theoretical basis for understanding how embedding methods transform high-dimensional network structures into meaningful low-dimensional representations.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m08-embedding/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying network embedding, ensure you understand: - From M01-M07: Network representations, linear algebra, eigenvalue theory, and Markov chain concepts - From M07: Stationary distributions and spectral properties of random walks",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#matrix-decomposition-theory",
    "href": "m08-embedding/00-preparation.html#matrix-decomposition-theory",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Essential decomposition for dimensionality reduction: - Definition: For matrix A: A = U \\Sigma V^T - Components: U (left singular vectors), \\Sigma (singular values), V (right singular vectors) - Properties: Provides optimal low-rank approximation in Frobenius norm - Truncated SVD: Using only top-k singular values/vectors for compression\n\n\n\nMathematical foundation for embedding: - Frobenius norm: ||A||_F = \\sqrt{\\sum_{ij} A_{ij}^2} - Optimal approximation: SVD minimizes ||A - A_k||_F for rank-k matrix A_k - Information preservation: How much structure is retained in low dimensions\n\n\n\nClassical dimensionality reduction technique: - Objective: Find directions of maximum variance - Covariance matrix: C = \\frac{1}{n-1}X^TX for centered data matrix X - Solution: Eigenvectors of covariance matrix - Connection to SVD: PCA eigenvectors are SVD right singular vectors",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#optimization-fundamentals",
    "href": "m08-embedding/00-preparation.html#optimization-fundamentals",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding what we optimize in embedding: - Reconstruction error: How well embeddings recreate original data - Preservation metrics: Maintaining distances, similarities, or other properties - Regularization: Preventing overfitting and ensuring generalization\n\n\n\nEssential for neural embedding methods: - Gradient descent: \\theta_{t+1} = \\theta_t - \\alpha \\nabla_\\theta L(\\theta_t) - Stochastic gradient descent: Using random samples for efficiency - Learning rate scheduling: Adaptive step sizes - Convergence criteria: When to stop optimization\n\n\n\nFor embedding problems with constraints: - Orthogonality constraints: When embedding vectors must be orthogonal - Norm constraints: Limiting embedding vector magnitudes - Lagrange multipliers: Mathematical tool for handling constraints",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#distance-and-similarity-measures",
    "href": "m08-embedding/00-preparation.html#distance-and-similarity-measures",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding what makes a good distance measure: - Non-negativity: d(x,y) \\geq 0 - Symmetry: d(x,y) = d(y,x) - Triangle inequality: d(x,z) \\leq d(x,y) + d(y,z) - Identity: d(x,y) = 0 if and only if x = y\n\n\n\n\nEuclidean distance: ||x - y||_2\nCosine similarity: \\frac{x \\cdot y}{||x|| ||y||}\nManhattan distance: ||x - y||_1\nJaccard similarity: For set-based comparisons\n\n\n\n\nHow to evaluate if embeddings preserve important properties: - Distance preservation: Do similar nodes remain close? - Neighborhood preservation: Are local structures maintained? - Global structure: Are long-range relationships captured?",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#high-dimensional-data-analysis",
    "href": "m08-embedding/00-preparation.html#high-dimensional-data-analysis",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Understanding challenges with high-dimensional spaces: - Distance concentration: All points become equidistant in high dimensions - Sparsity: High-dimensional spaces are mostly empty - Visualization challenges: Difficulty interpreting high-dimensional data\n\n\n\nAssumption underlying many embedding methods: - Manifold hypothesis: High-dimensional data lies on lower-dimensional manifolds - Local linearity: Small neighborhoods can be approximated linearly - Intrinsic dimensionality: True degrees of freedom in the data",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/00-preparation.html#computational-considerations",
    "href": "m08-embedding/00-preparation.html#computational-considerations",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Challenges with large networks: - Matrix operations: O(n³) complexity for eigenvalue decomposition - Memory requirements: Storing large adjacency matrices - Approximation methods: Trading accuracy for computational efficiency\n\n\n\nEssential for large network analysis: - Sparse storage: Only storing non-zero entries - Iterative methods: Lanczos algorithm for eigenvalues - Random sampling: Approximating matrix operations\nThese mathematical foundations provide the theoretical basis for understanding how embedding methods transform high-dimensional network structures into meaningful low-dimensional representations.",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html",
    "href": "m08-embedding/03-exercises.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises\n\n\n\n\n\n\nIn this exercise, we implement DeepWalk step by step. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand how to generate random walks from a graph - Learn how to apply word2vec to graph data - Practice extracting and visualizing node embeddings - Apply clustering methods to embedded representations\nKey Steps: 1. Data preparation: Load the karate club network 2. Generate random walks: Implement random walk sampling function 3. Train word2vec model: Apply word2vec to the random walks 4. Clustering: Use K-means clustering on the embeddings\n\n\n\nIn this exercise, we implement the biased random walk mechanism that makes node2vec different from DeepWalk. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand the biased random walk mechanism in node2vec - Learn about the parameters p and q and their effects - Implement the alias sampling method for biased walks - Compare node2vec results with DeepWalk\nKey Steps: 1. Implement biased random walk: Create functions for node2vec random walks 2. Understand p and q parameters: Learn how they control walk behavior 3. Train node2vec model: Apply word2vec with biased random walks 4. Compare results: Analyze differences between node2vec and DeepWalk\n\n\n\n\n\n\nObjective: Compare different spectral embedding methods on the same network.\nTasks: 1. Implement spectral embedding using the adjacency matrix 2. Implement modularity embedding 3. Implement Laplacian Eigenmap 4. Compare the resulting embeddings visually 5. Analyze which method best captures community structure\n\n\n\nObjective: Understand how different parameters affect embedding quality.\nTasks: 1. Vary the embedding dimension (d) in spectral methods 2. Test different window sizes in word2vec-based methods 3. Experiment with different p and q values in node2vec 4. Compare clustering performance across parameter settings\n\n\n\nObjective: Apply embedding methods to a real-world network.\nTasks: 1. Choose a real network dataset (e.g., social network, citation network) 2. Apply both spectral and neural embedding methods 3. Evaluate embeddings using downstream tasks (clustering, classification) 4. Compare computational efficiency and embedding quality\n\n\n\n\n\nConceptual Understanding:\n\nWhat is the main difference between spectral and neural embedding methods?\nHow do random walks help bridge the gap between word2vec and graph data?\nWhat role do eigenvalues and eigenvectors play in spectral embedding?\n\nTechnical Implementation:\n\nWhy do we exclude the first eigenvector in Laplacian Eigenmap?\nHow does the window size in word2vec affect the final embeddings?\nWhat is the computational complexity of different embedding methods?\n\nPractical Applications:\n\nWhen would you choose spectral methods over neural methods?\nHow do the p and q parameters in node2vec affect the type of structure captured?\nWhat are the trade-offs between embedding dimension and computational cost?\n\n\n\n\n\n\nSoftware Packages: Refer to the 01-concepts.md for recommended implementations\nMathematical Details: See 04-appendix.md for formal proofs and derivations\nPreparation Material: Review 00-preparation.md for background on random walks and linear algebra",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#pen-and-paper-exercises",
    "href": "m08-embedding/03-exercises.html#pen-and-paper-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "✍️ Pen and paper exercises",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#programming-exercises",
    "href": "m08-embedding/03-exercises.html#programming-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this exercise, we implement DeepWalk step by step. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand how to generate random walks from a graph - Learn how to apply word2vec to graph data - Practice extracting and visualizing node embeddings - Apply clustering methods to embedded representations\nKey Steps: 1. Data preparation: Load the karate club network 2. Generate random walks: Implement random walk sampling function 3. Train word2vec model: Apply word2vec to the random walks 4. Clustering: Use K-means clustering on the embeddings\n\n\n\nIn this exercise, we implement the biased random walk mechanism that makes node2vec different from DeepWalk. This exercise is covered in detail in the 02-coding.qmd file.\nObjectives: - Understand the biased random walk mechanism in node2vec - Learn about the parameters p and q and their effects - Implement the alias sampling method for biased walks - Compare node2vec results with DeepWalk\nKey Steps: 1. Implement biased random walk: Create functions for node2vec random walks 2. Understand p and q parameters: Learn how they control walk behavior 3. Train node2vec model: Apply word2vec with biased random walks 4. Compare results: Analyze differences between node2vec and DeepWalk",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#additional-practice-exercises",
    "href": "m08-embedding/03-exercises.html#additional-practice-exercises",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Objective: Compare different spectral embedding methods on the same network.\nTasks: 1. Implement spectral embedding using the adjacency matrix 2. Implement modularity embedding 3. Implement Laplacian Eigenmap 4. Compare the resulting embeddings visually 5. Analyze which method best captures community structure\n\n\n\nObjective: Understand how different parameters affect embedding quality.\nTasks: 1. Vary the embedding dimension (d) in spectral methods 2. Test different window sizes in word2vec-based methods 3. Experiment with different p and q values in node2vec 4. Compare clustering performance across parameter settings\n\n\n\nObjective: Apply embedding methods to a real-world network.\nTasks: 1. Choose a real network dataset (e.g., social network, citation network) 2. Apply both spectral and neural embedding methods 3. Evaluate embeddings using downstream tasks (clustering, classification) 4. Compare computational efficiency and embedding quality",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#evaluation-questions",
    "href": "m08-embedding/03-exercises.html#evaluation-questions",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Conceptual Understanding:\n\nWhat is the main difference between spectral and neural embedding methods?\nHow do random walks help bridge the gap between word2vec and graph data?\nWhat role do eigenvalues and eigenvectors play in spectral embedding?\n\nTechnical Implementation:\n\nWhy do we exclude the first eigenvector in Laplacian Eigenmap?\nHow does the window size in word2vec affect the final embeddings?\nWhat is the computational complexity of different embedding methods?\n\nPractical Applications:\n\nWhen would you choose spectral methods over neural methods?\nHow do the p and q parameters in node2vec affect the type of structure captured?\nWhat are the trade-offs between embedding dimension and computational cost?",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/03-exercises.html#additional-resources",
    "href": "m08-embedding/03-exercises.html#additional-resources",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Software Packages: Refer to the 01-concepts.md for recommended implementations\nMathematical Details: See 04-appendix.md for formal proofs and derivations\nPreparation Material: Review 00-preparation.md for background on random walks and linear algebra",
    "crumbs": [
      "Home",
      "M08: Embedding",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m08-embedding/pen-and-paper.html",
    "href": "m08-embedding/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and paper exercises\n\n✍️ Pen and paper exercises"
  },
  {
    "objectID": "m08-embedding/spectral-vs-neural-embedding.html",
    "href": "m08-embedding/spectral-vs-neural-embedding.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Spectral vs Neural Embedding\nWe have learned two types of graph embedding methods: spectral methods and neural embedding methods. But which one is better than the other? We will compare the two types of methods from multiple aspects as follows.\n\nAnalytical Tractability: Spectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized laplacian matrices are shown to be optimal for detecting communities in the stochastic block model {footcite}nadakuditi2012graph. Neural embedding methods are less analytically tractable. But still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under a very specific condition {footcite}qiu2018network,kojaku2023network. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact an optimal embedding methods for community detection for the stochatic block model.\nScalability: A key limitation of the spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit learn package as TruncatedSVD), they might be unstable depending on the spectrum distribution of the matrix to be decomposed. Neural embedding methods are often more stable and scalable.\nFlexibility: Neural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincaré embeddings {footcite}nickel2017poincare for embedding networks in hyperbolic space."
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html",
    "href": "m09-graph-neural-networks/00-preparation.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying Graph Neural Networks, ensure you understand: - From M01-M08: Network representations, linear algebra, optimization, and embedding concepts - From M08: Matrix decomposition techniques and dimensionality reduction principles\n\n\n\n\n\n\n\n\nPerceptron: y = \\sigma(w^T x + b) where \\sigma is an activation function\nMulti-layer: Composition of linear transformations and nonlinear activations\nUniversal approximation: Neural networks can approximate arbitrary functions\n\n\n\n\nEssential nonlinear functions: - ReLU: \\text{ReLU}(x) = \\max(0, x) - most common, helps with gradient flow - Sigmoid: \\sigma(x) = \\frac{1}{1 + e^{-x}} - outputs in (0,1) range - Tanh: \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} - outputs in (-1,1) range - Softmax: \\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}} - for probability distributions\n\n\n\n\n\n\nComputing network output: - Layer computation: h^{(l+1)} = \\sigma(W^{(l)} h^{(l)} + b^{(l)}) - Composition: Output is function composition through all layers - Vectorization: Efficient batch processing\n\n\n\nComputing gradients for optimization: - Chain rule: \\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial h^{(l+1)}} \\frac{\\partial h^{(l+1)}}{\\partial W^{(l)}} - Gradient flow: How gradients propagate backward through layers - Vanishing gradients: Challenge in deep networks\n\n\n\n\n\n\n\nDifferent objectives for different tasks: - Mean Squared Error: \\text{MSE} = \\frac{1}{n}\\sum_i (y_i - \\hat{y}_i)^2 for regression - Cross-entropy: \\text{CE} = -\\sum_i y_i \\log(\\hat{y}_i) for classification - Custom losses: Task-specific objectives for graph problems\n\n\n\nAdvanced optimization techniques: - SGD with momentum: v_t = \\gamma v_{t-1} + \\alpha \\nabla_\\theta L - Adam optimizer: Adaptive learning rates with momentum - Learning rate scheduling: Decreasing rates over time - Batch normalization: Normalizing layer inputs for stable training\n\n\n\nPreventing overfitting: - L1/L2 regularization: Adding penalty terms to loss function - Dropout: Randomly setting some neurons to zero during training - Early stopping: Stopping training when validation loss stops improving\n\n\n\n\n\n\n\nManual features: Hand-crafted features based on domain knowledge\nLearned features: Features discovered automatically by neural networks\nEnd-to-end learning: Learning features jointly with final task\n\n\n\n\nUnderstanding learned representations: - Distributed representations: Dense vectors vs. one-hot encodings - Semantic similarity: Similar inputs have similar representations - Linear relationships: Arithmetic in embedding space (e.g., king - man + woman ≈ queen)\n\n\n\n\n\n\nFoundation for understanding graph convolutions: - Local connectivity: Neurons connect to local regions of input - Parameter sharing: Same filters applied across different positions - Translation invariance: Feature detection regardless of position\n\n\n\nDimensionality reduction and invariance: - Max pooling: Taking maximum value in local regions - Average pooling: Taking average value in local regions - Global pooling: Reducing to single value per feature map\n\n\n\n\n\n\nComputing weighted combinations: - Query-key-value: \\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V - Self-attention: When queries, keys, and values come from same source - Multi-head attention: Multiple attention mechanisms in parallel\n\n\n\n\nNode attention: Weighting importance of different neighbors\nGraph-level attention: Weighting importance of different nodes\nDynamic weights: Learned attention weights vs. fixed graph structure\n\n\n\n\n\n\n\n\nVariable size: Graphs have different numbers of nodes and edges\nNo natural ordering: Nodes don’t have canonical ordering like pixels\nIrregular structure: Unlike grids or sequences\n\n\n\n\nEssential property for graph neural networks: - Node permutation: Network output shouldn’t change if nodes are reordered - Symmetric functions: Functions that respect permutation invariance - Aggregation operations: Sum, max, mean preserve invariance\nThese deep learning foundations provide the necessary background for understanding how Graph Neural Networks adapt neural network concepts to work with the irregular structure of graphs and networks.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#required-knowledge-from-previous-modules",
    "href": "m09-graph-neural-networks/00-preparation.html#required-knowledge-from-previous-modules",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Before studying Graph Neural Networks, ensure you understand: - From M01-M08: Network representations, linear algebra, optimization, and embedding concepts - From M08: Matrix decomposition techniques and dimensionality reduction principles",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#neural-network-fundamentals",
    "href": "m09-graph-neural-networks/00-preparation.html#neural-network-fundamentals",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Perceptron: y = \\sigma(w^T x + b) where \\sigma is an activation function\nMulti-layer: Composition of linear transformations and nonlinear activations\nUniversal approximation: Neural networks can approximate arbitrary functions\n\n\n\n\nEssential nonlinear functions: - ReLU: \\text{ReLU}(x) = \\max(0, x) - most common, helps with gradient flow - Sigmoid: \\sigma(x) = \\frac{1}{1 + e^{-x}} - outputs in (0,1) range - Tanh: \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} - outputs in (-1,1) range - Softmax: \\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}} - for probability distributions\n\n\n\n\n\n\nComputing network output: - Layer computation: h^{(l+1)} = \\sigma(W^{(l)} h^{(l)} + b^{(l)}) - Composition: Output is function composition through all layers - Vectorization: Efficient batch processing\n\n\n\nComputing gradients for optimization: - Chain rule: \\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial h^{(l+1)}} \\frac{\\partial h^{(l+1)}}{\\partial W^{(l)}} - Gradient flow: How gradients propagate backward through layers - Vanishing gradients: Challenge in deep networks",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#optimization-for-neural-networks",
    "href": "m09-graph-neural-networks/00-preparation.html#optimization-for-neural-networks",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Different objectives for different tasks: - Mean Squared Error: \\text{MSE} = \\frac{1}{n}\\sum_i (y_i - \\hat{y}_i)^2 for regression - Cross-entropy: \\text{CE} = -\\sum_i y_i \\log(\\hat{y}_i) for classification - Custom losses: Task-specific objectives for graph problems\n\n\n\nAdvanced optimization techniques: - SGD with momentum: v_t = \\gamma v_{t-1} + \\alpha \\nabla_\\theta L - Adam optimizer: Adaptive learning rates with momentum - Learning rate scheduling: Decreasing rates over time - Batch normalization: Normalizing layer inputs for stable training\n\n\n\nPreventing overfitting: - L1/L2 regularization: Adding penalty terms to loss function - Dropout: Randomly setting some neurons to zero during training - Early stopping: Stopping training when validation loss stops improving",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#representation-learning",
    "href": "m09-graph-neural-networks/00-preparation.html#representation-learning",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Manual features: Hand-crafted features based on domain knowledge\nLearned features: Features discovered automatically by neural networks\nEnd-to-end learning: Learning features jointly with final task\n\n\n\n\nUnderstanding learned representations: - Distributed representations: Dense vectors vs. one-hot encodings - Semantic similarity: Similar inputs have similar representations - Linear relationships: Arithmetic in embedding space (e.g., king - man + woman ≈ queen)",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#convolutional-neural-networks-cnns",
    "href": "m09-graph-neural-networks/00-preparation.html#convolutional-neural-networks-cnns",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Foundation for understanding graph convolutions: - Local connectivity: Neurons connect to local regions of input - Parameter sharing: Same filters applied across different positions - Translation invariance: Feature detection regardless of position\n\n\n\nDimensionality reduction and invariance: - Max pooling: Taking maximum value in local regions - Average pooling: Taking average value in local regions - Global pooling: Reducing to single value per feature map",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#attention-mechanisms",
    "href": "m09-graph-neural-networks/00-preparation.html#attention-mechanisms",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Computing weighted combinations: - Query-key-value: \\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V - Self-attention: When queries, keys, and values come from same source - Multi-head attention: Multiple attention mechanisms in parallel\n\n\n\n\nNode attention: Weighting importance of different neighbors\nGraph-level attention: Weighting importance of different nodes\nDynamic weights: Learned attention weights vs. fixed graph structure",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/00-preparation.html#deep-learning-for-irregular-data",
    "href": "m09-graph-neural-networks/00-preparation.html#deep-learning-for-irregular-data",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "Variable size: Graphs have different numbers of nodes and edges\nNo natural ordering: Nodes don’t have canonical ordering like pixels\nIrregular structure: Unlike grids or sequences\n\n\n\n\nEssential property for graph neural networks: - Node permutation: Network output shouldn’t change if nodes are reordered - Symmetric functions: Functions that respect permutation invariance - Aggregation operations: Sum, max, mean preserve invariance\nThese deep learning foundations provide the necessary background for understanding how Graph Neural Networks adapt neural network concepts to work with the irregular structure of graphs and networks.",
    "crumbs": [
      "Home",
      "M09: Graph Neural Networks",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m09-graph-neural-networks/pen-and-paper.html",
    "href": "m09-graph-neural-networks/pen-and-paper.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "1 Pen and paper exercises\n\n✍️ Pen and paper exercises"
  },
  {
    "objectID": "m04-node-degree/01-concepts.html",
    "href": "m04-node-degree/01-concepts.html",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "",
    "text": "What you’ll learn in this module\n\n\n\nThis module introduces a single, powerful idea — the node’s degree — and shows how that simple number reveals a network’s structure and behavior.\nYou’ll learn:\n\nWhat degree and degree distribution mean and how to read them.\nHow to visualize degree distributions so underlying patterns become clear.\nThe counterintuitive Friendship Paradox and the notion of degree bias.\nPractical consequences for network robustness, spreading processes, and targeted interventions.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Node Degree: The Building Block of Network Analysis"
    ]
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#the-humble-node-degree-a-window-into-the-networks-soul",
    "href": "m04-node-degree/01-concepts.html#the-humble-node-degree-a-window-into-the-networks-soul",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "1 The Humble Node Degree: A Window into the Network’s Soul",
    "text": "1 The Humble Node Degree: A Window into the Network’s Soul\nImagine you’re at a party. Some people are chatting with just one or two others, while some are the “life of the party,” surrounded by a large group. If we think of this party as a network, each person is a node, and each conversation is an edge. The number of conversations a person is in is their degree.\nIt’s that simple! The degree of a node is the number of edges connected to it. But don’t let its simplicity fool you. This single number is a gateway to understanding the network’s structure, function, and dynamics.\n\nFrom Individual Degrees to a Network’s “Fingerprint”\nIf we count the degree of every single node in a network, we get a list of numbers. But a long list of numbers isn’t very insightful. To make sense of it, we create a degree distribution. This is a summary that tells us how many nodes have a degree of 1, how many have a degree of 2, and so on.\nThink of it as the network’s “fingerprint.” It’s a first-order statistical snapshot of the network’s connectivity pattern. In many real-world networks, this distribution is heterogeneous: most nodes have only a few connections, while a handful of “hub” nodes have a vast number of connections. This feature is a hallmark of so-called scale-free networks.\n\n\nWhy Should We Care About Degree Distribution?\nSo, some nodes are more popular than others. Why is this important?\nThe degree distribution is not just a curious fact; it underpins many of the most important properties of a network.\n\nSmall-Worldness: Those “hub” nodes we mentioned? They act as super-connectors, drastically shortening the path between any two random nodes. They also help form many triangles (your friends being friends with each other), another key ingredient of small-world networks.\nRobustness and Vulnerability: A network with a heterogeneous degree distribution is surprisingly resilient to random failures. If you remove a random node, it’s probably one with a low degree, and the network stays connected. However, this same network is extremely vulnerable to targeted attacks. Take out the main hubs, and the network can shatter into disconnected fragments."
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#the-friendship-paradox-why-your-friends-have-more-friends-than-you-do",
    "href": "m04-node-degree/01-concepts.html#the-friendship-paradox-why-your-friends-have-more-friends-than-you-do",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "3 The Friendship Paradox: Why Your Friends Have More Friends Than You Do",
    "text": "3 The Friendship Paradox: Why Your Friends Have More Friends Than You Do\nLet’s move to a fascinating and often misunderstood phenomenon: the Friendship Paradox. First stated by sociologist Scott Feld in 1991, it says that, on average, your friends have more friends than you do.\nThis might sound like a personal failing, but it’s not! It’s a mathematical certainty in most social networks.\n\n\n\n\n\n\nThe Core Idea\n\n\n\nThe paradox arises from a form of measurement bias. When you average the number of friends your friends have, you are not sampling people randomly. You are sampling them through your friendships (the edges).\nPeople with many friends (high-degree nodes) are, by definition, part of many friendships. Therefore, they are over-represented in the group of “your friends.” They show up in many people’s friend lists, skewing the average upwards.\n\n\nLet’s build a simple intuition. Imagine a tiny social network: - Alex has 1 friend (Bob). - Bob has 3 friends (Alex, Carol, David). - Carol has 1 friend (Bob). - David has 1 friend (Bob).\nLet’s calculate the average number of friends (degree): - Node-level average: (1 + 3 + 1 + 1) / 4 = 1.5. The average person in this network has 1.5 friends.\nNow, let’s check the paradox. - Alex’s perspective: My only friend, Bob, has 3 friends. 3 &gt; 1. The paradox holds. - Carol’s perspective: My only friend, Bob, has 3 friends. 3 &gt; 1. The paradox holds. - David’s perspective: My only friend, Bob, has 3 friends. 3 &gt; 1. The paradox holds. - Bob’s perspective: My friends (Alex, Carol, David) each have 1 friend. 1 &lt; 3. The paradox does not hold for Bob, the hub.\nIt holds for most people! The high-degree node (Bob) is the key.\n\n\n\n\n\n\nTry It Yourself!\n\n\n\n\n🎉 Fun Challenge: Can you create a network where your friends always have more friends than you? 🤔💡 Give it a try in this interactive Friendship Paradox Game! 🎮✨\n\n\n\n\nThe Friendship Paradox in Public Health\nThis is not just a party trick; it has life-or-death implications. Imagine you want to stop a disease from spreading. A common strategy is to vaccinate a random portion of the population.\nBut what if we could be smarter? The Friendship Paradox gives us a powerful hint. People with a high degree are more likely to get infected and more likely to spread the disease. They are the super-spreaders.\nHow do we find them without mapping the entire network? We use the paradox!\n\nSelect a random group of people.\nAsk each of them to nominate one friend.\nVaccinate the nominated friends.\n\n\n\n🧠 Trivia Time!\nThe Friendship Paradox isn’t just for human social networks. It has been observed in scientific collaboration networks (your co-authors are likely more prolific than you), and even on Twitter (the people you follow likely have more followers than you). It’s a fundamental property of many real-world networks!\nFor a fun and visual explanation of the paradox, check out this video:\n{{&lt; video https://www.youtube.com/watch?v=s_4x23jng5I &gt;}} This “friend-of-a-friend” strategy is much more effective than random vaccination because the nominated group is strongly biased towards high-degree individuals. You are essentially using the network’s own structure to find its most important nodes.\n\n\n\n\n\n\nPut Your Theory to the Test\n\n\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? See if you can beat the random strategy using the friendship paradox principle! Give it a try in this Vaccination Game! 🎮✨\n\n\nA final thought experiment: Can you design a network where the friendship paradox is absent entirely? That is, a network where, for every single node, its average friend’s degree is the same as its own. (Hint: think about what kind of structure would eliminate the bias)."
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#visualizing-degree-distributions-beyond-the-simple-histogram",
    "href": "m04-node-degree/01-concepts.html#visualizing-degree-distributions-beyond-the-simple-histogram",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "3 Visualizing Degree Distributions: Beyond the Simple Histogram",
    "text": "3 Visualizing Degree Distributions: Beyond the Simple Histogram\nOkay, we are convinced that degree distributions are important. How do we properly visualize and analyze them?\nA simple histogram, as shown in ?@fig-lesmis-degree, is a good start. But for many real-world networks (especially scale-free ones), it has a major problem: - The vast majority of nodes pile up in the first few bins (degree 1, 2, 3…). - The high-degree “hubs” are spread out thinly along a very long tail.\nThis makes the histogram difficult to read and interpret.\n\nA Better Way: Log-Log Plots\nTo solve this, network scientists almost always plot degree distributions on a log-log scale. This means both the x-axis (degree) and the y-axis (number of nodes) are logarithmic.\nWhy does this help? 1. It compresses the axes, allowing us to see both the dense “head” and the long “tail” of the distribution in one clear view. 2. For scale-free networks, the degree distribution will appear as a straight line on a log-log plot. The slope of this line is a critical parameter of the network, often denoted by the Greek letter gamma (γ).\n\n\nFor a Clearer View: The CCDF\nEven better than a histogram is the Complementary Cumulative Distribution Function (CCDF).\n\nPDF (Probability Density Function): P(k) is the fraction of nodes that have degree k. This is what a normalized histogram shows.\nCDF (Cumulative Distribution Function): P_{CDF}(k) is the fraction of nodes that have a degree less than or equal to k.\nCCDF (Complementary CDF): P_{CCDF}(k) is the fraction of nodes that have a degree greater than k.\n\nSo, P_CCDF(10) would tell you the fraction of nodes that have more than 10 connections.\nPlotting the CCDF on a log-log scale is the standard, most robust way to visualize a heavy-tailed degree distribution. It’s less noisy than a raw histogram and makes the characteristic straight line of a scale-free network even clearer."
  },
  {
    "objectID": "m04-node-degree/what-to-learn.html",
    "href": "m04-node-degree/what-to-learn.html",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn about the friendship paradox. Specifically, - Friendship paradox: what is it, why it’s important, and what are the consequences? - Keywords: friendship paradox, degree bias"
  },
  {
    "objectID": "m04-node-degree/what-to-learn.html#what-to-learn-in-this-module",
    "href": "m04-node-degree/what-to-learn.html#what-to-learn-in-this-module",
    "title": "Advanced Topics in Network Science",
    "section": "",
    "text": "In this module, we will learn about the friendship paradox. Specifically, - Friendship paradox: what is it, why it’s important, and what are the consequences? - Keywords: friendship paradox, degree bias"
  },
  {
    "objectID": "m03-robustness/04-appendix.html#assignment",
    "href": "m03-robustness/04-appendix.html#assignment",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "We will compute the average path length of a network of scientists. The network is constructed from {footcite:p}sinatra2016quantifying, where each node represents a scientist and two scientists are connected if they have co-authored a paper in Physical Review Journals from American Physical Society.\n\nFor students enrolled in SSIE 641\n\nYou will receive a dedicated link to the assignment repository from the instructor.\n\nFor those who are not enrolled in SSIE 641\n\nYou can access the assignment repository at Github.\nThis repository does not offer auto-grading. But you can grade the assignment by yourself by\n\nbash grading-toolkit/grade_notebook.sh tests/test_01.py assignment/assignment.ipynb\nbash grading-toolkit/grade_notebook.sh tests/test_02.py assignment/assignment.ipynb",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#visualization-basics",
    "href": "m04-node-degree/02-coding.html#visualization-basics",
    "title": "Advanced Topics in Network Science",
    "section": "1.1 Visualization basics",
    "text": "1.1 Visualization basics\nTo learn the basics of data visualization, please take a pen and paper exercise.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#coding-exercise",
    "href": "m04-node-degree/02-coding.html#coding-exercise",
    "title": "Advanced Topics in Network Science",
    "section": "1.2 Coding exercise",
    "text": "1.2 Coding exercise\nExercise: Plotting degree distribution\n\nPlotting degree distribution\n(The following content includes the answer to the exercise. So please do the exercise first before reading the following content.)\nWe will first introduce a formal definition of the degree distribution. Then, we will learn how to plot the degree distribution of a network.\nThe degree of a node i, denoted by d_i, is the number of edges connected to it. With the adjacency matrix A, the degree of node i is given by:\n\nk_i = \\sum_{j=1}^N A_{ij}.\n\nLet us compute the degree distribution of a network. We will create a Barabási-Albert network with N=10,000 nodes and m=1 edge per node.\n\nimport igraph\ng = igraph.Graph.Barabasi(n = 10000, m = 1) # Create a Barabási-Albert network\nA = g.get_adjacency() # Get the adjacency matrix\n\nCompute the degree of each node by summing the elements of the adjacency matrix along the rows.\n\nimport numpy as np\ndeg = np.sum(A, axis=1)\ndeg = deg.flatten()\n\nThe degree distribution p(k) can be computed by counting the number of nodes with each degree and dividing by the total number of nodes.\n\np_deg = np.bincount(deg) / len(deg)\n\nLet us plot the degree distribution. This is not as trivial as you might think… 🤔\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\n\nWhile it clearly shows that most nodes have small degree, it does not show the tail of the distribution clearly, and often it is this tail that is of great interest (e.g., hub nodes). To show the tail of the distribution more clearly, we can use a log-log plot.\n\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_ylim(np.min(p_deg[p_deg&gt;0])*0.01, None)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\n\nWe see fluctuations for large degree nodes because of the small number of nodes with large degree. One can use “binning” to smooth the plot. Binning involves grouping the data into bins and calculating the fraction of data within each bin. However, selecting an appropriate bin size can be challenging, and even with a well-chosen bin size, some information may be lost.\nA more convenient way is to use the complementary cumulative distribution function (CCDF). The CCDF at degree k is the probability that a randomly chosen node has degree k' greater than k (k' &gt; k). For a visual comparison of CCDF and PDF, see Figure 3 in {footcite}newman2005power or the arxiv version\n\n\\text{CCDF}(k) = P(k' &gt; k) = \\sum_{k'=k+1}^\\infty p(k')\n\n\nCCDF is a monotonically decreasing function of k.\nCCDF encompasses the full information of p(k), i.e., taking the derivative of CCDF gives p(k).\nCCDF can be plotted as a smooth curve on a log-log scale without binning.\n\n\nccdf_deg = 1 - np.cumsum(p_deg)[:-1] # 1 - CDF (cumulative distribution function).\n# The last element is excluded because it is always 1, resulting in CCDF=0, which cannot be plotted on a log-log scale.\n\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\n\n\n:tags: [remove-cell]\nfrom myst_nb import glue\n\ncdf_deg = np.cumsum(p_deg)\nfig, ax = plt.subplots(figsize=(3,3))\nax = sns.lineplot(x=np.arange(len(cdf_deg)), y=cdf_deg, ax = ax)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CDF')\nglue(\"cdf_fig\", fig, display=False)\n\n\n\n\n\n\n\nNote\n\n\n\nCCDF (complementary cumulative distribution function) is used instead of CDF (cumulative distribution function) because it highlights the tail of the distribution better in a log-log plot. A log scale expands small values and compresses large values. In a CDF, large degree nodes have values close to 1, compressing the tail. In a CCDF, large degree nodes have small values, making the tail more visible. pcuivs cdf_fig :align: center\n\n\nThe slope of the CCDF tells us the heterogeneity of the degree distribution. - Steep slope: more homogeneous degree distribution (similar degrees) - Flat slope: more heterogeneous degree distribution (wide range of degrees)\nThe slope of the CCDF is related to the power-law exponent of the degree distribution. A power-law degree distribution is described by a continuous distribution with the density function (not the probability mass) p(d) given by {footcite}clauset2009power:\n\np(k) = \\frac{\\gamma-1}{k_{\\min}} \\left( \\frac{k}{k_{\\min}} \\right)^{-\\gamma}\n\nwhere: - p(k) is the probability density of a node having degree k - \\gamma is the power-law exponent - k_{\\min} is the minimum degree\n\n\n\n\n\n\nNote\n\n\n\nThe degree distribution is discrete but often approximated by a continuous distribution for mathematical convenience. While generally accurate, caution is needed as the reliability varies depending on the range of the degrees. See {footcite}clauset2009power for more details.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe power-law distribution is ill-defined for d=0, which is why there must be a minimum degree d_{\\min} to avoid this issue.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere has been a long-standing debate in network science as to whether the power-law well represents the real-world networks. Power-law is just one of many possible distributions with a heavy tail (i.e., a long tail on the right side of the distribution), and other distributions may also fit the data well such as log-normal distribution. This discussion is critical as many theories in network science are built on the assumption of the form of the degree distribution. See {footcite}artico2020rare,holme2019rare,voitalov2019scale,barabasi2003scale for the debate.\n\n\nThe CCDF for the power-law distribution is given by:\n\n\\begin{aligned}\n\\text{CCDF}(k) &= 1 - \\int_{k_{\\min}}^k p(x) {\\rm d}x \\\\\n  &= 1 - \\frac{\\gamma -1}{k_{\\min}}\\cdot \\frac{1}{1 - \\gamma} \\left[\n\\left(\\frac{k^{-\\gamma + 1}}{k_{\\min}^{-\\gamma}}\\right) - \\left(\\frac{k_{\\min} ^{-\\gamma + 1}}{k_{\\min} ^{-\n\\gamma}}\\right)\\right] \\\\\n&= \\left( \\frac{k}{k_{\\min}}\\right)^{-\\gamma + 1}\n\\end{aligned}\n\nTaking the logarithm:\n\n\\log \\left[ \\text{CCDF}(k) \\right] = (-\\gamma + 1) \\cdot \\log k + \\text{const.}\n\nThus, the slope of the CCDF in a log-log plot is related to the power-law exponent \\gamma. Specifically, a steeper negative slope (i.e., a more negative value of -\\gamma + 1) corresponds to a larger \\gamma. A larger \\gamma indicates a more homogeneous degree distribution, where the probability of finding nodes with very high degrees decreases more rapidly. Conversely, a flatter slope (i.e., a value of -\\gamma + 1 being closer to zero) corresponds to a smaller \\gamma. A smaller \\gamma indicates a more heterogeneous degree distribution, where there’s a high probability of finding nodes with high degrees compared to that with a large \\gamma value.\nFor students interested in real-world examples of the CCDF plot, refer to Figure 4 in {footcite}newman2005power, or the arxiv version\nIn sum, the CCDF in a log-log plot provides a convenient visual summary of the degree distribution, with the slope of the CCDF providing a measure of the heterogeneity of the degree distribution.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#degree-distribution-of-a-friend",
    "href": "m04-node-degree/02-coding.html#degree-distribution-of-a-friend",
    "title": "Advanced Topics in Network Science",
    "section": "1.3 Degree distribution of a friend",
    "text": "1.3 Degree distribution of a friend\nContinuing from the previous page, we will now consider the degree distribution of a friend of a node.\nThere are two ways to sample a friend of a node. 1. Sample a node uniformly at random and then sample a friend of the node. 2. Sample a friendship (i.e., edge) uniformly at random and then sample an end node of the edge.\nLet us focus on the second case and leave the first case for interested students as an exercise. In the second case, we sample an edge from the network. This sampling is biased towards nodes with many edges, i.e., a person with d edges is d times more likely to be sampled than someone with 1 edge. Thus, the degree distribution p'(k) of a friend is given by\n\np' (k) = C \\cdot k \\cdot p(k)\n The additional term k reflects the fact that a person with k friends is k times more likely to be sampled than someone with 1 friend. Term C is the normalization constant that ensures the sum of probabilities p'(k) over all k is 1, which can be easily computed as follows:\n\nC = \\frac{1}{\\sum_{k} k \\cdot p(k)} = \\frac{1}{\\langle k \\rangle}\n\nwhere \\langle k \\rangle is the average degree of the network. Substituting C into p'(k), we get:\n\np' (k) = \\frac{k}{\\langle k \\rangle} p(k)\n\nThis is the degree distribution of a friend, and it is easy to verify that the average degree of a friend is given by\n\n\\langle k' \\rangle = \\sum_{k} k \\cdot p'(k) = \\sum_{k} k \\cdot \\frac{k}{\\langle k \\rangle} p(k) = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}\n\nwhich is always larger than \\langle k \\rangle:\n\n\\langle k' \\rangle = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} \\geq \\langle k \\rangle\n\nwith equality only if every node has the same degree. This is a proof of the friendship paradox 😉!\n\n\n\n\n\n\nNote\n\n\n\nThe distribution p'(k) is related to the excess degree distribution given by\n\nq(k) = \\frac{k + 1}{\\langle k \\rangle} p(k+1)\n\nThe term excess comes from the fact that the distribution represents the number of additional connections a randomly chosen friend has, beyond the connection that led to their selection. It excludes the link to the focal node and focuses on the remaining connections of the selected friend.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe friend’s degree, \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}, concides with a term in Molloy-Reed condition:\n$$\n &gt;2\n$$\nwhich is a condition for the existence of a giant component in a network. The Molloy-Reed condition states that the average degree of a node’s friends must be at least 2 (the inequality is strict because the transition from a small component to a giant component is discontinuous). If a friend has only one edge, you and your friend form an isolated component. If a friend has two edges on average, your friend is a friend of someone else, and that someone else is also friend of another someone else and so on, forming a giant component.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#plotting-degree-distribution-of-a-friend",
    "href": "m04-node-degree/02-coding.html#plotting-degree-distribution-of-a-friend",
    "title": "Advanced Topics in Network Science",
    "section": "1.4 Plotting degree distribution of a friend",
    "text": "1.4 Plotting degree distribution of a friend\nLet us compare the degree distribution of a node and its friend. We first get the edges in the network, from which we sample a friend.\n\nfrom scipy import sparse\nsrc, trg, _ = sparse.find(A)\n\n\nsparse.find(A) returns the source node, target node, and edge weight of the edge.\nsrc is the source node of the edge\ntrg is the target node of the edge\n_ is used to ignore the edge weight values, as we only need the source and target nodes for this analysis.\n\nNow, let us get the degree of each friend\n\ndeg_friend = deg[src]\np_deg_friend = np.bincount(deg_friend) / len(deg_friend)\n\nThe CCDF of the degree distributions of a node and a friend can be computed by:\n\nccdf_deg = 1 - np.cumsum(p_deg)[:-1]\nccdf_deg_friend = 1 - np.cumsum(p_deg_friend)[:-1]\n\nand plotted by:\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg, label='Node')\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg_friend, label='Friend', ax = ax)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\nax.legend(frameon = False)\n\nThe slope of the CCDF of a friend is flatter than that of a node, indicating that the degree distribution of a friend is biased towards higher degrees.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Advanced Topics in Network Science"
    ]
  },
  {
    "objectID": "m03-robustness/01-concepts.html#network-design-challenges",
    "href": "m03-robustness/01-concepts.html#network-design-challenges",
    "title": "Core Concepts",
    "section": "3 Network Design Challenges",
    "text": "3 Network Design Challenges\n🚀 Interactive Demo",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Core Concepts"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#pen-and-paper-exercise-from-mst-to-robust-grid-design",
    "href": "m03-robustness/03-exercises.html#pen-and-paper-exercise-from-mst-to-robust-grid-design",
    "title": "Exercises and Assignments",
    "section": "",
    "text": "✍️ Pen and Paper Exercise",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m03-robustness/03-exercises.html#assignment",
    "href": "m03-robustness/03-exercises.html#assignment",
    "title": "Exercises and Assignments",
    "section": "3 Assignment",
    "text": "3 Assignment\n\nFor students enrolled in SSIE 641, you will receive a dedicated link to the assignment repository from the instructor.\nFor those who are not enrolled, fork this assignment repository at Github.",
    "crumbs": [
      "Home",
      "M03: Robustness",
      "Exercises and Assignments"
    ]
  },
  {
    "objectID": "m04-node-degree/03-exercises.html",
    "href": "m04-node-degree/03-exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Objective: Experience the friendship paradox interactively\n\n🎉 Fun Challenge: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this Friendship Paradox Game! 🎮✨\n\nQuestions to consider: - Can you create a network where the friendship paradox is absent? - In other words, can you create a graph where your friends have the same number of friends as you? - What network structures minimize or maximize the friendship paradox effect?\n\n\n\nObjective: Apply the friendship paradox to disease control strategies\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this Vaccination Game! 🎮✨\n\nQuestions to explore: - How does random vaccination compare to targeted vaccination? - Why is vaccinating highly connected individuals more effective? - What happens when vaccination resources are limited?",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m04-node-degree/03-exercises.html#interactive-exercises",
    "href": "m04-node-degree/03-exercises.html#interactive-exercises",
    "title": "Exercises",
    "section": "",
    "text": "Objective: Experience the friendship paradox interactively\n\n🎉 Fun Challenge: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this Friendship Paradox Game! 🎮✨\n\nQuestions to consider: - Can you create a network where the friendship paradox is absent? - In other words, can you create a graph where your friends have the same number of friends as you? - What network structures minimize or maximize the friendship paradox effect?\n\n\n\nObjective: Apply the friendship paradox to disease control strategies\n\n🎉 Fun Challenge: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this Vaccination Game! 🎮✨\n\nQuestions to explore: - How does random vaccination compare to targeted vaccination? - Why is vaccinating highly connected individuals more effective? - What happens when vaccination resources are limited?",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m04-node-degree/03-exercises.html#pen-and-paper-exercises",
    "href": "m04-node-degree/03-exercises.html#pen-and-paper-exercises",
    "title": "Exercises",
    "section": "2 Pen and Paper Exercises",
    "text": "2 Pen and Paper Exercises\nObjective: Understand the fundamentals of network data visualization\n📝 Exercise: Data Visualization Basics\nThis exercise covers: - Principles of effective data visualization - Common pitfalls in network visualization - Best practices for degree distribution plots",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m04-node-degree/03-exercises.html#coding-exercises",
    "href": "m04-node-degree/03-exercises.html#coding-exercises",
    "title": "Exercises",
    "section": "3 Coding Exercises",
    "text": "3 Coding Exercises\n\n4. Degree Distribution Analysis\n  \nObjective: Master the techniques for analyzing and visualizing degree distributions\n📝 Exercise: Plotting Degree Distribution\nThis coding exercise covers: - Computing degree distributions - Plotting degree distributions effectively - Understanding complementary cumulative distribution functions (CCDF) - Comparing degree distributions of nodes vs. friends - Mathematical proofs of the friendship paradox\nKey concepts to implement: 1. Basic degree distribution computation 2. Log-log plotting for heavy-tailed distributions 3. CCDF calculation and visualization 4. Friend sampling and degree bias analysis 5. Mathematical verification of the friendship paradox\n\n\n5. Extended Analysis (Optional)\nAdvanced Challenge: Implement the first sampling method mentioned in the coding section: - Sample a node uniformly at random and then sample a friend of the node - Compare this with edge-based sampling - Analyze the differences in resulting degree distributions\nResearch Questions: - How do different sampling methods affect the friendship paradox? - Can you derive the mathematical relationship for node-first sampling? - What are the practical implications of each sampling method?",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m04-node-degree/03-exercises.html#assessment-questions",
    "href": "m04-node-degree/03-exercises.html#assessment-questions",
    "title": "Exercises",
    "section": "4 Assessment Questions",
    "text": "4 Assessment Questions\n\nConceptual Understanding\n\nExplain why the friendship paradox occurs in mathematical terms\nDescribe the relationship between CCDF slope and network heterogeneity\nConnect the friendship paradox to the Molloy-Reed condition for giant components\n\n\n\nPractical Applications\n\nDesign a vaccination strategy for a social network\nIdentify potential biases in social network surveys\nPropose methods to mitigate sampling bias in network studies\n\n\n\nMathematical Analysis\n\nProve that \\langle k' \\rangle = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} \\geq \\langle k \\rangle\nDerive the relationship between power-law exponent and CCDF slope\nCalculate the exact friendship paradox magnitude for specific network types",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Exercises"
    ]
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#visualizing-degree-distributions-from-messy-to-meaningful",
    "href": "m04-node-degree/01-concepts.html#visualizing-degree-distributions-from-messy-to-meaningful",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "2 Visualizing Degree Distributions: From Messy to Meaningful",
    "text": "2 Visualizing Degree Distributions: From Messy to Meaningful\nOkay, we are convinced that degree distributions are important. But how do we properly visualize them? The answer is not as straightforward as it seems and learning to do it right is a crucial skill for any network scientist.\nLet’s use a synthetic network that follows a scale-free degree distribution, which is typical of many real-world systems like the internet, social networks, and citation networks.\n\nThe Problem with Simple Histograms\nOur first instinct might be to plot a simple histogram. Let’s see what happens.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 1: A histogram of a scale-free degree distribution on a linear scale. It’s nearly impossible to see the structure of the tail.\n\n\n\n\n\nAs you can see in Figure 1, this plot is not very informative. The vast majority of nodes have a very small degree, so they are all crammed into the first few bins on the left. The long tail of high-degree nodes is invisible because there are very few of them at any given high degree value.\n\n\nA Better Way: Log-Log Plots\nTo solve this, we can plot the same histogram but with both axes on a logarithmic scale. This is called a log-log plot.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 2: The same degree histogram on a log-log scale. The structure becomes much clearer, revealing a roughly linear relationship.\n\n\n\n\n\nThis is much better! In Figure 2, the log scale compresses the axes, allowing us to see the entire distribution, from the “head” on the left to the long “tail” on the right. For a scale-free network, the distribution appears as a straight line on a log-log plot. This is a key visual signature of a power law.\n\n\nThe Gold Standard: The CCDF\nWhile a log-log binned histogram is good, it can be noisy. The best practice for visualizing these distributions is to use the Complementary Cumulative Distribution Function (CCDF).\nLet’s define our terms: - PDF (Probability Density Function): P(k) is the fraction of nodes that have degree exactly k. This is what the binned histogram approximates. - CDF (Cumulative Distribution Function): P_{CDF}(k) is the fraction of nodes that have a degree less than or equal to k. - CCDF (Complementary CDF): P_{CCDF}(k) is the fraction of nodes that have a degree greater than k. It’s simply 1 - CDF.\nWhy is the CCDF so useful? It’s much less noisy than a histogram because each point incorporates all the data from the tail of the distribution. Let’s plot all three to see the difference.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 3: Comparison of PDF, CDF, and CCDF on a log-log scale. The CCDF provides the smoothest and clearest representation of the power-law tail.\n\n\n\n\n\nAs we see in Figure 3: - The PDF (left) is just our noisy log-binned histogram. - The CDF (right, orange) starts at 0 and goes to 1. It shows the fraction of nodes with degree up to k. - The CCDF (right, green) starts at 1 and goes to 0. This is our money plot! It clearly shows the straight-line power-law tail. For example, you can look at k=10 on the x-axis and read from the green line that roughly 10% (10⁻¹) of nodes have a degree greater than 10.\nPlotting the CCDF on a log-log scale is the standard, most robust way to visualize and identify a heavy-tailed degree distribution."
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#the-humble-node-degree-a-quick-way-to-see-a-network",
    "href": "m04-node-degree/01-concepts.html#the-humble-node-degree-a-quick-way-to-see-a-network",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "1 The humble node degree — a quick way to see a network",
    "text": "1 The humble node degree — a quick way to see a network\nPicture a party. Some people chat with one or two others; a few mingle with large groups. If people are nodes and conversations are edges, then a person’s number of conversations is their degree.\nThat is all degree is: the count of edges touching a node. Despite its simplicity, degree is a powerful diagnostic — it helps reveal how a network is organized and how processes (like information or disease) flow through it.\n\nFrom individual degrees to a network “fingerprint”\nCounting every node’s degree produces a list of numbers. To summarize that list we compute the degree distribution: how many nodes have degree 1, degree 2, and so on.\nThis distribution is the network’s first-order fingerprint. Many real networks are heterogeneous: most nodes have few links, while a small number of hubs have many. That heavy-tailed pattern is often described as “scale-free.”\n\n\nWhy degree distributions matter\nWhy does it matter that some nodes are more connected than others?\nThe shape of the degree distribution determines many global behaviors:\n\nShort paths and small-world effects: Hubs act as shortcuts, reducing distances across the network and fostering clustered groups (triangles).\nRobustness vs. fragility: Heavy-tailed networks tolerate random removals (most removed nodes have low degree) but are fragile to targeted attacks: removing hubs can fragment the network."
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#visualizing-degree-distributions-making-structure-visible",
    "href": "m04-node-degree/01-concepts.html#visualizing-degree-distributions-making-structure-visible",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "2 Visualizing degree distributions — making structure visible",
    "text": "2 Visualizing degree distributions — making structure visible\nWe now know degree distributions are important. The next skill is visualization: choosing plots that reveal the distribution’s shape instead of hiding it.\nWe’ll illustrate using synthetic data with a scale-free (heavy-tailed) distribution — a pattern common to the internet, social networks, and citation graphs.\n\nThe problem with simple histograms\nYour first impulse may be to draw a standard histogram. That often fails to show the full story.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 1: A histogram of a scale-free degree distribution on a linear scale. It’s nearly impossible to see the structure of the tail.\n\n\n\n\n\nAs you can see in Figure 1, this plot is not very informative. The vast majority of nodes have a very small degree, so they are all crammed into the first few bins on the left. The long tail of high-degree nodes is invisible because there are very few of them at any given high degree value.\n\n\nA better way: log–log plots\nTo solve this, we can plot the same histogram but with both axes on a logarithmic scale. This is called a log–log plot.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 2: The same degree histogram on a log-log scale. The structure becomes much clearer, revealing a roughly linear relationship.\n\n\n\n\n\nThis view is much more informative. In Figure 2 the log–log scaling spreads the head and tail across the axes so both low-degree and high-degree behavior are visible. For an approximate power law, the tail appears roughly linear on a log–log plot — a classic visual cue for heavy-tailed data.\n\n\nThe gold standard: the CCDF\nA log–log histogram is useful but often noisy. A better, more stable choice is the Complementary Cumulative Distribution Function (CCDF).\nDefinitions: - PDF (Probability Density Function): P(k) — fraction of nodes with degree exactly k (what a histogram approximates). - CDF (Cumulative Distribution Function): P_CDF(k) — fraction of nodes with degree ≤ k. - CCDF (Complementary CDF): P_CCDF(k) — fraction of nodes with degree &gt; k; CCDF = 1 − CDF.\nWhy use the CCDF? Each CCDF point aggregates all observations above a threshold k, which dramatically reduces noise in the tail. Below we plot PDF, CDF, and CCDF side-by-side to compare their behavior.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 3: Comparison of PDF, CDF, and CCDF on a log-log scale. The CCDF provides the smoothest and clearest representation of the power-law tail.\n\n\n\n\n\nIn Figure 3 you can see the practical differences: - PDF (left) — the noisy, binned estimate of P(k). - CDF (right, orange) — the fraction with degree ≤ k (rises from 0 to 1). - CCDF (right, green) — the fraction with degree &gt; k (falls from 1 to 0) and the cleanest way to inspect the tail. For instance, at k = 10 the CCDF gives the fraction of nodes with degree &gt; 10 (about 10⁻¹ in this synthetic example).\nPlotting the CCDF on log–log axes is a robust, widely used way to reveal heavy-tailed behavior."
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#the-friendship-paradox-why-your-friends-tend-to-be-more-connected",
    "href": "m04-node-degree/01-concepts.html#the-friendship-paradox-why-your-friends-tend-to-be-more-connected",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "3 The Friendship Paradox — why your friends tend to be more connected",
    "text": "3 The Friendship Paradox — why your friends tend to be more connected\nThe Friendship Paradox (Scott Feld, 1991) states that, on average, your friends have more friends than you do.\nThis is not an insult — it is a statistical consequence of how connections are counted in most social networks.\n\n\n\n\n\n\nThe core idea\n\n\n\nThe paradox is a sampling bias: when you average the degrees of your friends, you sample people via edges, not uniformly at random.\nHigh-degree nodes participate in many more edges, so they appear disproportionately often in others’ friend lists. That over-representation pushes the friend-average above the population average.\n\n\nA tiny example makes this concrete: - Alex has 1 friend (Bob). - Bob has 3 friends (Alex, Carol, David). - Carol has 1 friend (Bob). - David has 1 friend (Bob).\nPopulation average degree: (1 + 3 + 1 + 1) / 4 = 1.5.\nFrom individuals’ viewpoints: - Alex’s friend (Bob) has 3 friends → 3 &gt; 1. - Carol’s friend (Bob) has 3 friends → 3 &gt; 1. - David’s friend (Bob) has 3 friends → 3 &gt; 1. - Bob’s friends each have 1 friend → 1 &lt; 3.\nMost people see friends who are better connected than themselves because the hub (Bob) appears in many friend lists.\n\n\n\n\n\n\nTry it yourself\n\n\n\n\nChallenge: Can you build a network where your friends always have more friends than you? Test ideas with this interactive Friendship Paradox Game 🎮.\n\n\n\n\nThe friendship paradox in public health\nThis observation has practical consequences. To slow an epidemic you could vaccinate people at random — or you can use the friendship paradox to find better targets.\nHigh-degree individuals are more likely to get infected and to transmit infection. Without reconstructing the whole network, you can bias selection toward hubs:\n\nPick a random sample of individuals.\nAsk each to nominate one friend.\nVaccinate the nominated friends (who tend to be better connected).\n\n\n\n🧠 Trivia\nThe friendship paradox appears in many settings: coauthorship networks (your coauthors tend to be more prolific than you) and online platforms (the people you follow often have more followers). It’s a pervasive feature of real-world networks.\nFor a short visual explanation, see this video:\n\nThe “friend-of-a-friend” selection works because it preferentially samples higher-degree nodes — a simple, efficient way to target influential spreaders.\n\n\n\n\n\n\nPut the idea to the test\n\n\n\nChallenge: Can you control an outbreak by vaccinating people chosen via the friendship paradox? Try to outperform random vaccination in this Vaccination Game 🎮.\n\n\nFinal thought experiment: can you design a network with no friendship paradox — where each node’s average friend’s degree equals its own? (Hint: consider regular structures where every node has the same degree.)"
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#degree-distribution",
    "href": "m04-node-degree/01-concepts.html#degree-distribution",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "1 Degree distribution",
    "text": "1 Degree distribution\nPicture a party. Some people chat with one or two others; a few mingle with large groups. If people are nodes and conversations are edges, then a person’s number of conversations is their degree.\nThat is all degree is: the count of edges touching a node. Despite its simplicity, degree is a powerful diagnostic — it helps reveal how a network is organized and how processes (like information or disease) flow through it.\n\nFrom individual degrees to a network “fingerprint”\nCounting every node’s degree produces a list of numbers. To summarize that list we compute the degree distribution: how many nodes have degree 1, degree 2, and so on.\nThis distribution is the network’s first-order fingerprint. Many real networks are heterogeneous: most nodes have few links, while a small number of hubs have many. That heavy-tailed pattern is often described as “scale-free.”\n\n\nWhy degree distributions matter\nWhy does it matter that some nodes are more connected than others?\nThe shape of the degree distribution determines many global behaviors:\n\nShort paths and small-world effects: Hubs act as shortcuts, reducing distances across the network and fostering clustered groups (triangles).\nRobustness vs. fragility: Heavy-tailed networks tolerate random removals (most removed nodes have low degree) but are fragile to targeted attacks: removing hubs can fragment the network."
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#node-degree",
    "href": "m04-node-degree/01-concepts.html#node-degree",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "1 Node degree",
    "text": "1 Node degree\nLet’s talk about node degree. A node’s degree is the number of edges touching it. Here we focus on why that simple count matters.\nAt the level of an individual node, degree measures visibility and influence: high-degree nodes see and can spread information (or infection) quickly; low-degree nodes have limited reach. At the level of a network, the collection of degrees reveals how centralized or evenly distributed connectivity is — and that shape drives many collective behaviors.\n\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nA (3)\n\n\n\nB\n\nB (1)\n\n\n\nA--B\n\n\n\n\nC\n\nC (1)\n\n\n\nA--C\n\n\n\n\nD\n\nD (1)\n\n\n\nA--D\n\n\n\n\n\n\n\nFigure 1: A small example graph — node degrees are shown as labels\n\n\n\n\n\nThe tiny graph above makes the point visually: node A has degree 3 (it connects to three nodes) while B, C, and D each have degree 1. That asymmetry — a mix of hubs and leaves — is common in real networks and underlies many of the phenomena we study.\n\nDegree distribution\nShift your attention from single nodes to the whole network by asking: how common is each degree? The degree distribution answers that question — it lists the fraction of nodes with degree 1, degree 2, degree 3, and so on. Reading this distribution quickly tells you whether connectivity is evenly spread or concentrated in a few nodes.\nWhy does that summary matter in practice? Because the distribution shapes how networks behave. We have already seen this in the previous modules:\n\nRobustness vs. fragility — Networks with heavy-tailed degree distributions tolerate random node loss (most removals hit low-degree nodes) but are fragile to targeted hub removal, which can fragment the network.\nSmall-world effects — If a few hubs dominate the degree distribution, they act as shortcuts that dramatically reduce distances between nodes.\n\nWe will add an additional interesting example, called the Friendship Paradox, in the next section.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Node Degree: The Building Block of Network Analysis"
    ]
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#visualizing-degree-distributions-step-by-step",
    "href": "m04-node-degree/01-concepts.html#visualizing-degree-distributions-step-by-step",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "3 Visualizing degree distributions — step-by-step",
    "text": "3 Visualizing degree distributions — step-by-step\nVisualizing degree distributions is both an art and a science. Good visualization follows a thoughtful sequence: (1) try the obvious plot and note its limitations, (2) transform axes to reveal hidden structure, and (3) prefer aggregated summaries (like the CCDF) to reduce noise and highlight patterns. We’ll follow those steps using synthetic scale-free data (a common heavy-tailed pattern in social and information networks).\nThe way we visualize degree distributions dramatically affects what we can learn from them. A poor visualization might hide important patterns, while a well-chosen representation can reveal the underlying mathematical structure of the network. This is particularly crucial for degree distributions because they often span multiple orders of magnitude, with many nodes having low degrees and a few nodes having very high degrees.\nYour first impulse may be to draw a standard histogram. That often fails to show the full story, especially for networks with heavy-tailed degree distributions where most nodes have very few connections while a small number of hubs have thousands or even millions of connections.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 3: A histogram of a scale-free degree distribution on a linear scale. It’s nearly impossible to see the structure of the tail.\n\n\n\n\n\nAs you can see in Figure 3, this plot is not very informative. The vast majority of nodes have a very small degree, so they are all crammed into the first few bins on the left. The long tail of high-degree nodes is invisible because there are very few of them at any given high degree value.\nThis visualization failure is a classic example of how linear scales can hide important patterns in heavy-tailed distributions. The histogram appears to show that almost all nodes have degree 1 or 2, but this is misleading. The problem is that the few nodes with very high degrees (which might be crucial for understanding the network’s structure) are compressed into nearly invisible bars at the far right of the plot. This is why many researchers initially failed to recognize the true nature of scale-free networks—they were using the wrong visualization tools.\nIn a linear histogram, the bin widths are equal, but the importance of different degree ranges varies dramatically. A single node with degree 10,000 might be more important for network behavior than thousands of nodes with degree 1, yet the linear histogram gives equal visual weight to each bin, regardless of how many nodes it contains or how significant those nodes are for the network’s overall structure and dynamics.\nTo solve this, we can plot the same histogram but with both axes on a logarithmic scale. This is called a log–log plot.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 4: The same degree histogram on a log-log scale. The structure becomes much clearer, revealing a roughly linear relationship.\n\n\n\n\n\nThis view is much more informative. In Figure 4 the log–log scaling spreads the head and tail across the axes so both low-degree and high-degree behavior are visible. For an approximate power law, the tail appears roughly linear on a log–log plot — a classic visual cue for heavy-tailed data.\nThe power of log-log scaling lies in its ability to compress large ranges of values into a manageable visual space. By taking the logarithm of both the degree and the fraction of nodes, we can see patterns that span multiple orders of magnitude. This transformation is particularly valuable for network science because many real-world networks have degree distributions that follow power laws, where the probability of a node having degree k is proportional to k^(-γ) for some exponent γ.\nWhen plotted on a log-log scale, a power law appears as a straight line, making it easy to identify this important pattern. The slope of this line corresponds to the exponent γ, which characterizes how quickly the probability decays with increasing degree. A steeper slope (larger γ) indicates a network with fewer high-degree nodes, while a shallower slope (smaller γ) suggests a network with more hubs and super-connectors.\nThis visualization technique was crucial in the discovery of scale-free networks by Albert-László Barabási and his colleagues in the late 1990s. By using log-log plots, they were able to identify the power-law degree distribution in the World Wide Web and many other real-world networks, leading to a fundamental shift in our understanding of network structure.\nA log–log histogram is useful but often noisy, especially in the tail where there are few observations. A better, more stable choice is the Complementary Cumulative Distribution Function (CCDF), which has become the gold standard for visualizing heavy-tailed distributions in network science and many other fields.\nDefinitions: - PDF (Probability Density Function): P(k) — fraction of nodes with degree exactly k (what a histogram approximates). - CDF (Cumulative Distribution Function): P_CDF(k) — fraction of nodes with degree ≤ k. - CCDF (Complementary CDF): P_CCDF(k) — fraction of nodes with degree &gt; k; CCDF = 1 − CDF.\nWhy use the CCDF? Each CCDF point aggregates all observations above a threshold k, which dramatically reduces noise in the tail. This statistical smoothing is particularly valuable for heavy-tailed distributions where the tail contains the most interesting and important information but also the fewest data points. By accumulating all observations above each threshold, the CCDF provides a much clearer view of the distribution’s shape, especially in the critical high-degree region.\nThe CCDF has another important advantage: it directly answers the question “What fraction of nodes have degree greater than k?” which is often more relevant for network analysis than the PDF’s question of “What fraction of nodes have degree exactly k?” For example, when studying network robustness, we might want to know what fraction of nodes have degree greater than 100 (potential hubs whose removal could fragment the network), rather than what fraction have degree exactly 100.\nBelow we plot PDF, CDF, and CCDF side-by-side to compare their behavior and demonstrate why the CCDF is preferred for analyzing heavy-tailed degree distributions.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 5: Comparison of PDF, CDF, and CCDF on a log-log scale. The CCDF provides the smoothest and clearest representation of the power-law tail.\n\n\n\n\n\nIn Figure 5 you can see the practical differences: - PDF (left) — the noisy, binned estimate of P(k). The histogram shows significant fluctuations, especially in the tail where there are few observations. This noise makes it difficult to discern the true underlying distribution, particularly for high-degree values. - CDF (right, orange) — the fraction with degree ≤ k (rises from 0 to 1). While smoother than the PDF, the CDF compresses the tail behavior into a small region near 1, making it hard to distinguish between different heavy-tailed distributions. - CCDF (right, green) — the fraction with degree &gt; k (falls from 1 to 0) and the cleanest way to inspect the tail. For instance, at k = 10 the CCDF gives the fraction of nodes with degree &gt; 10 (about 10⁻¹ in this synthetic example). The CCDF spreads the tail behavior across the entire plot, making it much easier to identify power laws and other heavy-tailed patterns.\nThe superiority of the CCDF is particularly evident when examining the tail of the distribution. In the PDF, the tail points appear scattered and erratic, while in the CCDF, they form a much clearer, more regular pattern. This clarity is invaluable for determining whether a network follows a power law, exponential distribution, or some other form, which has important implications for understanding the network’s structure and dynamics.\nPlotting the CCDF on log–log axes is a robust, widely used way to reveal heavy-tailed behavior. This combination has become the standard approach in network science research papers and is recommended for anyone serious about analyzing degree distributions. The log-log CCDF plot provides the best balance between noise reduction, visual clarity, and mathematical interpretability, making it an indispensable tool in the network scientist’s toolkit."
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#the-friendship-paradox",
    "href": "m04-node-degree/01-concepts.html#the-friendship-paradox",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "2 The Friendship Paradox",
    "text": "2 The Friendship Paradox\nThe Friendship Paradox (Scott Feld, 1991) states that your friends have more friends than you do on average. This is not an insult — it is a statistical consequence of how connections are counted in most social networks. This counterintuitive phenomenon emerges from the mathematical properties of networks and has profound implications for how we understand social structures, information flow, and even public health interventions.\n\n\n\n\nAt its core, the Friendship Paradox reveals a fundamental asymmetry in social networks: high-degree nodes (popular individuals) are more likely to be counted as friends by others, while low-degree nodes are less likely to be referenced. This creates a sampling bias where the average degree of your friends tends to be higher than your own degree, and indeed higher than the average degree of the entire network.\n\n\n\n\n\n\n\n\nG\n\n\n\nAlex\n\nAlex\n(1)\n\n\n\nBob\n\nBob\n(3)\n\n\n\nAlex--Bob\n\n\n\n\nCarol\n\nCarol\n(1)\n\n\n\nCarol--Bob\n\n\n\n\nDavid\n\nDavid\n(1)\n\n\n\nDavid--Bob\n\n\n\n\n\n\n\nFigure 2: Friendship paradox example — node labels show degrees\n\n\n\n\n\nThe network diagram above illustrates the Friendship Paradox with a simple four-node network. The average degree in this network is (1+3+1+1)/4 = 1.5, but when we look at the average degree of each person’s friends, we get a different story.\nLet us list all the friendship ties in adjacency list format, along with the degree of each node in parentheses:\n\nBob: Alex (1), Carol (1), David (1)\nAlex: Bob (3)\nCarol: Bob (3)\nDavid: Bob (3)\n\nNow, let’s compute the average degree of a friend.\n\n\\frac{\\overbrace{1 + 1 + 1}^{\\text{Bob's friends}} + \\overbrace{3 + 3 + 3}^{\\text{The friends of Alex, Carol, and David}}}{\\underbrace{6}_{\\text{\\# of friends}}} = 2\n\nwhich confirms the friendship paradox, i.e., a someone’s friend tends to have more friends than that someone.\nWhy this produces the paradox? Notice that high-degree nodes like Bob are referenced multiple times when computing the average degree of a friend. This is because Bob are a friend of many friends! On the other hand, low-degree nodes are referenced less often. This bias towards high-degree nodes is what makes the friendship paradox a paradox.\nBeyond a fun trivia, the friendship paradox has practical implications. In social networks, most people will find that their friends have more friends than they do, not because they’re unpopular, but because of this statistical bias. The same principle applies to many other networks: in scientific collaboration networks, your coauthors tend to have more collaborators than you do; in the internet, the websites you link to tend to have more incoming links than your website.\n\n\n\n\n\n\nTry it yourself\n\n\n\n\nChallenge: Can you build a network where your friends always have more friends than you? Test ideas with this interactive Friendship Paradox Game 🎮.\n\n\n\n\nThe friendship paradox in public health\nThis observation has profound practical consequences, especially in public health and epidemiology. To slow an epidemic you can use the friendship paradox to find better targets, called acquaintance immunization (Cohen, Havlin, and ben-Avraham 2003), which goes as follows:\n\nPick a random sample of individuals.\nAsk each to nominate one friend.\nVaccinate the nominated friends (who tend to be better connected).\n\nThis works because when people nominate a friend, they’re more likely to name someone with many social connections. By targeting these nominated friends, public health officials can reach the most connected individuals in a network without needing to map the entire social structure.\n\n\nThe acquaintance immunization does not require the knowledge of the entire network structure, which makes it a practical and effective way to slow an epidemic.\n\n\n\n\n\n\nPut the idea to the test\n\n\n\nChallenge: Can you control an outbreak by vaccinating people chosen via the friendship paradox? Try to outperform random vaccination in this Vaccination Game 🎮.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Node Degree: The Building Block of Network Analysis"
    ]
  },
  {
    "objectID": "m04-node-degree/01-concepts.html#visualizing-degree-distributions",
    "href": "m04-node-degree/01-concepts.html#visualizing-degree-distributions",
    "title": "Node Degree: The Building Block of Network Analysis",
    "section": "3 Visualizing degree distributions",
    "text": "3 Visualizing degree distributions\nThe very first step to understand degree distribution is to visualize it. But visualizing degree distribution is not as simple as it seems. Take for example, the following histogram of a degree distribution.\n\n\nCalculating best minimal value for power law fit\nxmin progress: 00%xmin progress: 05%xmin progress: 10%xmin progress: 15%xmin progress: 20%xmin progress: 25%xmin progress: 30%xmin progress: 35%xmin progress: 40%xmin progress: 45%xmin progress: 50%xmin progress: 55%xmin progress: 60%xmin progress: 65%xmin progress: 70%xmin progress: 75%xmin progress: 80%xmin progress: 85%xmin progress: 90%xmin progress: 95%\n\n\n\n\n\n\n\n\nFigure 3: A histogram of a scale-free degree distribution on a linear scale. It’s nearly impossible to see the structure of the tail.\n\n\n\n\n\nThis is a plot you would often see for a real-world network. Most nodes have a very small degree, so they are all crammed into the first few bins on the left. The long tail of high-degree nodes—which hold most edges in the network—is invisible because there are very few of them. This is a fat-tailed distribution, which is a common characteristics of real-world networks.\nTo solve this, we can plot the same histogram but with both axes on a logarithmic scale. This is called a log–log plot.\n\n\n\n\n\n\n\n\nFigure 4: The same degree histogram on a log-log scale. The structure becomes much clearer, revealing a roughly linear relationship.\n\n\n\n\n\nA log–log plot (Figure 4) makes both low- and high-degree nodes visible, revealing heavy-tailed patterns. If the tail is roughly linear, it suggests a power-law degree distribution: the probability a node has degree k falls off as k^{-\\gamma}. The slope of the line shows how quickly high-degree nodes become rare. A steeper slope (higher \\gamma) means fewer hubs; a shallower slope means more. Interestingly, many real-world networks exhibit power-law(-like) degree distributions, whether they are biological, technical, or social. This universality of power-law degree distributions is one of the foundational insights of Network Science.\n\n\nBarabási and Albert (1999) (Barabási and Albert 1999) reported the universality of power-law degree distribution in real-world networks. They proposed a mechanism of the emergence of power-law degree distribution, called preferential attachment, which is a subject of a separate module.\nWhether power-law degree distribution is a good model for real-world networks is a topic of debate (Artico et al. 2020) (Holme 2019) (Voitalov et al. 2019) (Broido and Clauset 2019). A straight line on a log-log plot is not a unique signature of power-law degree distribution. One can construct it by a mixture of poisson distributions, or some other distributions. Testing whether a network is a power-law or not requires statistical assessment going beyond the visual inspection.\nThe log-log plot above shows probability density function (PDF) of the degree distribution. It is defined as the fraction of nodes with degree exactly k.\n\np(k) = \\frac{\\text{number of nodes with degree } k}{N}\n\nwhere N is the total number of nodes in the network.\nThe PDF is useful but often noisy, especially in the tail where there are few observations. A better, more stable choice is the complementary cumulative distribution function (CCDF), which is useful for plotting heavy-tailed distributions.\n\n\nFor a visual comparison of CCDF and PDF, see Figure 3 in (Newman 2005)\n\n\\text{CCDF}(k) = P(k' &gt; k) = \\sum_{k'=k+1}^\\infty p(k')\n\nCCDF represents the fraction of nodes with degree greater than k, or equivalently, the fraction of nodes that survive the degree cutoff k. It is also known as the survival function of the degree distribution.\n\n\n\n\n\n\n\n\nFigure 5: The CCDF of the degree distribution on a log-log scale.\n\n\n\n\n\nA nice feature of the CCDF compared to the PDF is that it does not require any binning of the data. When calculating the PDF, we need to bin the data into a finite number of bins, which is subject to the choice of bin size. CCDF does not require any binning of the data.\n\n\nThere is a related function called the cumulative distribution function (CDF), which is the fraction of nodes with degree less than or equal to k, i.e., 1 - \\text{CCDF}(k).\nFor degree-heterogenous networks, the CCDF is preferred over the CDF because the CDF does not show the tail of the distribution clearly.\n\n\n\n\n\n\n\n\nFigure 6: The CDF of the degree distribution on a log-log scale.\n\n\n\n\n\n\nInterpreting the CCDF for Power-Law Distributions\nFor networks whose degree distribution follows a power law, the CCDF offers a direct path to estimating the power-law exponent, \\gamma. Let’s walk through the derivation to see how.\nA continuous power-law distribution is defined by the probability density function (PDF): \np(k) = Ck^{-\\gamma}\n where C is a normalization constant ensuring the total probability is 1.\nThe CCDF, which we denote as P(k), is the probability that a node’s degree k' is greater than some value k. We calculate this by integrating the PDF from k to infinity: \nP(k) = \\int_{k}^{\\infty} p(k') dk' = \\int_{k}^{\\infty} Ck'^{-\\gamma} dk'\n Performing the integration gives us: \nP(k) = C \\left[ \\frac{k'^{-\\gamma+1}}{-\\gamma+1} \\right]_{k}^{\\infty}\n Assuming \\gamma &gt; 1, which is typical for real-world networks, the term k'^{-\\gamma+1} approaches zero as k' approaches infinity. The expression simplifies to: \nP(k) = -C \\left( \\frac{k^{-\\gamma+1}}{-\\gamma+1} \\right) = \\frac{C}{\\gamma-1} k^{-(\\gamma-1)}\n This result shows that the CCDF itself follows a power law, P(k) \\propto k^{-(\\gamma-1)}.\nTo see what this means for a log-log plot, we take the logarithm of both sides: \n\\log P(k) = \\log\\left(\\frac{C}{\\gamma-1}\\right) - (\\gamma-1)\\log(k)\n This equation is in the form of a straight line, y = b + mx, where:\n\ny = \\log P(k)\nx = \\log(k)\nThe y-intercept b = \\log\\left(\\frac{C}{\\gamma-1}\\right)\nThe slope m = -(\\gamma-1) = 1-\\gamma\n\n\n\n\n\n\n\nKey Relationship\n\n\n\nFor a power-law distribution, the slope of the CCDF on a log-log plot is 1 - \\gamma.\nThis is a crucial point for accurately estimating the scaling exponent from empirical data. For example, if you measure the slope of the CCDF plot to be -1.3, the estimated power-law exponent \\gamma is 2.3, not 1.3 (since -1.3 = 1 - 2.3).",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Node Degree: The Building Block of Network Analysis"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#computing-degree-distributions-from-network-data",
    "href": "m04-node-degree/02-coding.html#computing-degree-distributions-from-network-data",
    "title": "Visualizing Degree Distributions in Python",
    "section": "1 Computing degree distributions from network data",
    "text": "1 Computing degree distributions from network data\nWe’ll start by creating a scale-free network using the Barabási-Albert model and computing its degree distribution. This model generates networks with power-law degree distributions, making it ideal for demonstrating visualization techniques that work well with heavy-tailed distributions.\n\nimport igraph\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a Barabási-Albert network with 10,000 nodes\ng = igraph.Graph.Barabasi(n=10000, m=1)\nA = g.get_adjacency()\n\nThe first step in analyzing any network is computing the degree sequence. In Python, we can extract degrees directly from the adjacency matrix by summing along rows (for undirected networks, row and column sums are identical). The flatten() method ensures we get a 1D array of degree values.\n\n# Compute degree for each node\ndeg = np.sum(A, axis=1).flatten()\n\n# Convert to probability distribution\np_deg = np.bincount(deg) / len(deg)",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#why-standard-histograms-fail-for-degree-distributions",
    "href": "m04-node-degree/02-coding.html#why-standard-histograms-fail-for-degree-distributions",
    "title": "Visualizing Degree Distributions in Python",
    "section": "2 Why standard histograms fail for degree distributions",
    "text": "2 Why standard histograms fail for degree distributions\nLet’s start with the obvious approach—a simple histogram. This immediately reveals why degree distribution visualization is challenging.\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\nax.set_title('Linear Scale: Most Information Hidden')\n\nText(0.5, 1.0, 'Linear Scale: Most Information Hidden')\n\n\n\n\n\n\n\n\n\nThis linear-scale plot shows the fundamental problem: most nodes cluster at low degrees, making the interesting high-degree tail invisible. Since power-law networks have heavy tails—a few nodes with very high degrees—we need visualization techniques that can handle this extreme heterogeneity.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#log-log-plots-revealing-the-power-law-structure",
    "href": "m04-node-degree/02-coding.html#log-log-plots-revealing-the-power-law-structure",
    "title": "Visualizing Degree Distributions in Python",
    "section": "3 Log-log plots: revealing the power-law structure",
    "text": "3 Log-log plots: revealing the power-law structure\nSwitching to logarithmic scales on both axes dramatically improves visibility across the entire degree range. This transformation is essential for identifying power-law behavior, which appears as straight lines in log-log space.\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax = sns.lineplot(x=np.arange(len(p_deg)), y=p_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_ylim(np.min(p_deg[p_deg&gt;0])*0.01, None)\nax.set_xlabel('Degree')\nax.set_ylabel('Probability')\nax.set_title('Log-Log Scale: Structure Revealed')\n\nText(0.5, 1.0, 'Log-Log Scale: Structure Revealed')\n\n\n\n\n\n\n\n\n\nThe log-log plot reveals the power-law structure, but notice the noisy fluctuations at high degrees. This noise occurs because only a few nodes have very high degrees, leading to statistical fluctuations. While binning could smooth these fluctuations, it introduces arbitrary choices about bin sizes and loses information.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#the-ccdf-approach-smooth-curves-without-binning",
    "href": "m04-node-degree/02-coding.html#the-ccdf-approach-smooth-curves-without-binning",
    "title": "Visualizing Degree Distributions in Python",
    "section": "4 The CCDF approach: smooth curves without binning",
    "text": "4 The CCDF approach: smooth curves without binning\nThe complementary cumulative distribution function (CCDF) provides a superior visualization method. Instead of plotting the fraction of nodes with exactly degree k, CCDF plots the fraction with degree greater than k. This approach naturally smooths the data without requiring binning decisions.\n\n# Compute CCDF: fraction of nodes with degree &gt; k\nccdf_deg = 1 - np.cumsum(p_deg)[:-1]  # Exclude last element (always 0)\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\nax.set_title('CCDF: Smooth Power-Law Visualization')\n\nText(0.5, 1.0, 'CCDF: Smooth Power-Law Visualization')\n\n\n\n\n\n\n\n\n\nThe CCDF produces clean, interpretable curves even for noisy data. The slope directly relates to the power-law exponent: steeper slopes indicate more homogeneous degree distributions (fewer hubs), while flatter slopes suggest more heterogeneous distributions (more extreme hubs). This visualization technique has become the standard in network science for analyzing heavy-tailed distributions.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#implementing-the-friendship-paradox",
    "href": "m04-node-degree/02-coding.html#implementing-the-friendship-paradox",
    "title": "Visualizing Degree Distributions in Python",
    "section": "5 Implementing the friendship paradox",
    "text": "5 Implementing the friendship paradox\nNow let’s demonstrate the friendship paradox computationally. As covered in the concepts module, this phenomenon arises because high-degree nodes are more likely to be someone’s friend than low-degree nodes. We’ll implement this by sampling friends through edge-based sampling.\nTo capture this bias, we need to sample edges rather than nodes. When we sample an edge uniformly at random, we’re effectively sampling one endpoint of that edge—this gives us a “friend” from someone’s perspective. The key insight is that nodes with higher degrees appear as endpoints more frequently, creating the degree bias that drives the friendship paradox.\n\nfrom scipy import sparse\n\n# Extract all edges from the adjacency matrix\nsrc, trg, _ = sparse.find(A)\nprint(f\"Total number of edges: {len(src)}\")\nprint(f\"First few source nodes: {src[:10]}\")\nprint(f\"First few target nodes: {trg[:10]}\")\n\nTotal number of edges: 19998\nFirst few source nodes: [0 0 0 0 0 0 0 0 0 0]\nFirst few target nodes: [   1    3   15   42  190  566  866  962 1044 1068]\n\n\nThe sparse.find() function returns three arrays: source nodes, target nodes, and edge weights. Since we’re working with an unweighted network, we ignore the weights. Each edge appears twice in an undirected network (once as src→trg and once as trg→src), which is exactly what we want for sampling friends.\nNow we can compute the degree distribution of friends by taking the degrees of the source nodes from our edge list. This automatically implements the degree-biased sampling because high-degree nodes appear more frequently in the source node list.\n\n# Get degrees of \"friends\" (source nodes from edge sampling)\ndeg_friend = deg[src]\n\n# Compute degree distribution of friends\np_deg_friend = np.bincount(deg_friend) / len(deg_friend)\n\nprint(f\"Average degree in network: {np.mean(deg):.2f}\")\nprint(f\"Average degree of friends: {np.mean(deg_friend):.2f}\")\nprint(f\"Friendship paradox ratio: {np.mean(deg_friend) / np.mean(deg):.2f}\")\n\nAverage degree in network: 2.00\nAverage degree of friends: 4.97\nFriendship paradox ratio: 2.48",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html#visualizing-the-degree-bias",
    "href": "m04-node-degree/02-coding.html#visualizing-the-degree-bias",
    "title": "Visualizing Degree Distributions in Python",
    "section": "6 Visualizing the degree bias",
    "text": "6 Visualizing the degree bias\nLet’s create a side-by-side comparison of both distributions using CCDF plots. This clearly shows how the friendship paradox manifests as a shift toward higher degrees in the friend distribution.\n\n# Compute CCDFs for both distributions\nccdf_deg = 1 - np.cumsum(p_deg)[:-1]\nccdf_deg_friend = 1 - np.cumsum(p_deg_friend)[:-1]\n\n# Create comparison plot\nfig, ax = plt.subplots(figsize=(10, 6))\nax = sns.lineplot(x=np.arange(len(ccdf_deg)), y=ccdf_deg,\n                  label='Regular nodes', linewidth=2, color='blue')\nax = sns.lineplot(x=np.arange(len(ccdf_deg_friend)), y=ccdf_deg_friend,\n                  label='Friends (degree-biased)', linewidth=2, color='red', ax=ax)\n\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlabel('Degree')\nax.set_ylabel('CCDF')\nax.set_title('Friendship Paradox: Friends Have Higher Degrees')\nax.legend(frameon=False)\nax.grid(True, alpha=0.3)\n\n\n\n\n\n\n\n\nThe plot clearly demonstrates the friendship paradox: the friend distribution (red line) lies below the node distribution (blue line), indicating that friends have systematically higher degrees. The flatter slope of the friend CCDF shows that the probability of encountering high-degree friends is much higher than encountering high-degree nodes when sampling uniformly.\nThis computational demonstration confirms the theoretical prediction that your friends will, on average, have more friends than you do. The magnitude of this effect depends on the heterogeneity of the degree distribution—the more heterogeneous the network, the stronger the friendship paradox becomes.",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m04-node-degree/02-coding.html",
    "href": "m04-node-degree/02-coding.html",
    "title": "Visualizing Degree Distributions in Python",
    "section": "",
    "text": "Now that we understand the theoretical foundations of degree distributions and the friendship paradox, let’s dive into the practical aspects of computing and visualizing these distributions in Python. This notebook focuses on the technical implementation details and best practices for degree distribution analysis. ::: {.callout-note title=“Try it yourself”} - Challenge: Can you build a network where your friends always have more friends than you? Test ideas with this interactive Friendship Paradox Game 🎮. :::",
    "crumbs": [
      "Home",
      "M04: Friendship Paradox",
      "Visualizing Degree Distributions in Python"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#a-puzzle-that-changed-the-world",
    "href": "m01-euler_tour/01-concepts.html#a-puzzle-that-changed-the-world",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "",
    "text": "Our story begins not in a laboratory or a university, but on the streets of an 18th-century Prussian city. The citizens of Königsberg, a bustling hub on the Pregel River, had a favorite recreational puzzle: could they take a Sunday stroll that crossed each of the city’s seven beautiful bridges exactly once and return to where they started?\nIt seemed like a simple question. Yet, it stumped everyone who tried. This seemingly trivial brain-teaser would eventually land on the desk of one of history’s greatest mathematicians, Leonhard Euler. His solution didn’t just solve the puzzle—it invented an entirely new field of mathematics and gave us the language to describe the interconnected world we live in today.\n\n\n\n\n\n\nWhat You Will Learn\n\n\n\nIn this module, we’ll follow in Euler’s footsteps to understand the core concepts that launched network science:\n\nThe Power of Abstraction: How to strip away distracting details to find the hidden structure of a problem.\nThe Language of Networks: How to represent complex systems using simple dots (nodes) and lines (edges).\nThe Importance of Degree: A simple but powerful idea that unlocks the solution to the bridge puzzle and many other network problems.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#the-seven-bridges-of-königsberg",
    "href": "m01-euler_tour/01-concepts.html#the-seven-bridges-of-königsberg",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "2 The Seven Bridges of Königsberg",
    "text": "2 The Seven Bridges of Königsberg\nThe city of Königsberg was built around two large islands in the Pregel River. These islands were connected to each other and the mainland by seven bridges, as shown in Figure 1.\n\n\n\n\n\n\nFigure 1: A map illustrating the seven bridges connecting the landmasses of Königsberg.\n\n\n\nFor years, townspeople tried to find a route that crossed each bridge just once. No one could do it. But more importantly, no one could prove it was impossible. Was there a secret path they were all missing, or was the puzzle itself flawed?\n\n\n\n\n\n\nTry It Yourself First!\n\n\n\nBefore we continue, try solving the puzzle yourself. This is the heart of mathematical thinking: struggling with a problem, noticing patterns, and forming your own ideas.\nWe highly recommend this excellent pen-and-paper worksheet by Esteban Moro. It guides you through Euler’s reasoning, allowing you to have the same “aha!” moments he did.\nQuestions to ponder: - What makes this problem tricky? - Does the shape of the land or the length of the bridges matter? - How could you prove a solution doesn’t exist?\n\n\n\n\n\n\n\n\n⚠️ Pause and Think\n\n\n\nThe rest of this note reveals the solution. The learning experience is far richer if you grapple with the puzzle on your own first. Don’t skip this step!",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#eulers-stroke-of-genius-the-power-of-abstraction",
    "href": "m01-euler_tour/01-concepts.html#eulers-stroke-of-genius-the-power-of-abstraction",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "3 Euler’s Stroke of Genius: The Power of Abstraction",
    "text": "3 Euler’s Stroke of Genius: The Power of Abstraction\nWhen Leonhard Euler tackled this problem in 1736, he did something revolutionary. He ignored the physical details—the river, the buildings, the exact placement of the bridges. He realized that to solve the puzzle, only one thing mattered: the connections.\nHe simplified the complex map of Königsberg into a “skeleton” diagram: 1. He represented each of the four landmasses as a single dot (or node). 2. He represented each of the seven bridges as a line (or edge) connecting the dots.\n\n\n\n\n\n\nFigure 2: Euler’s abstraction of the Königsberg bridge problem. The complex city map is reduced to a simple network of nodes and edges. Image from The Essential Guide to Graph Theory.\n\n\n\nThis radical simplification was the birth of graph theory. Euler created a new mathematical object—the graph, or network—that described relationships, not quantities. He showed that sometimes, the most important thing about a system isn’t what the pieces are, but how they are connected.\n\nThe Key Insight: Counting Connections\nWith his abstract graph, Euler made another brilliant leap. Instead of trying to trace every possible path, he asked a simpler question: How many bridges connect to each landmass?\nHe called this the degree of a node.\n\n\n\n\n\n\nKey Concept: Node Degree\n\n\n\nThe degree of a node is the number of edges connected to it. It’s the most basic, and often most important, property of a node in a network.\n\n\nThink about what happens as you walk through the city. To cross a bridge, you must enter a landmass and then leave it. Each time you pass through a landmass, you use up two bridges: one to arrive and one to depart.\n\nIf a landmass has an even number of bridges (e.g., degree 4), you can always pass through it. You arrive through one bridge, leave through another; arrive through a third, leave through a fourth. The bridges pair up nicely.\nIf a landmass has an odd number of bridges (e.g., degree 3), you have a problem. You can arrive and leave once, but there’s one bridge left over. This “leftover” bridge means that landmass must be either the start or the end of your journey.\n\nSince a journey can only have one start and one end, a path that crosses every bridge is only possible if the graph has at most two nodes with an odd degree.\n\n\nThe Verdict on Königsberg\nLet’s count the degrees of the Königsberg graph: - North Shore: 3 bridges (odd) - South Shore: 3 bridges (odd) - East Island (Kneiphof): 5 bridges (odd) - West Island (Lomse): 3 bridges (odd)\nEvery single landmass has an odd degree! With four “odd” nodes, a continuous walk crossing every bridge exactly once is mathematically impossible. The citizens of Königsberg weren’t failing to find a path—they were trying to do something that couldn’t be done.\n\n\n\n\n\n\nEuler’s Conditions for a Walk\n\n\n\nA walk that crosses every edge exactly once (an Eulerian Path) is possible if and only if:\n\nThe graph is connected (you can get from any node to any other).\nEither:\n\nZero nodes have an odd degree. The walk will be a closed loop, starting and ending at the same point (an Eulerian Circuit).\nExactly two nodes have an odd degree. The walk will start at one of the odd nodes and end at the other.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#a-tragic-epilogue",
    "href": "m01-euler_tour/01-concepts.html#a-tragic-epilogue",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "4 A Tragic Epilogue",
    "text": "4 A Tragic Epilogue\nThe story of the seven bridges has a sad, ironic twist. During World War II, the city of Königsberg was heavily bombed. Two of the seven bridges were destroyed, changing the layout of the city forever.\n\n\n\n\n\n\nFigure 3: After WWII bombing, only five bridges remained—finally making an Euler path possible.\n\n\n\nWith the two bridges gone, the network changed. Two of the landmasses now had an even degree, leaving just two with an odd degree. The impossible puzzle, which had fascinated people for over 200 years, was suddenly “solved” by the destruction of war.\nThis historical footnote reminds us that while mathematical principles are timeless, the real-world systems they describe are constantly changing.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#why-eulers-discovery-matters-today",
    "href": "m01-euler_tour/01-concepts.html#why-eulers-discovery-matters-today",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "5 Why Euler’s Discovery Matters Today",
    "text": "5 Why Euler’s Discovery Matters Today\nEuler’s solution to a simple puzzle did more than just settle a local curiosity. It gave us a new way to see the world. The act of abstracting the city into nodes and edges is the same fundamental process we use today to:\n\nNavigate with GPS: Your phone models the road system as a graph to find the shortest path.\nAnalyze Social Networks: We study influence and information spread by mapping people as nodes and relationships as edges.\nUnderstand the Brain: Neuroscientists map neurons and synapses as a network to understand cognition.\nDesign Resilient Power Grids: Engineers model power stations and transmission lines to prevent blackouts.\n\nEvery time you see a diagram of interconnected points, you are seeing the legacy of Euler’s stroll through Königsberg.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#the-vocabulary-of-networks",
    "href": "m01-euler_tour/01-concepts.html#the-vocabulary-of-networks",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "4 The Vocabulary of Networks",
    "text": "4 The Vocabulary of Networks\nTo talk precisely about networks, we need to formalize the language Euler created. Here are the key terms.\n\nWalk, Trail, and Path\n\n\n\n\n\n\n\n\nTerm\nDefinition\nAnalogy: A Road Trip\n\n\n\n\nWalk\nA sequence of nodes where you can repeat both roads (edges) and cities (nodes).\nA casual drive where you can go down the same street multiple times.\n\n\nTrail\nA walk where you cannot repeat edges, but you can revisit nodes.\nA mail route. The carrier can’t cover the same street twice but may pass the same intersection.\n\n\nPath\nA walk where you cannot repeat nodes (or edges, by consequence).\nA trip visiting a sequence of cities, each one new.\n\n\n\n\n\nCycle and Circuit\nA journey that starts and ends at the same place is closed. This gives us two more terms:\n\n\n\n\n\n\n\n\nTerm\nDefinition\nAnalogy: A Round Trip\n\n\n\n\nCircuit\nA trail that starts and ends at the same node.\nA scenic drive from your hotel and back, never taking the same road twice.\n\n\nCycle\nA path that starts and ends at the same node.\nA perfect loop, like a lap on a racetrack.\n\n\n\nWith this vocabulary, we can be more precise about the Königsberg problem.\n\nAn Eulerian Trail/Path is a trail that uses every edge in the graph.\nAn Eulerian Circuit/Cycle is a circuit that uses every edge in the graph.\n\nThe citizens were looking for an Eulerian circuit. Euler proved that to have one, all nodes must have an even degree.\n\n\nNetwork Connectivity\nEuler’s theorem only applies if the graph is connected. If you can’t get from one part of the network to another, then a single walk can’t possibly cover all the edges.\n\nA graph is connected if there is a path between any two nodes.\nA disconnected graph is made of two or more separate “islands” of nodes, called connected components.\n\n\n\n\n\n\n\nFigure 4: A graph with three distinct connected components, highlighted in different colors.\n\n\n\n\nConnectivity in Directed Networks\nWhat if edges have a direction, like one-way streets? We call these directed graphs. This introduces two flavors of connectivity:\n\nWeakly Connected: The graph would be connected if you ignored the edge directions. You can get from A to B, but maybe not from B to A.\nStrongly Connected: There is a directed path from every node to every other node. No matter where you start, you can get anywhere else by following the arrows.\n\n\n\n\n\n\n\nFigure 5: A directed graph showing strongly and weakly connected components.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#why-is-this-puzzle-so-hard",
    "href": "m01-euler_tour/01-concepts.html#why-is-this-puzzle-so-hard",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "",
    "text": "Our story begins not in a lab, but on the streets of an 18th-century Prussian city called Königsberg. It was a city of thinkers, most famously the philosopher Immanuel Kant, but the puzzle that would change mathematics belonged to everyone.\nThe city was built around two islands in the Pregel River, connected to the mainland and each other by seven distinct bridges. During their Sunday strolls, the citizens amused themselves with a challenge:\n\n\n\n\n\n\nThe Königsberg Bridge Problem\n\n\n\nIs it possible to design a walk through the city that crosses each of the seven bridges exactly once?\n\n\nGo ahead, try it yourself on the map below. Trace a path with your finger. It seems simple enough, but you’ll soon discover the same frustrating problem the citizens did: you either get stuck, missing a bridge, or you have to cross one twice.\n\n\n\n\n\n\nFigure 1: A map of the seven bridges of Königsberg. Four landmasses are connected by seven bridges over the Pregel River.\n\n\n\nWhat makes this so difficult? No one could find a path, but more importantly, no one could prove it was impossible. The problem eventually reached the brilliant mathematician Leonhard Euler. His goal was not just to find an answer, but to understand the reason behind the answer.\n\n\n\n\n\n\nPause and Think Like a Mathematician\n\n\n\nBefore we reveal Euler’s solution, take a moment to be a mathematician yourself. This is how discovery happens. We strongly recommend working through this pen-and-paper worksheet to experience the discovery process.\nAs you work, ask yourself: - What information is essential? The length of the bridge? The size of the island? - What are the fundamental constraints of the problem? - How can you move from “I can’t find a path” to “A path cannot exist”?\nThe “aha!” moment is much more powerful when it’s your own.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#a-new-way-of-seeing-the-power-of-abstraction",
    "href": "m01-euler_tour/01-concepts.html#a-new-way-of-seeing-the-power-of-abstraction",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "2 A New Way of Seeing: The Power of Abstraction",
    "text": "2 A New Way of Seeing: The Power of Abstraction\nEuler’s genius was to realize that most of the information in the map was a distraction. He performed a radical act of simplification, an approach we now call abstraction.\nHe stripped the problem down to its skeleton: 1. He turned each of the four distinct landmasses into a simple dot (a node). 2. He turned each of the seven bridges into a simple line connecting the dots (an edge).\n\n\n\n\n\n\nFigure 2: Euler’s abstraction of the Königsberg bridge problem. The complex city map is reduced to a simple network of nodes and edges. Image from The Essential Guide to Graph Theory.\n\n\n\nThis wasn’t just a sketch; it was a new mathematical object. Euler had invented the graph (or network). He had created a new language to talk not about numbers or shapes, but about pure relationships and connectivity.\n\n\nLeonhard Euler (1707-1783)  One of history’s most prolific mathematicians. Despite losing his sight, he produced nearly half of his life’s work while completely blind.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#from-a-walk-to-a-proof-the-idea-of-degree",
    "href": "m01-euler_tour/01-concepts.html#from-a-walk-to-a-proof-the-idea-of-degree",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "3 From a Walk to a Proof: The Idea of Degree",
    "text": "3 From a Walk to a Proof: The Idea of Degree\nWith this new, simplified representation, Euler could stop thinking about walking and start thinking about rules. He focused on the nodes and asked a crucial question: how does a journey through a node work?\nImagine you are on a walk. Every time you arrive at a landmass, you cross one bridge. Every time you leave, you cross another. This means that for any landmass that is not the start or end of your journey, you must use bridges in pairs: one “in” and one “out.”\nThis leads to the key insight. Let’s count the number of bridges connected to each landmass. We’ll call this the degree of the node.\n\n\n\n\n\n\nKey Concept: Node Degree\n\n\n\nThe degree of a node is the number of edges connected to it. It is the most fundamental property of a node in a network.\n\n\n\nIf a node has an even degree (like 2, 4, or 6), you can always pass through it. For every “in” bridge, there is an “out” bridge.\nIf a node has an odd degree (like 1, 3, or 5), it must be special. The “in” and “out” bridges can’t all be paired up. One bridge will be left over. This means an odd-degree node must be the start or the end point of your walk.\n\nA walk can only have one start and one end. Therefore, to cross every bridge, there can be at most two nodes with an odd degree.\n\nThe Verdict\nLet’s apply this logic to the Königsberg graph:\n\nNorth Shore: Degree 3 (Odd)\nSouth Shore: Degree 3 (Odd)\nIsland A: Degree 5 (Odd)\nIsland B: Degree 3 (Odd)\n\nAll four landmasses have an odd degree! Since a walk can have at most two odd-degree nodes (one for the start, one for the end), the desired walk is mathematically impossible. Euler didn’t just fail to find a path; he proved, with logical certainty, that no such path could ever exist.\n\n\n\n\n\n\nEuler’s Conditions for a Walk\n\n\n\nA walk that crosses every edge in a graph exactly once (an Eulerian Path) is possible if and only if:\n\nThe graph is connected (you can get from any node to any other).\nAnd one of these is true:\n\nZero nodes have an odd degree. The walk must start and end at the same node (a closed loop, or Eulerian Circuit).\nExactly two nodes have an odd degree. The walk must start at one of the odd nodes and end at the other.\n\n\n\n\n\n\nA Tragic Epilogue\nThe story of the seven bridges has a sad, ironic twist. During World War II, the city of Königsberg was heavily bombed. Two of the seven bridges were destroyed, changing the layout of the city forever.\n\n\n\n\n\n\nFigure 3: After WWII bombing, only five bridges remained—finally making an Euler path possible.\n\n\n\nWith the two bridges gone, the network changed. Two of the landmasses now had an even degree, leaving just two with an odd degree. The impossible puzzle, which had fascinated people for over 200 years, was suddenly “solved” by the destruction of war.\nEuler’s solution was far more than fun trivia. It was the beginning of a new field of science. The idea of abstracting a system into nodes and edges is how we now understand our modern world. Every time you rely on a connected system, you are benefiting from the intellectual leap made by Euler over a puzzle about a Sunday stroll!",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#the-legacy-of-a-solved-puzzle",
    "href": "m01-euler_tour/01-concepts.html#the-legacy-of-a-solved-puzzle",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "4 The Legacy of a Solved Puzzle",
    "text": "4 The Legacy of a Solved Puzzle\nEuler’s solution was far more than an answer to a brain-teaser. It was the beginning of a new field of science. The idea of abstracting a system into nodes and edges is how we now understand our modern world:\n\nGPS Navigation: Your phone sees the world as a graph of roads and intersections to find the fastest route.\nSocial Networks: Companies map users and their connections to predict trends and model the flow of information.\nEpidemiology: Scientists model disease spread through networks of human contact to predict and control outbreaks.\n\nEvery time you rely on a connected system, you are benefiting from the intellectual leap made by Euler over a puzzle about a Sunday stroll.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#a-vocabulary-for-navigating-networks",
    "href": "m01-euler_tour/01-concepts.html#a-vocabulary-for-navigating-networks",
    "title": "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "5 A Vocabulary for Navigating Networks",
    "text": "5 A Vocabulary for Navigating Networks\nTo be precise, we need a formal language for talking about movement in networks. Let’s define the key terms using a road trip analogy.\n\n\n\n\n\n\n\n\nTerm\nDefinition\nAnalogy: A Road Trip\n\n\n\n\nWalk\nA sequence of nodes where you can repeat both roads (edges) and cities (nodes).\nA casual drive where you can go down the same street multiple times.\n\n\nTrail\nA walk where you cannot repeat edges, but you can revisit nodes.\nA mail route. The carrier can’t cover the same street twice but may pass the same intersection.\n\n\nPath\nA walk where you cannot repeat nodes (or edges, by consequence).\nA trip visiting a sequence of cities, each one new.\n\n\n\nA journey that starts and ends at the same place is closed. This gives us two more terms:\n\n\n\n\n\n\n\n\nTerm\nDefinition\nAnalogy: A Round Trip\n\n\n\n\nCircuit\nA trail that starts and ends at the same node.\nA scenic drive from your hotel and back, never taking the same road twice.\n\n\nCycle\nA path that starts and ends at the same node.\nA perfect loop, like a lap on a racetrack.\n\n\n\nUsing this language, we can say the Königsberg citizens were looking for an Eulerian circuit: a circuit that uses every single edge in the graph. Euler’s theorem proves this is only possible if every node has an even degree.",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "The Birth of Network Science: A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  },
  {
    "objectID": "m01-euler_tour/01-concepts.html#why-was-this-puzzle-so-hard",
    "href": "m01-euler_tour/01-concepts.html#why-was-this-puzzle-so-hard",
    "title": "A Stroll, Seven Bridges, and a Mathematical Revolution",
    "section": "",
    "text": "Our story begins not in a lab, but on the streets of an 18th-century Prussian city called Königsberg. It was a city of thinkers—most famously the philosopher Immanuel Kant—but the puzzle that would change mathematics belonged to everyone.\nThe city was built around two islands in the Pregel River, connected to the mainland and each other by seven distinct bridges. During their Sunday strolls, the citizens amused themselves with a challenge:\n\n\n\n\n\n\nThe Königsberg Bridge Problem\n\n\n\nIs it possible to design a walk through the city that crosses each of the seven bridges exactly once and return to the starting point?\n\n\nGo ahead, try it yourself on the map below. Tracing a path with your finger, you’ll soon discover the same frustrating problem the citizens did: you either get stuck, missing a bridge, or you have to cross one twice.\n\n\n\n\n\n\nFigure 1: A map of the seven bridges of Königsberg. Four landmasses are connected by seven bridges over the Pregel River.\n\n\n\nWhat makes this so difficult? No one could find a path, but more importantly, no one could prove it was impossible. The problem eventually reached the brilliant mathematician Leonhard Euler. His goal was not just to find an answer, but to understand the reason behind the answer.\n\n\n\n\n\n\nPause and Think Like a Mathematician\n\n\n\nBefore we reveal Euler’s solution, take a moment to be a mathematician yourself. This is how discovery happens. We strongly recommend working through this pen-and-paper worksheet to experience the discovery process.\nAs you work, ask yourself: - What information is essential? The length of the bridge? The size of the island? - What are the fundamental constraints of the problem? - How can you move from “I can’t find a path” to “A path cannot exist”?",
    "crumbs": [
      "Home",
      "M01: Euler Path",
      "A Stroll, Seven Bridges, and a Mathematical Revolution"
    ]
  }
]