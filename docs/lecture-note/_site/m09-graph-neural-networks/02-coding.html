<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sadamori Kojaku">
<meta name="dcterms.date" content="2025-10-06">

<title>Coding: Graph Neural Networks Implementation – Advanced Topics in Network Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../m09-graph-neural-networks/03-exercises.html" rel="next">
<link href="../m09-graph-neural-networks/01-concepts.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e6dc204ec8b52f55243daf2cac742210.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "|"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/custom.css">
</head>

<body class="nav-sidebar docked nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../logo.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Advanced Topics in Network Science</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-course" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Course</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-course">    
        <li>
    <a class="dropdown-item" href="../course/welcome.html">
 <span class="dropdown-text">Welcome</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../course/about.html">
 <span class="dropdown-text">About</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../course/discord.html">
 <span class="dropdown-text">Discord</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../course/minidora-usage.html">
 <span class="dropdown-text">Minidora</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../course/setup.html">
 <span class="dropdown-text">Setup</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-intro">    
        <li>
    <a class="dropdown-item" href="../intro/why-networks.html">
 <span class="dropdown-text">Why Networks?</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-foundations" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Foundations</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-foundations">    
        <li class="dropdown-header">─── M01: Euler Path ───</li>
        <li>
    <a class="dropdown-item" href="../m01-euler_tour/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-euler_tour/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-euler_tour/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m01-euler_tour/04-advanced.html">
 <span class="dropdown-text">Advanced</span></a>
  </li>  
        <li class="dropdown-header">─── M02: Small World ───</li>
        <li>
    <a class="dropdown-item" href="../m02-small-world/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-small-world/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-small-world/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m02-small-world/04-appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
        <li class="dropdown-header">─── M03: Robustness ───</li>
        <li>
    <a class="dropdown-item" href="../m03-robustness/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-robustness/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-robustness/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m03-robustness/04-appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-core-topics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Core Topics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-core-topics">    
        <li class="dropdown-header">─── M04: Friendship Paradox ───</li>
        <li>
    <a class="dropdown-item" href="../m04-node-degree/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-node-degree/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m04-node-degree/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li class="dropdown-header">─── M05: Clustering ───</li>
        <li>
    <a class="dropdown-item" href="../m05-clustering/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-clustering/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m05-clustering/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li class="dropdown-header">─── M06: Centrality ───</li>
        <li>
    <a class="dropdown-item" href="../m06-centrality/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-centrality/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m06-centrality/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-advanced-topics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Advanced Topics</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-advanced-topics">    
        <li class="dropdown-header">─── M07: Random Walks ───</li>
        <li>
    <a class="dropdown-item" href="../m07-random-walks/01-concepts.html">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m07-random-walks/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m07-random-walks/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li class="dropdown-header">─── M08: Embedding ───</li>
        <li>
    <a class="dropdown-item" href="../m08-embedding/01-concepts.md">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-embedding/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-embedding/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m08-embedding/04-appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
        <li class="dropdown-header">─── M09: Graph Neural Networks ───</li>
        <li>
    <a class="dropdown-item" href="../m09-graph-neural-networks/01-concepts.md">
 <span class="dropdown-text">Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m09-graph-neural-networks/02-coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m09-graph-neural-networks/03-exercises.html">
 <span class="dropdown-text">Exercises</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../m09-graph-neural-networks/04-appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../m09-graph-neural-networks/00-preparation.html">M09: Graph Neural Networks</a></li><li class="breadcrumb-item"><a href="../m09-graph-neural-networks/02-coding.html">Coding: Graph Neural Networks Implementation</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About us</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/discord.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discord</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/minidora-usage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Using Minidora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course/how-to-submit-assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to submit assignment</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Introduction</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro/why-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">M01: Euler Path</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-euler_tour/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A Stroll, Seven Bridges, and a Mathematical Revolution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-euler_tour/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Networks in Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-euler_tour/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m01-euler_tour/04-advanced.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced: Sparse Matrices for Large-Scale Networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">M02: Small World</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-small-world/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-small-world/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient Network Representation and Computing Paths</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-small-world/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises and Assignments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m02-small-world/04-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix - Brief Introduction to igraph</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">M03: Robustness</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-robustness/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-robustness/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding - Network Robustness Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-robustness/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises and Assignments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m03-robustness/04-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises and Assignments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">M04: Friendship Paradox</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-node-degree/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-node-degree/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Visualizing Degree Distributions in Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m04-node-degree/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">M05: Clustering</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-clustering/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-clustering/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering Algorithms and Implementation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m05-clustering/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises and Assignments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">M06: Centrality</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-centrality/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Centrality Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-centrality/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding - Centrality</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m06-centrality/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises &amp; Assignments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">M07: Random Walks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-random-walks/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Walks Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-random-walks/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding - Random Walks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m07-random-walks/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises &amp; Assignments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">M08: Embedding</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-embedding/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Network Embedding Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-embedding/02-coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Network Embedding Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-embedding/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m08-embedding/04-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics in Network Science</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">M09: Graph Neural Networks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/00-preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preparation - Image processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/01-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Concepts - From image to graph</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/02-coding.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Coding: Graph Neural Networks Implementation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/03-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises: Graph Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../m09-graph-neural-networks/04-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix: Graph Neural Networks</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../m09-graph-neural-networks/00-preparation.html">M09: Graph Neural Networks</a></li><li class="breadcrumb-item"><a href="../m09-graph-neural-networks/02-coding.html">Coding: Graph Neural Networks Implementation</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Coding: Graph Neural Networks Implementation</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sadamori Kojaku </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 6, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="hand-crafted-low-pass-and-high-pass-filters" class="level3">
<h3 class="anchored" data-anchor-id="hand-crafted-low-pass-and-high-pass-filters">Hand-crafted Low pass and high pass filters</h3>
<p>Let us showcase the idea of spectral filtering with a simple example with the karate club network.</p>
<p>We will first compute the laplacian matrix and its eigendecomposition.</p>
<div id="3839e7af" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Laplacian matrix</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>deg <span class="op">=</span> np.array(A.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)).reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> sparse.diags(deg)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> D <span class="op">-</span> A</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute eigendecomposition</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>evals, evecs <span class="op">=</span> np.linalg.eigh(L.toarray())</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort eigenvalues and eigenvectors</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> np.argsort(evals)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>evals <span class="op">=</span> evals[order]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>evecs <span class="op">=</span> evecs[:, order]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, let’s create a low-pass and high-pass filter.</p>
<div id="08dcbfc5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>L_low <span class="op">=</span> evecs <span class="op">@</span> np.diag(<span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> alpha <span class="op">*</span> evals)) <span class="op">@</span> evecs.T</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>L_high <span class="op">=</span> evecs <span class="op">@</span> np.diag(alpha <span class="op">*</span> evals <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> alpha <span class="op">*</span> evals)) <span class="op">@</span> evecs.T</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Size of low-pass filter:"</span>, L_low.shape)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Size of high-pass filter:"</span>, L_high.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Size of low-pass filter: (34, 34)
Size of high-pass filter: (34, 34)</code></pre>
</div>
</div>
<p>Notice that the high-pass filter and low-pass filter are matrices of the same size as the adjacency matrix <span class="math inline">A</span>, which defines a ‘convolution’ on the graph as follows:</p>
<p><span class="math display">
{\bf x}' = {\bf L}_{\text{low}} {\bf x} \quad \text{or} \quad {\bf x}' = {\bf L}_{\text{high}} {\bf x}.
</span></p>
<p>where <span class="math inline">{\bf L}_{\text{low}}</span> and <span class="math inline">{\bf L}_{\text{high}}</span> are the low-pass and high-pass filters, respectively, and <span class="math inline">{\bf x}'</span> is the convolved feature vector.</p>
<p>Now, let’s see how these filters work. Our first example is a random feature vector.</p>
<div id="eef301c9" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random feature vector</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.randn(A.shape[<span class="dv">0</span>], <span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolve with low-pass filter</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>x_low <span class="op">=</span> L_low <span class="op">@</span> x</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolve with high-pass filter</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>x_high <span class="op">=</span> L_high <span class="op">@</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us visualize the results.</p>
<div id="7da7d98b" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02-coding_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We observe that the low-pass filter results in smoother <span class="math inline">{\bf x}</span> between connected nodes (i.e., neighboring nodes have similar <span class="math inline">{\bf x}</span>). The original <span class="math inline">{\bf x}</span> and <span class="math inline">{\bf x}'_{\text{low}}</span> are very similar because random variables are high-frequency components. In contrast, when we apply the high-pass filter, <span class="math inline">{\bf x}'_{\text{high}}</span> is similar to <span class="math inline">{\bf x}</span> because the high-frequency components are not filtered.</p>
<p>Let’s now use an eigenvector as our feature vector <span class="math inline">{\bf x}</span>.</p>
<div id="3dfd8e99" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02-coding_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality.</p>
</section>
<section id="training-graph-neural-networks-with-pytorch-geometric" class="level2 page-columns page-full" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="training-graph-neural-networks-with-pytorch-geometric"><span class="header-section-number">1</span> Training Graph Neural Networks with PyTorch Geometric</h2>
<section id="what-is-pytorch-geometric" class="level3">
<h3 class="anchored" data-anchor-id="what-is-pytorch-geometric">What is PyTorch Geometric?</h3>
<p><a href="https://pytorch-geometric.readthedocs.io/">PyTorch Geometric (PyG)</a> is a library built on top of PyTorch specifically designed for deep learning on graphs and other irregular structures. It provides:</p>
<ul>
<li><strong>Efficient data structures</strong> for representing graphs (edge lists, sparse matrices)</li>
<li><strong>Pre-implemented GNN layers</strong> (GCN, GAT, GraphSAGE, GIN, and many more)</li>
<li><strong>Common graph datasets</strong> (citation networks, social networks, molecular graphs)</li>
<li><strong>Mini-batching utilities</strong> for training on large graphs</li>
<li><strong>Message passing framework</strong> for easily building custom GNN architectures</li>
</ul>
<p>PyTorch Geometric handles the complexity of implementing graph convolutions and lets us focus on model design and experimentation. Instead of manually implementing the aggregation operations we discussed earlier, we can use pre-built layers like <code>GCNConv</code>, <code>GATConv</code>, etc.</p>
</section>
<section id="our-task-semi-supervised-node-classification" class="level3">
<h3 class="anchored" data-anchor-id="our-task-semi-supervised-node-classification">Our Task: Semi-Supervised Node Classification</h3>
<p>In this section, we’ll learn how to train a Graph Neural Network (GNN) to perform node classification. We’ll use the Karate Club network and predict membership labels based on partially labeled nodes. Our node features will be eigenvectors of the normalized Laplacian matrix.</p>
<p>This is a <strong>semi-supervised learning</strong> task: we have labels for only a small subset of nodes and want to predict labels for the remaining nodes by leveraging the graph structure.</p>
</section>
<section id="step-1-install-and-import-libraries" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="step-1-install-and-import-libraries">Step 1: Install and Import Libraries</h3>
<p>First, let’s import the necessary libraries:</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Installing PyTorch Geometric</strong>: If you don’t have PyTorch Geometric installed, run:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install torch-geometric</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>For detailed installation instructions (including GPU support and specific PyTorch versions), see the <a href="https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html">official installation guide</a>.</p>
</div></div><div id="65f23b00" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch_geometric.nn <span class="im">import</span> GCNConv</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch_geometric.data <span class="im">import</span> Data</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> igraph <span class="im">as</span> ig</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> sparse</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-2-prepare-the-data" class="level3">
<h3 class="anchored" data-anchor-id="step-2-prepare-the-data">Step 2: Prepare the Data</h3>
<p>We’ll load the Karate Club network and compute node features from the normalized Laplacian eigenvectors.</p>
<div id="030a14b9" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Karate Club network</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.karate_club_graph()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> nx.adjacency_matrix(G)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get true community labels</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>membership <span class="op">=</span> np.unique([d[<span class="dv">1</span>][<span class="st">'club'</span>] <span class="cf">for</span> d <span class="kw">in</span> G.nodes(data<span class="op">=</span><span class="va">True</span>)], return_inverse<span class="op">=</span><span class="va">True</span>)[<span class="dv">1</span>]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>n_nodes <span class="op">=</span> A.shape[<span class="dv">0</span>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of nodes: </span><span class="sc">{</span>n_nodes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Membership: </span><span class="sc">{</span>membership<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of nodes: 34
Membership: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1]</code></pre>
</div>
</div>
<section id="creating-node-features" class="level4">
<h4 class="anchored" data-anchor-id="creating-node-features">Creating Node Features</h4>
<p>Graph neural networks require node features as input to make predictions. However, the Karate Club network doesn’t come with node metadata (attributes like age, interests, etc.) - we only have the network structure and membership labels.</p>
<p>Since we need features but don’t have any, we’ll create them using <strong>spectral embedding</strong> - specifically, eigenvectors of the normalized Laplacian matrix. This is a common approach when dealing with networks that lack node attributes.</p>
<p>Now, let’s compute the normalized Laplacian and extract eigenvectors as node features:</p>
<div id="25684f3e" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute normalized Laplacian: L_norm = I - D^{-1/2} A D^{-1/2}</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>deg <span class="op">=</span> np.array(A.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)).reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>D_inv_sqrt <span class="op">=</span> sparse.diags(<span class="fl">1.0</span> <span class="op">/</span> np.sqrt(deg))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>L_norm <span class="op">=</span> sparse.eye(n_nodes) <span class="op">-</span> D_inv_sqrt <span class="op">@</span> A <span class="op">@</span> D_inv_sqrt</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute eigendecomposition</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>evals, evecs <span class="op">=</span> np.linalg.eigh(L_norm.toarray())</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the first k eigenvectors as features (excluding the trivial one)</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>node_features <span class="op">=</span> evecs[:, <span class="dv">1</span>:k<span class="op">+</span><span class="dv">1</span>]  <span class="co"># Skip the first eigenvector (constant)</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Node feature shape: </span><span class="sc">{</span>node_features<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Feature matrix:</span><span class="ch">\n</span><span class="sc">{</span>node_features[:<span class="dv">5</span>]<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Show first 5 rows</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Node feature shape: (34, 5)
Feature matrix:
[[-2.88145579e-01  1.12567115e-01 -5.73186014e-02  5.25378039e-02
  -3.14434772e-01]
 [-1.40842407e-01  3.44386666e-01 -1.59157964e-02  3.24502220e-02
   2.26171287e-02]
 [-6.72590109e-02  2.73089509e-01 -9.84243347e-03 -7.56784621e-02
   1.19000575e-01]
 [-1.34361370e-01  3.15397166e-01 -5.20087178e-02  1.41200733e-01
   2.48990185e-01]
 [-2.32296270e-01 -1.63500942e-01 -2.17413053e-05  2.41275396e-02
  -4.45745025e-01]]</code></pre>
</div>
</div>
</section>
</section>
<section id="step-3-create-pytorch-geometric-data-object" class="level3">
<h3 class="anchored" data-anchor-id="step-3-create-pytorch-geometric-data-object">Step 3: Create PyTorch Geometric Data Object</h3>
<p>PyTorch Geometric requires data in a specific format. We need to convert our network into an edge list and create a <code>Data</code> object.</p>
<div id="5d5a001a" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert adjacency matrix to edge list (COO format)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>edge_index <span class="op">=</span> torch.tensor(np.array(A.nonzero()), dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert node features to tensor</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(node_features, dtype<span class="op">=</span>torch.<span class="bu">float</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert labels to tensor</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(membership, dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create PyTorch Geometric Data object</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> Data(x<span class="op">=</span>x, edge_index<span class="op">=</span>edge_index, y<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-4-create-traintest-masks" class="level3">
<h3 class="anchored" data-anchor-id="step-4-create-traintest-masks">Step 4: Create Train/Test Masks</h3>
<p>We’ll use only a small subset of labeled nodes for training (semi-supervised learning) and test on the rest.</p>
<div id="72ec5486" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create train/test masks</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>train_mask <span class="op">=</span> torch.zeros(n_nodes, dtype<span class="op">=</span>torch.<span class="bu">bool</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>test_mask <span class="op">=</span> torch.zeros(n_nodes, dtype<span class="op">=</span>torch.<span class="bu">bool</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Select 2 nodes from each class for training</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label <span class="kw">in</span> [<span class="dv">0</span>, <span class="dv">1</span>]:</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    label_indices <span class="op">=</span> np.where(membership <span class="op">==</span> label)[<span class="dv">0</span>]</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    np.random.shuffle(label_indices)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    train_mask[label_indices[:<span class="dv">2</span>]] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># All other nodes are for testing</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>test_mask <span class="op">=</span> <span class="op">~</span>train_mask</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>data.train_mask <span class="op">=</span> train_mask</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>data.test_mask <span class="op">=</span> test_mask</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of training nodes: </span><span class="sc">{</span>train_mask<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of test nodes: </span><span class="sc">{</span>test_mask<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training node indices: </span><span class="sc">{</span>torch<span class="sc">.</span>where(train_mask)[<span class="dv">0</span>]<span class="sc">.</span>numpy()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of training nodes: 4
Number of test nodes: 30
Training node indices: [ 4 11 23 26]</code></pre>
</div>
</div>
</section>
<section id="step-5-define-the-gnn-model" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="step-5-define-the-gnn-model">Step 5: Define the GNN Model</h3>
<p>We’ll create a simple 2-layer Graph Convolutional Network (GCN).</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>GCNConv</strong>: PyTorch Geometric’s implementation of Graph Convolutional Network layer from <a href="https://arxiv.org/abs/1609.02907">Kipf &amp; Welling (2017)</a>. It performs neighborhood aggregation with symmetric normalization: <span class="math inline">\mathbf{X}^{(l+1)} = \sigma(\mathbf{\hat{D}}^{-1/2}\mathbf{\hat{A}}\mathbf{\hat{D}}^{-1/2}\mathbf{X}^{(l)}\mathbf{W}^{(l)})</span>.</p>
<p><a href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html">GCNConv Documentation →</a></p>
</div></div><div id="b62d6453" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GCN(torch.nn.Module):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_features, hidden_channels, num_classes):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(GCN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First GCN layer: input features -&gt; hidden dimension</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> GCNConv(num_features, hidden_channels)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Second GCN layer: hidden dimension -&gt; output classes</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> GCNConv(hidden_channels, num_classes)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, edge_index):</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First layer with ReLU activation</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv1(x, edge_index)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.dropout(x, p<span class="op">=</span><span class="fl">0.5</span>, training<span class="op">=</span><span class="va">self</span>.training)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Second layer (no activation, we'll use softmax later)</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv2(x, edge_index)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the model</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GCN(</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    num_features<span class="op">=</span>data.num_node_features,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    hidden_channels<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="dv">2</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Total parameters: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>GCN(
  (conv1): GCNConv(5, 16)
  (conv2): GCNConv(16, 2)
)

Total parameters: 130</code></pre>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>ReLU</strong> (Rectified Linear Unit): Activation function <span class="math inline">\text{ReLU}(x) = \max(0, x)</span> that introduces non-linearity. It outputs the input if positive, otherwise zero. This allows the network to learn complex patterns.</p>
<p><strong>Dropout</strong>: Regularization technique that randomly sets a fraction of neurons to zero during training (here 50%). This prevents overfitting by forcing the network to learn robust features that don’t rely on specific neurons.</p>
</div></div></section>
<section id="step-6-training-loop" class="level3">
<h3 class="anchored" data-anchor-id="step-6-training-loop">Step 6: Training Loop</h3>
<p>Now let’s train the GNN model using gradient descent.</p>
<div id="0b33f862" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up optimizer and loss function</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>, weight_decay<span class="op">=</span><span class="fl">5e-4</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Training function</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train():</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> model(data.x, data.edge_index)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute loss only on training nodes</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(out[data.train_mask], data.y[data.train_mask])</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Backward pass</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss.item()</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation function</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test():</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> model(data.x, data.edge_index)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> out.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate accuracy on train and test sets</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>        train_correct <span class="op">=</span> pred[data.train_mask] <span class="op">==</span> data.y[data.train_mask]</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>        test_correct <span class="op">=</span> pred[data.test_mask] <span class="op">==</span> data.y[data.test_mask]</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>        train_acc <span class="op">=</span> <span class="bu">int</span>(train_correct.<span class="bu">sum</span>()) <span class="op">/</span> <span class="bu">int</span>(data.train_mask.<span class="bu">sum</span>())</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        test_acc <span class="op">=</span> <span class="bu">int</span>(test_correct.<span class="bu">sum</span>()) <span class="op">/</span> <span class="bu">int</span>(data.test_mask.<span class="bu">sum</span>())</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_acc, test_acc</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> []</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>train_accs <span class="op">=</span> []</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>test_accs <span class="op">=</span> []</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> train()</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    train_acc, test_acc <span class="op">=</span> test()</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>    losses.append(loss)</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>    train_accs.append(train_acc)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    test_accs.append(test_acc)</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">20</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:03d}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">:.4f}</span><span class="ss">, '</span></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f'Train Acc: </span><span class="sc">{</span>train_acc<span class="sc">:.4f}</span><span class="ss">, Test Acc: </span><span class="sc">{</span>test_acc<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Final Test Accuracy: </span><span class="sc">{</span>test_accs[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 020, Loss: 0.5297, Train Acc: 1.0000, Test Acc: 0.8333
Epoch 040, Loss: 0.3153, Train Acc: 1.0000, Test Acc: 0.9333
Epoch 060, Loss: 0.1510, Train Acc: 1.0000, Test Acc: 0.9333
Epoch 080, Loss: 0.0596, Train Acc: 1.0000, Test Acc: 1.0000
Epoch 100, Loss: 0.0221, Train Acc: 1.0000, Test Acc: 0.9333
Epoch 120, Loss: 0.0247, Train Acc: 1.0000, Test Acc: 1.0000
Epoch 140, Loss: 0.0413, Train Acc: 1.0000, Test Acc: 0.9667
Epoch 160, Loss: 0.0218, Train Acc: 1.0000, Test Acc: 1.0000
Epoch 180, Loss: 0.0179, Train Acc: 1.0000, Test Acc: 0.9667
Epoch 200, Loss: 0.0070, Train Acc: 1.0000, Test Acc: 1.0000

Final Test Accuracy: 1.0000</code></pre>
</div>
</div>
</section>
<section id="step-7-visualize-training-progress" class="level3">
<h3 class="anchored" data-anchor-id="step-7-visualize-training-progress">Step 7: Visualize Training Progress</h3>
<p>Let’s visualize how the model learned over time.</p>
<div id="b5e2c2b4" class="cell" data-execution_count="14">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02-coding_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="step-8-visualize-predictions" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="step-8-visualize-predictions">Step 8: Visualize Predictions</h3>
<p>Finally, let’s visualize the network with true labels, training nodes, and predictions.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Squares vs Circles</strong>: In the left plot, square nodes represent the <strong>training nodes</strong> (labeled data used for learning), while circle nodes represent <strong>test nodes</strong> (unlabeled data to predict). This visualization shows that the GNN learned from only 4 labeled nodes to predict labels for the remaining 30 nodes.</p>
</div></div><div id="d58025f8" class="cell" data-execution_count="15">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02-coding_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Misclassified nodes: []
Number of misclassified nodes: 0</code></pre>
</div>
</div>
</section>
<section id="understanding-what-we-did" class="level3">
<h3 class="anchored" data-anchor-id="understanding-what-we-did">Understanding What We Did</h3>
<p><strong>Data Preparation</strong>: We used eigenvectors of the normalized Laplacian as node features. These features capture the structural position of each node in the network.</p>
<p><strong>Semi-Supervised Learning</strong>: We trained on only 4 labeled nodes (2 from each community) and predicted labels for the remaining 30 nodes. This demonstrates the power of GNNs to propagate information through the network structure.</p>
<p><strong>GCN Architecture</strong>: Our 2-layer GCN works as follows: - <strong>Layer 1</strong>: Aggregates features from neighbors and transforms them to a hidden representation - <strong>Layer 2</strong>: Aggregates hidden representations and outputs class probabilities</p>
<p><strong>Message Passing</strong>: Each GCN layer performs: <span class="math inline">\mathbf{h}_i^{(l+1)} = \sigma\left(\sum_{j \in \mathcal{N}(i)} \frac{1}{\sqrt{d_i d_j}} \mathbf{W}^{(l)} \mathbf{h}_j^{(l)}\right)</span></p>
<p>where neighbors influence each node’s representation, allowing label information to propagate through the network.</p>
<p><strong>Training</strong>: We optimized the model using cross-entropy loss on the small set of labeled nodes, but the loss gradients propagate through the entire network structure, allowing all nodes to contribute to learning.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/skojaku\.github\.io\/adv-net-sci\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../m09-graph-neural-networks/01-concepts.html" class="pagination-link" aria-label="Concepts - From image to graph">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Concepts - From image to graph</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../m09-graph-neural-networks/03-exercises.html" class="pagination-link" aria-label="Exercises: Graph Neural Networks">
        <span class="nav-page-text">Exercises: Graph Neural Networks</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb19" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Coding: Graph Neural Networks Implementation"</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> advnetsci</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">    enabled: true</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hand-crafted Low pass and high pass filters</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>Let us showcase the idea of spectral filtering with a simple example with the karate club network.</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> igraph <span class="im">as</span> ig</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> sparse</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> ig.Graph.Famous(<span class="st">"Zachary"</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> G.get_adjacency_sparse()</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>We will first compute the laplacian matrix and its eigendecomposition.</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Laplacian matrix</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>deg <span class="op">=</span> np.array(A.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)).reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> sparse.diags(deg)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> D <span class="op">-</span> A</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute eigendecomposition</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>evals, evecs <span class="op">=</span> np.linalg.eigh(L.toarray())</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort eigenvalues and eigenvectors</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> np.argsort(evals)</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>evals <span class="op">=</span> evals[order]</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>evecs <span class="op">=</span> evecs[:, order]</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>Now, let's create a low-pass and high-pass filter.</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>L_low <span class="op">=</span> evecs <span class="op">@</span> np.diag(<span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> alpha <span class="op">*</span> evals)) <span class="op">@</span> evecs.T</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>L_high <span class="op">=</span> evecs <span class="op">@</span> np.diag(alpha <span class="op">*</span> evals <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> alpha <span class="op">*</span> evals)) <span class="op">@</span> evecs.T</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Size of low-pass filter:"</span>, L_low.shape)</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Size of high-pass filter:"</span>, L_high.shape)</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>Notice that the high-pass filter and low-pass filter are matrices of the same size as the adjacency matrix $A$, which defines a 'convolution' on the graph as follows:</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>{\bf x}' = {\bf L}_{\text{low}} {\bf x} \quad \text{or} \quad {\bf x}' = {\bf L}_{\text{high}} {\bf x}.</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>where ${\bf L}_{\text{low}}$ and ${\bf L}_{\text{high}}$ are the low-pass and high-pass filters, respectively, and ${\bf x}'$ is the convolved feature vector.</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>Now, let's see how these filters work. Our first example is a random feature vector.</span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Random feature vector</span></span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.randn(A.shape[<span class="dv">0</span>], <span class="dv">1</span>)</span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolve with low-pass filter</span></span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a>x_low <span class="op">=</span> L_low <span class="op">@</span> x</span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolve with high-pass filter</span></span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a>x_high <span class="op">=</span> L_high <span class="op">@</span> x</span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a>Let us visualize the results.</span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb19-91"><a href="#cb19-91" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette(<span class="st">"viridis"</span>, as_cmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-92"><a href="#cb19-92" aria-hidden="true" tabindex="-1"></a>norm <span class="op">=</span> mpl.colors.Normalize(vmin<span class="op">=-</span><span class="fl">0.3</span>, vmax<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-93"><a href="#cb19-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-94"><a href="#cb19-94" aria-hidden="true" tabindex="-1"></a><span class="co"># Original</span></span>
<span id="cb19-95"><a href="#cb19-95" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> x.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-96"><a href="#cb19-96" aria-hidden="true" tabindex="-1"></a>values <span class="op">/=</span> np.linalg.norm(values)</span>
<span id="cb19-97"><a href="#cb19-97" aria-hidden="true" tabindex="-1"></a>ig.plot(G, vertex_color<span class="op">=</span>[palette(norm(x)) <span class="cf">for</span> x <span class="kw">in</span> values], bbox<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">500</span>, <span class="dv">500</span>), vertex_size<span class="op">=</span><span class="dv">20</span>, target<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb19-98"><a href="#cb19-98" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"Original"</span>)</span>
<span id="cb19-99"><a href="#cb19-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-100"><a href="#cb19-100" aria-hidden="true" tabindex="-1"></a><span class="co"># Low-pass filter applied</span></span>
<span id="cb19-101"><a href="#cb19-101" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> L_low <span class="op">@</span> x</span>
<span id="cb19-102"><a href="#cb19-102" aria-hidden="true" tabindex="-1"></a>values <span class="op">/=</span> np.linalg.norm(values)</span>
<span id="cb19-103"><a href="#cb19-103" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> values.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-104"><a href="#cb19-104" aria-hidden="true" tabindex="-1"></a>ig.plot(G, vertex_color<span class="op">=</span>[palette(norm(x)) <span class="cf">for</span> x <span class="kw">in</span> values], bbox<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">500</span>, <span class="dv">500</span>), vertex_size<span class="op">=</span><span class="dv">20</span>, target<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb19-105"><a href="#cb19-105" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"Low-pass filter"</span>)</span>
<span id="cb19-106"><a href="#cb19-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-107"><a href="#cb19-107" aria-hidden="true" tabindex="-1"></a><span class="co"># High-pass filter applied</span></span>
<span id="cb19-108"><a href="#cb19-108" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> L_high <span class="op">@</span> x</span>
<span id="cb19-109"><a href="#cb19-109" aria-hidden="true" tabindex="-1"></a>values <span class="op">/=</span> np.linalg.norm(values)</span>
<span id="cb19-110"><a href="#cb19-110" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> values.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-111"><a href="#cb19-111" aria-hidden="true" tabindex="-1"></a>ig.plot(G, vertex_color<span class="op">=</span>[palette(norm(x)) <span class="cf">for</span> x <span class="kw">in</span> values], bbox<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">500</span>, <span class="dv">500</span>), vertex_size<span class="op">=</span><span class="dv">20</span>, target<span class="op">=</span>axes[<span class="dv">2</span>])</span>
<span id="cb19-112"><a href="#cb19-112" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">"High-pass filter"</span>)</span>
<span id="cb19-113"><a href="#cb19-113" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb19-114"><a href="#cb19-114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-115"><a href="#cb19-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-116"><a href="#cb19-116" aria-hidden="true" tabindex="-1"></a>We observe that the low-pass filter results in smoother ${\bf x}$ between connected nodes (i.e., neighboring nodes have similar ${\bf x}$).</span>
<span id="cb19-117"><a href="#cb19-117" aria-hidden="true" tabindex="-1"></a>The original ${\bf x}$ and ${\bf x}'_{\text{low}}$ are very similar because random variables are high-frequency components. In contrast, when we apply the high-pass filter, ${\bf x}'_{\text{high}}$ is similar to ${\bf x}$ because the high-frequency components are not filtered.</span>
<span id="cb19-118"><a href="#cb19-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-119"><a href="#cb19-119" aria-hidden="true" tabindex="-1"></a>Let's now use an eigenvector as our feature vector ${\bf x}$.</span>
<span id="cb19-120"><a href="#cb19-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-123"><a href="#cb19-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-124"><a href="#cb19-124" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb19-125"><a href="#cb19-125" aria-hidden="true" tabindex="-1"></a>eigen_centrality <span class="op">=</span> np.array(G.eigenvector_centrality()).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb19-126"><a href="#cb19-126" aria-hidden="true" tabindex="-1"></a>low_pass_eigen <span class="op">=</span> L_low <span class="op">@</span> eigen_centrality</span>
<span id="cb19-127"><a href="#cb19-127" aria-hidden="true" tabindex="-1"></a>high_pass_eigen <span class="op">=</span> L_high <span class="op">@</span> eigen_centrality</span>
<span id="cb19-128"><a href="#cb19-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-129"><a href="#cb19-129" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb19-130"><a href="#cb19-130" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette(<span class="st">"viridis"</span>, as_cmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-131"><a href="#cb19-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-132"><a href="#cb19-132" aria-hidden="true" tabindex="-1"></a>norm <span class="op">=</span> mpl.colors.Normalize(vmin<span class="op">=-</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-133"><a href="#cb19-133" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> eigen_centrality.reshape(<span class="op">-</span><span class="dv">1</span>)<span class="co"># high_pass_random.reshape(-1)</span></span>
<span id="cb19-134"><a href="#cb19-134" aria-hidden="true" tabindex="-1"></a>values <span class="op">/=</span> np.linalg.norm(values)</span>
<span id="cb19-135"><a href="#cb19-135" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> values.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-136"><a href="#cb19-136" aria-hidden="true" tabindex="-1"></a>ig.plot(G, vertex_color<span class="op">=</span>[palette(norm(x)) <span class="cf">for</span> x <span class="kw">in</span> values], bbox<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">500</span>, <span class="dv">500</span>), vertex_size<span class="op">=</span><span class="dv">20</span>, target<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb19-137"><a href="#cb19-137" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"Original"</span>)</span>
<span id="cb19-138"><a href="#cb19-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-139"><a href="#cb19-139" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> low_pass_eigen.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-140"><a href="#cb19-140" aria-hidden="true" tabindex="-1"></a>values <span class="op">/=</span> np.linalg.norm(values)</span>
<span id="cb19-141"><a href="#cb19-141" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> values.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-142"><a href="#cb19-142" aria-hidden="true" tabindex="-1"></a>ig.plot(G, vertex_color<span class="op">=</span>[palette(norm(x)) <span class="cf">for</span> x <span class="kw">in</span> values], bbox<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">500</span>, <span class="dv">500</span>), vertex_size<span class="op">=</span><span class="dv">20</span>, target<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb19-143"><a href="#cb19-143" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"Low-pass filter"</span>)</span>
<span id="cb19-144"><a href="#cb19-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-145"><a href="#cb19-145" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> high_pass_eigen.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-146"><a href="#cb19-146" aria-hidden="true" tabindex="-1"></a>values <span class="op">/=</span> np.linalg.norm(values)</span>
<span id="cb19-147"><a href="#cb19-147" aria-hidden="true" tabindex="-1"></a>ig.plot(G, vertex_color<span class="op">=</span>[palette(norm(x)) <span class="cf">for</span> x <span class="kw">in</span> values], bbox<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">500</span>, <span class="dv">500</span>), vertex_size<span class="op">=</span><span class="dv">20</span>, target<span class="op">=</span>axes[<span class="dv">2</span>])</span>
<span id="cb19-148"><a href="#cb19-148" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">"High-pass filter"</span>)</span>
<span id="cb19-149"><a href="#cb19-149" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb19-150"><a href="#cb19-150" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-151"><a href="#cb19-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-152"><a href="#cb19-152" aria-hidden="true" tabindex="-1"></a>The high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality.</span>
<span id="cb19-153"><a href="#cb19-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-154"><a href="#cb19-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-155"><a href="#cb19-155" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training Graph Neural Networks with PyTorch Geometric</span></span>
<span id="cb19-156"><a href="#cb19-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-157"><a href="#cb19-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### What is PyTorch Geometric?</span></span>
<span id="cb19-158"><a href="#cb19-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-159"><a href="#cb19-159" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">PyTorch Geometric (PyG)</span><span class="co">](https://pytorch-geometric.readthedocs.io/)</span> is a library built on top of PyTorch specifically designed for deep learning on graphs and other irregular structures. It provides:</span>
<span id="cb19-160"><a href="#cb19-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-161"><a href="#cb19-161" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Efficient data structures** for representing graphs (edge lists, sparse matrices)</span>
<span id="cb19-162"><a href="#cb19-162" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Pre-implemented GNN layers** (GCN, GAT, GraphSAGE, GIN, and many more)</span>
<span id="cb19-163"><a href="#cb19-163" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Common graph datasets** (citation networks, social networks, molecular graphs)</span>
<span id="cb19-164"><a href="#cb19-164" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Mini-batching utilities** for training on large graphs</span>
<span id="cb19-165"><a href="#cb19-165" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Message passing framework** for easily building custom GNN architectures</span>
<span id="cb19-166"><a href="#cb19-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-167"><a href="#cb19-167" aria-hidden="true" tabindex="-1"></a>PyTorch Geometric handles the complexity of implementing graph convolutions and lets us focus on model design and experimentation. Instead of manually implementing the aggregation operations we discussed earlier, we can use pre-built layers like <span class="in">`GCNConv`</span>, <span class="in">`GATConv`</span>, etc.</span>
<span id="cb19-168"><a href="#cb19-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-169"><a href="#cb19-169" aria-hidden="true" tabindex="-1"></a><span class="fu">### Our Task: Semi-Supervised Node Classification</span></span>
<span id="cb19-170"><a href="#cb19-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-171"><a href="#cb19-171" aria-hidden="true" tabindex="-1"></a>In this section, we'll learn how to train a Graph Neural Network (GNN) to perform node classification. We'll use the Karate Club network and predict membership labels based on partially labeled nodes. Our node features will be eigenvectors of the normalized Laplacian matrix.</span>
<span id="cb19-172"><a href="#cb19-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-173"><a href="#cb19-173" aria-hidden="true" tabindex="-1"></a>This is a **semi-supervised learning** task: we have labels for only a small subset of nodes and want to predict labels for the remaining nodes by leveraging the graph structure.</span>
<span id="cb19-174"><a href="#cb19-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-175"><a href="#cb19-175" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 1: Install and Import Libraries</span></span>
<span id="cb19-176"><a href="#cb19-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-177"><a href="#cb19-177" aria-hidden="true" tabindex="-1"></a>First, let's import the necessary libraries:</span>
<span id="cb19-178"><a href="#cb19-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-179"><a href="#cb19-179" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb19-180"><a href="#cb19-180" aria-hidden="true" tabindex="-1"></a>**Installing PyTorch Geometric**: If you don't have PyTorch Geometric installed, run:</span>
<span id="cb19-181"><a href="#cb19-181" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb19-182"><a href="#cb19-182" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install torch_geometric</span>
<span id="cb19-183"><a href="#cb19-183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-184"><a href="#cb19-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-185"><a href="#cb19-185" aria-hidden="true" tabindex="-1"></a>For detailed installation instructions (including GPU support and specific PyTorch versions), see the <span class="co">[</span><span class="ot">official installation guide</span><span class="co">](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html)</span>.</span>
<span id="cb19-186"><a href="#cb19-186" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb19-187"><a href="#cb19-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-190"><a href="#cb19-190" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-191"><a href="#cb19-191" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb19-192"><a href="#cb19-192" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb19-193"><a href="#cb19-193" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch_geometric.nn <span class="im">import</span> GCNConv</span>
<span id="cb19-194"><a href="#cb19-194" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch_geometric.data <span class="im">import</span> Data</span>
<span id="cb19-195"><a href="#cb19-195" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-196"><a href="#cb19-196" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> igraph <span class="im">as</span> ig</span>
<span id="cb19-197"><a href="#cb19-197" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> sparse</span>
<span id="cb19-198"><a href="#cb19-198" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-199"><a href="#cb19-199" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb19-200"><a href="#cb19-200" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-201"><a href="#cb19-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-202"><a href="#cb19-202" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 2: Prepare the Data</span></span>
<span id="cb19-203"><a href="#cb19-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-204"><a href="#cb19-204" aria-hidden="true" tabindex="-1"></a>We'll load the Karate Club network and compute node features from the normalized Laplacian eigenvectors.</span>
<span id="cb19-205"><a href="#cb19-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-208"><a href="#cb19-208" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-209"><a href="#cb19-209" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb19-210"><a href="#cb19-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-211"><a href="#cb19-211" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Karate Club network</span></span>
<span id="cb19-212"><a href="#cb19-212" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.karate_club_graph()</span>
<span id="cb19-213"><a href="#cb19-213" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> nx.adjacency_matrix(G)</span>
<span id="cb19-214"><a href="#cb19-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-215"><a href="#cb19-215" aria-hidden="true" tabindex="-1"></a><span class="co"># Get true community labels</span></span>
<span id="cb19-216"><a href="#cb19-216" aria-hidden="true" tabindex="-1"></a>membership <span class="op">=</span> np.unique([d[<span class="dv">1</span>][<span class="st">'club'</span>] <span class="cf">for</span> d <span class="kw">in</span> G.nodes(data<span class="op">=</span><span class="va">True</span>)], return_inverse<span class="op">=</span><span class="va">True</span>)[<span class="dv">1</span>]</span>
<span id="cb19-217"><a href="#cb19-217" aria-hidden="true" tabindex="-1"></a>n_nodes <span class="op">=</span> A.shape[<span class="dv">0</span>]</span>
<span id="cb19-218"><a href="#cb19-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-219"><a href="#cb19-219" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of nodes: </span><span class="sc">{</span>n_nodes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-220"><a href="#cb19-220" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Membership: </span><span class="sc">{</span>membership<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-221"><a href="#cb19-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-222"><a href="#cb19-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-223"><a href="#cb19-223" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Creating Node Features</span></span>
<span id="cb19-224"><a href="#cb19-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-225"><a href="#cb19-225" aria-hidden="true" tabindex="-1"></a>Graph neural networks require node features as input to make predictions. However, the Karate Club network doesn't come with node metadata (attributes like age, interests, etc.) - we only have the network structure and membership labels.</span>
<span id="cb19-226"><a href="#cb19-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-227"><a href="#cb19-227" aria-hidden="true" tabindex="-1"></a>Since we need features but don't have any, we'll create them using **spectral embedding** - specifically, eigenvectors of the normalized Laplacian matrix. This is a common approach when dealing with networks that lack node attributes.</span>
<span id="cb19-228"><a href="#cb19-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-229"><a href="#cb19-229" aria-hidden="true" tabindex="-1"></a>Now, let's compute the normalized Laplacian and extract eigenvectors as node features:</span>
<span id="cb19-230"><a href="#cb19-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-233"><a href="#cb19-233" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-234"><a href="#cb19-234" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute normalized Laplacian: L_norm = I - D^{-1/2} A D^{-1/2}</span></span>
<span id="cb19-235"><a href="#cb19-235" aria-hidden="true" tabindex="-1"></a>deg <span class="op">=</span> np.array(A.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)).reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb19-236"><a href="#cb19-236" aria-hidden="true" tabindex="-1"></a>D_inv_sqrt <span class="op">=</span> sparse.diags(<span class="fl">1.0</span> <span class="op">/</span> np.sqrt(deg))</span>
<span id="cb19-237"><a href="#cb19-237" aria-hidden="true" tabindex="-1"></a>L_norm <span class="op">=</span> sparse.eye(n_nodes) <span class="op">-</span> D_inv_sqrt <span class="op">@</span> A <span class="op">@</span> D_inv_sqrt</span>
<span id="cb19-238"><a href="#cb19-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-239"><a href="#cb19-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute eigendecomposition</span></span>
<span id="cb19-240"><a href="#cb19-240" aria-hidden="true" tabindex="-1"></a>evals, evecs <span class="op">=</span> np.linalg.eigh(L_norm.toarray())</span>
<span id="cb19-241"><a href="#cb19-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-242"><a href="#cb19-242" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the first k eigenvectors as features (excluding the trivial one)</span></span>
<span id="cb19-243"><a href="#cb19-243" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb19-244"><a href="#cb19-244" aria-hidden="true" tabindex="-1"></a>node_features <span class="op">=</span> evecs[:, <span class="dv">1</span>:k<span class="op">+</span><span class="dv">1</span>]  <span class="co"># Skip the first eigenvector (constant)</span></span>
<span id="cb19-245"><a href="#cb19-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-246"><a href="#cb19-246" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Node feature shape: </span><span class="sc">{</span>node_features<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-247"><a href="#cb19-247" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Feature matrix:</span><span class="ch">\n</span><span class="sc">{</span>node_features[:<span class="dv">5</span>]<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Show first 5 rows</span></span>
<span id="cb19-248"><a href="#cb19-248" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-249"><a href="#cb19-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-250"><a href="#cb19-250" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 3: Create PyTorch Geometric Data Object</span></span>
<span id="cb19-251"><a href="#cb19-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-252"><a href="#cb19-252" aria-hidden="true" tabindex="-1"></a>PyTorch Geometric requires data in a specific format. We need to convert our network into an edge list and create a <span class="in">`Data`</span> object.</span>
<span id="cb19-253"><a href="#cb19-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-256"><a href="#cb19-256" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-257"><a href="#cb19-257" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert adjacency matrix to edge list (COO format)</span></span>
<span id="cb19-258"><a href="#cb19-258" aria-hidden="true" tabindex="-1"></a>edge_index <span class="op">=</span> torch.tensor(np.array(A.nonzero()), dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb19-259"><a href="#cb19-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-260"><a href="#cb19-260" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert node features to tensor</span></span>
<span id="cb19-261"><a href="#cb19-261" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(node_features, dtype<span class="op">=</span>torch.<span class="bu">float</span>)</span>
<span id="cb19-262"><a href="#cb19-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-263"><a href="#cb19-263" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert labels to tensor</span></span>
<span id="cb19-264"><a href="#cb19-264" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(membership, dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb19-265"><a href="#cb19-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-266"><a href="#cb19-266" aria-hidden="true" tabindex="-1"></a><span class="co"># Create PyTorch Geometric Data object</span></span>
<span id="cb19-267"><a href="#cb19-267" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> Data(x<span class="op">=</span>x, edge_index<span class="op">=</span>edge_index, y<span class="op">=</span>y)</span>
<span id="cb19-268"><a href="#cb19-268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-269"><a href="#cb19-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-270"><a href="#cb19-270" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 4: Create Train/Test Masks</span></span>
<span id="cb19-271"><a href="#cb19-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-272"><a href="#cb19-272" aria-hidden="true" tabindex="-1"></a>We'll use only a small subset of labeled nodes for training (semi-supervised learning) and test on the rest.</span>
<span id="cb19-273"><a href="#cb19-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-276"><a href="#cb19-276" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-277"><a href="#cb19-277" aria-hidden="true" tabindex="-1"></a><span class="co"># Create train/test masks</span></span>
<span id="cb19-278"><a href="#cb19-278" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll label only 4 nodes (2 from each community) for training</span></span>
<span id="cb19-279"><a href="#cb19-279" aria-hidden="true" tabindex="-1"></a>train_mask <span class="op">=</span> torch.zeros(n_nodes, dtype<span class="op">=</span>torch.<span class="bu">bool</span>)</span>
<span id="cb19-280"><a href="#cb19-280" aria-hidden="true" tabindex="-1"></a>test_mask <span class="op">=</span> torch.zeros(n_nodes, dtype<span class="op">=</span>torch.<span class="bu">bool</span>)</span>
<span id="cb19-281"><a href="#cb19-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-282"><a href="#cb19-282" aria-hidden="true" tabindex="-1"></a><span class="co"># Select 4 nodes from each class for training</span></span>
<span id="cb19-283"><a href="#cb19-283" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label <span class="kw">in</span> [<span class="dv">0</span>, <span class="dv">1</span>]:</span>
<span id="cb19-284"><a href="#cb19-284" aria-hidden="true" tabindex="-1"></a>    label_indices <span class="op">=</span> np.where(membership <span class="op">==</span> label)[<span class="dv">0</span>]</span>
<span id="cb19-285"><a href="#cb19-285" aria-hidden="true" tabindex="-1"></a>    train_indices <span class="op">=</span> np.random.choice(label_indices, size<span class="op">=</span><span class="dv">4</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-286"><a href="#cb19-286" aria-hidden="true" tabindex="-1"></a>    train_mask[train_indices] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb19-287"><a href="#cb19-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-288"><a href="#cb19-288" aria-hidden="true" tabindex="-1"></a><span class="co"># All other nodes are for testing</span></span>
<span id="cb19-289"><a href="#cb19-289" aria-hidden="true" tabindex="-1"></a>test_mask <span class="op">=</span> <span class="op">~</span>train_mask</span>
<span id="cb19-290"><a href="#cb19-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-291"><a href="#cb19-291" aria-hidden="true" tabindex="-1"></a>data.train_mask <span class="op">=</span> train_mask</span>
<span id="cb19-292"><a href="#cb19-292" aria-hidden="true" tabindex="-1"></a>data.test_mask <span class="op">=</span> test_mask</span>
<span id="cb19-293"><a href="#cb19-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-294"><a href="#cb19-294" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of training nodes: </span><span class="sc">{</span>train_mask<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-295"><a href="#cb19-295" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of test nodes: </span><span class="sc">{</span>test_mask<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-296"><a href="#cb19-296" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training node indices: </span><span class="sc">{</span>torch<span class="sc">.</span>where(train_mask)[<span class="dv">0</span>]<span class="sc">.</span>numpy()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-297"><a href="#cb19-297" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-298"><a href="#cb19-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-299"><a href="#cb19-299" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 5: Define the GNN Model</span></span>
<span id="cb19-300"><a href="#cb19-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-301"><a href="#cb19-301" aria-hidden="true" tabindex="-1"></a>We'll create a simple 2-layer Graph Convolutional Network (GCN).</span>
<span id="cb19-302"><a href="#cb19-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-303"><a href="#cb19-303" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb19-304"><a href="#cb19-304" aria-hidden="true" tabindex="-1"></a>**GCNConv**: PyTorch Geometric's implementation of Graph Convolutional Network layer from <span class="co">[</span><span class="ot">Kipf &amp; Welling (2017)</span><span class="co">](https://arxiv.org/abs/1609.02907)</span>. It performs neighborhood aggregation with symmetric normalization: $\mathbf{X}^{(l+1)} = \sigma(\mathbf{\hat{D}}^{-1/2}\mathbf{\hat{A}}\mathbf{\hat{D}}^{-1/2}\mathbf{X}^{(l)}\mathbf{W}^{(l)})$.</span>
<span id="cb19-305"><a href="#cb19-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-306"><a href="#cb19-306" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">GCNConv Documentation →</span><span class="co">](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html)</span></span>
<span id="cb19-307"><a href="#cb19-307" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb19-308"><a href="#cb19-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-311"><a href="#cb19-311" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-312"><a href="#cb19-312" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GCN(torch.nn.Module):</span>
<span id="cb19-313"><a href="#cb19-313" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_features, hidden_channels, num_classes):</span>
<span id="cb19-314"><a href="#cb19-314" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(GCN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb19-315"><a href="#cb19-315" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First GCN layer: input features -&gt; hidden dimension</span></span>
<span id="cb19-316"><a href="#cb19-316" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> GCNConv(num_features, hidden_channels)</span>
<span id="cb19-317"><a href="#cb19-317" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Second GCN layer: hidden dimension -&gt; output classes</span></span>
<span id="cb19-318"><a href="#cb19-318" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> GCNConv(hidden_channels, num_classes)</span>
<span id="cb19-319"><a href="#cb19-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-320"><a href="#cb19-320" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, edge_index):</span>
<span id="cb19-321"><a href="#cb19-321" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First layer with ReLU activation</span></span>
<span id="cb19-322"><a href="#cb19-322" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv1(x, edge_index)</span>
<span id="cb19-323"><a href="#cb19-323" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)</span>
<span id="cb19-324"><a href="#cb19-324" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.dropout(x, p<span class="op">=</span><span class="fl">0.5</span>, training<span class="op">=</span><span class="va">self</span>.training)</span>
<span id="cb19-325"><a href="#cb19-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-326"><a href="#cb19-326" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Second layer (no activation, we'll use softmax later)</span></span>
<span id="cb19-327"><a href="#cb19-327" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv2(x, edge_index)</span>
<span id="cb19-328"><a href="#cb19-328" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb19-329"><a href="#cb19-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-330"><a href="#cb19-330" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the model</span></span>
<span id="cb19-331"><a href="#cb19-331" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GCN(</span>
<span id="cb19-332"><a href="#cb19-332" aria-hidden="true" tabindex="-1"></a>    num_features<span class="op">=</span>data.num_node_features,</span>
<span id="cb19-333"><a href="#cb19-333" aria-hidden="true" tabindex="-1"></a>    hidden_channels<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb19-334"><a href="#cb19-334" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="dv">2</span></span>
<span id="cb19-335"><a href="#cb19-335" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-336"><a href="#cb19-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-337"><a href="#cb19-337" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model)</span>
<span id="cb19-338"><a href="#cb19-338" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Total parameters: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-339"><a href="#cb19-339" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-340"><a href="#cb19-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-341"><a href="#cb19-341" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb19-342"><a href="#cb19-342" aria-hidden="true" tabindex="-1"></a>**ReLU** (Rectified Linear Unit): Activation function $\text{ReLU}(x) = \max(0, x)$ that introduces non-linearity. It outputs the input if positive, otherwise zero. This allows the network to learn complex patterns.</span>
<span id="cb19-343"><a href="#cb19-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-344"><a href="#cb19-344" aria-hidden="true" tabindex="-1"></a>**Dropout**: Regularization technique that randomly sets a fraction of neurons to zero during training (here 50%). This prevents overfitting by forcing the network to learn robust features that don't rely on specific neurons.</span>
<span id="cb19-345"><a href="#cb19-345" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb19-346"><a href="#cb19-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-347"><a href="#cb19-347" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 6: Training Loop</span></span>
<span id="cb19-348"><a href="#cb19-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-349"><a href="#cb19-349" aria-hidden="true" tabindex="-1"></a>Now let's train the GNN model using gradient descent.</span>
<span id="cb19-350"><a href="#cb19-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-353"><a href="#cb19-353" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-354"><a href="#cb19-354" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up optimizer and loss function</span></span>
<span id="cb19-355"><a href="#cb19-355" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>, weight_decay<span class="op">=</span><span class="fl">5e-4</span>)</span>
<span id="cb19-356"><a href="#cb19-356" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb19-357"><a href="#cb19-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-358"><a href="#cb19-358" aria-hidden="true" tabindex="-1"></a><span class="co"># Training function</span></span>
<span id="cb19-359"><a href="#cb19-359" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train():</span>
<span id="cb19-360"><a href="#cb19-360" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb19-361"><a href="#cb19-361" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb19-362"><a href="#cb19-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-363"><a href="#cb19-363" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb19-364"><a href="#cb19-364" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> model(data.x, data.edge_index)</span>
<span id="cb19-365"><a href="#cb19-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-366"><a href="#cb19-366" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute loss only on training nodes</span></span>
<span id="cb19-367"><a href="#cb19-367" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(out[data.train_mask], data.y[data.train_mask])</span>
<span id="cb19-368"><a href="#cb19-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-369"><a href="#cb19-369" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Backward pass</span></span>
<span id="cb19-370"><a href="#cb19-370" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb19-371"><a href="#cb19-371" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb19-372"><a href="#cb19-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-373"><a href="#cb19-373" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss.item()</span>
<span id="cb19-374"><a href="#cb19-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-375"><a href="#cb19-375" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation function</span></span>
<span id="cb19-376"><a href="#cb19-376" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test():</span>
<span id="cb19-377"><a href="#cb19-377" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb19-378"><a href="#cb19-378" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-379"><a href="#cb19-379" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> model(data.x, data.edge_index)</span>
<span id="cb19-380"><a href="#cb19-380" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> out.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-381"><a href="#cb19-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-382"><a href="#cb19-382" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate accuracy on train and test sets</span></span>
<span id="cb19-383"><a href="#cb19-383" aria-hidden="true" tabindex="-1"></a>        train_correct <span class="op">=</span> pred[data.train_mask] <span class="op">==</span> data.y[data.train_mask]</span>
<span id="cb19-384"><a href="#cb19-384" aria-hidden="true" tabindex="-1"></a>        test_correct <span class="op">=</span> pred[data.test_mask] <span class="op">==</span> data.y[data.test_mask]</span>
<span id="cb19-385"><a href="#cb19-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-386"><a href="#cb19-386" aria-hidden="true" tabindex="-1"></a>        train_acc <span class="op">=</span> <span class="bu">int</span>(train_correct.<span class="bu">sum</span>()) <span class="op">/</span> <span class="bu">int</span>(data.train_mask.<span class="bu">sum</span>())</span>
<span id="cb19-387"><a href="#cb19-387" aria-hidden="true" tabindex="-1"></a>        test_acc <span class="op">=</span> <span class="bu">int</span>(test_correct.<span class="bu">sum</span>()) <span class="op">/</span> <span class="bu">int</span>(data.test_mask.<span class="bu">sum</span>())</span>
<span id="cb19-388"><a href="#cb19-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-389"><a href="#cb19-389" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_acc, test_acc</span>
<span id="cb19-390"><a href="#cb19-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-391"><a href="#cb19-391" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb19-392"><a href="#cb19-392" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> []</span>
<span id="cb19-393"><a href="#cb19-393" aria-hidden="true" tabindex="-1"></a>train_accs <span class="op">=</span> []</span>
<span id="cb19-394"><a href="#cb19-394" aria-hidden="true" tabindex="-1"></a>test_accs <span class="op">=</span> []</span>
<span id="cb19-395"><a href="#cb19-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-396"><a href="#cb19-396" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb19-397"><a href="#cb19-397" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> train()</span>
<span id="cb19-398"><a href="#cb19-398" aria-hidden="true" tabindex="-1"></a>    train_acc, test_acc <span class="op">=</span> test()</span>
<span id="cb19-399"><a href="#cb19-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-400"><a href="#cb19-400" aria-hidden="true" tabindex="-1"></a>    losses.append(loss)</span>
<span id="cb19-401"><a href="#cb19-401" aria-hidden="true" tabindex="-1"></a>    train_accs.append(train_acc)</span>
<span id="cb19-402"><a href="#cb19-402" aria-hidden="true" tabindex="-1"></a>    test_accs.append(test_acc)</span>
<span id="cb19-403"><a href="#cb19-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-404"><a href="#cb19-404" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">20</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb19-405"><a href="#cb19-405" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:03d}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">:.4f}</span><span class="ss">, '</span></span>
<span id="cb19-406"><a href="#cb19-406" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f'Train Acc: </span><span class="sc">{</span>train_acc<span class="sc">:.4f}</span><span class="ss">, Test Acc: </span><span class="sc">{</span>test_acc<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb19-407"><a href="#cb19-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-408"><a href="#cb19-408" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Final Test Accuracy: </span><span class="sc">{</span>test_accs[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb19-409"><a href="#cb19-409" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-410"><a href="#cb19-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-411"><a href="#cb19-411" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 7: Visualize Training Progress</span></span>
<span id="cb19-412"><a href="#cb19-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-413"><a href="#cb19-413" aria-hidden="true" tabindex="-1"></a>Let's visualize how the model learned over time.</span>
<span id="cb19-414"><a href="#cb19-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-417"><a href="#cb19-417" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-418"><a href="#cb19-418" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb19-419"><a href="#cb19-419" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb19-420"><a href="#cb19-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-421"><a href="#cb19-421" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot loss</span></span>
<span id="cb19-422"><a href="#cb19-422" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(losses)</span>
<span id="cb19-423"><a href="#cb19-423" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb19-424"><a href="#cb19-424" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb19-425"><a href="#cb19-425" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Training Loss'</span>)</span>
<span id="cb19-426"><a href="#cb19-426" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-427"><a href="#cb19-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-428"><a href="#cb19-428" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot accuracy</span></span>
<span id="cb19-429"><a href="#cb19-429" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(train_accs, label<span class="op">=</span><span class="st">'Train'</span>)</span>
<span id="cb19-430"><a href="#cb19-430" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(test_accs, label<span class="op">=</span><span class="st">'Test'</span>)</span>
<span id="cb19-431"><a href="#cb19-431" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb19-432"><a href="#cb19-432" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb19-433"><a href="#cb19-433" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Train vs Test Accuracy'</span>)</span>
<span id="cb19-434"><a href="#cb19-434" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb19-435"><a href="#cb19-435" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-436"><a href="#cb19-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-437"><a href="#cb19-437" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-438"><a href="#cb19-438" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-439"><a href="#cb19-439" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-440"><a href="#cb19-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-441"><a href="#cb19-441" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 8: Visualize Predictions</span></span>
<span id="cb19-442"><a href="#cb19-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-443"><a href="#cb19-443" aria-hidden="true" tabindex="-1"></a>Finally, let's visualize the network with true labels, training nodes, and predictions.</span>
<span id="cb19-444"><a href="#cb19-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-447"><a href="#cb19-447" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-448"><a href="#cb19-448" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb19-449"><a href="#cb19-449" aria-hidden="true" tabindex="-1"></a><span class="co"># Get final predictions</span></span>
<span id="cb19-450"><a href="#cb19-450" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb19-451"><a href="#cb19-451" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-452"><a href="#cb19-452" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> model(data.x, data.edge_index)</span>
<span id="cb19-453"><a href="#cb19-453" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> out.argmax(dim<span class="op">=</span><span class="dv">1</span>).numpy()</span>
<span id="cb19-454"><a href="#cb19-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-455"><a href="#cb19-455" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb19-456"><a href="#cb19-456" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb19-457"><a href="#cb19-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-458"><a href="#cb19-458" aria-hidden="true" tabindex="-1"></a><span class="co"># Define colors</span></span>
<span id="cb19-459"><a href="#cb19-459" aria-hidden="true" tabindex="-1"></a>colors_true <span class="op">=</span> [<span class="st">'#FF6B6B'</span>, <span class="st">'#4ECDC4'</span>]  <span class="co"># Red and Teal</span></span>
<span id="cb19-460"><a href="#cb19-460" aria-hidden="true" tabindex="-1"></a>colors_pred <span class="op">=</span> [<span class="st">'#FF6B6B'</span>, <span class="st">'#4ECDC4'</span>]</span>
<span id="cb19-461"><a href="#cb19-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-462"><a href="#cb19-462" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: True labels with training nodes highlighted</span></span>
<span id="cb19-463"><a href="#cb19-463" aria-hidden="true" tabindex="-1"></a>vertex_colors_true <span class="op">=</span> [colors_true[label] <span class="cf">for</span> label <span class="kw">in</span> membership]</span>
<span id="cb19-464"><a href="#cb19-464" aria-hidden="true" tabindex="-1"></a>vertex_shapes <span class="op">=</span> [<span class="st">'circle'</span> <span class="cf">if</span> <span class="kw">not</span> train_mask[i] <span class="cf">else</span> <span class="st">'square'</span></span>
<span id="cb19-465"><a href="#cb19-465" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes)]</span>
<span id="cb19-466"><a href="#cb19-466" aria-hidden="true" tabindex="-1"></a>vertex_sizes <span class="op">=</span> [<span class="dv">15</span> <span class="cf">if</span> <span class="kw">not</span> train_mask[i] <span class="cf">else</span> <span class="dv">25</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_nodes)]</span>
<span id="cb19-467"><a href="#cb19-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-468"><a href="#cb19-468" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> ig.Graph.Famous(<span class="st">"Zachary"</span>)</span>
<span id="cb19-469"><a href="#cb19-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-470"><a href="#cb19-470" aria-hidden="true" tabindex="-1"></a>ig.plot(</span>
<span id="cb19-471"><a href="#cb19-471" aria-hidden="true" tabindex="-1"></a>    G,</span>
<span id="cb19-472"><a href="#cb19-472" aria-hidden="true" tabindex="-1"></a>    vertex_color<span class="op">=</span>vertex_colors_true,</span>
<span id="cb19-473"><a href="#cb19-473" aria-hidden="true" tabindex="-1"></a>    vertex_shape<span class="op">=</span>vertex_shapes,</span>
<span id="cb19-474"><a href="#cb19-474" aria-hidden="true" tabindex="-1"></a>    vertex_size<span class="op">=</span>vertex_sizes,</span>
<span id="cb19-475"><a href="#cb19-475" aria-hidden="true" tabindex="-1"></a>    bbox<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">500</span>, <span class="dv">500</span>),</span>
<span id="cb19-476"><a href="#cb19-476" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span>axes[<span class="dv">0</span>]</span>
<span id="cb19-477"><a href="#cb19-477" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-478"><a href="#cb19-478" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"True Labels</span><span class="ch">\n</span><span class="st">(Squares = Training Nodes)"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb19-479"><a href="#cb19-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-480"><a href="#cb19-480" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: Predicted labels</span></span>
<span id="cb19-481"><a href="#cb19-481" aria-hidden="true" tabindex="-1"></a>vertex_colors_pred <span class="op">=</span> [colors_pred[pred] <span class="cf">for</span> pred <span class="kw">in</span> predictions]</span>
<span id="cb19-482"><a href="#cb19-482" aria-hidden="true" tabindex="-1"></a>ig.plot(</span>
<span id="cb19-483"><a href="#cb19-483" aria-hidden="true" tabindex="-1"></a>    G,</span>
<span id="cb19-484"><a href="#cb19-484" aria-hidden="true" tabindex="-1"></a>    vertex_color<span class="op">=</span>vertex_colors_pred,</span>
<span id="cb19-485"><a href="#cb19-485" aria-hidden="true" tabindex="-1"></a>    vertex_size<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb19-486"><a href="#cb19-486" aria-hidden="true" tabindex="-1"></a>    bbox<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">500</span>, <span class="dv">500</span>),</span>
<span id="cb19-487"><a href="#cb19-487" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span>axes[<span class="dv">1</span>]</span>
<span id="cb19-488"><a href="#cb19-488" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-489"><a href="#cb19-489" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"Predicted Labels"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb19-490"><a href="#cb19-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-491"><a href="#cb19-491" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-492"><a href="#cb19-492" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-493"><a href="#cb19-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-494"><a href="#cb19-494" aria-hidden="true" tabindex="-1"></a><span class="co"># Print misclassified nodes</span></span>
<span id="cb19-495"><a href="#cb19-495" aria-hidden="true" tabindex="-1"></a>misclassified <span class="op">=</span> np.where(predictions <span class="op">!=</span> membership)[<span class="dv">0</span>]</span>
<span id="cb19-496"><a href="#cb19-496" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Misclassified nodes: </span><span class="sc">{</span>misclassified<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-497"><a href="#cb19-497" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of misclassified nodes: </span><span class="sc">{</span><span class="bu">len</span>(misclassified)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-498"><a href="#cb19-498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-499"><a href="#cb19-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-500"><a href="#cb19-500" aria-hidden="true" tabindex="-1"></a><span class="fu">### Understanding What We Did</span></span>
<span id="cb19-501"><a href="#cb19-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-502"><a href="#cb19-502" aria-hidden="true" tabindex="-1"></a>**Data Preparation**: We used eigenvectors of the normalized Laplacian as node features. These features capture the structural position of each node in the network.</span>
<span id="cb19-503"><a href="#cb19-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-504"><a href="#cb19-504" aria-hidden="true" tabindex="-1"></a>**Semi-Supervised Learning**: We trained on only 4 labeled nodes (2 from each community) and predicted labels for the remaining 30 nodes. This demonstrates the power of GNNs to propagate information through the network structure.</span>
<span id="cb19-505"><a href="#cb19-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-506"><a href="#cb19-506" aria-hidden="true" tabindex="-1"></a>**GCN Architecture**: Our 2-layer GCN works as follows:</span>
<span id="cb19-507"><a href="#cb19-507" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Layer 1**: Aggregates features from neighbors and transforms them to a hidden representation</span>
<span id="cb19-508"><a href="#cb19-508" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Layer 2**: Aggregates hidden representations and outputs class probabilities</span>
<span id="cb19-509"><a href="#cb19-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-510"><a href="#cb19-510" aria-hidden="true" tabindex="-1"></a>**Message Passing**: Each GCN layer performs: $\mathbf{h}_i^{(l+1)} = \sigma\left(\sum_{j \in \mathcal{N}(i)} \frac{1}{\sqrt{d_i d_j}} \mathbf{W}^{(l)} \mathbf{h}_j^{(l)}\right)$</span>
<span id="cb19-511"><a href="#cb19-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-512"><a href="#cb19-512" aria-hidden="true" tabindex="-1"></a>where neighbors influence each node's representation, allowing label information to propagate through the network.</span>
<span id="cb19-513"><a href="#cb19-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-514"><a href="#cb19-514" aria-hidden="true" tabindex="-1"></a>**Training**: We optimized the model using cross-entropy loss on the small set of labeled nodes, but the loss gradients propagate through the entire network structure, allowing all nodes to contribute to learning.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024, Sadamori Kojaku</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions"><ul><li><a href="https://github.com/skojaku/adv-net-sci/edit/main/m09-graph-neural-networks/02-coding.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/skojaku/adv-net-sci/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/skojaku/adv-net-sci">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>